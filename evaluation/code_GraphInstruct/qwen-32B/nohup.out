INFO 04-04 09:38:18 config.py:510] This model supports multiple tasks: {'classify', 'generate', 'embed', 'reward', 'score'}. Defaulting to 'generate'.
INFO 04-04 09:38:18 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-04 09:38:18 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-04 09:38:18 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-04 09:38:18 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-04 09:38:19 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-04 09:38:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-04 09:38:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-04 09:38:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:21 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-04 09:38:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2027050)[0;0m WARNING 04-04 09:38:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-04 09:38:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2027051)[0;0m WARNING 04-04 09:38:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2027052)[0;0m WARNING 04-04 09:38:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-04 09:38:21 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_f6c7e2ea'), local_subscribe_port=57593, remote_subscribe_port=None)
INFO 04-04 09:38:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.52it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.65it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.10it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.92it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.84it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:03<00:04,  1.81it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.76it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.74it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.72it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.72it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.84it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:07<00:00,  1.80it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.77it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.84it/s]

[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:30 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-04 09:38:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:32 worker.py:241] Memory profiling takes 2.59 seconds
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:32 worker.py:241] Memory profiling takes 2.59 seconds
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-04 09:38:33 worker.py:241] Memory profiling takes 2.75 seconds
INFO 04-04 09:38:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-04 09:38:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:33 worker.py:241] Memory profiling takes 2.77 seconds
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
INFO 04-04 09:38:33 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-04 09:38:33 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:38:47 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-04 09:38:47 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:38:47 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:38:47 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<02:07,  1.02it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:10,  1.02s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:12,  1.03s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:11,  1.04s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:10,  1.04s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:10,  1.04s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:08,  1.04s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:05,  1.02s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<02:03,  1.01s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<02:03,  1.02s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:11<02:00,  1.01s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:12<01:59,  1.01s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:13<01:58,  1.00s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:14<01:58,  1.01s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:15<01:56,  1.01s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:16<01:55,  1.00s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:17<01:53,  1.01it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:18<01:50,  1.03it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:19<01:49,  1.02it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:20<01:48,  1.02it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:21<01:47,  1.02it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:22<01:45,  1.03it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:23<01:45,  1.03it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:24<01:54,  1.07s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:25<02:08,  1.22s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:27<02:07,  1.21s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:28<02:03,  1.19s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:29<02:00,  1.17s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:30<01:57,  1.16s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:31<01:55,  1.15s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:32<01:51,  1.12s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:33<01:50,  1.12s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:34<01:49,  1.12s/it]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:36<01:50,  1.14s/it]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:37<01:49,  1.15s/it]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:38<01:47,  1.13s/it]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:39<01:48,  1.15s/it]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:40<01:46,  1.15s/it]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:41<01:46,  1.15s/it]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:42<01:44,  1.15s/it]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:44<01:41,  1.12s/it]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:45<01:38,  1.11s/it]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:46<01:38,  1.12s/it]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:47<01:38,  1.13s/it]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:48<01:35,  1.11s/it]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:49<01:34,  1.11s/it]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:50<01:32,  1.10s/it]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:51<01:31,  1.11s/it]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:52<01:29,  1.09s/it]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:53<01:27,  1.08s/it]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:54<01:25,  1.07s/it]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:56<01:25,  1.09s/it]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:57<01:26,  1.11s/it]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:58<01:24,  1.09s/it]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:59<01:23,  1.10s/it]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [01:00<01:22,  1.10s/it]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [01:01<01:19,  1.08s/it]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [01:02<01:18,  1.08s/it]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [01:03<01:17,  1.07s/it]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [01:04<01:16,  1.08s/it]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:05<01:15,  1.08s/it]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:06<01:15,  1.09s/it]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:08<01:14,  1.09s/it]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:09<01:12,  1.08s/it]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:10<01:10,  1.08s/it]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:11<01:08,  1.06s/it]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:12<01:07,  1.05s/it]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:13<01:05,  1.04s/it]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:14<01:03,  1.02s/it]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:15<01:02,  1.02s/it]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:16<01:00,  1.00s/it]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:17<00:58,  1.00it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:18<00:58,  1.01s/it]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:19<00:56,  1.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:20<00:54,  1.02it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:21<00:53,  1.03it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:22<00:53,  1.01it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:23<00:53,  1.00s/it]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:24<00:51,  1.01it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:25<00:49,  1.02it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:25<00:47,  1.04it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:26<00:46,  1.04it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:27<00:45,  1.05it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:28<00:45,  1.03it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:29<00:43,  1.06it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:30<00:42,  1.05it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:31<00:40,  1.08it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:32<00:40,  1.06it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:33<00:39,  1.07it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:34<00:37,  1.09it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:35<00:36,  1.09it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:36<00:35,  1.09it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:37<00:34,  1.09it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:37<00:33,  1.10it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:38<00:32,  1.10it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:39<00:31,  1.11it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:40<00:30,  1.11it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:41<00:30,  1.10it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:42<00:28,  1.11it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:43<00:28,  1.10it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:44<00:26,  1.13it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:45<00:25,  1.13it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:45<00:24,  1.15it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:46<00:23,  1.15it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:47<00:22,  1.15it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:48<00:21,  1.16it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:49<00:21,  1.14it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:50<00:20,  1.13it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:51<00:19,  1.15it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:52<00:18,  1.14it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:52<00:17,  1.16it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:53<00:16,  1.17it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:54<00:15,  1.19it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:55<00:14,  1.18it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:56<00:13,  1.20it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:57<00:12,  1.21it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:57<00:11,  1.21it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:58<00:10,  1.22it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:59<00:09,  1.21it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [02:00<00:09,  1.19it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [02:01<00:08,  1.21it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [02:01<00:07,  1.21it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [02:02<00:06,  1.23it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [02:03<00:05,  1.21it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [02:04<00:04,  1.24it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [02:05<00:04,  1.23it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [02:05<00:03,  1.25it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [02:06<00:02,  1.26it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [02:07<00:01,  1.24it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [02:08<00:00,  1.26it/s][1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 09:40:56 model_runner.py:1535] Graph capturing finished in 130 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:09<00:00,  1.11it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:09<00:00,  1.01it/s]
INFO 04-04 09:40:56 model_runner.py:1535] Graph capturing finished in 130 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 09:40:56 model_runner.py:1535] Graph capturing finished in 130 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 09:40:57 model_runner.py:1535] Graph capturing finished in 130 secs, took 8.20 GiB
INFO 04-04 09:40:57 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 146.82 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: cycle
Generating answers for task: cycle
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-04 09:41:59 scheduler.py:1555] Sequence group 278 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-04 09:42:22 scheduler.py:1555] Sequence group 228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
Processed prompts:   0%|          | 1/500 [01:50<15:18:19, 110.42s/it, est. speed input: 1.87 toks/s, output: 4.26 toks/s]WARNING 04-04 09:42:58 scheduler.py:1555] Sequence group 178 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   0%|          | 2/500 [02:09<7:52:24, 56.92s/it, est. speed input: 3.10 toks/s, output: 8.52 toks/s]  Processed prompts:   1%|          | 3/500 [02:13<4:28:19, 32.39s/it, est. speed input: 6.26 toks/s, output: 13.42 toks/s]Processed prompts:   1%|          | 4/500 [02:18<2:59:05, 21.67s/it, est. speed input: 7.61 toks/s, output: 17.93 toks/s]Processed prompts:   1%|          | 5/500 [02:22<2:06:54, 15.38s/it, est. speed input: 8.96 toks/s, output: 22.90 toks/s]Processed prompts:   1%|          | 6/500 [02:23<1:27:24, 10.62s/it, est. speed input: 10.44 toks/s, output: 28.07 toks/s]Processed prompts:   1%|▏         | 7/500 [02:24<1:00:41,  7.39s/it, est. speed input: 12.52 toks/s, output: 33.23 toks/s]Processed prompts:   2%|▏         | 8/500 [02:24<42:06,  5.13s/it, est. speed input: 18.29 toks/s, output: 38.75 toks/s]  Processed prompts:   2%|▏         | 9/500 [02:27<35:50,  4.38s/it, est. speed input: 19.48 toks/s, output: 43.46 toks/s]Processed prompts:   2%|▏         | 10/500 [02:28<26:02,  3.19s/it, est. speed input: 25.03 toks/s, output: 49.00 toks/s]Processed prompts:   2%|▏         | 11/500 [02:29<20:23,  2.50s/it, est. speed input: 26.34 toks/s, output: 54.12 toks/s]Processed prompts:   2%|▏         | 12/500 [02:30<17:13,  2.12s/it, est. speed input: 27.58 toks/s, output: 59.41 toks/s]Processed prompts:   3%|▎         | 13/500 [02:32<18:19,  2.26s/it, est. speed input: 28.55 toks/s, output: 63.98 toks/s]Processed prompts:   3%|▎         | 14/500 [02:34<15:16,  1.89s/it, est. speed input: 30.36 toks/s, output: 69.19 toks/s]Processed prompts:   3%|▎         | 15/500 [02:35<13:54,  1.72s/it, est. speed input: 31.67 toks/s, output: 74.23 toks/s]Processed prompts:   3%|▎         | 16/500 [02:38<16:58,  2.11s/it, est. speed input: 32.56 toks/s, output: 78.69 toks/s]Processed prompts:   3%|▎         | 17/500 [02:39<14:07,  1.75s/it, est. speed input: 35.64 toks/s, output: 84.04 toks/s]Processed prompts:   4%|▎         | 18/500 [02:40<13:53,  1.73s/it, est. speed input: 36.97 toks/s, output: 89.13 toks/s]Processed prompts:   4%|▍         | 19/500 [02:42<12:57,  1.62s/it, est. speed input: 40.47 toks/s, output: 94.20 toks/s]Processed prompts:   4%|▍         | 20/500 [02:45<17:29,  2.19s/it, est. speed input: 41.37 toks/s, output: 98.30 toks/s]Processed prompts:   4%|▍         | 21/500 [02:48<18:47,  2.35s/it, est. speed input: 42.14 toks/s, output: 102.64 toks/s]Processed prompts:   4%|▍         | 22/500 [02:51<20:31,  2.58s/it, est. speed input: 44.59 toks/s, output: 106.94 toks/s]Processed prompts:   5%|▍         | 23/500 [02:51<14:46,  1.86s/it, est. speed input: 45.85 toks/s, output: 112.98 toks/s]Processed prompts:   5%|▍         | 24/500 [02:56<21:26,  2.70s/it, est. speed input: 46.60 toks/s, output: 116.32 toks/s]Processed prompts:   5%|▌         | 25/500 [02:56<15:36,  1.97s/it, est. speed input: 47.77 toks/s, output: 122.30 toks/s]Processed prompts:   5%|▌         | 26/500 [02:58<14:41,  1.86s/it, est. speed input: 50.86 toks/s, output: 127.52 toks/s]Processed prompts:   6%|▌         | 28/500 [02:59<09:15,  1.18s/it, est. speed input: 54.97 toks/s, output: 139.51 toks/s]Processed prompts:   6%|▌         | 29/500 [03:01<11:15,  1.43s/it, est. speed input: 63.04 toks/s, output: 144.30 toks/s]Processed prompts:   6%|▌         | 30/500 [03:05<16:27,  2.10s/it, est. speed input: 65.56 toks/s, output: 147.75 toks/s]Processed prompts:   6%|▌         | 31/500 [03:08<19:01,  2.43s/it, est. speed input: 66.21 toks/s, output: 151.79 toks/s]Processed prompts:   6%|▋         | 32/500 [03:08<14:14,  1.83s/it, est. speed input: 67.69 toks/s, output: 158.11 toks/s]Processed prompts:   7%|▋         | 33/500 [03:09<10:43,  1.38s/it, est. speed input: 69.16 toks/s, output: 164.59 toks/s]Processed prompts:   7%|▋         | 34/500 [03:10<10:16,  1.32s/it, est. speed input: 70.16 toks/s, output: 170.18 toks/s]Processed prompts:   7%|▋         | 35/500 [03:12<11:11,  1.44s/it, est. speed input: 73.30 toks/s, output: 175.38 toks/s]Processed prompts:   7%|▋         | 36/500 [03:13<10:03,  1.30s/it, est. speed input: 75.25 toks/s, output: 181.28 toks/s]Processed prompts:   7%|▋         | 37/500 [03:13<08:14,  1.07s/it, est. speed input: 78.06 toks/s, output: 187.42 toks/s]Processed prompts:   8%|▊         | 38/500 [03:14<08:17,  1.08s/it, est. speed input: 82.48 toks/s, output: 193.13 toks/s]Processed prompts:   8%|▊         | 39/500 [03:15<08:33,  1.11s/it, est. speed input: 83.62 toks/s, output: 198.80 toks/s]Processed prompts:   8%|▊         | 40/500 [03:17<09:30,  1.24s/it, est. speed input: 85.14 toks/s, output: 204.17 toks/s]Processed prompts:   8%|▊         | 41/500 [03:18<09:00,  1.18s/it, est. speed input: 86.01 toks/s, output: 209.99 toks/s]Processed prompts:   8%|▊         | 42/500 [03:21<13:06,  1.72s/it, est. speed input: 86.09 toks/s, output: 213.84 toks/s]Processed prompts:   9%|▊         | 43/500 [03:23<13:14,  1.74s/it, est. speed input: 88.17 toks/s, output: 218.80 toks/s]Processed prompts:   9%|▉         | 44/500 [03:24<11:23,  1.50s/it, est. speed input: 94.99 toks/s, output: 224.66 toks/s]Processed prompts:   9%|▉         | 45/500 [03:25<11:09,  1.47s/it, est. speed input: 98.77 toks/s, output: 229.93 toks/s]Processed prompts:   9%|▉         | 46/500 [03:25<08:26,  1.12s/it, est. speed input: 99.70 toks/s, output: 236.61 toks/s]Processed prompts:   9%|▉         | 47/500 [03:26<07:26,  1.02it/s, est. speed input: 101.65 toks/s, output: 242.86 toks/s]Processed prompts:  10%|▉         | 48/500 [03:27<06:19,  1.19it/s, est. speed input: 102.55 toks/s, output: 249.33 toks/s]Processed prompts:  10%|▉         | 49/500 [03:27<06:22,  1.18it/s, est. speed input: 104.85 toks/s, output: 255.39 toks/s]Processed prompts:  10%|█         | 50/500 [03:30<10:28,  1.40s/it, est. speed input: 105.38 toks/s, output: 259.28 toks/s]Processed prompts:  10%|█         | 52/500 [03:32<08:18,  1.11s/it, est. speed input: 106.70 toks/s, output: 271.47 toks/s]Processed prompts:  11%|█         | 53/500 [03:32<07:09,  1.04it/s, est. speed input: 116.10 toks/s, output: 277.95 toks/s]Processed prompts:  11%|█         | 54/500 [03:32<05:45,  1.29it/s, est. speed input: 118.90 toks/s, output: 282.64 toks/s]Processed prompts:  11%|█         | 55/500 [03:37<14:25,  1.95s/it, est. speed input: 122.62 toks/s, output: 283.30 toks/s]Processed prompts:  11%|█         | 56/500 [03:38<11:55,  1.61s/it, est. speed input: 123.28 toks/s, output: 289.59 toks/s]Processed prompts:  11%|█▏        | 57/500 [03:40<11:55,  1.62s/it, est. speed input: 123.42 toks/s, output: 294.78 toks/s]Processed prompts:  12%|█▏        | 58/500 [03:40<09:20,  1.27s/it, est. speed input: 126.69 toks/s, output: 301.47 toks/s]Processed prompts:  12%|█▏        | 59/500 [03:40<07:01,  1.05it/s, est. speed input: 127.63 toks/s, output: 308.48 toks/s]Processed prompts:  12%|█▏        | 60/500 [03:42<07:46,  1.06s/it, est. speed input: 129.21 toks/s, output: 314.11 toks/s]Processed prompts:  12%|█▏        | 61/500 [03:42<06:43,  1.09it/s, est. speed input: 130.70 toks/s, output: 320.71 toks/s]Processed prompts:  12%|█▏        | 62/500 [03:43<06:17,  1.16it/s, est. speed input: 140.88 toks/s, output: 327.04 toks/s]Processed prompts:  13%|█▎        | 63/500 [03:43<04:55,  1.48it/s, est. speed input: 142.00 toks/s, output: 334.11 toks/s]Processed prompts:  13%|█▎        | 64/500 [03:47<12:16,  1.69s/it, est. speed input: 141.55 toks/s, output: 335.69 toks/s]Processed prompts:  13%|█▎        | 65/500 [03:48<10:00,  1.38s/it, est. speed input: 144.49 toks/s, output: 339.44 toks/s]Processed prompts:  13%|█▎        | 66/500 [03:51<13:05,  1.81s/it, est. speed input: 143.78 toks/s, output: 342.86 toks/s]Processed prompts:  13%|█▎        | 67/500 [03:54<16:04,  2.23s/it, est. speed input: 146.67 toks/s, output: 342.66 toks/s]Processed prompts:  14%|█▎        | 68/500 [03:54<11:45,  1.63s/it, est. speed input: 147.68 toks/s, output: 349.92 toks/s]Processed prompts:  14%|█▍        | 69/500 [03:56<11:06,  1.55s/it, est. speed input: 149.96 toks/s, output: 355.61 toks/s]Processed prompts:  14%|█▍        | 70/500 [04:02<21:26,  2.99s/it, est. speed input: 148.66 toks/s, output: 354.00 toks/s]Processed prompts:  14%|█▍        | 71/500 [04:03<18:06,  2.53s/it, est. speed input: 152.98 toks/s, output: 359.54 toks/s]Processed prompts:  14%|█▍        | 72/500 [04:08<21:24,  3.00s/it, est. speed input: 153.28 toks/s, output: 361.02 toks/s]WARNING 04-04 09:45:09 scheduler.py:1555] Sequence group 149 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:  15%|█▍        | 73/500 [04:12<25:09,  3.53s/it, est. speed input: 157.86 toks/s, output: 362.20 toks/s]Processed prompts:  15%|█▍        | 74/500 [04:16<24:30,  3.45s/it, est. speed input: 159.25 toks/s, output: 365.56 toks/s]Processed prompts:  15%|█▌        | 75/500 [04:18<21:54,  3.09s/it, est. speed input: 159.08 toks/s, output: 370.42 toks/s]Processed prompts:  15%|█▌        | 76/500 [04:19<18:31,  2.62s/it, est. speed input: 159.96 toks/s, output: 376.22 toks/s]Processed prompts:  15%|█▌        | 77/500 [04:20<13:21,  1.89s/it, est. speed input: 168.74 toks/s, output: 382.43 toks/s]Processed prompts:  16%|█▌        | 78/500 [04:22<13:42,  1.95s/it, est. speed input: 168.87 toks/s, output: 387.38 toks/s]Processed prompts:  16%|█▌        | 79/500 [04:25<15:47,  2.25s/it, est. speed input: 174.76 toks/s, output: 391.08 toks/s]Processed prompts:  16%|█▌        | 80/500 [04:25<11:25,  1.63s/it, est. speed input: 177.18 toks/s, output: 398.90 toks/s]Processed prompts:  16%|█▌        | 81/500 [04:27<12:06,  1.73s/it, est. speed input: 177.85 toks/s, output: 404.09 toks/s]Processed prompts:  16%|█▋        | 82/500 [04:28<10:18,  1.48s/it, est. speed input: 180.70 toks/s, output: 409.81 toks/s]Processed prompts:  17%|█▋        | 83/500 [04:29<09:48,  1.41s/it, est. speed input: 182.11 toks/s, output: 415.99 toks/s]Processed prompts:  17%|█▋        | 84/500 [04:30<09:48,  1.41s/it, est. speed input: 187.02 toks/s, output: 421.93 toks/s]Processed prompts:  17%|█▋        | 85/500 [04:32<09:37,  1.39s/it, est. speed input: 195.33 toks/s, output: 428.03 toks/s]Processed prompts:  17%|█▋        | 86/500 [04:35<14:10,  2.05s/it, est. speed input: 195.21 toks/s, output: 426.86 toks/s]Processed prompts:  17%|█▋        | 87/500 [04:40<19:00,  2.76s/it, est. speed input: 194.74 toks/s, output: 426.04 toks/s]Processed prompts:  18%|█▊        | 88/500 [04:52<38:10,  5.56s/it, est. speed input: 189.50 toks/s, output: 416.85 toks/s]Processed prompts:  18%|█▊        | 89/500 [04:52<26:52,  3.92s/it, est. speed input: 196.56 toks/s, output: 425.25 toks/s]Processed prompts:  18%|█▊        | 90/500 [04:54<22:08,  3.24s/it, est. speed input: 197.56 toks/s, output: 431.30 toks/s]Processed prompts:  18%|█▊        | 91/500 [04:55<17:33,  2.58s/it, est. speed input: 199.85 toks/s, output: 433.68 toks/s]Processed prompts:  18%|█▊        | 92/500 [04:56<15:12,  2.24s/it, est. speed input: 200.57 toks/s, output: 440.05 toks/s]Processed prompts:  19%|█▊        | 93/500 [04:58<14:23,  2.12s/it, est. speed input: 200.76 toks/s, output: 445.89 toks/s]Processed prompts:  19%|█▉        | 94/500 [05:02<18:23,  2.72s/it, est. speed input: 200.10 toks/s, output: 448.53 toks/s]Processed prompts:  19%|█▉        | 95/500 [05:03<13:57,  2.07s/it, est. speed input: 200.76 toks/s, output: 456.37 toks/s]Processed prompts:  19%|█▉        | 96/500 [05:05<13:54,  2.07s/it, est. speed input: 203.27 toks/s, output: 462.01 toks/s]Processed prompts:  19%|█▉        | 97/500 [05:05<10:47,  1.61s/it, est. speed input: 204.39 toks/s, output: 468.20 toks/s]Processed prompts:  20%|█▉        | 98/500 [05:06<08:29,  1.27s/it, est. speed input: 206.31 toks/s, output: 476.07 toks/s]Processed prompts:  20%|█▉        | 99/500 [05:08<11:06,  1.66s/it, est. speed input: 208.09 toks/s, output: 474.14 toks/s]Processed prompts:  20%|██        | 100/500 [05:10<11:43,  1.76s/it, est. speed input: 207.83 toks/s, output: 479.88 toks/s]Processed prompts:  20%|██        | 101/500 [05:13<13:24,  2.02s/it, est. speed input: 209.83 toks/s, output: 484.68 toks/s]Processed prompts:  20%|██        | 102/500 [05:15<14:19,  2.16s/it, est. speed input: 209.75 toks/s, output: 489.70 toks/s]Processed prompts:  21%|██        | 103/500 [05:17<14:19,  2.16s/it, est. speed input: 209.60 toks/s, output: 492.33 toks/s]Processed prompts:  21%|██        | 104/500 [05:19<12:39,  1.92s/it, est. speed input: 210.05 toks/s, output: 499.13 toks/s]Processed prompts:  21%|██        | 105/500 [05:19<09:34,  1.45s/it, est. speed input: 216.62 toks/s, output: 507.41 toks/s]Processed prompts:  21%|██        | 106/500 [05:21<10:32,  1.61s/it, est. speed input: 216.81 toks/s, output: 513.11 toks/s]Processed prompts:  21%|██▏       | 107/500 [05:25<15:39,  2.39s/it, est. speed input: 216.20 toks/s, output: 515.33 toks/s]Processed prompts:  22%|██▏       | 108/500 [05:26<11:37,  1.78s/it, est. speed input: 217.56 toks/s, output: 523.73 toks/s]Processed prompts:  22%|██▏       | 109/500 [05:27<11:07,  1.71s/it, est. speed input: 218.78 toks/s, output: 530.11 toks/s]Processed prompts:  22%|██▏       | 110/500 [05:29<11:49,  1.82s/it, est. speed input: 219.39 toks/s, output: 528.80 toks/s]Processed prompts:  22%|██▏       | 111/500 [05:31<11:50,  1.83s/it, est. speed input: 219.30 toks/s, output: 534.82 toks/s]Processed prompts:  22%|██▏       | 112/500 [05:32<09:49,  1.52s/it, est. speed input: 220.63 toks/s, output: 538.71 toks/s]Processed prompts:  23%|██▎       | 113/500 [05:35<13:41,  2.12s/it, est. speed input: 220.03 toks/s, output: 541.99 toks/s]Processed prompts:  23%|██▎       | 115/500 [05:36<08:22,  1.31s/it, est. speed input: 224.95 toks/s, output: 558.78 toks/s]Processed prompts:  23%|██▎       | 116/500 [05:44<19:06,  2.99s/it, est. speed input: 223.20 toks/s, output: 554.69 toks/s]Processed prompts:  23%|██▎       | 117/500 [05:45<15:18,  2.40s/it, est. speed input: 223.43 toks/s, output: 559.76 toks/s]Processed prompts:  24%|██▎       | 118/500 [05:51<21:33,  3.39s/it, est. speed input: 222.86 toks/s, output: 553.60 toks/s]Processed prompts:  24%|██▍       | 119/500 [05:51<16:11,  2.55s/it, est. speed input: 225.77 toks/s, output: 562.06 toks/s]Processed prompts:  24%|██▍       | 120/500 [05:53<14:21,  2.27s/it, est. speed input: 229.54 toks/s, output: 563.70 toks/s]Processed prompts:  24%|██▍       | 121/500 [05:55<13:01,  2.06s/it, est. speed input: 229.37 toks/s, output: 564.41 toks/s]Processed prompts:  24%|██▍       | 122/500 [05:56<11:05,  1.76s/it, est. speed input: 233.99 toks/s, output: 571.89 toks/s]Processed prompts:  25%|██▍       | 123/500 [05:56<08:54,  1.42s/it, est. speed input: 235.59 toks/s, output: 580.11 toks/s]Processed prompts:  25%|██▍       | 124/500 [05:56<06:48,  1.09s/it, est. speed input: 236.36 toks/s, output: 588.79 toks/s]Processed prompts:  25%|██▌       | 125/500 [05:57<05:03,  1.23it/s, est. speed input: 240.65 toks/s, output: 597.63 toks/s]Processed prompts:  25%|██▌       | 126/500 [05:59<08:37,  1.38s/it, est. speed input: 240.13 toks/s, output: 602.31 toks/s]Processed prompts:  25%|██▌       | 127/500 [06:00<07:58,  1.28s/it, est. speed input: 240.64 toks/s, output: 609.72 toks/s]Processed prompts:  26%|██▌       | 128/500 [06:11<25:20,  4.09s/it, est. speed input: 237.32 toks/s, output: 596.00 toks/s]Processed prompts:  26%|██▌       | 129/500 [06:14<23:14,  3.76s/it, est. speed input: 237.80 toks/s, output: 600.51 toks/s]Processed prompts:  26%|██▌       | 130/500 [06:18<24:23,  3.96s/it, est. speed input: 239.54 toks/s, output: 596.25 toks/s]Processed prompts:  26%|██▌       | 131/500 [06:21<21:50,  3.55s/it, est. speed input: 238.94 toks/s, output: 601.57 toks/s]Processed prompts:  26%|██▋       | 132/500 [06:24<20:24,  3.33s/it, est. speed input: 242.79 toks/s, output: 599.90 toks/s]Processed prompts:  27%|██▋       | 133/500 [06:25<15:27,  2.53s/it, est. speed input: 248.76 toks/s, output: 602.21 toks/s]Processed prompts:  27%|██▋       | 134/500 [06:25<11:52,  1.95s/it, est. speed input: 253.36 toks/s, output: 610.70 toks/s]Processed prompts:  27%|██▋       | 135/500 [06:29<14:48,  2.43s/it, est. speed input: 252.67 toks/s, output: 614.50 toks/s]Processed prompts:  27%|██▋       | 136/500 [06:31<14:20,  2.36s/it, est. speed input: 253.01 toks/s, output: 620.44 toks/s]Processed prompts:  27%|██▋       | 137/500 [06:33<13:42,  2.26s/it, est. speed input: 254.76 toks/s, output: 620.93 toks/s]Processed prompts:  28%|██▊       | 138/500 [06:34<12:03,  2.00s/it, est. speed input: 256.76 toks/s, output: 621.45 toks/s]Processed prompts:  28%|██▊       | 139/500 [06:41<20:17,  3.37s/it, est. speed input: 255.89 toks/s, output: 615.96 toks/s]Processed prompts:  28%|██▊       | 140/500 [06:46<23:01,  3.84s/it, est. speed input: 258.57 toks/s, output: 611.00 toks/s]Processed prompts:  28%|██▊       | 141/500 [06:53<28:17,  4.73s/it, est. speed input: 257.93 toks/s, output: 610.44 toks/s]Processed prompts:  28%|██▊       | 142/500 [06:56<26:00,  4.36s/it, est. speed input: 258.36 toks/s, output: 614.93 toks/s]Processed prompts:  29%|██▊       | 143/500 [07:05<34:32,  5.81s/it, est. speed input: 254.31 toks/s, output: 611.32 toks/s]Processed prompts:  29%|██▉       | 144/500 [07:07<26:48,  4.52s/it, est. speed input: 256.56 toks/s, output: 618.80 toks/s]Processed prompts:  29%|██▉       | 145/500 [07:08<21:06,  3.57s/it, est. speed input: 257.04 toks/s, output: 626.48 toks/s]Processed prompts:  29%|██▉       | 146/500 [07:09<15:38,  2.65s/it, est. speed input: 257.55 toks/s, output: 628.75 toks/s]Processed prompts:  29%|██▉       | 147/500 [07:15<22:40,  3.85s/it, est. speed input: 256.59 toks/s, output: 623.81 toks/s]Processed prompts:  30%|██▉       | 148/500 [07:22<27:00,  4.60s/it, est. speed input: 257.33 toks/s, output: 621.08 toks/s]Processed prompts:  30%|██▉       | 149/500 [07:23<20:40,  3.53s/it, est. speed input: 258.01 toks/s, output: 629.37 toks/s]Processed prompts:  30%|███       | 150/500 [07:25<17:52,  3.06s/it, est. speed input: 260.62 toks/s, output: 629.01 toks/s]Processed prompts:  30%|███       | 151/500 [07:26<14:18,  2.46s/it, est. speed input: 264.94 toks/s, output: 630.78 toks/s]Processed prompts:  30%|███       | 152/500 [07:30<17:38,  3.04s/it, est. speed input: 263.74 toks/s, output: 629.39 toks/s]Processed prompts:  31%|███       | 153/500 [07:33<16:31,  2.86s/it, est. speed input: 262.85 toks/s, output: 627.55 toks/s]Processed prompts:  31%|███       | 154/500 [07:33<11:48,  2.05s/it, est. speed input: 264.56 toks/s, output: 637.10 toks/s]Processed prompts:  31%|███       | 155/500 [07:36<14:09,  2.46s/it, est. speed input: 263.99 toks/s, output: 640.91 toks/s]Processed prompts:  31%|███       | 156/500 [07:39<14:14,  2.49s/it, est. speed input: 263.84 toks/s, output: 642.50 toks/s]Processed prompts:  31%|███▏      | 157/500 [07:41<13:26,  2.35s/it, est. speed input: 264.97 toks/s, output: 643.89 toks/s]Processed prompts:  32%|███▏      | 158/500 [07:49<24:14,  4.25s/it, est. speed input: 262.39 toks/s, output: 635.57 toks/s]Processed prompts:  32%|███▏      | 159/500 [07:50<18:39,  3.28s/it, est. speed input: 262.83 toks/s, output: 635.21 toks/s]Processed prompts:  32%|███▏      | 160/500 [08:00<28:36,  5.05s/it, est. speed input: 258.95 toks/s, output: 633.00 toks/s]WARNING 04-04 09:49:03 scheduler.py:1555] Sequence group 219 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:  32%|███▏      | 161/500 [08:17<49:26,  8.75s/it, est. speed input: 253.80 toks/s, output: 620.93 toks/s]Processed prompts:  32%|███▏      | 162/500 [08:22<42:53,  7.61s/it, est. speed input: 252.29 toks/s, output: 618.66 toks/s]Processed prompts:  33%|███▎      | 163/500 [08:23<32:22,  5.76s/it, est. speed input: 252.17 toks/s, output: 619.47 toks/s]Processed prompts:  33%|███▎      | 164/500 [08:26<27:18,  4.88s/it, est. speed input: 252.27 toks/s, output: 626.11 toks/s]Processed prompts:  33%|███▎      | 165/500 [08:28<22:34,  4.04s/it, est. speed input: 254.93 toks/s, output: 627.97 toks/s]Processed prompts:  33%|███▎      | 166/500 [08:35<27:07,  4.87s/it, est. speed input: 253.12 toks/s, output: 629.80 toks/s]Processed prompts:  33%|███▎      | 167/500 [08:40<26:50,  4.84s/it, est. speed input: 254.49 toks/s, output: 634.25 toks/s]Processed prompts:  34%|███▎      | 168/500 [08:45<27:53,  5.04s/it, est. speed input: 252.68 toks/s, output: 632.38 toks/s]Processed prompts:  34%|███▍      | 169/500 [08:47<22:23,  4.06s/it, est. speed input: 253.48 toks/s, output: 634.21 toks/s]Processed prompts:  34%|███▍      | 170/500 [08:48<16:16,  2.96s/it, est. speed input: 254.32 toks/s, output: 640.15 toks/s]Processed prompts:  34%|███▍      | 171/500 [08:53<19:38,  3.58s/it, est. speed input: 255.40 toks/s, output: 635.79 toks/s]Processed prompts:  34%|███▍      | 172/500 [08:54<15:50,  2.90s/it, est. speed input: 255.70 toks/s, output: 639.95 toks/s]Processed prompts:  35%|███▍      | 173/500 [08:55<12:17,  2.26s/it, est. speed input: 257.26 toks/s, output: 643.32 toks/s]Processed prompts:  35%|███▍      | 174/500 [08:55<09:35,  1.77s/it, est. speed input: 260.11 toks/s, output: 648.30 toks/s]Processed prompts:  35%|███▌      | 175/500 [08:57<09:38,  1.78s/it, est. speed input: 262.20 toks/s, output: 648.38 toks/s]Processed prompts:  35%|███▌      | 176/500 [08:59<09:49,  1.82s/it, est. speed input: 264.09 toks/s, output: 656.29 toks/s]Processed prompts:  35%|███▌      | 177/500 [09:00<09:00,  1.67s/it, est. speed input: 265.42 toks/s, output: 662.18 toks/s]Processed prompts:  36%|███▌      | 178/500 [09:04<11:58,  2.23s/it, est. speed input: 267.26 toks/s, output: 668.07 toks/s]Processed prompts:  36%|███▌      | 179/500 [09:05<10:38,  1.99s/it, est. speed input: 266.99 toks/s, output: 672.20 toks/s]Processed prompts:  36%|███▌      | 180/500 [09:14<20:41,  3.88s/it, est. speed input: 266.50 toks/s, output: 667.21 toks/s]Processed prompts:  36%|███▌      | 181/500 [09:18<21:20,  4.01s/it, est. speed input: 264.83 toks/s, output: 666.91 toks/s]Processed prompts:  36%|███▋      | 182/500 [09:36<42:54,  8.10s/it, est. speed input: 258.70 toks/s, output: 656.84 toks/s]Processed prompts:  37%|███▋      | 183/500 [09:39<35:09,  6.66s/it, est. speed input: 258.17 toks/s, output: 659.36 toks/s]Processed prompts:  37%|███▋      | 184/500 [09:39<25:14,  4.79s/it, est. speed input: 258.51 toks/s, output: 662.27 toks/s]Processed prompts:  37%|███▋      | 185/500 [09:41<20:48,  3.97s/it, est. speed input: 260.23 toks/s, output: 664.17 toks/s]Processed prompts:  37%|███▋      | 186/500 [09:44<19:20,  3.70s/it, est. speed input: 260.34 toks/s, output: 671.05 toks/s]Processed prompts:  37%|███▋      | 187/500 [09:48<18:57,  3.63s/it, est. speed input: 260.87 toks/s, output: 672.80 toks/s]Processed prompts:  38%|███▊      | 188/500 [09:51<17:25,  3.35s/it, est. speed input: 262.27 toks/s, output: 671.55 toks/s]Processed prompts:  38%|███▊      | 189/500 [10:00<26:18,  5.07s/it, est. speed input: 260.95 toks/s, output: 671.82 toks/s]Processed prompts:  38%|███▊      | 190/500 [10:03<24:16,  4.70s/it, est. speed input: 261.79 toks/s, output: 672.41 toks/s]Processed prompts:  38%|███▊      | 191/500 [10:06<20:10,  3.92s/it, est. speed input: 261.34 toks/s, output: 676.77 toks/s]Processed prompts:  38%|███▊      | 192/500 [10:07<16:47,  3.27s/it, est. speed input: 260.97 toks/s, output: 681.32 toks/s]Processed prompts:  39%|███▊      | 193/500 [10:13<21:07,  4.13s/it, est. speed input: 258.78 toks/s, output: 681.27 toks/s]Processed prompts:  39%|███▉      | 194/500 [10:14<15:02,  2.95s/it, est. speed input: 259.23 toks/s, output: 686.94 toks/s]Processed prompts:  39%|███▉      | 195/500 [10:17<16:02,  3.16s/it, est. speed input: 260.04 toks/s, output: 693.37 toks/s]WARNING 04-04 09:51:22 scheduler.py:1555] Sequence group 272 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:  39%|███▉      | 196/500 [10:26<23:56,  4.72s/it, est. speed input: 257.46 toks/s, output: 689.63 toks/s]Processed prompts:  39%|███▉      | 197/500 [10:27<18:27,  3.65s/it, est. speed input: 260.15 toks/s, output: 698.79 toks/s]Processed prompts:  40%|███▉      | 198/500 [10:30<16:55,  3.36s/it, est. speed input: 261.24 toks/s, output: 706.24 toks/s]Processed prompts:  40%|███▉      | 199/500 [10:50<42:17,  8.43s/it, est. speed input: 255.80 toks/s, output: 688.62 toks/s]Processed prompts:  40%|████      | 200/500 [10:51<31:40,  6.33s/it, est. speed input: 258.69 toks/s, output: 687.89 toks/s]Processed prompts:  40%|████      | 201/500 [10:55<28:08,  5.65s/it, est. speed input: 258.03 toks/s, output: 685.98 toks/s]Processed prompts:  40%|████      | 202/500 [10:56<20:51,  4.20s/it, est. speed input: 260.62 toks/s, output: 687.48 toks/s]Processed prompts:  41%|████      | 203/500 [10:59<18:15,  3.69s/it, est. speed input: 260.00 toks/s, output: 686.15 toks/s]Processed prompts:  41%|████      | 204/500 [11:03<19:00,  3.85s/it, est. speed input: 258.92 toks/s, output: 689.30 toks/s]Processed prompts:  41%|████      | 205/500 [11:05<16:22,  3.33s/it, est. speed input: 258.98 toks/s, output: 691.86 toks/s]Processed prompts:  41%|████      | 206/500 [11:07<14:11,  2.89s/it, est. speed input: 258.65 toks/s, output: 692.68 toks/s]Processed prompts:  41%|████▏     | 207/500 [11:09<12:37,  2.58s/it, est. speed input: 261.10 toks/s, output: 701.26 toks/s]Processed prompts:  42%|████▏     | 208/500 [11:09<09:41,  1.99s/it, est. speed input: 262.14 toks/s, output: 702.82 toks/s]Processed prompts:  42%|████▏     | 209/500 [11:20<21:48,  4.50s/it, est. speed input: 258.74 toks/s, output: 698.52 toks/s]Processed prompts:  42%|████▏     | 210/500 [11:20<15:24,  3.19s/it, est. speed input: 262.42 toks/s, output: 708.92 toks/s]Processed prompts:  42%|████▏     | 211/500 [11:25<18:07,  3.76s/it, est. speed input: 260.79 toks/s, output: 704.81 toks/s]Processed prompts:  42%|████▏     | 212/500 [11:27<15:11,  3.16s/it, est. speed input: 263.55 toks/s, output: 704.04 toks/s]Processed prompts:  43%|████▎     | 213/500 [11:28<12:59,  2.72s/it, est. speed input: 264.41 toks/s, output: 703.72 toks/s]Processed prompts:  43%|████▎     | 214/500 [11:30<12:08,  2.55s/it, est. speed input: 264.91 toks/s, output: 707.35 toks/s]Processed prompts:  43%|████▎     | 215/500 [11:32<10:12,  2.15s/it, est. speed input: 265.12 toks/s, output: 708.26 toks/s]WARNING 04-04 09:52:42 scheduler.py:1555] Sequence group 294 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  43%|████▎     | 216/500 [11:44<25:14,  5.33s/it, est. speed input: 262.84 toks/s, output: 698.28 toks/s]Processed prompts:  43%|████▎     | 217/500 [11:50<26:08,  5.54s/it, est. speed input: 260.98 toks/s, output: 695.35 toks/s]Processed prompts:  44%|████▎     | 218/500 [11:53<21:41,  4.62s/it, est. speed input: 261.14 toks/s, output: 694.71 toks/s]Processed prompts:  44%|████▍     | 219/500 [11:58<21:37,  4.62s/it, est. speed input: 259.90 toks/s, output: 692.56 toks/s]Processed prompts:  44%|████▍     | 220/500 [11:59<16:29,  3.53s/it, est. speed input: 259.86 toks/s, output: 693.50 toks/s]Processed prompts:  44%|████▍     | 221/500 [12:00<13:28,  2.90s/it, est. speed input: 260.23 toks/s, output: 695.26 toks/s]Processed prompts:  44%|████▍     | 222/500 [12:00<09:56,  2.15s/it, est. speed input: 260.79 toks/s, output: 697.93 toks/s]Processed prompts:  45%|████▍     | 223/500 [12:01<07:58,  1.73s/it, est. speed input: 262.31 toks/s, output: 698.89 toks/s]Processed prompts:  45%|████▍     | 224/500 [12:03<07:53,  1.72s/it, est. speed input: 264.34 toks/s, output: 707.82 toks/s]Processed prompts:  45%|████▌     | 225/500 [12:12<17:35,  3.84s/it, est. speed input: 261.71 toks/s, output: 705.87 toks/s]Processed prompts:  45%|████▌     | 226/500 [12:13<13:57,  3.06s/it, est. speed input: 262.92 toks/s, output: 705.81 toks/s]Processed prompts:  45%|████▌     | 227/500 [12:20<19:46,  4.35s/it, est. speed input: 262.25 toks/s, output: 702.18 toks/s]Processed prompts:  46%|████▌     | 228/500 [12:32<30:01,  6.62s/it, est. speed input: 258.91 toks/s, output: 694.74 toks/s]Processed prompts:  46%|████▌     | 229/500 [12:35<24:49,  5.50s/it, est. speed input: 259.23 toks/s, output: 694.22 toks/s]Processed prompts:  46%|████▌     | 230/500 [12:40<23:37,  5.25s/it, est. speed input: 257.93 toks/s, output: 691.95 toks/s]Processed prompts:  46%|████▌     | 231/500 [12:43<21:16,  4.74s/it, est. speed input: 257.53 toks/s, output: 696.68 toks/s]Processed prompts:  46%|████▋     | 232/500 [12:45<17:04,  3.82s/it, est. speed input: 258.64 toks/s, output: 704.02 toks/s]Processed prompts:  47%|████▋     | 233/500 [12:45<12:20,  2.77s/it, est. speed input: 260.65 toks/s, output: 706.89 toks/s]Processed prompts:  47%|████▋     | 234/500 [12:47<10:50,  2.44s/it, est. speed input: 260.82 toks/s, output: 712.22 toks/s]Processed prompts:  47%|████▋     | 235/500 [12:47<08:16,  1.87s/it, est. speed input: 262.69 toks/s, output: 713.39 toks/s]Processed prompts:  47%|████▋     | 236/500 [12:50<09:40,  2.20s/it, est. speed input: 262.55 toks/s, output: 711.35 toks/s]Processed prompts:  47%|████▋     | 237/500 [12:52<08:14,  1.88s/it, est. speed input: 263.88 toks/s, output: 714.65 toks/s]Processed prompts:  48%|████▊     | 238/500 [12:56<10:59,  2.52s/it, est. speed input: 265.41 toks/s, output: 721.55 toks/s]Processed prompts:  48%|████▊     | 239/500 [12:59<11:50,  2.72s/it, est. speed input: 264.79 toks/s, output: 720.03 toks/s]Processed prompts:  48%|████▊     | 240/500 [13:01<10:50,  2.50s/it, est. speed input: 264.81 toks/s, output: 724.52 toks/s]Processed prompts:  48%|████▊     | 241/500 [13:12<22:04,  5.11s/it, est. speed input: 261.51 toks/s, output: 717.92 toks/s]Processed prompts:  48%|████▊     | 242/500 [13:13<17:11,  4.00s/it, est. speed input: 262.48 toks/s, output: 727.21 toks/s]Processed prompts:  49%|████▊     | 243/500 [13:14<13:14,  3.09s/it, est. speed input: 262.44 toks/s, output: 727.96 toks/s]Processed prompts:  49%|████▉     | 244/500 [13:15<10:19,  2.42s/it, est. speed input: 263.55 toks/s, output: 734.51 toks/s]Processed prompts:  49%|████▉     | 245/500 [13:20<13:09,  3.10s/it, est. speed input: 262.33 toks/s, output: 731.79 toks/s]Processed prompts:  49%|████▉     | 246/500 [13:23<12:37,  2.98s/it, est. speed input: 261.81 toks/s, output: 731.38 toks/s]Processed prompts:  49%|████▉     | 247/500 [13:23<09:02,  2.14s/it, est. speed input: 262.95 toks/s, output: 734.20 toks/s]Processed prompts:  50%|████▉     | 248/500 [13:27<11:19,  2.70s/it, est. speed input: 262.68 toks/s, output: 734.53 toks/s]Processed prompts:  50%|████▉     | 249/500 [13:28<10:01,  2.40s/it, est. speed input: 262.67 toks/s, output: 736.95 toks/s]Processed prompts:  50%|█████     | 250/500 [13:34<13:30,  3.24s/it, est. speed input: 261.31 toks/s, output: 736.48 toks/s]Processed prompts:  50%|█████     | 251/500 [13:35<10:54,  2.63s/it, est. speed input: 262.32 toks/s, output: 739.34 toks/s]Processed prompts:  50%|█████     | 252/500 [13:40<14:21,  3.47s/it, est. speed input: 261.68 toks/s, output: 734.71 toks/s]Processed prompts:  51%|█████     | 253/500 [13:42<12:09,  2.96s/it, est. speed input: 261.42 toks/s, output: 736.23 toks/s]WARNING 04-04 09:54:49 scheduler.py:1555] Sequence group 340 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  51%|█████     | 254/500 [13:51<19:23,  4.73s/it, est. speed input: 259.80 toks/s, output: 731.29 toks/s]Processed prompts:  51%|█████     | 255/500 [13:56<19:39,  4.81s/it, est. speed input: 258.69 toks/s, output: 727.56 toks/s]Processed prompts:  51%|█████     | 256/500 [13:57<14:47,  3.64s/it, est. speed input: 259.41 toks/s, output: 730.74 toks/s]Processed prompts:  51%|█████▏    | 257/500 [13:58<12:07,  2.99s/it, est. speed input: 260.53 toks/s, output: 733.02 toks/s]Processed prompts:  52%|█████▏    | 258/500 [14:01<11:51,  2.94s/it, est. speed input: 261.90 toks/s, output: 731.29 toks/s]Processed prompts:  52%|█████▏    | 259/500 [14:10<18:58,  4.72s/it, est. speed input: 259.50 toks/s, output: 724.61 toks/s]Processed prompts:  52%|█████▏    | 260/500 [14:11<14:04,  3.52s/it, est. speed input: 259.56 toks/s, output: 724.68 toks/s]Processed prompts:  52%|█████▏    | 261/500 [14:15<15:06,  3.79s/it, est. speed input: 258.51 toks/s, output: 723.22 toks/s]Processed prompts:  52%|█████▏    | 262/500 [14:15<10:50,  2.73s/it, est. speed input: 258.70 toks/s, output: 724.02 toks/s]Processed prompts:  53%|█████▎    | 263/500 [14:17<09:16,  2.35s/it, est. speed input: 259.55 toks/s, output: 724.89 toks/s]Processed prompts:  53%|█████▎    | 264/500 [14:24<14:23,  3.66s/it, est. speed input: 259.75 toks/s, output: 729.77 toks/s]Processed prompts:  53%|█████▎    | 265/500 [14:35<23:37,  6.03s/it, est. speed input: 256.56 toks/s, output: 721.37 toks/s]Processed prompts:  53%|█████▎    | 266/500 [14:36<16:58,  4.35s/it, est. speed input: 256.83 toks/s, output: 723.53 toks/s]Processed prompts:  53%|█████▎    | 267/500 [14:36<12:02,  3.10s/it, est. speed input: 257.18 toks/s, output: 724.64 toks/s]Processed prompts:  54%|█████▎    | 268/500 [14:42<15:31,  4.02s/it, est. speed input: 256.01 toks/s, output: 723.81 toks/s]Processed prompts:  54%|█████▍    | 269/500 [14:45<14:03,  3.65s/it, est. speed input: 255.51 toks/s, output: 724.29 toks/s]Processed prompts:  54%|█████▍    | 270/500 [14:46<11:42,  3.06s/it, est. speed input: 255.92 toks/s, output: 728.57 toks/s]Processed prompts:  54%|█████▍    | 271/500 [14:49<10:40,  2.80s/it, est. speed input: 256.06 toks/s, output: 728.54 toks/s]Processed prompts:  54%|█████▍    | 272/500 [14:53<12:17,  3.23s/it, est. speed input: 256.05 toks/s, output: 726.52 toks/s]Processed prompts:  55%|█████▍    | 273/500 [14:57<13:43,  3.63s/it, est. speed input: 255.29 toks/s, output: 727.48 toks/s]Processed prompts:  55%|█████▌    | 275/500 [14:58<07:40,  2.05s/it, est. speed input: 256.16 toks/s, output: 731.47 toks/s]Processed prompts:  55%|█████▌    | 276/500 [15:00<08:01,  2.15s/it, est. speed input: 256.10 toks/s, output: 735.53 toks/s]Processed prompts:  55%|█████▌    | 277/500 [15:01<06:27,  1.74s/it, est. speed input: 256.40 toks/s, output: 742.42 toks/s]Processed prompts:  56%|█████▌    | 278/500 [15:05<08:52,  2.40s/it, est. speed input: 255.66 toks/s, output: 744.22 toks/s]Processed prompts:  56%|█████▌    | 279/500 [15:08<09:47,  2.66s/it, est. speed input: 255.13 toks/s, output: 744.87 toks/s]Processed prompts:  56%|█████▌    | 280/500 [15:10<09:16,  2.53s/it, est. speed input: 254.96 toks/s, output: 744.59 toks/s]Processed prompts:  56%|█████▌    | 281/500 [15:13<09:39,  2.64s/it, est. speed input: 254.44 toks/s, output: 748.00 toks/s]Processed prompts:  56%|█████▋    | 282/500 [15:15<08:52,  2.44s/it, est. speed input: 254.48 toks/s, output: 751.16 toks/s]Processed prompts:  57%|█████▋    | 283/500 [15:17<07:31,  2.08s/it, est. speed input: 254.63 toks/s, output: 751.15 toks/s]Processed prompts:  57%|█████▋    | 284/500 [15:23<12:02,  3.35s/it, est. speed input: 253.78 toks/s, output: 750.60 toks/s]Processed prompts:  57%|█████▋    | 285/500 [15:23<08:46,  2.45s/it, est. speed input: 253.93 toks/s, output: 751.90 toks/s]Processed prompts:  57%|█████▋    | 286/500 [15:25<07:43,  2.16s/it, est. speed input: 254.17 toks/s, output: 754.32 toks/s]Processed prompts:  57%|█████▋    | 287/500 [15:28<09:08,  2.57s/it, est. speed input: 253.72 toks/s, output: 753.71 toks/s]Processed prompts:  58%|█████▊    | 288/500 [15:30<08:26,  2.39s/it, est. speed input: 253.91 toks/s, output: 756.88 toks/s]Processed prompts:  58%|█████▊    | 289/500 [15:45<21:07,  6.01s/it, est. speed input: 250.79 toks/s, output: 746.81 toks/s]Processed prompts:  58%|█████▊    | 290/500 [15:47<17:06,  4.89s/it, est. speed input: 250.93 toks/s, output: 750.36 toks/s]Processed prompts:  58%|█████▊    | 291/500 [15:47<12:17,  3.53s/it, est. speed input: 251.98 toks/s, output: 751.72 toks/s]Processed prompts:  58%|█████▊    | 292/500 [15:48<09:06,  2.63s/it, est. speed input: 253.05 toks/s, output: 752.65 toks/s]Processed prompts:  59%|█████▊    | 293/500 [15:48<06:40,  1.94s/it, est. speed input: 253.82 toks/s, output: 757.19 toks/s]WARNING 04-04 09:56:53 scheduler.py:1555] Sequence group 381 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  59%|█████▉    | 294/500 [15:56<13:08,  3.83s/it, est. speed input: 252.38 toks/s, output: 755.54 toks/s]Processed prompts:  59%|█████▉    | 295/500 [16:00<12:21,  3.62s/it, est. speed input: 252.38 toks/s, output: 759.78 toks/s]Processed prompts:  59%|█████▉    | 296/500 [16:08<17:40,  5.20s/it, est. speed input: 251.07 toks/s, output: 757.36 toks/s]Processed prompts:  59%|█████▉    | 297/500 [16:14<18:02,  5.33s/it, est. speed input: 250.36 toks/s, output: 755.09 toks/s]Processed prompts:  60%|█████▉    | 298/500 [16:17<15:07,  4.49s/it, est. speed input: 250.24 toks/s, output: 757.30 toks/s]Processed prompts:  60%|█████▉    | 299/500 [16:18<11:52,  3.54s/it, est. speed input: 251.32 toks/s, output: 756.86 toks/s]Processed prompts:  60%|██████    | 300/500 [16:26<16:21,  4.91s/it, est. speed input: 251.17 toks/s, output: 752.99 toks/s]Processed prompts:  60%|██████    | 301/500 [16:29<14:36,  4.41s/it, est. speed input: 252.05 toks/s, output: 751.00 toks/s]Processed prompts:  60%|██████    | 302/500 [16:32<12:37,  3.83s/it, est. speed input: 251.68 toks/s, output: 751.30 toks/s]Processed prompts:  61%|██████    | 303/500 [16:37<13:43,  4.18s/it, est. speed input: 250.65 toks/s, output: 749.76 toks/s]Processed prompts:  61%|██████    | 304/500 [16:38<10:43,  3.28s/it, est. speed input: 251.25 toks/s, output: 752.70 toks/s]Processed prompts:  61%|██████    | 305/500 [16:41<10:16,  3.16s/it, est. speed input: 253.41 toks/s, output: 751.61 toks/s]Processed prompts:  61%|██████    | 306/500 [16:48<14:01,  4.34s/it, est. speed input: 252.43 toks/s, output: 746.95 toks/s]Processed prompts:  61%|██████▏   | 307/500 [16:50<12:02,  3.74s/it, est. speed input: 252.40 toks/s, output: 746.35 toks/s]Processed prompts:  62%|██████▏   | 308/500 [16:58<15:59,  5.00s/it, est. speed input: 250.91 toks/s, output: 744.30 toks/s]Processed prompts:  62%|██████▏   | 309/500 [16:59<12:13,  3.84s/it, est. speed input: 250.87 toks/s, output: 744.62 toks/s]Processed prompts:  62%|██████▏   | 310/500 [17:11<19:47,  6.25s/it, est. speed input: 248.70 toks/s, output: 738.94 toks/s]Processed prompts:  62%|██████▏   | 311/500 [17:16<18:06,  5.75s/it, est. speed input: 247.83 toks/s, output: 738.80 toks/s]Processed prompts:  62%|██████▏   | 312/500 [17:17<13:48,  4.41s/it, est. speed input: 248.13 toks/s, output: 739.26 toks/s]Processed prompts:  63%|██████▎   | 313/500 [17:22<13:48,  4.43s/it, est. speed input: 247.95 toks/s, output: 739.88 toks/s]Processed prompts:  63%|██████▎   | 314/500 [17:24<11:30,  3.71s/it, est. speed input: 247.71 toks/s, output: 739.90 toks/s]Processed prompts:  63%|██████▎   | 315/500 [17:25<09:15,  3.00s/it, est. speed input: 248.84 toks/s, output: 742.82 toks/s]Processed prompts:  63%|██████▎   | 316/500 [17:27<08:40,  2.83s/it, est. speed input: 248.53 toks/s, output: 744.42 toks/s]Processed prompts:  63%|██████▎   | 317/500 [17:34<12:35,  4.13s/it, est. speed input: 247.14 toks/s, output: 740.91 toks/s]Processed prompts:  64%|██████▎   | 318/500 [17:35<08:54,  2.94s/it, est. speed input: 247.80 toks/s, output: 744.80 toks/s]Processed prompts:  64%|██████▍   | 319/500 [17:39<10:15,  3.40s/it, est. speed input: 247.01 toks/s, output: 742.69 toks/s]Processed prompts:  64%|██████▍   | 320/500 [17:40<08:16,  2.76s/it, est. speed input: 248.27 toks/s, output: 743.09 toks/s]Processed prompts:  64%|██████▍   | 321/500 [17:45<09:38,  3.23s/it, est. speed input: 247.76 toks/s, output: 742.81 toks/s]Processed prompts:  64%|██████▍   | 322/500 [17:46<07:55,  2.67s/it, est. speed input: 248.29 toks/s, output: 742.88 toks/s]Processed prompts:  65%|██████▍   | 323/500 [17:50<09:11,  3.11s/it, est. speed input: 248.50 toks/s, output: 742.92 toks/s]Processed prompts:  65%|██████▍   | 324/500 [17:52<07:46,  2.65s/it, est. speed input: 248.45 toks/s, output: 743.59 toks/s]Processed prompts:  65%|██████▌   | 325/500 [17:58<10:31,  3.61s/it, est. speed input: 247.80 toks/s, output: 742.62 toks/s]Processed prompts:  65%|██████▌   | 326/500 [17:58<07:30,  2.59s/it, est. speed input: 248.21 toks/s, output: 744.43 toks/s]Processed prompts:  65%|██████▌   | 327/500 [17:58<05:21,  1.86s/it, est. speed input: 248.44 toks/s, output: 746.05 toks/s]Processed prompts:  66%|██████▌   | 328/500 [18:00<05:14,  1.83s/it, est. speed input: 248.26 toks/s, output: 747.25 toks/s]Processed prompts:  66%|██████▌   | 329/500 [18:03<06:10,  2.16s/it, est. speed input: 247.87 toks/s, output: 750.00 toks/s]Processed prompts:  66%|██████▌   | 330/500 [18:04<05:37,  1.99s/it, est. speed input: 248.12 toks/s, output: 753.30 toks/s]WARNING 04-04 09:59:10 scheduler.py:1555] Sequence group 400 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  66%|██████▌   | 331/500 [18:18<15:14,  5.41s/it, est. speed input: 245.50 toks/s, output: 745.55 toks/s]Processed prompts:  66%|██████▋   | 332/500 [18:22<14:02,  5.02s/it, est. speed input: 245.16 toks/s, output: 747.42 toks/s]Processed prompts:  67%|██████▋   | 333/500 [18:22<09:56,  3.57s/it, est. speed input: 245.76 toks/s, output: 749.91 toks/s]Processed prompts:  67%|██████▋   | 334/500 [18:23<07:57,  2.88s/it, est. speed input: 245.88 toks/s, output: 750.16 toks/s]Processed prompts:  67%|██████▋   | 335/500 [18:26<07:50,  2.85s/it, est. speed input: 245.91 toks/s, output: 748.87 toks/s]Processed prompts:  67%|██████▋   | 336/500 [18:27<06:05,  2.23s/it, est. speed input: 248.03 toks/s, output: 750.27 toks/s]Processed prompts:  67%|██████▋   | 337/500 [18:28<04:50,  1.78s/it, est. speed input: 248.49 toks/s, output: 751.75 toks/s]Processed prompts:  68%|██████▊   | 338/500 [18:31<05:57,  2.21s/it, est. speed input: 248.22 toks/s, output: 751.52 toks/s]Processed prompts:  68%|██████▊   | 339/500 [18:33<06:20,  2.36s/it, est. speed input: 248.19 toks/s, output: 751.76 toks/s]Processed prompts:  68%|██████▊   | 340/500 [18:45<13:28,  5.05s/it, est. speed input: 247.10 toks/s, output: 746.35 toks/s]Processed prompts:  68%|██████▊   | 341/500 [18:45<09:32,  3.60s/it, est. speed input: 247.67 toks/s, output: 749.58 toks/s]Processed prompts:  68%|██████▊   | 342/500 [18:57<15:49,  6.01s/it, est. speed input: 245.71 toks/s, output: 745.60 toks/s]Processed prompts:  69%|██████▉   | 344/500 [18:57<08:31,  3.28s/it, est. speed input: 248.20 toks/s, output: 758.39 toks/s]Processed prompts:  69%|██████▉   | 345/500 [19:03<10:17,  3.98s/it, est. speed input: 247.71 toks/s, output: 757.02 toks/s]Processed prompts:  69%|██████▉   | 346/500 [19:07<10:00,  3.90s/it, est. speed input: 247.31 toks/s, output: 758.55 toks/s]Processed prompts:  69%|██████▉   | 347/500 [19:11<10:33,  4.14s/it, est. speed input: 246.64 toks/s, output: 756.04 toks/s]Processed prompts:  70%|██████▉   | 348/500 [19:25<17:06,  6.75s/it, est. speed input: 245.15 toks/s, output: 748.14 toks/s]Processed prompts:  70%|██████▉   | 349/500 [19:31<16:19,  6.49s/it, est. speed input: 244.33 toks/s, output: 745.05 toks/s]Processed prompts:  70%|███████   | 350/500 [19:36<15:10,  6.07s/it, est. speed input: 243.74 toks/s, output: 745.49 toks/s]Processed prompts:  70%|███████   | 351/500 [19:36<10:48,  4.35s/it, est. speed input: 244.01 toks/s, output: 749.25 toks/s]Processed prompts:  70%|███████   | 352/500 [19:39<09:25,  3.82s/it, est. speed input: 243.72 toks/s, output: 751.88 toks/s]Processed prompts:  71%|███████   | 353/500 [19:39<07:12,  2.94s/it, est. speed input: 244.05 toks/s, output: 754.98 toks/s]Processed prompts:  71%|███████   | 354/500 [19:45<08:53,  3.66s/it, est. speed input: 243.17 toks/s, output: 753.00 toks/s]Processed prompts:  71%|███████   | 355/500 [19:48<08:28,  3.50s/it, est. speed input: 242.75 toks/s, output: 753.65 toks/s]Processed prompts:  71%|███████   | 356/500 [19:49<06:29,  2.70s/it, est. speed input: 243.85 toks/s, output: 756.95 toks/s]Processed prompts:  71%|███████▏  | 357/500 [19:51<06:20,  2.66s/it, est. speed input: 243.57 toks/s, output: 757.35 toks/s]Processed prompts:  72%|███████▏  | 358/500 [19:53<05:27,  2.31s/it, est. speed input: 243.82 toks/s, output: 762.51 toks/s]Processed prompts:  72%|███████▏  | 359/500 [19:58<07:35,  3.23s/it, est. speed input: 243.40 toks/s, output: 761.78 toks/s]Processed prompts:  72%|███████▏  | 360/500 [20:00<06:35,  2.82s/it, est. speed input: 243.29 toks/s, output: 763.14 toks/s]Processed prompts:  72%|███████▏  | 361/500 [20:06<08:52,  3.83s/it, est. speed input: 242.54 toks/s, output: 761.96 toks/s]Processed prompts:  72%|███████▏  | 362/500 [20:08<07:16,  3.17s/it, est. speed input: 243.41 toks/s, output: 763.99 toks/s]Processed prompts:  73%|███████▎  | 363/500 [20:09<06:10,  2.70s/it, est. speed input: 243.82 toks/s, output: 765.73 toks/s]Processed prompts:  73%|███████▎  | 364/500 [20:15<08:24,  3.71s/it, est. speed input: 242.93 toks/s, output: 764.61 toks/s]WARNING 04-04 10:01:20 scheduler.py:1555] Sequence group 445 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  73%|███████▎  | 365/500 [20:22<10:17,  4.57s/it, est. speed input: 242.69 toks/s, output: 761.59 toks/s]Processed prompts:  73%|███████▎  | 366/500 [20:37<17:24,  7.80s/it, est. speed input: 240.20 toks/s, output: 756.58 toks/s]Processed prompts:  73%|███████▎  | 367/500 [20:43<16:08,  7.29s/it, est. speed input: 239.30 toks/s, output: 756.30 toks/s]Processed prompts:  74%|███████▎  | 368/500 [20:46<12:37,  5.74s/it, est. speed input: 239.10 toks/s, output: 755.51 toks/s]Processed prompts:  74%|███████▍  | 369/500 [20:47<09:55,  4.55s/it, est. speed input: 239.84 toks/s, output: 758.54 toks/s]Processed prompts:  74%|███████▍  | 370/500 [20:54<11:22,  5.25s/it, est. speed input: 238.71 toks/s, output: 755.19 toks/s]Processed prompts:  74%|███████▍  | 371/500 [20:58<10:00,  4.66s/it, est. speed input: 239.24 toks/s, output: 757.35 toks/s]Processed prompts:  74%|███████▍  | 372/500 [21:02<10:02,  4.71s/it, est. speed input: 238.68 toks/s, output: 759.58 toks/s]Processed prompts:  75%|███████▍  | 373/500 [21:04<07:49,  3.69s/it, est. speed input: 238.85 toks/s, output: 760.24 toks/s]Processed prompts:  75%|███████▍  | 374/500 [21:06<06:43,  3.20s/it, est. speed input: 238.63 toks/s, output: 760.45 toks/s]Processed prompts:  75%|███████▌  | 375/500 [21:12<08:42,  4.18s/it, est. speed input: 237.90 toks/s, output: 758.26 toks/s]Processed prompts:  75%|███████▌  | 376/500 [21:14<07:19,  3.54s/it, est. speed input: 238.15 toks/s, output: 760.25 toks/s]Processed prompts:  75%|███████▌  | 377/500 [21:18<07:07,  3.47s/it, est. speed input: 238.95 toks/s, output: 761.48 toks/s]Processed prompts:  76%|███████▌  | 378/500 [21:21<07:02,  3.46s/it, est. speed input: 239.04 toks/s, output: 761.08 toks/s]Processed prompts:  76%|███████▌  | 379/500 [21:28<09:02,  4.49s/it, est. speed input: 238.31 toks/s, output: 758.24 toks/s]Processed prompts:  76%|███████▌  | 380/500 [21:29<07:01,  3.51s/it, est. speed input: 238.67 toks/s, output: 760.42 toks/s]Processed prompts:  76%|███████▌  | 381/500 [21:33<07:11,  3.62s/it, est. speed input: 239.35 toks/s, output: 758.28 toks/s]Processed prompts:  76%|███████▋  | 382/500 [21:33<05:15,  2.67s/it, est. speed input: 239.87 toks/s, output: 758.80 toks/s]Processed prompts:  77%|███████▋  | 383/500 [21:34<03:53,  1.99s/it, est. speed input: 241.38 toks/s, output: 761.84 toks/s]Processed prompts:  77%|███████▋  | 384/500 [21:37<04:44,  2.45s/it, est. speed input: 242.14 toks/s, output: 764.13 toks/s]Processed prompts:  77%|███████▋  | 385/500 [21:41<05:32,  2.89s/it, est. speed input: 241.61 toks/s, output: 763.38 toks/s]Processed prompts:  77%|███████▋  | 386/500 [21:42<04:12,  2.22s/it, est. speed input: 241.92 toks/s, output: 769.70 toks/s]Processed prompts:  77%|███████▋  | 387/500 [21:48<06:10,  3.27s/it, est. speed input: 241.18 toks/s, output: 772.66 toks/s]Processed prompts:  78%|███████▊  | 388/500 [21:54<07:36,  4.08s/it, est. speed input: 240.68 toks/s, output: 771.52 toks/s]Processed prompts:  78%|███████▊  | 389/500 [22:05<11:44,  6.35s/it, est. speed input: 239.57 toks/s, output: 766.03 toks/s]Processed prompts:  78%|███████▊  | 390/500 [22:10<10:40,  5.83s/it, est. speed input: 239.86 toks/s, output: 768.33 toks/s]Processed prompts:  78%|███████▊  | 391/500 [22:20<12:55,  7.11s/it, est. speed input: 238.34 toks/s, output: 763.42 toks/s]Processed prompts:  78%|███████▊  | 392/500 [22:21<09:15,  5.15s/it, est. speed input: 238.47 toks/s, output: 764.55 toks/s]Processed prompts:  79%|███████▊  | 393/500 [22:22<07:00,  3.93s/it, est. speed input: 239.20 toks/s, output: 765.96 toks/s]Processed prompts:  79%|███████▉  | 394/500 [22:22<04:59,  2.83s/it, est. speed input: 240.46 toks/s, output: 766.07 toks/s]Processed prompts:  79%|███████▉  | 395/500 [22:22<03:38,  2.08s/it, est. speed input: 240.93 toks/s, output: 767.84 toks/s]Processed prompts:  79%|███████▉  | 396/500 [22:23<02:52,  1.66s/it, est. speed input: 242.25 toks/s, output: 768.65 toks/s]Processed prompts:  79%|███████▉  | 397/500 [22:28<04:40,  2.73s/it, est. speed input: 242.04 toks/s, output: 767.48 toks/s]Processed prompts:  80%|███████▉  | 398/500 [22:29<03:47,  2.24s/it, est. speed input: 242.09 toks/s, output: 768.47 toks/s]WARNING 04-04 10:03:33 scheduler.py:1555] Sequence group 481 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  80%|███████▉  | 399/500 [22:35<05:31,  3.28s/it, est. speed input: 241.52 toks/s, output: 766.43 toks/s]Processed prompts:  80%|████████  | 400/500 [22:38<05:35,  3.36s/it, est. speed input: 242.32 toks/s, output: 765.92 toks/s]Processed prompts:  80%|████████  | 401/500 [22:40<04:29,  2.72s/it, est. speed input: 242.45 toks/s, output: 767.63 toks/s]Processed prompts:  80%|████████  | 402/500 [22:46<06:11,  3.79s/it, est. speed input: 241.87 toks/s, output: 766.19 toks/s]Processed prompts:  81%|████████  | 403/500 [22:47<04:45,  2.95s/it, est. speed input: 242.25 toks/s, output: 767.05 toks/s]Processed prompts:  81%|████████  | 404/500 [22:49<04:11,  2.62s/it, est. speed input: 242.09 toks/s, output: 767.72 toks/s]Processed prompts:  81%|████████  | 405/500 [22:52<04:20,  2.74s/it, est. speed input: 242.44 toks/s, output: 766.28 toks/s]Processed prompts:  81%|████████  | 406/500 [22:55<04:35,  2.93s/it, est. speed input: 243.32 toks/s, output: 765.61 toks/s]Processed prompts:  81%|████████▏ | 407/500 [22:56<03:19,  2.15s/it, est. speed input: 243.89 toks/s, output: 767.12 toks/s]Processed prompts:  82%|████████▏ | 408/500 [22:58<03:13,  2.10s/it, est. speed input: 244.51 toks/s, output: 767.02 toks/s]Processed prompts:  82%|████████▏ | 409/500 [22:58<02:21,  1.55s/it, est. speed input: 245.88 toks/s, output: 767.22 toks/s]Processed prompts:  82%|████████▏ | 410/500 [23:05<04:39,  3.11s/it, est. speed input: 245.17 toks/s, output: 765.81 toks/s]Processed prompts:  82%|████████▏ | 411/500 [23:05<03:28,  2.34s/it, est. speed input: 245.54 toks/s, output: 766.92 toks/s]Processed prompts:  82%|████████▏ | 412/500 [23:14<06:31,  4.45s/it, est. speed input: 244.79 toks/s, output: 768.57 toks/s]Processed prompts:  83%|████████▎ | 413/500 [23:16<04:58,  3.43s/it, est. speed input: 245.70 toks/s, output: 770.28 toks/s]Processed prompts:  83%|████████▎ | 414/500 [23:23<06:51,  4.79s/it, est. speed input: 244.64 toks/s, output: 766.36 toks/s]Processed prompts:  83%|████████▎ | 415/500 [23:28<06:32,  4.62s/it, est. speed input: 244.22 toks/s, output: 765.86 toks/s]Processed prompts:  83%|████████▎ | 416/500 [23:34<07:13,  5.16s/it, est. speed input: 243.37 toks/s, output: 763.51 toks/s]Processed prompts:  83%|████████▎ | 417/500 [23:42<08:14,  5.96s/it, est. speed input: 242.30 toks/s, output: 759.95 toks/s]Processed prompts:  84%|████████▎ | 418/500 [23:46<07:15,  5.31s/it, est. speed input: 242.02 toks/s, output: 758.83 toks/s]Processed prompts:  84%|████████▍ | 419/500 [23:47<05:23,  3.99s/it, est. speed input: 242.06 toks/s, output: 760.05 toks/s]Processed prompts:  84%|████████▍ | 420/500 [23:49<04:48,  3.61s/it, est. speed input: 241.76 toks/s, output: 760.66 toks/s]Processed prompts:  84%|████████▍ | 421/500 [23:55<05:33,  4.22s/it, est. speed input: 241.25 toks/s, output: 762.56 toks/s]Processed prompts:  84%|████████▍ | 422/500 [24:01<06:17,  4.84s/it, est. speed input: 240.65 toks/s, output: 760.24 toks/s]Processed prompts:  85%|████████▍ | 423/500 [24:08<06:51,  5.34s/it, est. speed input: 240.24 toks/s, output: 758.81 toks/s]Processed prompts:  85%|████████▍ | 424/500 [24:09<05:12,  4.11s/it, est. speed input: 240.42 toks/s, output: 759.24 toks/s]Processed prompts:  85%|████████▌ | 425/500 [24:11<04:10,  3.34s/it, est. speed input: 240.68 toks/s, output: 761.24 toks/s]Processed prompts:  85%|████████▌ | 426/500 [24:15<04:36,  3.73s/it, est. speed input: 240.42 toks/s, output: 761.43 toks/s]Processed prompts:  85%|████████▌ | 427/500 [24:16<03:37,  2.98s/it, est. speed input: 240.85 toks/s, output: 762.80 toks/s]Processed prompts:  86%|████████▌ | 428/500 [24:18<02:55,  2.43s/it, est. speed input: 241.16 toks/s, output: 763.68 toks/s]Processed prompts:  86%|████████▌ | 429/500 [24:23<03:58,  3.35s/it, est. speed input: 240.45 toks/s, output: 763.66 toks/s]Processed prompts:  86%|████████▌ | 430/500 [24:30<05:17,  4.54s/it, est. speed input: 239.55 toks/s, output: 761.07 toks/s]Processed prompts:  86%|████████▌ | 431/500 [24:32<04:06,  3.58s/it, est. speed input: 239.67 toks/s, output: 764.49 toks/s]Processed prompts:  86%|████████▋ | 432/500 [24:36<04:08,  3.65s/it, est. speed input: 239.70 toks/s, output: 764.83 toks/s]Processed prompts:  87%|████████▋ | 433/500 [24:39<04:05,  3.66s/it, est. speed input: 239.59 toks/s, output: 763.97 toks/s]Processed prompts:  87%|████████▋ | 434/500 [24:40<02:53,  2.64s/it, est. speed input: 239.87 toks/s, output: 764.37 toks/s]Processed prompts:  87%|████████▋ | 435/500 [24:50<05:18,  4.90s/it, est. speed input: 238.39 toks/s, output: 760.88 toks/s]Processed prompts:  87%|████████▋ | 436/500 [24:54<04:55,  4.62s/it, est. speed input: 238.40 toks/s, output: 763.91 toks/s]Processed prompts:  87%|████████▋ | 437/500 [25:03<06:25,  6.11s/it, est. speed input: 237.12 toks/s, output: 760.44 toks/s]Processed prompts:  88%|████████▊ | 438/500 [25:04<04:38,  4.49s/it, est. speed input: 237.98 toks/s, output: 762.86 toks/s]Processed prompts:  88%|████████▊ | 439/500 [25:18<07:19,  7.21s/it, est. speed input: 236.01 toks/s, output: 757.46 toks/s]WARNING 04-04 10:06:23 scheduler.py:1555] Sequence group 495 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  88%|████████▊ | 440/500 [25:26<07:30,  7.51s/it, est. speed input: 235.44 toks/s, output: 755.28 toks/s]Processed prompts:  88%|████████▊ | 441/500 [25:27<05:33,  5.65s/it, est. speed input: 235.41 toks/s, output: 756.24 toks/s]Processed prompts:  88%|████████▊ | 442/500 [25:31<04:56,  5.12s/it, est. speed input: 235.32 toks/s, output: 756.97 toks/s]Processed prompts:  89%|████████▉ | 444/500 [25:31<02:40,  2.86s/it, est. speed input: 235.96 toks/s, output: 759.08 toks/s]Processed prompts:  89%|████████▉ | 445/500 [25:33<02:27,  2.67s/it, est. speed input: 235.83 toks/s, output: 762.37 toks/s]Processed prompts:  89%|████████▉ | 446/500 [25:36<02:22,  2.64s/it, est. speed input: 235.63 toks/s, output: 762.76 toks/s]Processed prompts:  89%|████████▉ | 447/500 [25:36<01:44,  1.97s/it, est. speed input: 235.92 toks/s, output: 765.09 toks/s]Processed prompts:  90%|████████▉ | 448/500 [25:39<01:54,  2.20s/it, est. speed input: 235.64 toks/s, output: 765.40 toks/s]Processed prompts:  90%|█████████ | 450/500 [25:43<01:41,  2.03s/it, est. speed input: 236.65 toks/s, output: 770.37 toks/s]Processed prompts:  90%|█████████ | 451/500 [25:45<01:40,  2.06s/it, est. speed input: 236.85 toks/s, output: 769.96 toks/s]Processed prompts:  90%|█████████ | 452/500 [25:47<01:36,  2.01s/it, est. speed input: 237.59 toks/s, output: 771.49 toks/s]Processed prompts:  91%|█████████ | 454/500 [25:48<01:08,  1.49s/it, est. speed input: 237.84 toks/s, output: 773.32 toks/s]Processed prompts:  91%|█████████ | 455/500 [25:52<01:27,  1.94s/it, est. speed input: 237.87 toks/s, output: 774.66 toks/s]Processed prompts:  91%|█████████ | 456/500 [25:52<01:12,  1.65s/it, est. speed input: 239.35 toks/s, output: 776.11 toks/s]Processed prompts:  91%|█████████▏| 457/500 [25:54<01:06,  1.54s/it, est. speed input: 239.67 toks/s, output: 777.29 toks/s]Processed prompts:  92%|█████████▏| 458/500 [25:56<01:12,  1.72s/it, est. speed input: 239.72 toks/s, output: 778.39 toks/s]Processed prompts:  92%|█████████▏| 459/500 [25:58<01:13,  1.80s/it, est. speed input: 240.15 toks/s, output: 779.97 toks/s]Processed prompts:  92%|█████████▏| 460/500 [26:03<01:50,  2.77s/it, est. speed input: 239.53 toks/s, output: 779.27 toks/s]Processed prompts:  92%|█████████▏| 461/500 [26:03<01:19,  2.03s/it, est. speed input: 240.28 toks/s, output: 782.57 toks/s]Processed prompts:  92%|█████████▏| 462/500 [26:06<01:27,  2.31s/it, est. speed input: 241.33 toks/s, output: 783.00 toks/s]Processed prompts:  93%|█████████▎| 463/500 [26:09<01:35,  2.58s/it, est. speed input: 241.74 toks/s, output: 783.24 toks/s]Processed prompts:  93%|█████████▎| 464/500 [26:10<01:08,  1.91s/it, est. speed input: 242.02 toks/s, output: 785.00 toks/s]Processed prompts:  93%|█████████▎| 465/500 [26:12<01:05,  1.87s/it, est. speed input: 243.13 toks/s, output: 785.24 toks/s]Processed prompts:  93%|█████████▎| 466/500 [26:12<00:50,  1.49s/it, est. speed input: 243.69 toks/s, output: 786.56 toks/s]Processed prompts:  93%|█████████▎| 467/500 [26:23<02:17,  4.16s/it, est. speed input: 242.51 toks/s, output: 783.44 toks/s]Processed prompts:  94%|█████████▎| 468/500 [26:25<01:59,  3.73s/it, est. speed input: 242.23 toks/s, output: 783.74 toks/s]Processed prompts:  94%|█████████▍| 469/500 [26:30<02:07,  4.13s/it, est. speed input: 242.95 toks/s, output: 786.96 toks/s]Processed prompts:  94%|█████████▍| 470/500 [26:34<01:58,  3.94s/it, est. speed input: 242.57 toks/s, output: 788.35 toks/s]Processed prompts:  94%|█████████▍| 471/500 [26:39<02:05,  4.32s/it, est. speed input: 242.71 toks/s, output: 787.53 toks/s]Processed prompts:  94%|█████████▍| 472/500 [26:42<01:48,  3.87s/it, est. speed input: 243.98 toks/s, output: 789.51 toks/s]Processed prompts:  95%|█████████▍| 473/500 [26:42<01:16,  2.85s/it, est. speed input: 244.17 toks/s, output: 792.23 toks/s]Processed prompts:  95%|█████████▍| 474/500 [26:44<01:03,  2.45s/it, est. speed input: 244.10 toks/s, output: 793.09 toks/s]Processed prompts:  95%|█████████▌| 475/500 [26:54<01:58,  4.76s/it, est. speed input: 243.04 toks/s, output: 790.72 toks/s]Processed prompts:  95%|█████████▌| 476/500 [27:04<02:29,  6.23s/it, est. speed input: 241.87 toks/s, output: 787.94 toks/s]Processed prompts:  95%|█████████▌| 477/500 [27:08<02:09,  5.64s/it, est. speed input: 242.30 toks/s, output: 789.06 toks/s]Processed prompts:  96%|█████████▌| 478/500 [27:10<01:42,  4.64s/it, est. speed input: 242.74 toks/s, output: 790.47 toks/s]Processed prompts:  96%|█████████▌| 479/500 [27:12<01:16,  3.63s/it, est. speed input: 243.00 toks/s, output: 792.40 toks/s]Processed prompts:  96%|█████████▌| 480/500 [27:17<01:24,  4.23s/it, est. speed input: 242.31 toks/s, output: 792.52 toks/s]Processed prompts:  96%|█████████▌| 481/500 [27:23<01:31,  4.81s/it, est. speed input: 241.95 toks/s, output: 791.13 toks/s]Processed prompts:  96%|█████████▋| 482/500 [27:30<01:37,  5.41s/it, est. speed input: 241.18 toks/s, output: 790.93 toks/s]Processed prompts:  97%|█████████▋| 483/500 [27:30<01:05,  3.87s/it, est. speed input: 241.50 toks/s, output: 794.03 toks/s]Processed prompts:  97%|█████████▋| 484/500 [27:34<00:58,  3.65s/it, est. speed input: 241.18 toks/s, output: 794.42 toks/s]Processed prompts:  97%|█████████▋| 485/500 [27:35<00:46,  3.09s/it, est. speed input: 241.14 toks/s, output: 795.55 toks/s]Processed prompts:  97%|█████████▋| 487/500 [27:37<00:27,  2.11s/it, est. speed input: 241.85 toks/s, output: 799.40 toks/s]Processed prompts:  98%|█████████▊| 488/500 [27:38<00:22,  1.85s/it, est. speed input: 242.11 toks/s, output: 801.31 toks/s]Processed prompts:  98%|█████████▊| 489/500 [27:42<00:26,  2.37s/it, est. speed input: 241.70 toks/s, output: 801.87 toks/s]Processed prompts:  98%|█████████▊| 490/500 [27:43<00:19,  1.92s/it, est. speed input: 242.84 toks/s, output: 805.41 toks/s]Processed prompts:  98%|█████████▊| 491/500 [28:02<01:01,  6.86s/it, est. speed input: 240.33 toks/s, output: 799.06 toks/s]Processed prompts:  98%|█████████▊| 492/500 [28:09<00:54,  6.78s/it, est. speed input: 240.04 toks/s, output: 799.17 toks/s]Processed prompts:  99%|█████████▊| 493/500 [28:17<00:50,  7.15s/it, est. speed input: 239.56 toks/s, output: 803.28 toks/s]Processed prompts:  99%|█████████▉| 494/500 [29:00<01:45, 17.58s/it, est. speed input: 234.35 toks/s, output: 787.38 toks/s]Processed prompts:  99%|█████████▉| 495/500 [29:01<01:03, 12.76s/it, est. speed input: 235.39 toks/s, output: 789.49 toks/s]Processed prompts:  99%|█████████▉| 496/500 [29:11<00:48, 12.01s/it, est. speed input: 234.92 toks/s, output: 788.88 toks/s]Processed prompts:  99%|█████████▉| 497/500 [29:20<00:32, 10.99s/it, est. speed input: 234.20 toks/s, output: 789.13 toks/s]Processed prompts: 100%|█████████▉| 498/500 [31:08<01:20, 40.09s/it, est. speed input: 221.34 toks/s, output: 749.67 toks/s]Processed prompts: 100%|█████████▉| 499/500 [33:18<01:06, 66.71s/it, est. speed input: 208.26 toks/s, output: 708.14 toks/s]Processed prompts: 100%|██████████| 500/500 [37:18<00:00, 118.62s/it, est. speed input: 186.52 toks/s, output: 646.78 toks/s]Processed prompts: 100%|██████████| 500/500 [37:18<00:00,  4.48s/it, est. speed input: 186.52 toks/s, output: 646.78 toks/s] 
INFO 04-04 10:18:17 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2027050)[0;0m INFO 04-04 10:18:17 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2027051)[0;0m INFO 04-04 10:18:17 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2027052)[0;0m INFO 04-04 10:18:17 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W404 10:18:30.919508390 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-04 10:18:46 config.py:510] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 04-04 10:18:47 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-04 10:18:47 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-04 10:18:47 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-04 10:18:47 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-04 10:18:47 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-04 10:18:47 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:48 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:48 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:48 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:48 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:48 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:48 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-04 10:18:48 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:49 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-04 10:18:49 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:49 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:49 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-04 10:18:49 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:49 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:49 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:49 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2049410)[0;0m WARNING 04-04 10:18:50 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2049411)[0;0m WARNING 04-04 10:18:50 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2049412)[0;0m WARNING 04-04 10:18:50 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-04 10:18:50 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-04 10:18:50 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_1cf3ad46'), local_subscribe_port=49785, remote_subscribe_port=None)
INFO 04-04 10:18:50 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:50 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:50 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:50 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.39it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.66it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.11it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.90it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.84it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:03<00:04,  1.80it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.76it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.75it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.71it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.70it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.84it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:07<00:00,  1.79it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.78it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.84it/s]

[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:18:58 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:18:58 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:18:58 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-04 10:18:58 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:19:01 worker.py:241] Memory profiling takes 2.61 seconds
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:19:01 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:19:01 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:19:01 worker.py:241] Memory profiling takes 2.62 seconds
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:19:01 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:19:01 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:19:01 worker.py:241] Memory profiling takes 2.65 seconds
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:19:01 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:19:01 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-04 10:19:01 worker.py:241] Memory profiling takes 2.86 seconds
INFO 04-04 10:19:01 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-04 10:19:01 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-04 10:19:01 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-04 10:19:01 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:19:15 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:19:15 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-04 10:19:15 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:19:15 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:39,  1.23s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:34,  1.20s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:27,  1.15s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:27,  1.16s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:23,  1.14s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:23,  1.15s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:08<02:22,  1.15s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:09<02:19,  1.13s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:10<02:16,  1.12s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:11<02:16,  1.13s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:12<02:14,  1.12s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:13<02:14,  1.13s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:14<02:13,  1.13s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:15<02:10,  1.12s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:16<02:08,  1.11s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:18<02:06,  1.10s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:19<02:03,  1.09s/it]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:20<02:03,  1.09s/it]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:21<02:03,  1.10s/it]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:22<02:01,  1.10s/it]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:23<02:00,  1.10s/it]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:24<01:59,  1.10s/it]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:25<01:57,  1.09s/it]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:26<01:54,  1.07s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:27<01:52,  1.06s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:28<01:50,  1.05s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:29<01:50,  1.06s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:30<01:50,  1.07s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:32<01:47,  1.06s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:33<01:45,  1.04s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:34<01:45,  1.06s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:35<01:43,  1.04s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:36<01:41,  1.04s/it]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:37<01:41,  1.05s/it]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:38<01:38,  1.03s/it]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:39<01:37,  1.03s/it]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:40<01:34,  1.00s/it]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:41<01:31,  1.01it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:42<01:32,  1.01s/it]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:43<01:30,  1.01it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:44<01:28,  1.02it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:45<01:27,  1.02it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:46<01:26,  1.02it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:47<01:26,  1.00it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:48<01:24,  1.02it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:49<01:23,  1.01it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:50<01:23,  1.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:51<01:22,  1.00it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:52<01:22,  1.00s/it]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:53<01:21,  1.00s/it]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:54<01:19,  1.00it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:55<01:19,  1.00s/it]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:55<01:16,  1.02it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:56<01:14,  1.04it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:57<01:14,  1.02it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:58<01:12,  1.03it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:59<01:09,  1.06it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [01:00<01:10,  1.04it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [01:01<01:09,  1.04it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [01:02<01:07,  1.05it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:03<01:06,  1.06it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:04<01:04,  1.07it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:05<01:04,  1.06it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:06<01:02,  1.08it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:07<00:59,  1.11it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:08<00:59,  1.10it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:08<00:56,  1.13it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:09<00:56,  1.12it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:10<00:54,  1.13it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:11<00:54,  1.12it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:12<00:52,  1.14it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:13<00:52,  1.13it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:14<00:51,  1.13it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:15<00:49,  1.15it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:15<00:49,  1.13it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:16<00:48,  1.14it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:17<00:47,  1.13it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:18<00:45,  1.15it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:19<00:44,  1.17it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:20<00:43,  1.16it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:21<00:42,  1.18it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:21<00:41,  1.17it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:22<00:39,  1.20it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:23<00:38,  1.22it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:24<00:38,  1.21it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:25<00:37,  1.20it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:26<00:37,  1.19it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:26<00:35,  1.21it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:27<00:35,  1.19it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:28<00:33,  1.22it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:29<00:32,  1.23it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:30<00:31,  1.23it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:30<00:30,  1.24it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:31<00:29,  1.25it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:32<00:29,  1.23it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:33<00:28,  1.23it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:34<00:27,  1.23it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:34<00:26,  1.26it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:35<00:25,  1.28it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:36<00:23,  1.30it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:37<00:23,  1.28it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:38<00:22,  1.27it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:38<00:22,  1.26it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:39<00:21,  1.26it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:40<00:20,  1.27it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:41<00:19,  1.28it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:41<00:18,  1.30it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:42<00:17,  1.29it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:43<00:16,  1.30it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:44<00:16,  1.31it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:44<00:14,  1.33it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:45<00:14,  1.34it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:46<00:13,  1.35it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:47<00:12,  1.32it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:47<00:12,  1.33it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:48<00:11,  1.34it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:49<00:10,  1.32it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:50<00:09,  1.33it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:50<00:08,  1.34it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:51<00:08,  1.34it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:52<00:07,  1.31it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:53<00:06,  1.30it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:54<00:06,  1.31it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:54<00:05,  1.34it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:55<00:04,  1.36it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:56<00:03,  1.38it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:56<00:02,  1.37it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:57<00:02,  1.40it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:58<00:01,  1.36it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:59<00:00,  1.38it/s][1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 10:21:15 model_runner.py:1535] Graph capturing finished in 120 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 10:21:15 model_runner.py:1535] Graph capturing finished in 120 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 10:21:15 model_runner.py:1535] Graph capturing finished in 120 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.22it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.09it/s]
INFO 04-04 10:21:16 model_runner.py:1535] Graph capturing finished in 120 secs, took 8.20 GiB
INFO 04-04 10:21:16 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 137.25 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: connectivity
Generating answers for task: connectivity
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-04 10:22:19 scheduler.py:1555] Sequence group 457 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-04 10:22:31 scheduler.py:1555] Sequence group 407 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-04 10:22:44 scheduler.py:1555] Sequence group 357 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   0%|          | 1/500 [01:27<12:05:44, 87.26s/it, est. speed input: 2.34 toks/s, output: 2.01 toks/s]Processed prompts:   0%|          | 2/500 [01:34<5:33:37, 40.20s/it, est. speed input: 4.63 toks/s, output: 4.48 toks/s] Processed prompts:   1%|          | 3/500 [01:37<3:13:20, 23.34s/it, est. speed input: 6.56 toks/s, output: 7.22 toks/s]Processed prompts:   1%|          | 4/500 [01:41<2:08:56, 15.60s/it, est. speed input: 8.39 toks/s, output: 10.19 toks/s]Processed prompts:   1%|          | 5/500 [01:42<1:26:05, 10.44s/it, est. speed input: 10.45 toks/s, output: 12.99 toks/s]Processed prompts:   1%|          | 6/500 [01:43<57:36,  7.00s/it, est. speed input: 12.45 toks/s, output: 16.19 toks/s]  Processed prompts:   2%|▏         | 8/500 [01:44<31:21,  3.82s/it, est. speed input: 17.73 toks/s, output: 22.11 toks/s]Processed prompts:   2%|▏         | 9/500 [01:44<24:09,  2.95s/it, est. speed input: 19.77 toks/s, output: 24.78 toks/s]Processed prompts:   2%|▏         | 10/500 [01:44<17:55,  2.19s/it, est. speed input: 21.68 toks/s, output: 27.53 toks/s]WARNING 04-04 10:23:03 scheduler.py:1555] Sequence group 306 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:   2%|▏         | 11/500 [01:45<15:03,  1.85s/it, est. speed input: 23.81 toks/s, output: 30.32 toks/s]Processed prompts:   2%|▏         | 12/500 [01:46<11:27,  1.41s/it, est. speed input: 25.72 toks/s, output: 33.48 toks/s]Processed prompts:   3%|▎         | 13/500 [01:46<08:52,  1.09s/it, est. speed input: 31.68 toks/s, output: 36.72 toks/s]Processed prompts:   3%|▎         | 14/500 [01:47<08:07,  1.00s/it, est. speed input: 33.74 toks/s, output: 39.66 toks/s]Processed prompts:   3%|▎         | 15/500 [01:48<09:04,  1.12s/it, est. speed input: 35.35 toks/s, output: 42.24 toks/s]Processed prompts:   3%|▎         | 16/500 [01:49<07:51,  1.03it/s, est. speed input: 37.40 toks/s, output: 45.48 toks/s]Processed prompts:   3%|▎         | 17/500 [01:50<08:05,  1.01s/it, est. speed input: 39.20 toks/s, output: 48.39 toks/s]Processed prompts:   4%|▎         | 18/500 [01:50<06:02,  1.33it/s, est. speed input: 41.16 toks/s, output: 51.77 toks/s]Processed prompts:   4%|▍         | 19/500 [01:50<04:58,  1.61it/s, est. speed input: 42.99 toks/s, output: 55.02 toks/s]Processed prompts:   4%|▍         | 20/500 [01:51<04:57,  1.61it/s, est. speed input: 44.75 toks/s, output: 58.05 toks/s]Processed prompts:   4%|▍         | 21/500 [01:51<03:49,  2.08it/s, est. speed input: 46.57 toks/s, output: 60.98 toks/s]Processed prompts:   4%|▍         | 22/500 [01:51<03:02,  2.62it/s, est. speed input: 49.13 toks/s, output: 64.38 toks/s]Processed prompts:   5%|▍         | 23/500 [01:52<04:40,  1.70it/s, est. speed input: 51.27 toks/s, output: 66.84 toks/s]Processed prompts:   5%|▍         | 24/500 [01:54<06:11,  1.28it/s, est. speed input: 52.83 toks/s, output: 69.36 toks/s]Processed prompts:   5%|▌         | 25/500 [01:54<05:24,  1.47it/s, est. speed input: 54.71 toks/s, output: 72.71 toks/s]Processed prompts:   5%|▌         | 26/500 [01:54<04:29,  1.76it/s, est. speed input: 56.61 toks/s, output: 75.70 toks/s]Processed prompts:   5%|▌         | 27/500 [01:55<04:34,  1.72it/s, est. speed input: 59.30 toks/s, output: 78.55 toks/s]Processed prompts:   6%|▌         | 28/500 [01:55<04:16,  1.84it/s, est. speed input: 60.93 toks/s, output: 81.59 toks/s]Processed prompts:   6%|▌         | 29/500 [01:56<05:06,  1.53it/s, est. speed input: 62.67 toks/s, output: 84.53 toks/s]Processed prompts:   6%|▌         | 30/500 [01:57<04:16,  1.83it/s, est. speed input: 64.35 toks/s, output: 87.45 toks/s]Processed prompts:   6%|▌         | 31/500 [01:57<03:41,  2.11it/s, est. speed input: 65.92 toks/s, output: 90.92 toks/s]Processed prompts:   6%|▋         | 32/500 [01:58<05:44,  1.36it/s, est. speed input: 67.97 toks/s, output: 93.51 toks/s]Processed prompts:   7%|▋         | 33/500 [02:01<10:09,  1.31s/it, est. speed input: 68.18 toks/s, output: 94.90 toks/s]Processed prompts:   7%|▋         | 34/500 [02:03<12:39,  1.63s/it, est. speed input: 68.75 toks/s, output: 96.69 toks/s]Processed prompts:   7%|▋         | 35/500 [02:04<10:46,  1.39s/it, est. speed input: 70.65 toks/s, output: 99.91 toks/s]Processed prompts:   7%|▋         | 36/500 [02:05<09:45,  1.26s/it, est. speed input: 71.83 toks/s, output: 102.85 toks/s]Processed prompts:   8%|▊         | 38/500 [02:06<06:12,  1.24it/s, est. speed input: 75.66 toks/s, output: 109.78 toks/s]Processed prompts:   8%|▊         | 39/500 [02:06<05:10,  1.48it/s, est. speed input: 78.61 toks/s, output: 113.36 toks/s]Processed prompts:   8%|▊         | 40/500 [02:06<04:05,  1.87it/s, est. speed input: 80.37 toks/s, output: 116.94 toks/s]Processed prompts:   8%|▊         | 41/500 [02:07<04:07,  1.86it/s, est. speed input: 82.86 toks/s, output: 120.12 toks/s]Processed prompts:   8%|▊         | 42/500 [02:08<06:26,  1.18it/s, est. speed input: 83.58 toks/s, output: 122.14 toks/s]Processed prompts:   9%|▊         | 43/500 [02:10<08:41,  1.14s/it, est. speed input: 85.18 toks/s, output: 124.30 toks/s]Processed prompts:   9%|▉         | 44/500 [02:14<14:22,  1.89s/it, est. speed input: 84.87 toks/s, output: 124.88 toks/s]Processed prompts:   9%|▉         | 45/500 [02:15<11:54,  1.57s/it, est. speed input: 86.41 toks/s, output: 128.07 toks/s]Processed prompts:   9%|▉         | 46/500 [02:19<17:25,  2.30s/it, est. speed input: 88.29 toks/s, output: 128.50 toks/s]Processed prompts:   9%|▉         | 47/500 [02:19<12:31,  1.66s/it, est. speed input: 90.14 toks/s, output: 132.32 toks/s]Processed prompts:  10%|▉         | 48/500 [02:20<10:32,  1.40s/it, est. speed input: 95.13 toks/s, output: 135.60 toks/s]Processed prompts:  10%|▉         | 49/500 [02:20<07:40,  1.02s/it, est. speed input: 97.30 toks/s, output: 139.48 toks/s]Processed prompts:  10%|█         | 50/500 [02:20<06:14,  1.20it/s, est. speed input: 99.25 toks/s, output: 143.11 toks/s]Processed prompts:  10%|█         | 51/500 [02:20<04:38,  1.61it/s, est. speed input: 101.38 toks/s, output: 147.09 toks/s]Processed prompts:  11%|█         | 53/500 [02:21<03:11,  2.33it/s, est. speed input: 104.91 toks/s, output: 154.77 toks/s]Processed prompts:  11%|█         | 54/500 [02:22<05:37,  1.32it/s, est. speed input: 105.68 toks/s, output: 157.20 toks/s]Processed prompts:  11%|█         | 56/500 [02:23<04:37,  1.60it/s, est. speed input: 108.54 toks/s, output: 164.68 toks/s]Processed prompts:  11%|█▏        | 57/500 [02:23<03:59,  1.85it/s, est. speed input: 111.87 toks/s, output: 168.55 toks/s]Processed prompts:  12%|█▏        | 58/500 [02:24<03:27,  2.14it/s, est. speed input: 113.59 toks/s, output: 172.24 toks/s]Processed prompts:  12%|█▏        | 59/500 [02:24<02:47,  2.64it/s, est. speed input: 116.01 toks/s, output: 176.45 toks/s]Processed prompts:  12%|█▏        | 60/500 [02:25<04:43,  1.55it/s, est. speed input: 117.06 toks/s, output: 179.11 toks/s]Processed prompts:  12%|█▏        | 61/500 [02:27<07:41,  1.05s/it, est. speed input: 116.98 toks/s, output: 180.65 toks/s]Processed prompts:  12%|█▏        | 62/500 [02:29<09:50,  1.35s/it, est. speed input: 116.91 toks/s, output: 182.42 toks/s]Processed prompts:  13%|█▎        | 63/500 [02:31<10:45,  1.48s/it, est. speed input: 117.06 toks/s, output: 184.80 toks/s]Processed prompts:  13%|█▎        | 64/500 [02:32<08:21,  1.15s/it, est. speed input: 118.60 toks/s, output: 188.66 toks/s]WARNING 04-04 10:23:51 scheduler.py:1555] Sequence group 251 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:  13%|█▎        | 65/500 [02:33<09:12,  1.27s/it, est. speed input: 119.74 toks/s, output: 191.31 toks/s]Processed prompts:  13%|█▎        | 66/500 [02:35<10:47,  1.49s/it, est. speed input: 119.97 toks/s, output: 193.23 toks/s]Processed prompts:  13%|█▎        | 67/500 [02:37<12:21,  1.71s/it, est. speed input: 120.21 toks/s, output: 194.94 toks/s]Processed prompts:  14%|█▎        | 68/500 [02:38<10:09,  1.41s/it, est. speed input: 124.04 toks/s, output: 198.68 toks/s]Processed prompts:  14%|█▍        | 69/500 [02:42<15:28,  2.15s/it, est. speed input: 123.55 toks/s, output: 198.65 toks/s]Processed prompts:  14%|█▍        | 70/500 [02:43<13:29,  1.88s/it, est. speed input: 126.23 toks/s, output: 201.81 toks/s]Processed prompts:  14%|█▍        | 71/500 [02:44<10:38,  1.49s/it, est. speed input: 127.59 toks/s, output: 205.93 toks/s]Processed prompts:  14%|█▍        | 72/500 [02:44<07:54,  1.11s/it, est. speed input: 129.05 toks/s, output: 210.42 toks/s]Processed prompts:  15%|█▍        | 73/500 [02:46<08:53,  1.25s/it, est. speed input: 129.94 toks/s, output: 213.09 toks/s]Processed prompts:  15%|█▍        | 74/500 [02:46<06:55,  1.02it/s, est. speed input: 132.41 toks/s, output: 217.43 toks/s]Processed prompts:  15%|█▌        | 75/500 [02:46<05:04,  1.40it/s, est. speed input: 136.62 toks/s, output: 222.10 toks/s]Processed prompts:  15%|█▌        | 76/500 [02:46<03:47,  1.87it/s, est. speed input: 140.56 toks/s, output: 226.67 toks/s]Processed prompts:  15%|█▌        | 77/500 [02:46<03:02,  2.32it/s, est. speed input: 145.46 toks/s, output: 231.21 toks/s]Processed prompts:  16%|█▌        | 78/500 [02:47<03:55,  1.79it/s, est. speed input: 146.11 toks/s, output: 234.91 toks/s]Processed prompts:  16%|█▌        | 79/500 [02:49<06:01,  1.16it/s, est. speed input: 146.58 toks/s, output: 237.54 toks/s]Processed prompts:  16%|█▌        | 80/500 [02:50<06:46,  1.03it/s, est. speed input: 147.08 toks/s, output: 240.77 toks/s]Processed prompts:  16%|█▌        | 81/500 [02:53<12:02,  1.72s/it, est. speed input: 146.23 toks/s, output: 240.79 toks/s]Processed prompts:  17%|█▋        | 83/500 [02:56<09:52,  1.42s/it, est. speed input: 148.43 toks/s, output: 247.53 toks/s]Processed prompts:  17%|█▋        | 84/500 [02:56<08:48,  1.27s/it, est. speed input: 149.71 toks/s, output: 251.39 toks/s]Processed prompts:  17%|█▋        | 85/500 [02:59<10:55,  1.58s/it, est. speed input: 151.45 toks/s, output: 252.87 toks/s]Processed prompts:  17%|█▋        | 86/500 [02:59<08:32,  1.24s/it, est. speed input: 155.36 toks/s, output: 257.53 toks/s]Processed prompts:  17%|█▋        | 87/500 [03:01<09:11,  1.34s/it, est. speed input: 156.55 toks/s, output: 260.38 toks/s]Processed prompts:  18%|█▊        | 88/500 [03:02<09:15,  1.35s/it, est. speed input: 157.91 toks/s, output: 263.46 toks/s]Processed prompts:  18%|█▊        | 89/500 [03:03<07:49,  1.14s/it, est. speed input: 160.13 toks/s, output: 267.67 toks/s]Processed prompts:  18%|█▊        | 91/500 [03:05<07:21,  1.08s/it, est. speed input: 165.35 toks/s, output: 275.01 toks/s]Processed prompts:  18%|█▊        | 92/500 [03:08<10:25,  1.53s/it, est. speed input: 164.25 toks/s, output: 275.94 toks/s]Processed prompts:  19%|█▊        | 93/500 [03:08<07:53,  1.16s/it, est. speed input: 168.37 toks/s, output: 280.97 toks/s]Processed prompts:  19%|█▉        | 94/500 [03:09<07:23,  1.09s/it, est. speed input: 169.28 toks/s, output: 284.97 toks/s]Processed prompts:  19%|█▉        | 95/500 [03:10<07:16,  1.08s/it, est. speed input: 170.23 toks/s, output: 288.79 toks/s]Processed prompts:  19%|█▉        | 96/500 [03:10<05:35,  1.20it/s, est. speed input: 172.97 toks/s, output: 293.67 toks/s]Processed prompts:  19%|█▉        | 97/500 [03:10<04:10,  1.61it/s, est. speed input: 175.03 toks/s, output: 298.92 toks/s]Processed prompts:  20%|█▉        | 98/500 [03:11<04:03,  1.65it/s, est. speed input: 177.75 toks/s, output: 303.44 toks/s]Processed prompts:  20%|█▉        | 99/500 [03:13<06:43,  1.01s/it, est. speed input: 177.78 toks/s, output: 305.65 toks/s]Processed prompts:  20%|██        | 100/500 [03:13<05:57,  1.12it/s, est. speed input: 178.68 toks/s, output: 309.92 toks/s]Processed prompts:  20%|██        | 101/500 [03:15<07:25,  1.12s/it, est. speed input: 181.96 toks/s, output: 312.70 toks/s]Processed prompts:  20%|██        | 102/500 [03:15<05:23,  1.23it/s, est. speed input: 183.49 toks/s, output: 317.94 toks/s]Processed prompts:  21%|██        | 103/500 [03:16<04:47,  1.38it/s, est. speed input: 186.30 toks/s, output: 322.44 toks/s]Processed prompts:  21%|██        | 104/500 [03:18<08:18,  1.26s/it, est. speed input: 187.96 toks/s, output: 323.86 toks/s]Processed prompts:  21%|██        | 105/500 [03:21<11:26,  1.74s/it, est. speed input: 190.07 toks/s, output: 324.76 toks/s]Processed prompts:  21%|██        | 106/500 [03:23<11:25,  1.74s/it, est. speed input: 192.07 toks/s, output: 327.64 toks/s]Processed prompts:  22%|██▏       | 108/500 [03:23<06:16,  1.04it/s, est. speed input: 195.49 toks/s, output: 338.62 toks/s]Processed prompts:  22%|██▏       | 109/500 [03:24<06:58,  1.07s/it, est. speed input: 196.90 toks/s, output: 341.99 toks/s]Processed prompts:  22%|██▏       | 110/500 [03:24<05:18,  1.22it/s, est. speed input: 200.47 toks/s, output: 347.47 toks/s]Processed prompts:  22%|██▏       | 111/500 [03:25<05:33,  1.17it/s, est. speed input: 203.45 toks/s, output: 351.03 toks/s]Processed prompts:  22%|██▏       | 112/500 [03:25<04:10,  1.55it/s, est. speed input: 205.27 toks/s, output: 356.59 toks/s]Processed prompts:  23%|██▎       | 113/500 [03:27<05:55,  1.09it/s, est. speed input: 208.07 toks/s, output: 358.27 toks/s]Processed prompts:  23%|██▎       | 114/500 [03:29<09:01,  1.40s/it, est. speed input: 209.01 toks/s, output: 359.41 toks/s]Processed prompts:  23%|██▎       | 115/500 [03:30<08:06,  1.26s/it, est. speed input: 211.34 toks/s, output: 363.54 toks/s]Processed prompts:  23%|██▎       | 116/500 [03:31<06:17,  1.02it/s, est. speed input: 213.05 toks/s, output: 368.79 toks/s]Processed prompts:  23%|██▎       | 117/500 [03:31<05:11,  1.23it/s, est. speed input: 214.42 toks/s, output: 373.84 toks/s]Processed prompts:  24%|██▎       | 118/500 [03:31<04:07,  1.55it/s, est. speed input: 217.77 toks/s, output: 379.05 toks/s]Processed prompts:  24%|██▍       | 119/500 [03:32<03:43,  1.71it/s, est. speed input: 218.74 toks/s, output: 384.05 toks/s]Processed prompts:  24%|██▍       | 120/500 [03:33<04:56,  1.28it/s, est. speed input: 219.29 toks/s, output: 387.57 toks/s]Processed prompts:  24%|██▍       | 121/500 [03:35<07:09,  1.13s/it, est. speed input: 219.88 toks/s, output: 389.77 toks/s]Processed prompts:  24%|██▍       | 122/500 [03:36<06:12,  1.02it/s, est. speed input: 222.03 toks/s, output: 394.39 toks/s]Processed prompts:  25%|██▍       | 123/500 [03:39<09:56,  1.58s/it, est. speed input: 220.87 toks/s, output: 394.83 toks/s]Processed prompts:  25%|██▍       | 124/500 [03:39<07:17,  1.16s/it, est. speed input: 222.51 toks/s, output: 400.30 toks/s]Processed prompts:  25%|██▌       | 125/500 [03:39<05:45,  1.08it/s, est. speed input: 225.40 toks/s, output: 405.56 toks/s]Processed prompts:  25%|██▌       | 126/500 [03:40<05:16,  1.18it/s, est. speed input: 227.54 toks/s, output: 410.23 toks/s]Processed prompts:  25%|██▌       | 127/500 [03:40<04:45,  1.31it/s, est. speed input: 231.72 toks/s, output: 415.11 toks/s]Processed prompts:  26%|██▌       | 128/500 [03:42<05:17,  1.17it/s, est. speed input: 235.00 toks/s, output: 419.01 toks/s]Processed prompts:  26%|██▌       | 129/500 [03:43<07:01,  1.14s/it, est. speed input: 235.04 toks/s, output: 421.71 toks/s]Processed prompts:  26%|██▌       | 130/500 [03:47<11:33,  1.87s/it, est. speed input: 234.06 toks/s, output: 421.16 toks/s]Processed prompts:  26%|██▌       | 131/500 [03:48<09:12,  1.50s/it, est. speed input: 234.71 toks/s, output: 426.13 toks/s]Processed prompts:  26%|██▋       | 132/500 [03:50<10:20,  1.69s/it, est. speed input: 234.87 toks/s, output: 428.42 toks/s]Processed prompts:  27%|██▋       | 134/500 [03:52<08:19,  1.36s/it, est. speed input: 236.92 toks/s, output: 437.20 toks/s]Processed prompts:  27%|██▋       | 135/500 [03:52<07:02,  1.16s/it, est. speed input: 238.84 toks/s, output: 442.36 toks/s]Processed prompts:  27%|██▋       | 136/500 [03:52<05:27,  1.11it/s, est. speed input: 240.63 toks/s, output: 448.30 toks/s]Processed prompts:  27%|██▋       | 137/500 [03:55<08:07,  1.34s/it, est. speed input: 239.52 toks/s, output: 449.69 toks/s]Processed prompts:  28%|██▊       | 138/500 [03:56<08:21,  1.39s/it, est. speed input: 240.36 toks/s, output: 451.45 toks/s]Processed prompts:  28%|██▊       | 139/500 [04:00<11:30,  1.91s/it, est. speed input: 239.18 toks/s, output: 451.73 toks/s]Processed prompts:  28%|██▊       | 140/500 [04:00<08:54,  1.48s/it, est. speed input: 241.22 toks/s, output: 457.27 toks/s]Processed prompts:  28%|██▊       | 141/500 [04:03<11:41,  1.95s/it, est. speed input: 241.02 toks/s, output: 457.98 toks/s]Processed prompts:  28%|██▊       | 142/500 [04:04<09:44,  1.63s/it, est. speed input: 241.77 toks/s, output: 462.83 toks/s]Processed prompts:  29%|██▊       | 143/500 [04:04<07:04,  1.19s/it, est. speed input: 243.46 toks/s, output: 469.03 toks/s]Processed prompts:  29%|██▉       | 144/500 [04:05<06:13,  1.05s/it, est. speed input: 246.25 toks/s, output: 471.81 toks/s]Processed prompts:  29%|██▉       | 145/500 [04:06<05:34,  1.06it/s, est. speed input: 248.06 toks/s, output: 476.89 toks/s]Processed prompts:  29%|██▉       | 146/500 [04:07<06:35,  1.12s/it, est. speed input: 247.95 toks/s, output: 480.35 toks/s]Processed prompts:  29%|██▉       | 147/500 [04:08<05:31,  1.07it/s, est. speed input: 249.99 toks/s, output: 485.80 toks/s]Processed prompts:  30%|██▉       | 148/500 [04:09<06:53,  1.18s/it, est. speed input: 249.59 toks/s, output: 488.86 toks/s]Processed prompts:  30%|██▉       | 149/500 [04:11<07:32,  1.29s/it, est. speed input: 251.82 toks/s, output: 492.35 toks/s]Processed prompts:  30%|███       | 150/500 [04:12<07:14,  1.24s/it, est. speed input: 253.28 toks/s, output: 496.82 toks/s]Processed prompts:  30%|███       | 151/500 [04:13<07:05,  1.22s/it, est. speed input: 254.54 toks/s, output: 501.05 toks/s]Processed prompts:  30%|███       | 152/500 [04:13<05:29,  1.06it/s, est. speed input: 257.00 toks/s, output: 507.07 toks/s]Processed prompts:  31%|███       | 153/500 [04:16<08:44,  1.51s/it, est. speed input: 256.31 toks/s, output: 508.06 toks/s]Processed prompts:  31%|███       | 154/500 [04:18<09:03,  1.57s/it, est. speed input: 256.65 toks/s, output: 511.42 toks/s]Processed prompts:  31%|███       | 155/500 [04:19<07:39,  1.33s/it, est. speed input: 258.60 toks/s, output: 516.69 toks/s]Processed prompts:  31%|███       | 156/500 [04:19<06:18,  1.10s/it, est. speed input: 260.71 toks/s, output: 522.21 toks/s]Processed prompts:  31%|███▏      | 157/500 [04:20<05:04,  1.13it/s, est. speed input: 262.72 toks/s, output: 528.16 toks/s]Processed prompts:  32%|███▏      | 158/500 [04:22<06:53,  1.21s/it, est. speed input: 263.05 toks/s, output: 531.02 toks/s]Processed prompts:  32%|███▏      | 159/500 [04:22<05:58,  1.05s/it, est. speed input: 264.20 toks/s, output: 536.28 toks/s]Processed prompts:  32%|███▏      | 160/500 [04:24<07:13,  1.28s/it, est. speed input: 264.03 toks/s, output: 539.42 toks/s]Processed prompts:  32%|███▏      | 161/500 [04:25<06:38,  1.18s/it, est. speed input: 266.00 toks/s, output: 540.82 toks/s]Processed prompts:  32%|███▏      | 162/500 [04:26<05:35,  1.01it/s, est. speed input: 268.67 toks/s, output: 546.56 toks/s]Processed prompts:  33%|███▎      | 163/500 [04:30<10:25,  1.86s/it, est. speed input: 267.23 toks/s, output: 545.60 toks/s]Processed prompts:  33%|███▎      | 164/500 [04:32<11:21,  2.03s/it, est. speed input: 268.36 toks/s, output: 547.52 toks/s]Processed prompts:  33%|███▎      | 165/500 [04:32<08:47,  1.57s/it, est. speed input: 271.10 toks/s, output: 553.46 toks/s]Processed prompts:  33%|███▎      | 166/500 [04:34<08:15,  1.48s/it, est. speed input: 272.66 toks/s, output: 557.81 toks/s]Processed prompts:  33%|███▎      | 167/500 [04:34<05:59,  1.08s/it, est. speed input: 275.46 toks/s, output: 564.39 toks/s]Processed prompts:  34%|███▎      | 168/500 [04:36<08:25,  1.52s/it, est. speed input: 274.91 toks/s, output: 566.20 toks/s]Processed prompts:  34%|███▍      | 169/500 [04:37<06:34,  1.19s/it, est. speed input: 275.59 toks/s, output: 572.21 toks/s]Processed prompts:  34%|███▍      | 170/500 [04:38<06:38,  1.21s/it, est. speed input: 276.07 toks/s, output: 575.13 toks/s]Processed prompts:  34%|███▍      | 171/500 [04:43<11:52,  2.17s/it, est. speed input: 274.31 toks/s, output: 573.29 toks/s]Processed prompts:  34%|███▍      | 172/500 [04:43<08:39,  1.58s/it, est. speed input: 276.26 toks/s, output: 579.95 toks/s]Processed prompts:  35%|███▍      | 173/500 [04:45<09:02,  1.66s/it, est. speed input: 277.00 toks/s, output: 580.74 toks/s]Processed prompts:  35%|███▍      | 174/500 [04:46<07:49,  1.44s/it, est. speed input: 277.32 toks/s, output: 582.03 toks/s]Processed prompts:  35%|███▌      | 175/500 [04:51<14:43,  2.72s/it, est. speed input: 273.33 toks/s, output: 577.75 toks/s]Processed prompts:  35%|███▌      | 176/500 [04:52<10:57,  2.03s/it, est. speed input: 276.34 toks/s, output: 584.10 toks/s]Processed prompts:  35%|███▌      | 177/500 [04:53<09:05,  1.69s/it, est. speed input: 277.60 toks/s, output: 589.49 toks/s]Processed prompts:  36%|███▌      | 178/500 [04:55<10:34,  1.97s/it, est. speed input: 276.90 toks/s, output: 591.41 toks/s]Processed prompts:  36%|███▌      | 179/500 [04:57<09:46,  1.83s/it, est. speed input: 276.92 toks/s, output: 595.70 toks/s]Processed prompts:  36%|███▌      | 180/500 [05:03<16:32,  3.10s/it, est. speed input: 273.41 toks/s, output: 591.14 toks/s]Processed prompts:  36%|███▌      | 181/500 [05:03<12:43,  2.39s/it, est. speed input: 274.25 toks/s, output: 596.99 toks/s]Processed prompts:  36%|███▋      | 182/500 [05:05<11:55,  2.25s/it, est. speed input: 274.11 toks/s, output: 600.71 toks/s]Processed prompts:  37%|███▋      | 183/500 [05:07<10:10,  1.93s/it, est. speed input: 275.36 toks/s, output: 605.92 toks/s]Processed prompts:  37%|███▋      | 184/500 [05:09<11:23,  2.16s/it, est. speed input: 275.57 toks/s, output: 608.06 toks/s]Processed prompts:  37%|███▋      | 185/500 [05:11<10:22,  1.98s/it, est. speed input: 275.60 toks/s, output: 612.54 toks/s]Processed prompts:  37%|███▋      | 186/500 [05:11<07:26,  1.42s/it, est. speed input: 277.58 toks/s, output: 619.70 toks/s]Processed prompts:  37%|███▋      | 187/500 [05:13<08:00,  1.54s/it, est. speed input: 276.77 toks/s, output: 620.08 toks/s]Processed prompts:  38%|███▊      | 188/500 [05:14<07:07,  1.37s/it, est. speed input: 277.19 toks/s, output: 625.57 toks/s]Processed prompts:  38%|███▊      | 189/500 [05:16<08:44,  1.69s/it, est. speed input: 276.11 toks/s, output: 628.38 toks/s]Processed prompts:  38%|███▊      | 190/500 [05:19<11:00,  2.13s/it, est. speed input: 275.82 toks/s, output: 629.71 toks/s]Processed prompts:  38%|███▊      | 191/500 [05:24<15:34,  3.03s/it, est. speed input: 273.35 toks/s, output: 627.55 toks/s]Processed prompts:  38%|███▊      | 192/500 [05:26<12:51,  2.50s/it, est. speed input: 273.65 toks/s, output: 632.70 toks/s]Processed prompts:  39%|███▊      | 193/500 [05:29<13:32,  2.65s/it, est. speed input: 273.06 toks/s, output: 634.65 toks/s]Processed prompts:  39%|███▉      | 194/500 [05:30<11:14,  2.20s/it, est. speed input: 273.28 toks/s, output: 640.21 toks/s]Processed prompts:  39%|███▉      | 195/500 [05:32<10:30,  2.07s/it, est. speed input: 273.59 toks/s, output: 642.16 toks/s]Processed prompts:  39%|███▉      | 196/500 [05:33<08:46,  1.73s/it, est. speed input: 274.68 toks/s, output: 648.16 toks/s]Processed prompts:  39%|███▉      | 197/500 [05:37<13:29,  2.67s/it, est. speed input: 272.74 toks/s, output: 646.65 toks/s]Processed prompts:  40%|███▉      | 198/500 [05:39<11:32,  2.29s/it, est. speed input: 274.45 toks/s, output: 651.87 toks/s]Processed prompts:  40%|███▉      | 199/500 [05:40<10:04,  2.01s/it, est. speed input: 275.13 toks/s, output: 657.11 toks/s]Processed prompts:  40%|████      | 200/500 [05:41<08:01,  1.60s/it, est. speed input: 276.84 toks/s, output: 663.76 toks/s]WARNING 04-04 10:27:03 scheduler.py:1555] Sequence group 281 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:  40%|████      | 201/500 [05:52<21:45,  4.37s/it, est. speed input: 269.57 toks/s, output: 651.43 toks/s]Processed prompts:  40%|████      | 202/500 [05:52<16:10,  3.26s/it, est. speed input: 270.58 toks/s, output: 658.16 toks/s]Processed prompts:  41%|████      | 203/500 [05:59<20:54,  4.23s/it, est. speed input: 266.79 toks/s, output: 654.38 toks/s]Processed prompts:  41%|████      | 204/500 [06:00<15:41,  3.18s/it, est. speed input: 267.65 toks/s, output: 661.13 toks/s]Processed prompts:  41%|████      | 205/500 [06:00<12:12,  2.48s/it, est. speed input: 268.71 toks/s, output: 667.70 toks/s]Processed prompts:  41%|████▏     | 207/500 [06:02<08:45,  1.79s/it, est. speed input: 270.48 toks/s, output: 680.22 toks/s]Processed prompts:  42%|████▏     | 208/500 [06:03<07:30,  1.54s/it, est. speed input: 271.63 toks/s, output: 686.86 toks/s]Processed prompts:  42%|████▏     | 209/500 [06:08<11:28,  2.37s/it, est. speed input: 269.43 toks/s, output: 686.22 toks/s]Processed prompts:  42%|████▏     | 210/500 [06:08<08:41,  1.80s/it, est. speed input: 270.02 toks/s, output: 686.96 toks/s]Processed prompts:  42%|████▏     | 211/500 [06:08<06:40,  1.39s/it, est. speed input: 270.66 toks/s, output: 694.46 toks/s]Processed prompts:  42%|████▏     | 212/500 [06:10<06:20,  1.32s/it, est. speed input: 271.15 toks/s, output: 697.33 toks/s]Processed prompts:  43%|████▎     | 213/500 [06:16<14:02,  2.93s/it, est. speed input: 267.24 toks/s, output: 689.93 toks/s]Processed prompts:  43%|████▎     | 214/500 [06:28<26:20,  5.53s/it, est. speed input: 259.80 toks/s, output: 674.87 toks/s]Processed prompts:  43%|████▎     | 215/500 [06:36<29:19,  6.18s/it, est. speed input: 255.73 toks/s, output: 670.13 toks/s]Processed prompts:  43%|████▎     | 216/500 [06:51<41:38,  8.80s/it, est. speed input: 247.38 toks/s, output: 654.26 toks/s]Processed prompts:  43%|████▎     | 217/500 [06:53<31:15,  6.63s/it, est. speed input: 247.88 toks/s, output: 660.46 toks/s]Processed prompts:  44%|████▎     | 218/500 [06:54<23:25,  4.98s/it, est. speed input: 248.70 toks/s, output: 664.42 toks/s]Processed prompts:  44%|████▍     | 219/500 [07:01<26:35,  5.68s/it, est. speed input: 246.18 toks/s, output: 661.57 toks/s]Processed prompts:  44%|████▍     | 220/500 [07:03<21:58,  4.71s/it, est. speed input: 246.14 toks/s, output: 666.47 toks/s]Processed prompts:  44%|████▍     | 221/500 [07:06<19:22,  4.17s/it, est. speed input: 246.44 toks/s, output: 666.87 toks/s]Processed prompts:  44%|████▍     | 222/500 [07:08<15:40,  3.38s/it, est. speed input: 246.70 toks/s, output: 669.65 toks/s]Processed prompts:  45%|████▍     | 223/500 [07:19<26:41,  5.78s/it, est. speed input: 242.51 toks/s, output: 661.15 toks/s]Processed prompts:  45%|████▍     | 224/500 [07:27<29:17,  6.37s/it, est. speed input: 239.63 toks/s, output: 658.63 toks/s]Processed prompts:  45%|████▌     | 225/500 [07:36<32:23,  7.07s/it, est. speed input: 236.22 toks/s, output: 653.16 toks/s]Processed prompts:  45%|████▌     | 226/500 [07:47<38:34,  8.45s/it, est. speed input: 232.77 toks/s, output: 645.94 toks/s]Processed prompts:  45%|████▌     | 227/500 [07:50<31:02,  6.82s/it, est. speed input: 233.16 toks/s, output: 650.94 toks/s]Processed prompts:  46%|████▌     | 228/500 [07:53<25:10,  5.55s/it, est. speed input: 233.00 toks/s, output: 656.55 toks/s]Processed prompts:  46%|████▌     | 229/500 [07:53<17:42,  3.92s/it, est. speed input: 233.45 toks/s, output: 662.65 toks/s]Processed prompts:  46%|████▌     | 230/500 [07:55<14:42,  3.27s/it, est. speed input: 234.34 toks/s, output: 669.43 toks/s]Processed prompts:  46%|████▌     | 231/500 [07:59<15:33,  3.47s/it, est. speed input: 234.22 toks/s, output: 673.14 toks/s]Processed prompts:  46%|████▋     | 232/500 [07:59<11:47,  2.64s/it, est. speed input: 235.18 toks/s, output: 680.58 toks/s]Processed prompts:  47%|████▋     | 233/500 [08:00<08:45,  1.97s/it, est. speed input: 236.37 toks/s, output: 689.19 toks/s]Processed prompts:  47%|████▋     | 234/500 [08:02<08:58,  2.03s/it, est. speed input: 236.35 toks/s, output: 693.27 toks/s]Processed prompts:  47%|████▋     | 235/500 [08:09<15:05,  3.42s/it, est. speed input: 235.30 toks/s, output: 693.13 toks/s]Processed prompts:  47%|████▋     | 236/500 [08:14<16:53,  3.84s/it, est. speed input: 233.97 toks/s, output: 695.71 toks/s]Processed prompts:  47%|████▋     | 237/500 [08:14<12:15,  2.80s/it, est. speed input: 234.88 toks/s, output: 704.46 toks/s]Processed prompts:  48%|████▊     | 238/500 [08:15<10:38,  2.44s/it, est. speed input: 235.44 toks/s, output: 711.54 toks/s]Processed prompts:  48%|████▊     | 239/500 [08:19<12:22,  2.85s/it, est. speed input: 234.15 toks/s, output: 708.46 toks/s]Processed prompts:  48%|████▊     | 240/500 [08:20<09:57,  2.30s/it, est. speed input: 234.11 toks/s, output: 707.77 toks/s]Processed prompts:  48%|████▊     | 242/500 [08:22<06:46,  1.58s/it, est. speed input: 235.95 toks/s, output: 724.28 toks/s]WARNING 04-04 10:29:46 scheduler.py:1555] Sequence group 316 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  49%|████▊     | 243/500 [08:29<12:15,  2.86s/it, est. speed input: 234.87 toks/s, output: 724.04 toks/s]Processed prompts:  49%|████▉     | 244/500 [08:29<09:16,  2.17s/it, est. speed input: 236.03 toks/s, output: 731.00 toks/s]Processed prompts:  49%|████▉     | 245/500 [08:38<17:20,  4.08s/it, est. speed input: 233.45 toks/s, output: 727.44 toks/s]Processed prompts:  49%|████▉     | 246/500 [08:42<17:21,  4.10s/it, est. speed input: 233.20 toks/s, output: 728.45 toks/s]Processed prompts:  49%|████▉     | 247/500 [08:45<15:15,  3.62s/it, est. speed input: 232.75 toks/s, output: 726.11 toks/s]Processed prompts:  50%|████▉     | 248/500 [08:46<13:03,  3.11s/it, est. speed input: 233.12 toks/s, output: 732.96 toks/s]Processed prompts:  50%|████▉     | 249/500 [08:49<13:01,  3.12s/it, est. speed input: 232.34 toks/s, output: 729.90 toks/s]Processed prompts:  50%|█████     | 250/500 [08:53<13:31,  3.24s/it, est. speed input: 231.74 toks/s, output: 734.46 toks/s]Processed prompts:  50%|█████     | 251/500 [08:58<15:13,  3.67s/it, est. speed input: 231.83 toks/s, output: 737.61 toks/s]Processed prompts:  50%|█████     | 252/500 [09:02<15:32,  3.76s/it, est. speed input: 231.01 toks/s, output: 741.70 toks/s]Processed prompts:  51%|█████     | 253/500 [09:02<11:46,  2.86s/it, est. speed input: 231.95 toks/s, output: 750.20 toks/s]Processed prompts:  51%|█████     | 254/500 [09:05<11:34,  2.82s/it, est. speed input: 231.98 toks/s, output: 755.96 toks/s]Processed prompts:  51%|█████     | 255/500 [09:11<14:37,  3.58s/it, est. speed input: 232.06 toks/s, output: 751.85 toks/s]Processed prompts:  51%|█████     | 256/500 [09:14<13:55,  3.42s/it, est. speed input: 231.17 toks/s, output: 748.32 toks/s]Processed prompts:  51%|█████▏    | 257/500 [09:14<09:54,  2.45s/it, est. speed input: 231.85 toks/s, output: 757.63 toks/s]Processed prompts:  52%|█████▏    | 258/500 [09:14<07:28,  1.85s/it, est. speed input: 233.04 toks/s, output: 760.75 toks/s]Processed prompts:  52%|█████▏    | 259/500 [09:18<09:20,  2.33s/it, est. speed input: 232.78 toks/s, output: 765.62 toks/s]Processed prompts:  52%|█████▏    | 260/500 [09:19<08:24,  2.10s/it, est. speed input: 232.76 toks/s, output: 765.10 toks/s]Processed prompts:  52%|█████▏    | 262/500 [09:20<05:10,  1.30s/it, est. speed input: 234.54 toks/s, output: 768.43 toks/s]Processed prompts:  53%|█████▎    | 263/500 [09:21<04:34,  1.16s/it, est. speed input: 235.09 toks/s, output: 769.33 toks/s]Processed prompts:  53%|█████▎    | 264/500 [09:21<04:06,  1.04s/it, est. speed input: 235.33 toks/s, output: 769.04 toks/s]Processed prompts:  53%|█████▎    | 265/500 [09:28<10:14,  2.61s/it, est. speed input: 233.29 toks/s, output: 766.13 toks/s]Processed prompts:  53%|█████▎    | 266/500 [09:30<08:45,  2.24s/it, est. speed input: 233.44 toks/s, output: 766.22 toks/s]Processed prompts:  53%|█████▎    | 267/500 [09:30<07:14,  1.87s/it, est. speed input: 233.47 toks/s, output: 767.01 toks/s]Processed prompts:  54%|█████▎    | 268/500 [09:35<10:04,  2.61s/it, est. speed input: 232.27 toks/s, output: 770.18 toks/s]Processed prompts:  54%|█████▍    | 269/500 [09:35<07:30,  1.95s/it, est. speed input: 232.72 toks/s, output: 770.76 toks/s]Processed prompts:  54%|█████▍    | 270/500 [09:43<14:37,  3.82s/it, est. speed input: 231.31 toks/s, output: 769.40 toks/s]Processed prompts:  54%|█████▍    | 271/500 [09:45<12:13,  3.20s/it, est. speed input: 231.61 toks/s, output: 776.66 toks/s]Processed prompts:  54%|█████▍    | 272/500 [09:50<13:56,  3.67s/it, est. speed input: 230.31 toks/s, output: 771.63 toks/s]Processed prompts:  55%|█████▍    | 273/500 [09:52<12:21,  3.27s/it, est. speed input: 230.30 toks/s, output: 778.20 toks/s]Processed prompts:  55%|█████▍    | 274/500 [09:53<09:15,  2.46s/it, est. speed input: 231.06 toks/s, output: 787.03 toks/s]WARNING 04-04 10:31:18 scheduler.py:1555] Sequence group 364 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  55%|█████▌    | 275/500 [10:02<16:23,  4.37s/it, est. speed input: 228.22 toks/s, output: 776.61 toks/s]Processed prompts:  55%|█████▌    | 276/500 [10:05<14:46,  3.96s/it, est. speed input: 228.08 toks/s, output: 782.43 toks/s]Processed prompts:  55%|█████▌    | 277/500 [10:05<10:33,  2.84s/it, est. speed input: 229.23 toks/s, output: 788.72 toks/s]Processed prompts:  56%|█████▌    | 278/500 [10:08<10:14,  2.77s/it, est. speed input: 229.46 toks/s, output: 787.75 toks/s]Processed prompts:  56%|█████▌    | 279/500 [10:12<12:28,  3.39s/it, est. speed input: 229.27 toks/s, output: 787.15 toks/s]Processed prompts:  56%|█████▌    | 280/500 [10:15<11:34,  3.16s/it, est. speed input: 229.02 toks/s, output: 786.84 toks/s]Processed prompts:  56%|█████▌    | 281/500 [10:16<08:36,  2.36s/it, est. speed input: 229.81 toks/s, output: 788.20 toks/s]Processed prompts:  56%|█████▋    | 282/500 [10:20<10:27,  2.88s/it, est. speed input: 229.17 toks/s, output: 785.53 toks/s]Processed prompts:  57%|█████▋    | 283/500 [10:20<07:28,  2.07s/it, est. speed input: 229.78 toks/s, output: 787.01 toks/s]Processed prompts:  57%|█████▋    | 284/500 [10:24<09:29,  2.64s/it, est. speed input: 229.11 toks/s, output: 784.63 toks/s]Processed prompts:  57%|█████▋    | 285/500 [10:29<12:11,  3.40s/it, est. speed input: 227.88 toks/s, output: 780.02 toks/s]Processed prompts:  57%|█████▋    | 286/500 [10:30<10:04,  2.82s/it, est. speed input: 228.67 toks/s, output: 787.87 toks/s]Processed prompts:  57%|█████▋    | 287/500 [10:31<08:00,  2.25s/it, est. speed input: 228.95 toks/s, output: 789.61 toks/s]Processed prompts:  58%|█████▊    | 288/500 [10:33<06:51,  1.94s/it, est. speed input: 229.22 toks/s, output: 796.22 toks/s]Processed prompts:  58%|█████▊    | 289/500 [10:37<09:19,  2.65s/it, est. speed input: 228.32 toks/s, output: 792.83 toks/s]Processed prompts:  58%|█████▊    | 290/500 [10:38<07:55,  2.26s/it, est. speed input: 228.92 toks/s, output: 793.11 toks/s]Processed prompts:  58%|█████▊    | 291/500 [10:39<06:07,  1.76s/it, est. speed input: 229.85 toks/s, output: 802.12 toks/s]Processed prompts:  58%|█████▊    | 292/500 [10:42<07:07,  2.06s/it, est. speed input: 229.82 toks/s, output: 801.73 toks/s]Processed prompts:  59%|█████▊    | 293/500 [10:44<07:32,  2.19s/it, est. speed input: 229.72 toks/s, output: 805.49 toks/s]Processed prompts:  59%|█████▉    | 294/500 [10:46<07:16,  2.12s/it, est. speed input: 229.83 toks/s, output: 804.81 toks/s]Processed prompts:  59%|█████▉    | 295/500 [10:56<15:45,  4.61s/it, est. speed input: 227.71 toks/s, output: 801.79 toks/s]Processed prompts:  59%|█████▉    | 296/500 [10:59<13:16,  3.91s/it, est. speed input: 227.28 toks/s, output: 799.66 toks/s]Processed prompts:  59%|█████▉    | 297/500 [11:05<15:18,  4.52s/it, est. speed input: 225.58 toks/s, output: 793.21 toks/s]Processed prompts:  60%|█████▉    | 298/500 [11:05<11:29,  3.41s/it, est. speed input: 226.11 toks/s, output: 795.36 toks/s]Processed prompts:  60%|█████▉    | 299/500 [11:07<09:44,  2.91s/it, est. speed input: 226.02 toks/s, output: 796.57 toks/s]Processed prompts:  60%|██████    | 300/500 [11:08<07:28,  2.24s/it, est. speed input: 226.15 toks/s, output: 799.16 toks/s]Processed prompts:  60%|██████    | 302/500 [11:10<05:13,  1.58s/it, est. speed input: 227.23 toks/s, output: 800.29 toks/s]Processed prompts:  61%|██████    | 303/500 [11:14<07:16,  2.21s/it, est. speed input: 226.84 toks/s, output: 802.10 toks/s]Processed prompts:  61%|██████    | 304/500 [11:16<07:21,  2.25s/it, est. speed input: 226.61 toks/s, output: 801.55 toks/s]Processed prompts:  61%|██████    | 305/500 [11:20<08:28,  2.61s/it, est. speed input: 226.19 toks/s, output: 805.09 toks/s]Processed prompts:  61%|██████    | 306/500 [11:23<09:01,  2.79s/it, est. speed input: 225.82 toks/s, output: 809.14 toks/s]WARNING 04-04 10:32:48 scheduler.py:1555] Sequence group 385 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  61%|██████▏   | 307/500 [11:31<13:51,  4.31s/it, est. speed input: 223.59 toks/s, output: 802.14 toks/s]Processed prompts:  62%|██████▏   | 308/500 [11:34<12:12,  3.81s/it, est. speed input: 223.20 toks/s, output: 800.31 toks/s]Processed prompts:  62%|██████▏   | 309/500 [11:38<12:17,  3.86s/it, est. speed input: 222.93 toks/s, output: 799.26 toks/s]Processed prompts:  62%|██████▏   | 310/500 [11:48<18:19,  5.79s/it, est. speed input: 220.34 toks/s, output: 790.15 toks/s]Processed prompts:  62%|██████▏   | 311/500 [11:50<15:12,  4.83s/it, est. speed input: 220.07 toks/s, output: 788.77 toks/s]Processed prompts:  62%|██████▏   | 312/500 [11:51<10:50,  3.46s/it, est. speed input: 221.29 toks/s, output: 791.50 toks/s]Processed prompts:  63%|██████▎   | 313/500 [11:52<09:12,  2.96s/it, est. speed input: 221.47 toks/s, output: 792.32 toks/s]Processed prompts:  63%|██████▎   | 314/500 [11:56<09:52,  3.19s/it, est. speed input: 220.85 toks/s, output: 790.45 toks/s]Processed prompts:  63%|██████▎   | 315/500 [12:00<10:37,  3.45s/it, est. speed input: 220.34 toks/s, output: 793.31 toks/s]Processed prompts:  63%|██████▎   | 316/500 [12:03<10:15,  3.34s/it, est. speed input: 220.60 toks/s, output: 794.57 toks/s]Processed prompts:  63%|██████▎   | 317/500 [12:04<07:24,  2.43s/it, est. speed input: 221.26 toks/s, output: 796.62 toks/s]Processed prompts:  64%|██████▎   | 318/500 [12:09<09:52,  3.25s/it, est. speed input: 220.35 toks/s, output: 792.68 toks/s]Processed prompts:  64%|██████▍   | 319/500 [12:09<07:05,  2.35s/it, est. speed input: 221.69 toks/s, output: 796.54 toks/s]Processed prompts:  64%|██████▍   | 320/500 [12:11<06:22,  2.13s/it, est. speed input: 221.78 toks/s, output: 799.35 toks/s]Processed prompts:  64%|██████▍   | 321/500 [12:11<04:53,  1.64s/it, est. speed input: 222.29 toks/s, output: 800.46 toks/s]Processed prompts:  64%|██████▍   | 322/500 [12:12<03:52,  1.31s/it, est. speed input: 222.80 toks/s, output: 800.76 toks/s]Processed prompts:  65%|██████▍   | 323/500 [12:23<12:41,  4.30s/it, est. speed input: 219.83 toks/s, output: 792.48 toks/s]Processed prompts:  65%|██████▍   | 324/500 [12:23<09:14,  3.15s/it, est. speed input: 220.31 toks/s, output: 795.38 toks/s]Processed prompts:  65%|██████▌   | 325/500 [12:26<08:18,  2.85s/it, est. speed input: 220.55 toks/s, output: 796.23 toks/s]Processed prompts:  65%|██████▌   | 326/500 [12:26<06:13,  2.15s/it, est. speed input: 221.69 toks/s, output: 805.70 toks/s]Processed prompts:  65%|██████▌   | 327/500 [12:27<05:25,  1.88s/it, est. speed input: 222.63 toks/s, output: 808.09 toks/s]Processed prompts:  66%|██████▌   | 328/500 [12:33<08:43,  3.04s/it, est. speed input: 221.41 toks/s, output: 802.94 toks/s]Processed prompts:  66%|██████▌   | 329/500 [12:41<13:09,  4.62s/it, est. speed input: 220.32 toks/s, output: 795.99 toks/s]Processed prompts:  66%|██████▌   | 330/500 [12:52<18:18,  6.46s/it, est. speed input: 218.07 toks/s, output: 787.83 toks/s]Processed prompts:  66%|██████▌   | 331/500 [13:01<20:09,  7.16s/it, est. speed input: 216.58 toks/s, output: 789.06 toks/s]Processed prompts:  66%|██████▋   | 332/500 [13:03<15:56,  5.69s/it, est. speed input: 217.08 toks/s, output: 796.88 toks/s]Processed prompts:  67%|██████▋   | 333/500 [13:06<13:15,  4.76s/it, est. speed input: 217.36 toks/s, output: 798.19 toks/s]Processed prompts:  67%|██████▋   | 334/500 [13:09<11:54,  4.31s/it, est. speed input: 217.30 toks/s, output: 798.46 toks/s]Processed prompts:  67%|██████▋   | 335/500 [13:16<13:37,  4.95s/it, est. speed input: 216.20 toks/s, output: 797.39 toks/s]WARNING 04-04 10:34:37 scheduler.py:1555] Sequence group 400 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  67%|██████▋   | 336/500 [13:21<13:34,  4.97s/it, est. speed input: 216.50 toks/s, output: 798.05 toks/s]Processed prompts:  67%|██████▋   | 337/500 [13:29<16:01,  5.90s/it, est. speed input: 215.12 toks/s, output: 798.74 toks/s]Processed prompts:  68%|██████▊   | 338/500 [13:40<20:07,  7.46s/it, est. speed input: 212.47 toks/s, output: 790.31 toks/s]Processed prompts:  68%|██████▊   | 339/500 [13:42<16:08,  6.02s/it, est. speed input: 213.16 toks/s, output: 791.09 toks/s]Processed prompts:  68%|██████▊   | 340/500 [13:54<20:31,  7.70s/it, est. speed input: 210.69 toks/s, output: 786.75 toks/s]Processed prompts:  68%|██████▊   | 341/500 [14:03<21:16,  8.03s/it, est. speed input: 208.76 toks/s, output: 784.12 toks/s]Processed prompts:  68%|██████▊   | 342/500 [14:03<15:11,  5.77s/it, est. speed input: 208.92 toks/s, output: 788.56 toks/s]Processed prompts:  69%|██████▊   | 343/500 [14:07<13:35,  5.19s/it, est. speed input: 208.52 toks/s, output: 790.45 toks/s]Processed prompts:  69%|██████▉   | 344/500 [14:09<10:49,  4.16s/it, est. speed input: 208.61 toks/s, output: 797.65 toks/s]Processed prompts:  69%|██████▉   | 345/500 [14:12<10:15,  3.97s/it, est. speed input: 208.36 toks/s, output: 799.59 toks/s]Processed prompts:  69%|██████▉   | 346/500 [14:14<08:34,  3.34s/it, est. speed input: 208.88 toks/s, output: 802.24 toks/s]Processed prompts:  69%|██████▉   | 347/500 [14:19<09:15,  3.63s/it, est. speed input: 208.70 toks/s, output: 803.29 toks/s]Processed prompts:  70%|██████▉   | 348/500 [14:20<07:29,  2.96s/it, est. speed input: 209.25 toks/s, output: 802.77 toks/s]Processed prompts:  70%|██████▉   | 349/500 [14:21<05:41,  2.26s/it, est. speed input: 209.55 toks/s, output: 805.92 toks/s]Processed prompts:  70%|███████   | 350/500 [14:22<05:03,  2.03s/it, est. speed input: 209.80 toks/s, output: 809.05 toks/s]Processed prompts:  70%|███████   | 351/500 [14:28<07:38,  3.08s/it, est. speed input: 209.27 toks/s, output: 809.25 toks/s]Processed prompts:  70%|███████   | 352/500 [14:34<09:52,  4.00s/it, est. speed input: 208.47 toks/s, output: 808.02 toks/s]Processed prompts:  71%|███████   | 353/500 [14:34<06:59,  2.85s/it, est. speed input: 208.83 toks/s, output: 811.27 toks/s]WARNING 04-04 10:36:02 scheduler.py:1555] Sequence group 433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  71%|███████   | 354/500 [14:45<12:34,  5.17s/it, est. speed input: 207.01 toks/s, output: 801.92 toks/s]Processed prompts:  71%|███████   | 355/500 [14:51<13:16,  5.49s/it, est. speed input: 206.38 toks/s, output: 806.63 toks/s]Processed prompts:  71%|███████   | 356/500 [15:04<18:43,  7.80s/it, est. speed input: 204.44 toks/s, output: 805.21 toks/s]Processed prompts:  71%|███████▏  | 357/500 [15:05<14:04,  5.91s/it, est. speed input: 204.38 toks/s, output: 804.58 toks/s]Processed prompts:  72%|███████▏  | 358/500 [15:06<09:54,  4.19s/it, est. speed input: 205.39 toks/s, output: 814.77 toks/s]Processed prompts:  72%|███████▏  | 359/500 [15:08<08:52,  3.78s/it, est. speed input: 205.24 toks/s, output: 812.93 toks/s]Processed prompts:  72%|███████▏  | 360/500 [15:12<08:56,  3.84s/it, est. speed input: 204.99 toks/s, output: 811.22 toks/s]Processed prompts:  72%|███████▏  | 361/500 [15:13<06:27,  2.79s/it, est. speed input: 205.20 toks/s, output: 811.72 toks/s]Processed prompts:  72%|███████▏  | 362/500 [15:14<05:09,  2.25s/it, est. speed input: 205.34 toks/s, output: 811.63 toks/s]Processed prompts:  73%|███████▎  | 363/500 [15:15<04:28,  1.96s/it, est. speed input: 206.02 toks/s, output: 815.41 toks/s]Processed prompts:  73%|███████▎  | 364/500 [15:16<04:02,  1.78s/it, est. speed input: 206.44 toks/s, output: 816.56 toks/s]Processed prompts:  73%|███████▎  | 365/500 [15:21<06:11,  2.75s/it, est. speed input: 206.31 toks/s, output: 814.75 toks/s]Processed prompts:  73%|███████▎  | 366/500 [15:23<05:26,  2.44s/it, est. speed input: 206.19 toks/s, output: 814.16 toks/s]Processed prompts:  74%|███████▎  | 368/500 [15:25<03:38,  1.65s/it, est. speed input: 207.02 toks/s, output: 817.82 toks/s]Processed prompts:  74%|███████▍  | 369/500 [15:26<03:28,  1.59s/it, est. speed input: 207.46 toks/s, output: 816.76 toks/s]Processed prompts:  74%|███████▍  | 370/500 [15:32<05:52,  2.71s/it, est. speed input: 206.75 toks/s, output: 815.06 toks/s]Processed prompts:  74%|███████▍  | 371/500 [15:36<06:26,  2.99s/it, est. speed input: 206.51 toks/s, output: 817.84 toks/s]Processed prompts:  74%|███████▍  | 372/500 [15:42<08:10,  3.83s/it, est. speed input: 206.22 toks/s, output: 818.37 toks/s]WARNING 04-04 10:37:07 scheduler.py:1555] Sequence group 462 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  75%|███████▍  | 374/500 [15:49<08:07,  3.87s/it, est. speed input: 205.50 toks/s, output: 814.88 toks/s]Processed prompts:  75%|███████▌  | 375/500 [15:54<08:12,  3.94s/it, est. speed input: 205.07 toks/s, output: 818.76 toks/s]Processed prompts:  75%|███████▌  | 376/500 [15:57<08:05,  3.91s/it, est. speed input: 204.62 toks/s, output: 816.11 toks/s]Processed prompts:  76%|███████▌  | 378/500 [15:59<05:23,  2.65s/it, est. speed input: 204.75 toks/s, output: 820.68 toks/s]Processed prompts:  76%|███████▌  | 379/500 [16:00<04:23,  2.18s/it, est. speed input: 205.29 toks/s, output: 820.69 toks/s]Processed prompts:  76%|███████▌  | 380/500 [16:01<03:56,  1.97s/it, est. speed input: 205.52 toks/s, output: 820.05 toks/s]Processed prompts:  76%|███████▌  | 381/500 [16:07<05:39,  2.86s/it, est. speed input: 204.65 toks/s, output: 818.05 toks/s]Processed prompts:  76%|███████▋  | 382/500 [16:07<04:18,  2.19s/it, est. speed input: 204.89 toks/s, output: 819.00 toks/s]Processed prompts:  77%|███████▋  | 383/500 [16:08<03:24,  1.74s/it, est. speed input: 205.59 toks/s, output: 819.86 toks/s]Processed prompts:  77%|███████▋  | 384/500 [16:09<03:20,  1.73s/it, est. speed input: 205.64 toks/s, output: 819.76 toks/s]Processed prompts:  77%|███████▋  | 385/500 [16:10<02:52,  1.50s/it, est. speed input: 206.05 toks/s, output: 819.62 toks/s]Processed prompts:  77%|███████▋  | 386/500 [16:13<03:28,  1.83s/it, est. speed input: 205.99 toks/s, output: 821.86 toks/s]Processed prompts:  77%|███████▋  | 387/500 [16:14<03:07,  1.66s/it, est. speed input: 206.08 toks/s, output: 821.46 toks/s]Processed prompts:  78%|███████▊  | 388/500 [16:15<02:33,  1.37s/it, est. speed input: 206.53 toks/s, output: 826.56 toks/s]Processed prompts:  78%|███████▊  | 389/500 [16:19<04:02,  2.19s/it, est. speed input: 206.04 toks/s, output: 824.49 toks/s]Processed prompts:  78%|███████▊  | 390/500 [16:22<04:27,  2.43s/it, est. speed input: 206.06 toks/s, output: 824.23 toks/s]Processed prompts:  78%|███████▊  | 391/500 [16:23<03:39,  2.02s/it, est. speed input: 206.06 toks/s, output: 825.02 toks/s]Processed prompts:  78%|███████▊  | 392/500 [16:27<04:55,  2.73s/it, est. speed input: 206.21 toks/s, output: 822.75 toks/s]Processed prompts:  79%|███████▊  | 393/500 [16:28<03:41,  2.07s/it, est. speed input: 206.51 toks/s, output: 825.45 toks/s]Processed prompts:  79%|███████▉  | 394/500 [16:31<03:58,  2.25s/it, est. speed input: 206.67 toks/s, output: 823.59 toks/s]Processed prompts:  79%|███████▉  | 395/500 [16:41<08:14,  4.71s/it, est. speed input: 205.69 toks/s, output: 820.31 toks/s]Processed prompts:  79%|███████▉  | 396/500 [16:41<05:48,  3.35s/it, est. speed input: 206.07 toks/s, output: 821.78 toks/s]Processed prompts:  79%|███████▉  | 397/500 [16:44<05:20,  3.12s/it, est. speed input: 206.58 toks/s, output: 820.90 toks/s]Processed prompts:  80%|███████▉  | 399/500 [16:46<03:32,  2.10s/it, est. speed input: 207.05 toks/s, output: 826.98 toks/s]Processed prompts:  80%|████████  | 400/500 [16:50<04:37,  2.78s/it, est. speed input: 206.73 toks/s, output: 824.18 toks/s]Processed prompts:  80%|████████  | 401/500 [17:09<11:21,  6.88s/it, est. speed input: 203.61 toks/s, output: 815.63 toks/s]Processed prompts:  80%|████████  | 402/500 [17:10<08:31,  5.22s/it, est. speed input: 204.42 toks/s, output: 816.16 toks/s]WARNING 04-04 10:38:31 scheduler.py:1555] Sequence group 472 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  81%|████████  | 403/500 [17:18<09:58,  6.17s/it, est. speed input: 202.93 toks/s, output: 811.04 toks/s]Processed prompts:  81%|████████  | 404/500 [17:18<07:07,  4.45s/it, est. speed input: 203.86 toks/s, output: 811.70 toks/s]Processed prompts:  81%|████████  | 405/500 [17:23<07:10,  4.53s/it, est. speed input: 203.15 toks/s, output: 809.07 toks/s]Processed prompts:  81%|████████  | 406/500 [17:32<08:58,  5.73s/it, est. speed input: 202.04 toks/s, output: 803.90 toks/s]Processed prompts:  81%|████████▏ | 407/500 [17:33<06:56,  4.47s/it, est. speed input: 202.26 toks/s, output: 804.46 toks/s]Processed prompts:  82%|████████▏ | 408/500 [17:37<06:23,  4.16s/it, est. speed input: 201.92 toks/s, output: 807.67 toks/s]Processed prompts:  82%|████████▏ | 409/500 [17:41<06:14,  4.12s/it, est. speed input: 201.94 toks/s, output: 806.16 toks/s]Processed prompts:  82%|████████▏ | 410/500 [17:42<04:59,  3.33s/it, est. speed input: 202.14 toks/s, output: 810.43 toks/s]Processed prompts:  82%|████████▏ | 411/500 [17:45<04:38,  3.13s/it, est. speed input: 202.17 toks/s, output: 810.18 toks/s]Processed prompts:  82%|████████▏ | 412/500 [17:48<04:41,  3.20s/it, est. speed input: 202.05 toks/s, output: 812.84 toks/s]Processed prompts:  83%|████████▎ | 413/500 [17:49<03:30,  2.42s/it, est. speed input: 202.48 toks/s, output: 821.80 toks/s]Processed prompts:  83%|████████▎ | 414/500 [18:01<07:27,  5.21s/it, est. speed input: 200.73 toks/s, output: 817.87 toks/s]Processed prompts:  83%|████████▎ | 415/500 [18:04<06:47,  4.80s/it, est. speed input: 200.99 toks/s, output: 815.62 toks/s]Processed prompts:  83%|████████▎ | 416/500 [18:28<14:32, 10.39s/it, est. speed input: 197.17 toks/s, output: 803.58 toks/s]Processed prompts:  83%|████████▎ | 417/500 [18:31<11:23,  8.24s/it, est. speed input: 196.99 toks/s, output: 804.05 toks/s]Processed prompts:  84%|████████▎ | 418/500 [18:35<09:34,  7.01s/it, est. speed input: 196.77 toks/s, output: 803.62 toks/s]Processed prompts:  84%|████████▍ | 420/500 [18:39<06:08,  4.60s/it, est. speed input: 197.60 toks/s, output: 804.73 toks/s]Processed prompts:  84%|████████▍ | 421/500 [18:41<05:22,  4.08s/it, est. speed input: 197.85 toks/s, output: 806.48 toks/s]Processed prompts:  84%|████████▍ | 422/500 [18:52<07:43,  5.94s/it, est. speed input: 196.20 toks/s, output: 801.57 toks/s]Processed prompts:  85%|████████▍ | 423/500 [18:55<06:24,  5.00s/it, est. speed input: 196.07 toks/s, output: 806.21 toks/s]Processed prompts:  85%|████████▍ | 424/500 [19:00<06:17,  4.97s/it, est. speed input: 195.98 toks/s, output: 806.80 toks/s]Processed prompts:  85%|████████▌ | 425/500 [19:01<04:44,  3.79s/it, est. speed input: 196.32 toks/s, output: 806.96 toks/s]Processed prompts:  85%|████████▌ | 426/500 [19:02<03:48,  3.08s/it, est. speed input: 196.84 toks/s, output: 811.82 toks/s]Processed prompts:  85%|████████▌ | 427/500 [19:10<05:38,  4.63s/it, est. speed input: 195.92 toks/s, output: 806.06 toks/s]WARNING 04-04 10:40:29 scheduler.py:1555] Sequence group 487 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  86%|████████▌ | 428/500 [19:16<06:04,  5.06s/it, est. speed input: 195.48 toks/s, output: 804.87 toks/s]Processed prompts:  86%|████████▌ | 429/500 [19:18<04:54,  4.15s/it, est. speed input: 195.98 toks/s, output: 804.92 toks/s]Processed prompts:  86%|████████▌ | 430/500 [19:23<05:04,  4.35s/it, est. speed input: 195.41 toks/s, output: 804.67 toks/s]Processed prompts:  86%|████████▌ | 431/500 [19:37<08:13,  7.15s/it, est. speed input: 193.99 toks/s, output: 798.31 toks/s]Processed prompts:  86%|████████▋ | 432/500 [19:44<08:12,  7.24s/it, est. speed input: 193.12 toks/s, output: 797.61 toks/s]Processed prompts:  87%|████████▋ | 433/500 [19:50<07:32,  6.76s/it, est. speed input: 192.61 toks/s, output: 796.56 toks/s]Processed prompts:  87%|████████▋ | 434/500 [19:52<05:52,  5.34s/it, est. speed input: 192.47 toks/s, output: 797.90 toks/s]Processed prompts:  87%|████████▋ | 435/500 [19:56<05:12,  4.80s/it, est. speed input: 192.15 toks/s, output: 800.06 toks/s]Processed prompts:  87%|████████▋ | 436/500 [19:57<04:02,  3.80s/it, est. speed input: 192.13 toks/s, output: 802.73 toks/s]Processed prompts:  87%|████████▋ | 437/500 [19:58<03:04,  2.93s/it, est. speed input: 192.42 toks/s, output: 808.41 toks/s]Processed prompts:  88%|████████▊ | 438/500 [19:59<02:33,  2.47s/it, est. speed input: 192.41 toks/s, output: 811.26 toks/s]Processed prompts:  88%|████████▊ | 439/500 [20:03<02:56,  2.90s/it, est. speed input: 191.98 toks/s, output: 808.89 toks/s]Processed prompts:  88%|████████▊ | 440/500 [20:05<02:35,  2.59s/it, est. speed input: 192.07 toks/s, output: 811.11 toks/s]Processed prompts:  88%|████████▊ | 441/500 [20:06<02:02,  2.07s/it, est. speed input: 192.43 toks/s, output: 813.83 toks/s]Processed prompts:  88%|████████▊ | 442/500 [20:12<03:16,  3.39s/it, est. speed input: 192.09 toks/s, output: 816.69 toks/s]Processed prompts:  89%|████████▊ | 443/500 [20:15<02:51,  3.01s/it, est. speed input: 192.18 toks/s, output: 818.27 toks/s]Processed prompts:  89%|████████▉ | 445/500 [20:18<02:17,  2.49s/it, est. speed input: 192.79 toks/s, output: 820.09 toks/s]Processed prompts:  89%|████████▉ | 446/500 [20:27<03:30,  3.90s/it, est. speed input: 191.85 toks/s, output: 818.15 toks/s]Processed prompts:  89%|████████▉ | 447/500 [20:28<02:58,  3.37s/it, est. speed input: 191.79 toks/s, output: 820.16 toks/s]Processed prompts:  90%|████████▉ | 448/500 [20:33<03:14,  3.73s/it, est. speed input: 191.54 toks/s, output: 821.59 toks/s]Processed prompts:  90%|████████▉ | 449/500 [20:45<05:01,  5.92s/it, est. speed input: 189.95 toks/s, output: 814.55 toks/s]Processed prompts:  90%|█████████ | 450/500 [20:46<03:46,  4.52s/it, est. speed input: 190.02 toks/s, output: 818.60 toks/s]Processed prompts:  90%|█████████ | 451/500 [20:46<02:45,  3.38s/it, est. speed input: 190.32 toks/s, output: 820.71 toks/s]Processed prompts:  90%|█████████ | 452/500 [20:48<02:19,  2.92s/it, est. speed input: 190.25 toks/s, output: 823.43 toks/s]Processed prompts:  91%|█████████ | 453/500 [20:59<04:07,  5.26s/it, est. speed input: 188.97 toks/s, output: 819.49 toks/s]Processed prompts:  91%|█████████ | 454/500 [21:02<03:34,  4.67s/it, est. speed input: 188.90 toks/s, output: 818.05 toks/s]Processed prompts:  91%|█████████ | 455/500 [21:07<03:31,  4.69s/it, est. speed input: 188.48 toks/s, output: 818.49 toks/s]Processed prompts:  91%|█████████ | 456/500 [21:08<02:42,  3.69s/it, est. speed input: 188.46 toks/s, output: 821.70 toks/s]Processed prompts:  91%|█████████▏| 457/500 [21:10<02:07,  2.97s/it, est. speed input: 188.73 toks/s, output: 823.10 toks/s]Processed prompts:  92%|█████████▏| 458/500 [21:11<01:45,  2.51s/it, est. speed input: 188.97 toks/s, output: 823.04 toks/s]Processed prompts:  92%|█████████▏| 459/500 [21:14<01:45,  2.58s/it, est. speed input: 189.38 toks/s, output: 822.09 toks/s]Processed prompts:  92%|█████████▏| 460/500 [21:15<01:21,  2.04s/it, est. speed input: 189.85 toks/s, output: 822.84 toks/s]Processed prompts:  92%|█████████▏| 461/500 [21:16<01:15,  1.95s/it, est. speed input: 190.17 toks/s, output: 825.05 toks/s]Processed prompts:  92%|█████████▏| 462/500 [21:19<01:26,  2.26s/it, est. speed input: 190.07 toks/s, output: 825.00 toks/s]Processed prompts:  93%|█████████▎| 463/500 [21:21<01:16,  2.08s/it, est. speed input: 190.21 toks/s, output: 827.75 toks/s]Processed prompts:  93%|█████████▎| 464/500 [21:26<01:46,  2.97s/it, est. speed input: 190.05 toks/s, output: 826.80 toks/s]Processed prompts:  93%|█████████▎| 465/500 [21:39<03:29,  6.00s/it, est. speed input: 188.57 toks/s, output: 824.35 toks/s]Processed prompts:  93%|█████████▎| 466/500 [21:44<03:16,  5.79s/it, est. speed input: 188.58 toks/s, output: 828.19 toks/s]Processed prompts:  94%|█████████▎| 468/500 [21:45<01:46,  3.33s/it, est. speed input: 188.92 toks/s, output: 835.15 toks/s]Processed prompts:  94%|█████████▍| 469/500 [21:54<02:26,  4.73s/it, est. speed input: 188.26 toks/s, output: 830.78 toks/s]Processed prompts:  94%|█████████▍| 470/500 [22:08<03:31,  7.05s/it, est. speed input: 186.67 toks/s, output: 823.76 toks/s]Processed prompts:  94%|█████████▍| 471/500 [22:18<03:45,  7.79s/it, est. speed input: 185.88 toks/s, output: 822.16 toks/s]Processed prompts:  94%|█████████▍| 472/500 [22:24<03:26,  7.39s/it, est. speed input: 185.42 toks/s, output: 825.65 toks/s]Processed prompts:  95%|█████████▍| 473/500 [22:26<02:41,  5.97s/it, est. speed input: 185.93 toks/s, output: 828.85 toks/s]Processed prompts:  95%|█████████▍| 474/500 [22:31<02:21,  5.45s/it, est. speed input: 185.81 toks/s, output: 829.12 toks/s]Processed prompts:  95%|█████████▌| 475/500 [22:37<02:25,  5.80s/it, est. speed input: 185.11 toks/s, output: 827.48 toks/s]Processed prompts:  95%|█████████▌| 476/500 [22:40<01:58,  4.94s/it, est. speed input: 185.03 toks/s, output: 829.25 toks/s]Processed prompts:  95%|█████████▌| 477/500 [22:48<02:16,  5.94s/it, est. speed input: 184.22 toks/s, output: 826.32 toks/s]Processed prompts:  96%|█████████▌| 478/500 [22:49<01:33,  4.23s/it, est. speed input: 184.98 toks/s, output: 830.32 toks/s]Processed prompts:  96%|█████████▌| 479/500 [22:56<01:50,  5.25s/it, est. speed input: 184.27 toks/s, output: 829.89 toks/s]Processed prompts:  96%|█████████▌| 480/500 [23:03<01:54,  5.71s/it, est. speed input: 183.80 toks/s, output: 831.11 toks/s]Processed prompts:  96%|█████████▌| 481/500 [23:05<01:28,  4.64s/it, est. speed input: 184.20 toks/s, output: 834.98 toks/s]Processed prompts:  96%|█████████▋| 482/500 [23:09<01:17,  4.33s/it, est. speed input: 183.88 toks/s, output: 835.53 toks/s]Processed prompts:  97%|█████████▋| 483/500 [23:15<01:22,  4.83s/it, est. speed input: 183.58 toks/s, output: 837.10 toks/s]Processed prompts:  97%|█████████▋| 484/500 [23:27<01:53,  7.08s/it, est. speed input: 182.49 toks/s, output: 837.76 toks/s]Processed prompts:  97%|█████████▋| 485/500 [23:28<01:19,  5.31s/it, est. speed input: 182.83 toks/s, output: 839.62 toks/s]Processed prompts:  97%|█████████▋| 486/500 [23:29<00:54,  3.89s/it, est. speed input: 183.08 toks/s, output: 841.79 toks/s]Processed prompts:  97%|█████████▋| 487/500 [23:37<01:06,  5.14s/it, est. speed input: 182.81 toks/s, output: 842.47 toks/s]Processed prompts:  98%|█████████▊| 488/500 [23:47<01:17,  6.49s/it, est. speed input: 182.27 toks/s, output: 839.48 toks/s]Processed prompts:  98%|█████████▊| 489/500 [23:52<01:06,  6.05s/it, est. speed input: 182.49 toks/s, output: 839.99 toks/s]Processed prompts:  98%|█████████▊| 490/500 [23:57<00:59,  5.93s/it, est. speed input: 182.16 toks/s, output: 839.75 toks/s]Processed prompts:  98%|█████████▊| 491/500 [24:00<00:45,  5.07s/it, est. speed input: 182.29 toks/s, output: 846.05 toks/s]Processed prompts:  98%|█████████▊| 492/500 [24:02<00:31,  4.00s/it, est. speed input: 182.25 toks/s, output: 848.62 toks/s]Processed prompts:  99%|█████████▊| 493/500 [24:18<00:53,  7.61s/it, est. speed input: 180.67 toks/s, output: 842.53 toks/s]Processed prompts:  99%|█████████▉| 494/500 [24:19<00:34,  5.74s/it, est. speed input: 180.89 toks/s, output: 845.20 toks/s]Processed prompts:  99%|█████████▉| 495/500 [25:04<01:27, 17.56s/it, est. speed input: 175.76 toks/s, output: 829.73 toks/s]Processed prompts:  99%|█████████▉| 496/500 [25:40<01:32, 23.01s/it, est. speed input: 171.87 toks/s, output: 817.30 toks/s]Processed prompts:  99%|█████████▉| 497/500 [25:45<00:52, 17.64s/it, est. speed input: 172.00 toks/s, output: 819.07 toks/s]Processed prompts: 100%|█████████▉| 498/500 [36:19<06:45, 202.60s/it, est. speed input: 122.25 toks/s, output: 595.80 toks/s]Processed prompts: 100%|█████████▉| 499/500 [37:39<02:45, 165.72s/it, est. speed input: 118.36 toks/s, output: 589.30 toks/s]Processed prompts: 100%|██████████| 500/500 [39:31<00:00, 149.66s/it, est. speed input: 113.00 toks/s, output: 575.24 toks/s]Processed prompts: 100%|██████████| 500/500 [39:31<00:00,  4.74s/it, est. speed input: 113.00 toks/s, output: 575.24 toks/s] 
INFO 04-04 11:00:49 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2049410)[0;0m INFO 04-04 11:00:49 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2049411)[0;0m INFO 04-04 11:00:49 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2049412)[0;0m INFO 04-04 11:00:49 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W404 11:01:02.211899664 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-04 11:01:18 config.py:510] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 04-04 11:01:18 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-04 11:01:18 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-04 11:01:18 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-04 11:01:18 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-04 11:01:18 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-04 11:01:18 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:19 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:19 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:19 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:19 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-04 11:01:19 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:19 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:19 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:21 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-04 11:01:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:21 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-04 11:01:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2050851)[0;0m WARNING 04-04 11:01:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2050852)[0;0m WARNING 04-04 11:01:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2050853)[0;0m WARNING 04-04 11:01:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-04 11:01:21 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-04 11:01:21 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_6e4d8081'), local_subscribe_port=58013, remote_subscribe_port=None)
INFO 04-04 11:01:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:21 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.42it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.72it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.19it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:04,  2.00it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.90it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.87it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.86it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.85it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.83it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.83it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.95it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.90it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.89it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.95it/s]

[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:29 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:29 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-04 11:01:29 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:29 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:32 worker.py:241] Memory profiling takes 2.63 seconds
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:32 worker.py:241] Memory profiling takes 2.64 seconds
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:32 worker.py:241] Memory profiling takes 2.70 seconds
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-04 11:01:32 worker.py:241] Memory profiling takes 2.85 seconds
INFO 04-04 11:01:32 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-04 11:01:32 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-04 11:01:32 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-04 11:01:32 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:01:46 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-04 11:01:46 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:01:46 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:01:46 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:44,  1.26s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:38,  1.22s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:35,  1.22s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:33,  1.21s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:06<02:31,  1.20s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:07<02:30,  1.20s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:08<02:28,  1.20s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:09<02:26,  1.19s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:10<02:25,  1.19s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:12<02:24,  1.19s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:13<02:22,  1.19s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:14<02:19,  1.18s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:15<02:19,  1.18s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:16<02:17,  1.18s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:17<02:16,  1.18s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:19<02:15,  1.18s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:20<02:13,  1.17s/it]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:21<02:11,  1.16s/it]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:22<02:09,  1.15s/it]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:23<02:06,  1.14s/it]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:24<02:05,  1.14s/it]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:25<02:04,  1.14s/it]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:27<02:02,  1.13s/it]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:28<02:00,  1.12s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:29<01:57,  1.11s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:30<01:57,  1.11s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:31<01:56,  1.12s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:32<01:54,  1.12s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:33<01:53,  1.12s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:34<01:51,  1.10s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:35<01:51,  1.11s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:36<01:49,  1.11s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:38<01:48,  1.10s/it]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:39<01:44,  1.07s/it]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:40<01:41,  1.06s/it]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:41<01:40,  1.06s/it]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:42<01:39,  1.06s/it]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:43<01:37,  1.05s/it]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:44<01:37,  1.06s/it]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:45<01:36,  1.06s/it]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:46<01:34,  1.05s/it]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:47<01:33,  1.05s/it]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:48<01:32,  1.06s/it]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:49<01:31,  1.05s/it]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:50<01:30,  1.05s/it]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:51<01:28,  1.04s/it]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:52<01:25,  1.02s/it]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:53<01:25,  1.03s/it]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:54<01:23,  1.02s/it]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:55<01:21,  1.01s/it]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:56<01:21,  1.01s/it]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:57<01:20,  1.02s/it]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:58<01:19,  1.02s/it]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:59<01:18,  1.02s/it]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [01:00<01:16,  1.01s/it]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [01:01<01:15,  1.00s/it]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [01:02<01:14,  1.00s/it]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [01:03<01:12,  1.00it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [01:04<01:12,  1.01s/it]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [01:05<01:11,  1.00s/it]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:06<01:09,  1.01it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:07<01:07,  1.01it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:08<01:06,  1.02it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:09<01:06,  1.01it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:10<01:04,  1.03it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:11<01:03,  1.03it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:12<01:01,  1.05it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:13<00:59,  1.05it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:14<00:58,  1.07it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:15<00:57,  1.06it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:16<00:56,  1.05it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:17<00:55,  1.06it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:18<00:53,  1.08it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:18<00:52,  1.09it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:19<00:51,  1.09it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:20<00:50,  1.09it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:21<00:49,  1.10it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:22<00:48,  1.10it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:23<00:47,  1.10it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:24<00:45,  1.12it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:25<00:44,  1.12it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:26<00:43,  1.12it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:26<00:42,  1.12it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:27<00:41,  1.14it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:28<00:40,  1.15it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:29<00:38,  1.16it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:30<00:38,  1.15it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:31<00:36,  1.17it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:32<00:35,  1.17it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:32<00:35,  1.16it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:33<00:34,  1.17it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:34<00:33,  1.18it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:35<00:32,  1.18it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:36<00:31,  1.19it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:37<00:30,  1.18it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:38<00:29,  1.17it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:38<00:28,  1.18it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:39<00:28,  1.18it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:40<00:27,  1.18it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:41<00:26,  1.17it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:42<00:25,  1.18it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:43<00:24,  1.20it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:43<00:23,  1.20it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:44<00:22,  1.21it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:45<00:21,  1.22it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:46<00:20,  1.23it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:47<00:19,  1.24it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:47<00:18,  1.23it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:48<00:17,  1.25it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:49<00:16,  1.26it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:50<00:15,  1.26it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:51<00:15,  1.26it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:51<00:13,  1.29it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:52<00:13,  1.28it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:53<00:12,  1.29it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:54<00:11,  1.31it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:54<00:10,  1.30it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:55<00:09,  1.34it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:56<00:09,  1.31it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:57<00:08,  1.31it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:57<00:07,  1.29it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:58<00:06,  1.29it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:59<00:06,  1.31it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [02:00<00:05,  1.32it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [02:00<00:04,  1.34it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [02:01<00:03,  1.35it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [02:02<00:02,  1.35it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [02:03<00:02,  1.36it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [02:03<00:01,  1.34it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [02:04<00:00,  1.33it/s][1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 11:03:52 model_runner.py:1535] Graph capturing finished in 125 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 11:03:52 model_runner.py:1535] Graph capturing finished in 125 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 11:03:52 model_runner.py:1535] Graph capturing finished in 126 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:05<00:00,  1.18it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:05<00:00,  1.04it/s]
INFO 04-04 11:03:52 model_runner.py:1535] Graph capturing finished in 126 secs, took 8.20 GiB
INFO 04-04 11:03:52 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 142.84 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: bipartite
Generating answers for task: bipartite
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-04 11:04:55 scheduler.py:1555] Sequence group 347 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-04 11:05:10 scheduler.py:1555] Sequence group 297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-04 11:05:32 scheduler.py:1555] Sequence group 247 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   0%|          | 1/500 [02:06<17:27:57, 126.01s/it, est. speed input: 1.54 toks/s, output: 4.48 toks/s]WARNING 04-04 11:06:05 scheduler.py:1555] Sequence group 197 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:   0%|          | 2/500 [02:50<10:49:27, 78.25s/it, est. speed input: 2.36 toks/s, output: 8.86 toks/s] WARNING 04-04 11:06:51 scheduler.py:1555] Sequence group 147 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:   1%|          | 3/500 [03:02<6:37:47, 48.02s/it, est. speed input: 3.29 toks/s, output: 14.10 toks/s]Processed prompts:   1%|          | 4/500 [03:22<5:04:03, 36.78s/it, est. speed input: 3.98 toks/s, output: 18.90 toks/s]Processed prompts:   1%|          | 5/500 [03:25<3:23:45, 24.70s/it, est. speed input: 4.89 toks/s, output: 24.96 toks/s]Processed prompts:   1%|          | 6/500 [03:26<2:17:44, 16.73s/it, est. speed input: 5.87 toks/s, output: 31.04 toks/s]Processed prompts:   1%|▏         | 7/500 [03:33<1:50:28, 13.44s/it, est. speed input: 6.71 toks/s, output: 36.55 toks/s]Processed prompts:   2%|▏         | 8/500 [03:39<1:30:21, 11.02s/it, est. speed input: 11.05 toks/s, output: 42.25 toks/s]Processed prompts:   2%|▏         | 9/500 [03:49<1:28:01, 10.76s/it, est. speed input: 11.47 toks/s, output: 47.12 toks/s]Processed prompts:   2%|▏         | 10/500 [03:49<1:01:09,  7.49s/it, est. speed input: 14.83 toks/s, output: 53.91 toks/s]Processed prompts:   2%|▏         | 11/500 [03:56<59:14,  7.27s/it, est. speed input: 20.09 toks/s, output: 59.38 toks/s]  Processed prompts:   2%|▏         | 12/500 [04:19<1:38:52, 12.16s/it, est. speed input: 22.11 toks/s, output: 61.44 toks/s]Processed prompts:   3%|▎         | 13/500 [04:30<1:33:39, 11.54s/it, est. speed input: 28.93 toks/s, output: 66.66 toks/s]Processed prompts:   3%|▎         | 14/500 [04:32<1:11:43,  8.86s/it, est. speed input: 30.95 toks/s, output: 73.61 toks/s]Processed prompts:   3%|▎         | 15/500 [04:33<51:48,  6.41s/it, est. speed input: 31.67 toks/s, output: 80.96 toks/s]  Processed prompts:   3%|▎         | 16/500 [04:35<41:06,  5.10s/it, est. speed input: 35.20 toks/s, output: 87.94 toks/s]Processed prompts:   3%|▎         | 17/500 [04:39<38:29,  4.78s/it, est. speed input: 35.65 toks/s, output: 94.33 toks/s]WARNING 04-04 11:08:37 scheduler.py:1555] Sequence group 97 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:   4%|▎         | 18/500 [04:43<36:43,  4.57s/it, est. speed input: 38.59 toks/s, output: 100.70 toks/s]Processed prompts:   4%|▍         | 19/500 [04:47<34:16,  4.28s/it, est. speed input: 39.08 toks/s, output: 107.24 toks/s]Processed prompts:   4%|▍         | 20/500 [04:51<35:03,  4.38s/it, est. speed input: 46.41 toks/s, output: 113.45 toks/s]Processed prompts:   4%|▍         | 21/500 [04:57<38:44,  4.85s/it, est. speed input: 46.78 toks/s, output: 119.17 toks/s]Processed prompts:   4%|▍         | 22/500 [04:58<29:23,  3.69s/it, est. speed input: 48.36 toks/s, output: 126.73 toks/s]Processed prompts:   5%|▍         | 24/500 [04:59<17:38,  2.22s/it, est. speed input: 54.33 toks/s, output: 142.29 toks/s]Processed prompts:   5%|▌         | 25/500 [05:00<13:57,  1.76s/it, est. speed input: 56.55 toks/s, output: 150.16 toks/s]Processed prompts:   5%|▌         | 26/500 [05:08<27:12,  3.44s/it, est. speed input: 55.95 toks/s, output: 154.25 toks/s]Processed prompts:   5%|▌         | 27/500 [05:11<26:10,  3.32s/it, est. speed input: 56.21 toks/s, output: 160.97 toks/s]Processed prompts:   6%|▌         | 28/500 [05:16<29:45,  3.78s/it, est. speed input: 57.52 toks/s, output: 166.67 toks/s]Processed prompts:   6%|▌         | 29/500 [05:23<37:35,  4.79s/it, est. speed input: 58.79 toks/s, output: 171.24 toks/s]Processed prompts:   6%|▌         | 30/500 [05:28<38:31,  4.92s/it, est. speed input: 59.57 toks/s, output: 176.87 toks/s]Processed prompts:   6%|▌         | 31/500 [05:31<33:03,  4.23s/it, est. speed input: 59.77 toks/s, output: 183.93 toks/s]Processed prompts:   6%|▋         | 32/500 [05:32<26:32,  3.40s/it, est. speed input: 60.24 toks/s, output: 191.60 toks/s]Processed prompts:   7%|▋         | 33/500 [05:36<26:45,  3.44s/it, est. speed input: 60.45 toks/s, output: 198.07 toks/s]Processed prompts:   7%|▋         | 34/500 [05:37<20:50,  2.68s/it, est. speed input: 62.55 toks/s, output: 206.04 toks/s]Processed prompts:   7%|▋         | 35/500 [05:38<17:02,  2.20s/it, est. speed input: 63.30 toks/s, output: 213.84 toks/s]Processed prompts:   7%|▋         | 36/500 [05:46<30:44,  3.98s/it, est. speed input: 63.81 toks/s, output: 217.46 toks/s]Processed prompts:   7%|▋         | 37/500 [05:47<22:45,  2.95s/it, est. speed input: 64.40 toks/s, output: 225.76 toks/s]Processed prompts:   8%|▊         | 38/500 [05:47<16:30,  2.14s/it, est. speed input: 65.17 toks/s, output: 233.56 toks/s]Processed prompts:   8%|▊         | 39/500 [05:47<13:02,  1.70s/it, est. speed input: 65.68 toks/s, output: 241.70 toks/s]Processed prompts:   8%|▊         | 40/500 [05:48<09:57,  1.30s/it, est. speed input: 66.54 toks/s, output: 250.10 toks/s]Processed prompts:   8%|▊         | 41/500 [05:51<14:11,  1.85s/it, est. speed input: 66.67 toks/s, output: 256.52 toks/s]Processed prompts:   8%|▊         | 42/500 [05:53<13:39,  1.79s/it, est. speed input: 69.11 toks/s, output: 264.01 toks/s]Processed prompts:   9%|▊         | 43/500 [05:55<14:46,  1.94s/it, est. speed input: 69.48 toks/s, output: 271.02 toks/s]Processed prompts:   9%|▉         | 44/500 [05:56<12:10,  1.60s/it, est. speed input: 71.19 toks/s, output: 279.14 toks/s]Processed prompts:   9%|▉         | 45/500 [06:01<20:46,  2.74s/it, est. speed input: 71.68 toks/s, output: 283.73 toks/s]Processed prompts:   9%|▉         | 46/500 [06:04<21:38,  2.86s/it, est. speed input: 72.49 toks/s, output: 290.06 toks/s]Processed prompts:   9%|▉         | 47/500 [06:07<21:26,  2.84s/it, est. speed input: 75.10 toks/s, output: 293.20 toks/s]Processed prompts:  10%|▉         | 48/500 [06:13<28:47,  3.82s/it, est. speed input: 74.72 toks/s, output: 297.33 toks/s]Processed prompts:  10%|▉         | 49/500 [06:15<23:15,  3.09s/it, est. speed input: 75.15 toks/s, output: 305.15 toks/s]Processed prompts:  10%|█         | 50/500 [06:18<22:56,  3.06s/it, est. speed input: 75.48 toks/s, output: 311.71 toks/s]Processed prompts:  10%|█         | 51/500 [06:27<36:53,  4.93s/it, est. speed input: 74.24 toks/s, output: 313.25 toks/s]Processed prompts:  11%|█         | 53/500 [06:29<24:24,  3.28s/it, est. speed input: 75.27 toks/s, output: 327.79 toks/s]Processed prompts:  11%|█         | 54/500 [06:30<18:54,  2.54s/it, est. speed input: 76.45 toks/s, output: 334.40 toks/s]Processed prompts:  11%|█         | 55/500 [06:41<36:06,  4.87s/it, est. speed input: 76.90 toks/s, output: 331.25 toks/s]Processed prompts:  11%|█         | 56/500 [06:59<1:02:54,  8.50s/it, est. speed input: 74.93 toks/s, output: 326.21 toks/s]Processed prompts:  11%|█▏        | 57/500 [07:00<47:16,  6.40s/it, est. speed input: 75.34 toks/s, output: 334.83 toks/s]  Processed prompts:  12%|█▏        | 58/500 [07:08<49:20,  6.70s/it, est. speed input: 76.26 toks/s, output: 338.43 toks/s]Processed prompts:  12%|█▏        | 59/500 [07:22<1:04:33,  8.78s/it, est. speed input: 75.19 toks/s, output: 337.34 toks/s]Processed prompts:  12%|█▏        | 60/500 [07:30<1:02:59,  8.59s/it, est. speed input: 74.34 toks/s, output: 340.95 toks/s]Processed prompts:  12%|█▏        | 61/500 [07:37<59:06,  8.08s/it, est. speed input: 73.70 toks/s, output: 345.56 toks/s]  Processed prompts:  12%|█▏        | 62/500 [07:42<53:32,  7.33s/it, est. speed input: 74.35 toks/s, output: 351.16 toks/s]Processed prompts:  13%|█▎        | 63/500 [07:50<53:16,  7.31s/it, est. speed input: 75.44 toks/s, output: 355.57 toks/s]Processed prompts:  13%|█▎        | 64/500 [07:52<41:25,  5.70s/it, est. speed input: 76.00 toks/s, output: 363.99 toks/s]Processed prompts:  13%|█▎        | 65/500 [07:54<35:01,  4.83s/it, est. speed input: 76.26 toks/s, output: 371.73 toks/s]Processed prompts:  13%|█▎        | 66/500 [08:10<58:19,  8.06s/it, est. speed input: 74.24 toks/s, output: 367.88 toks/s]Processed prompts:  14%|█▎        | 68/500 [08:12<35:03,  4.87s/it, est. speed input: 75.54 toks/s, output: 386.21 toks/s]Processed prompts:  14%|█▍        | 69/500 [08:23<45:24,  6.32s/it, est. speed input: 74.41 toks/s, output: 388.13 toks/s]Processed prompts:  14%|█▍        | 70/500 [08:31<48:52,  6.82s/it, est. speed input: 76.26 toks/s, output: 392.10 toks/s]Processed prompts:  14%|█▍        | 71/500 [08:34<41:15,  5.77s/it, est. speed input: 76.39 toks/s, output: 400.08 toks/s]Processed prompts:  14%|█▍        | 72/500 [08:51<1:02:29,  8.76s/it, est. speed input: 74.99 toks/s, output: 396.03 toks/s]Processed prompts:  15%|█▍        | 73/500 [08:54<52:26,  7.37s/it, est. speed input: 76.71 toks/s, output: 403.53 toks/s]  Processed prompts:  15%|█▍        | 74/500 [08:55<38:19,  5.40s/it, est. speed input: 77.51 toks/s, output: 413.51 toks/s]Processed prompts:  15%|█▌        | 75/500 [08:57<31:55,  4.51s/it, est. speed input: 77.88 toks/s, output: 418.40 toks/s]Processed prompts:  15%|█▌        | 76/500 [08:59<25:52,  3.66s/it, est. speed input: 78.37 toks/s, output: 427.56 toks/s]Processed prompts:  15%|█▌        | 77/500 [09:04<29:15,  4.15s/it, est. speed input: 79.74 toks/s, output: 429.03 toks/s]Processed prompts:  16%|█▌        | 78/500 [09:16<44:19,  6.30s/it, est. speed input: 78.94 toks/s, output: 430.80 toks/s]Processed prompts:  16%|█▌        | 79/500 [09:17<34:16,  4.88s/it, est. speed input: 79.23 toks/s, output: 440.12 toks/s]Processed prompts:  16%|█▌        | 80/500 [09:45<1:22:04, 11.72s/it, est. speed input: 77.69 toks/s, output: 430.00 toks/s]Processed prompts:  16%|█▌        | 81/500 [09:46<59:19,  8.50s/it, est. speed input: 79.34 toks/s, output: 440.06 toks/s]  Processed prompts:  16%|█▋        | 82/500 [10:01<1:11:57, 10.33s/it, est. speed input: 79.31 toks/s, output: 440.21 toks/s]Processed prompts:  17%|█▋        | 83/500 [10:03<55:02,  7.92s/it, est. speed input: 79.73 toks/s, output: 449.40 toks/s]  Processed prompts:  17%|█▋        | 84/500 [10:13<59:45,  8.62s/it, est. speed input: 81.79 toks/s, output: 452.78 toks/s]Processed prompts:  17%|█▋        | 85/500 [10:23<1:01:34,  8.90s/it, est. speed input: 80.99 toks/s, output: 456.77 toks/s]Processed prompts:  17%|█▋        | 86/500 [10:26<50:23,  7.30s/it, est. speed input: 81.49 toks/s, output: 465.12 toks/s]  WARNING 04-04 11:14:34 scheduler.py:1555] Sequence group 126 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  17%|█▋        | 87/500 [10:48<1:20:36, 11.71s/it, est. speed input: 80.86 toks/s, output: 460.42 toks/s]Processed prompts:  18%|█▊        | 88/500 [11:03<1:26:55, 12.66s/it, est. speed input: 80.42 toks/s, output: 461.26 toks/s]Processed prompts:  18%|█▊        | 89/500 [11:12<1:18:30, 11.46s/it, est. speed input: 79.88 toks/s, output: 460.62 toks/s]Processed prompts:  18%|█▊        | 90/500 [11:26<1:23:14, 12.18s/it, est. speed input: 78.77 toks/s, output: 462.62 toks/s]Processed prompts:  18%|█▊        | 91/500 [11:32<1:10:52, 10.40s/it, est. speed input: 78.46 toks/s, output: 469.80 toks/s]Processed prompts:  18%|█▊        | 92/500 [11:35<55:01,  8.09s/it, est. speed input: 80.29 toks/s, output: 479.31 toks/s]  Processed prompts:  19%|█▊        | 93/500 [11:39<47:00,  6.93s/it, est. speed input: 80.60 toks/s, output: 483.65 toks/s]Processed prompts:  19%|█▉        | 94/500 [11:46<46:49,  6.92s/it, est. speed input: 80.22 toks/s, output: 481.52 toks/s]Processed prompts:  19%|█▉        | 95/500 [11:54<48:41,  7.21s/it, est. speed input: 79.69 toks/s, output: 481.89 toks/s]Processed prompts:  19%|█▉        | 96/500 [11:54<35:39,  5.30s/it, est. speed input: 80.13 toks/s, output: 483.26 toks/s]Processed prompts:  19%|█▉        | 97/500 [12:10<56:17,  8.38s/it, est. speed input: 80.26 toks/s, output: 484.46 toks/s]Processed prompts:  20%|█▉        | 98/500 [12:38<1:34:40, 14.13s/it, est. speed input: 79.19 toks/s, output: 478.48 toks/s]Processed prompts:  20%|█▉        | 99/500 [12:42<1:14:40, 11.17s/it, est. speed input: 79.32 toks/s, output: 481.06 toks/s]Processed prompts:  20%|██        | 100/500 [12:42<53:12,  7.98s/it, est. speed input: 79.67 toks/s, output: 492.39 toks/s] Processed prompts:  20%|██        | 101/500 [12:45<41:37,  6.26s/it, est. speed input: 80.92 toks/s, output: 498.28 toks/s]Processed prompts:  20%|██        | 102/500 [12:58<56:08,  8.46s/it, est. speed input: 80.23 toks/s, output: 501.28 toks/s]Processed prompts:  21%|██        | 103/500 [13:00<42:23,  6.41s/it, est. speed input: 81.78 toks/s, output: 507.13 toks/s]Processed prompts:  21%|██        | 104/500 [13:14<57:01,  8.64s/it, est. speed input: 81.89 toks/s, output: 503.47 toks/s]Processed prompts:  21%|██        | 105/500 [13:20<52:20,  7.95s/it, est. speed input: 82.20 toks/s, output: 509.23 toks/s]Processed prompts:  21%|██        | 106/500 [13:21<38:09,  5.81s/it, est. speed input: 82.54 toks/s, output: 513.62 toks/s]Processed prompts:  21%|██▏       | 107/500 [13:26<35:46,  5.46s/it, est. speed input: 82.47 toks/s, output: 512.71 toks/s]Processed prompts:  22%|██▏       | 108/500 [13:29<31:09,  4.77s/it, est. speed input: 82.65 toks/s, output: 516.26 toks/s]Processed prompts:  22%|██▏       | 109/500 [13:39<41:27,  6.36s/it, est. speed input: 81.97 toks/s, output: 511.82 toks/s]Processed prompts:  22%|██▏       | 110/500 [13:53<56:08,  8.64s/it, est. speed input: 82.04 toks/s, output: 510.28 toks/s]Processed prompts:  22%|██▏       | 111/500 [13:53<40:41,  6.28s/it, est. speed input: 82.51 toks/s, output: 521.70 toks/s]Processed prompts:  22%|██▏       | 112/500 [14:13<1:05:56, 10.20s/it, est. speed input: 82.09 toks/s, output: 512.53 toks/s]Processed prompts:  23%|██▎       | 113/500 [14:26<1:12:27, 11.23s/it, est. speed input: 82.15 toks/s, output: 506.64 toks/s]Processed prompts:  23%|██▎       | 114/500 [14:27<51:50,  8.06s/it, est. speed input: 83.27 toks/s, output: 510.03 toks/s]  Processed prompts:  23%|██▎       | 115/500 [14:30<41:12,  6.42s/it, est. speed input: 83.47 toks/s, output: 520.49 toks/s]Processed prompts:  23%|██▎       | 116/500 [14:41<51:12,  8.00s/it, est. speed input: 83.66 toks/s, output: 525.63 toks/s]Processed prompts:  23%|██▎       | 117/500 [14:44<40:39,  6.37s/it, est. speed input: 83.92 toks/s, output: 527.72 toks/s]Processed prompts:  24%|██▎       | 118/500 [14:57<52:57,  8.32s/it, est. speed input: 83.81 toks/s, output: 522.59 toks/s]Processed prompts:  24%|██▍       | 119/500 [15:00<43:31,  6.85s/it, est. speed input: 83.75 toks/s, output: 527.91 toks/s]Processed prompts:  24%|██▍       | 120/500 [15:06<41:13,  6.51s/it, est. speed input: 83.74 toks/s, output: 528.15 toks/s]Processed prompts:  24%|██▍       | 121/500 [15:08<32:32,  5.15s/it, est. speed input: 83.96 toks/s, output: 539.09 toks/s]Processed prompts:  24%|██▍       | 122/500 [15:11<27:52,  4.42s/it, est. speed input: 84.30 toks/s, output: 538.42 toks/s]Processed prompts:  25%|██▍       | 123/500 [15:11<20:37,  3.28s/it, est. speed input: 84.94 toks/s, output: 550.16 toks/s]Processed prompts:  25%|██▍       | 124/500 [15:12<16:14,  2.59s/it, est. speed input: 85.18 toks/s, output: 552.09 toks/s]Processed prompts:  25%|██▌       | 125/500 [15:13<12:07,  1.94s/it, est. speed input: 85.47 toks/s, output: 553.14 toks/s]Processed prompts:  25%|██▌       | 126/500 [15:31<43:24,  6.96s/it, est. speed input: 84.13 toks/s, output: 543.16 toks/s]WARNING 04-04 11:19:36 scheduler.py:1555] Sequence group 164 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  25%|██▌       | 127/500 [15:44<53:52,  8.67s/it, est. speed input: 83.23 toks/s, output: 544.02 toks/s]Processed prompts:  26%|██▌       | 128/500 [15:45<39:20,  6.34s/it, est. speed input: 85.44 toks/s, output: 555.66 toks/s]Processed prompts:  26%|██▌       | 129/500 [15:59<53:47,  8.70s/it, est. speed input: 84.49 toks/s, output: 555.51 toks/s]Processed prompts:  26%|██▌       | 130/500 [16:14<1:04:08, 10.40s/it, est. speed input: 83.88 toks/s, output: 548.97 toks/s]Processed prompts:  26%|██▌       | 131/500 [16:19<55:17,  8.99s/it, est. speed input: 83.97 toks/s, output: 553.73 toks/s]  Processed prompts:  26%|██▋       | 132/500 [16:20<40:03,  6.53s/it, est. speed input: 84.22 toks/s, output: 560.74 toks/s]Processed prompts:  27%|██▋       | 133/500 [16:40<1:05:10, 10.66s/it, est. speed input: 83.84 toks/s, output: 551.85 toks/s]Processed prompts:  27%|██▋       | 134/500 [16:43<50:41,  8.31s/it, est. speed input: 85.63 toks/s, output: 562.58 toks/s]  Processed prompts:  27%|██▋       | 135/500 [16:58<1:03:22, 10.42s/it, est. speed input: 85.77 toks/s, output: 566.44 toks/s]Processed prompts:  27%|██▋       | 136/500 [17:16<1:15:30, 12.45s/it, est. speed input: 84.68 toks/s, output: 561.70 toks/s]Processed prompts:  27%|██▋       | 137/500 [17:18<57:43,  9.54s/it, est. speed input: 84.72 toks/s, output: 567.48 toks/s]  Processed prompts:  28%|██▊       | 138/500 [17:19<40:56,  6.78s/it, est. speed input: 84.94 toks/s, output: 569.37 toks/s]Processed prompts:  28%|██▊       | 139/500 [17:24<37:34,  6.25s/it, est. speed input: 85.56 toks/s, output: 569.06 toks/s]Processed prompts:  28%|██▊       | 140/500 [17:28<33:12,  5.54s/it, est. speed input: 85.87 toks/s, output: 579.31 toks/s]Processed prompts:  28%|██▊       | 141/500 [17:36<38:54,  6.50s/it, est. speed input: 85.66 toks/s, output: 586.85 toks/s]Processed prompts:  28%|██▊       | 142/500 [17:38<30:08,  5.05s/it, est. speed input: 86.16 toks/s, output: 586.94 toks/s]Processed prompts:  29%|██▊       | 143/500 [17:40<24:25,  4.11s/it, est. speed input: 86.65 toks/s, output: 590.91 toks/s]Processed prompts:  29%|██▉       | 144/500 [17:42<20:20,  3.43s/it, est. speed input: 87.23 toks/s, output: 596.74 toks/s]Processed prompts:  29%|██▉       | 145/500 [17:58<42:14,  7.14s/it, est. speed input: 86.19 toks/s, output: 593.91 toks/s]Processed prompts:  29%|██▉       | 146/500 [18:01<34:39,  5.87s/it, est. speed input: 87.29 toks/s, output: 592.96 toks/s]Processed prompts:  29%|██▉       | 147/500 [18:04<30:37,  5.21s/it, est. speed input: 88.00 toks/s, output: 591.63 toks/s]Processed prompts:  30%|██▉       | 148/500 [18:07<27:13,  4.64s/it, est. speed input: 88.73 toks/s, output: 593.28 toks/s]Processed prompts:  30%|██▉       | 149/500 [18:23<45:41,  7.81s/it, est. speed input: 88.11 toks/s, output: 597.42 toks/s]Processed prompts:  30%|███       | 150/500 [18:26<37:14,  6.38s/it, est. speed input: 88.06 toks/s, output: 596.88 toks/s]WARNING 04-04 11:22:24 scheduler.py:1555] Sequence group 211 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  30%|███       | 151/500 [18:32<37:44,  6.49s/it, est. speed input: 87.88 toks/s, output: 594.95 toks/s]Processed prompts:  30%|███       | 152/500 [18:42<43:03,  7.42s/it, est. speed input: 88.83 toks/s, output: 602.21 toks/s]Processed prompts:  31%|███       | 153/500 [18:48<40:52,  7.07s/it, est. speed input: 88.88 toks/s, output: 600.36 toks/s]Processed prompts:  31%|███       | 154/500 [19:03<53:58,  9.36s/it, est. speed input: 88.16 toks/s, output: 599.21 toks/s]Processed prompts:  31%|███       | 155/500 [19:14<57:26,  9.99s/it, est. speed input: 88.65 toks/s, output: 596.96 toks/s]Processed prompts:  31%|███       | 156/500 [19:34<1:14:23, 12.97s/it, est. speed input: 87.68 toks/s, output: 590.53 toks/s]Processed prompts:  31%|███▏      | 157/500 [19:47<1:13:13, 12.81s/it, est. speed input: 86.95 toks/s, output: 589.91 toks/s]Processed prompts:  32%|███▏      | 158/500 [19:52<1:00:13, 10.56s/it, est. speed input: 86.82 toks/s, output: 593.11 toks/s]Processed prompts:  32%|███▏      | 159/500 [20:02<58:22, 10.27s/it, est. speed input: 86.65 toks/s, output: 590.48 toks/s]  Processed prompts:  32%|███▏      | 160/500 [20:12<58:00, 10.24s/it, est. speed input: 86.26 toks/s, output: 591.52 toks/s]Processed prompts:  32%|███▏      | 161/500 [20:16<47:43,  8.45s/it, est. speed input: 86.12 toks/s, output: 593.21 toks/s]Processed prompts:  32%|███▏      | 162/500 [20:33<1:01:58, 11.00s/it, est. speed input: 85.11 toks/s, output: 587.44 toks/s]Processed prompts:  33%|███▎      | 163/500 [20:40<54:34,  9.72s/it, est. speed input: 84.98 toks/s, output: 588.29 toks/s]  Processed prompts:  33%|███▎      | 164/500 [20:48<52:23,  9.36s/it, est. speed input: 84.84 toks/s, output: 588.55 toks/s]Processed prompts:  33%|███▎      | 165/500 [20:54<45:22,  8.13s/it, est. speed input: 84.67 toks/s, output: 588.89 toks/s]Processed prompts:  33%|███▎      | 166/500 [20:59<41:21,  7.43s/it, est. speed input: 85.26 toks/s, output: 591.11 toks/s]Processed prompts:  33%|███▎      | 167/500 [21:04<36:20,  6.55s/it, est. speed input: 85.12 toks/s, output: 591.66 toks/s]Processed prompts:  34%|███▎      | 168/500 [21:05<27:57,  5.05s/it, est. speed input: 85.44 toks/s, output: 593.87 toks/s]Processed prompts:  34%|███▍      | 169/500 [21:10<27:47,  5.04s/it, est. speed input: 85.87 toks/s, output: 593.75 toks/s]Processed prompts:  34%|███▍      | 170/500 [21:13<23:46,  4.32s/it, est. speed input: 85.86 toks/s, output: 595.29 toks/s]Processed prompts:  34%|███▍      | 171/500 [21:14<17:39,  3.22s/it, est. speed input: 86.36 toks/s, output: 601.13 toks/s]Processed prompts:  34%|███▍      | 172/500 [21:18<18:48,  3.44s/it, est. speed input: 86.28 toks/s, output: 602.20 toks/s]Processed prompts:  35%|███▍      | 173/500 [21:24<23:51,  4.38s/it, est. speed input: 86.86 toks/s, output: 603.69 toks/s]Processed prompts:  35%|███▍      | 174/500 [21:27<21:22,  3.94s/it, est. speed input: 86.88 toks/s, output: 603.35 toks/s]Processed prompts:  35%|███▌      | 175/500 [21:34<26:28,  4.89s/it, est. speed input: 87.49 toks/s, output: 601.33 toks/s]Processed prompts:  35%|███▌      | 176/500 [21:40<28:25,  5.27s/it, est. speed input: 87.38 toks/s, output: 604.08 toks/s]Processed prompts:  35%|███▌      | 177/500 [21:47<29:34,  5.50s/it, est. speed input: 87.62 toks/s, output: 604.53 toks/s]Processed prompts:  36%|███▌      | 178/500 [21:47<21:12,  3.95s/it, est. speed input: 87.87 toks/s, output: 604.91 toks/s]Processed prompts:  36%|███▌      | 179/500 [21:52<22:39,  4.23s/it, est. speed input: 88.23 toks/s, output: 607.77 toks/s]WARNING 04-04 11:25:57 scheduler.py:1555] Sequence group 226 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  36%|███▌      | 180/500 [22:05<37:16,  6.99s/it, est. speed input: 88.28 toks/s, output: 602.15 toks/s]Processed prompts:  36%|███▌      | 181/500 [22:07<28:53,  5.43s/it, est. speed input: 88.68 toks/s, output: 602.18 toks/s]Processed prompts:  36%|███▋      | 182/500 [22:36<1:06:55, 12.63s/it, est. speed input: 86.90 toks/s, output: 590.56 toks/s]Processed prompts:  37%|███▋      | 183/500 [22:38<49:54,  9.45s/it, est. speed input: 87.07 toks/s, output: 593.51 toks/s]  Processed prompts:  37%|███▋      | 184/500 [22:46<46:16,  8.79s/it, est. speed input: 87.10 toks/s, output: 591.93 toks/s]Processed prompts:  37%|███▋      | 185/500 [22:57<50:33,  9.63s/it, est. speed input: 86.54 toks/s, output: 591.87 toks/s]Processed prompts:  37%|███▋      | 186/500 [22:59<37:55,  7.25s/it, est. speed input: 86.73 toks/s, output: 595.23 toks/s]Processed prompts:  37%|███▋      | 187/500 [23:00<27:26,  5.26s/it, est. speed input: 86.89 toks/s, output: 598.61 toks/s]Processed prompts:  38%|███▊      | 188/500 [23:04<26:15,  5.05s/it, est. speed input: 86.77 toks/s, output: 598.20 toks/s]Processed prompts:  38%|███▊      | 189/500 [23:08<24:52,  4.80s/it, est. speed input: 88.14 toks/s, output: 600.00 toks/s]Processed prompts:  38%|███▊      | 190/500 [23:09<19:09,  3.71s/it, est. speed input: 88.35 toks/s, output: 604.00 toks/s]Processed prompts:  38%|███▊      | 191/500 [23:27<40:58,  7.96s/it, est. speed input: 87.87 toks/s, output: 602.33 toks/s]Processed prompts:  38%|███▊      | 192/500 [23:29<31:09,  6.07s/it, est. speed input: 88.91 toks/s, output: 602.08 toks/s]Processed prompts:  39%|███▊      | 193/500 [23:30<23:32,  4.60s/it, est. speed input: 89.84 toks/s, output: 607.01 toks/s]Processed prompts:  39%|███▉      | 194/500 [23:35<23:07,  4.54s/it, est. speed input: 89.74 toks/s, output: 607.76 toks/s]Processed prompts:  39%|███▉      | 195/500 [23:48<36:08,  7.11s/it, est. speed input: 89.07 toks/s, output: 606.17 toks/s]Processed prompts:  39%|███▉      | 196/500 [23:49<27:13,  5.37s/it, est. speed input: 90.41 toks/s, output: 606.02 toks/s]Processed prompts:  39%|███▉      | 197/500 [24:23<1:10:45, 14.01s/it, est. speed input: 89.20 toks/s, output: 592.91 toks/s]Processed prompts:  40%|███▉      | 198/500 [24:24<50:04,  9.95s/it, est. speed input: 89.67 toks/s, output: 593.84 toks/s]  Processed prompts:  40%|███▉      | 199/500 [24:39<58:19, 11.63s/it, est. speed input: 88.95 toks/s, output: 590.24 toks/s]Processed prompts:  40%|████      | 200/500 [24:41<43:23,  8.68s/it, est. speed input: 89.65 toks/s, output: 596.02 toks/s]Processed prompts:  40%|████      | 201/500 [24:42<32:21,  6.49s/it, est. speed input: 89.72 toks/s, output: 597.12 toks/s]Processed prompts:  40%|████      | 202/500 [24:47<29:52,  6.01s/it, est. speed input: 89.56 toks/s, output: 596.67 toks/s]Processed prompts:  41%|████      | 203/500 [24:49<22:53,  4.63s/it, est. speed input: 89.62 toks/s, output: 600.70 toks/s]Processed prompts:  41%|████      | 204/500 [24:49<16:55,  3.43s/it, est. speed input: 90.41 toks/s, output: 601.24 toks/s]Processed prompts:  41%|████      | 205/500 [25:00<27:35,  5.61s/it, est. speed input: 89.92 toks/s, output: 606.76 toks/s]Processed prompts:  41%|████      | 206/500 [25:06<28:13,  5.76s/it, est. speed input: 89.70 toks/s, output: 605.21 toks/s]Processed prompts:  41%|████▏     | 207/500 [25:07<21:09,  4.33s/it, est. speed input: 90.54 toks/s, output: 605.45 toks/s]Processed prompts:  42%|████▏     | 208/500 [25:12<22:04,  4.54s/it, est. speed input: 90.67 toks/s, output: 608.02 toks/s]Processed prompts:  42%|████▏     | 209/500 [25:13<16:31,  3.41s/it, est. speed input: 90.78 toks/s, output: 612.25 toks/s]WARNING 04-04 11:29:14 scheduler.py:1555] Sequence group 265 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  42%|████▏     | 210/500 [25:19<21:04,  4.36s/it, est. speed input: 91.44 toks/s, output: 614.08 toks/s]Processed prompts:  42%|████▏     | 211/500 [25:20<15:32,  3.23s/it, est. speed input: 91.71 toks/s, output: 615.76 toks/s]Processed prompts:  42%|████▏     | 212/500 [25:21<12:14,  2.55s/it, est. speed input: 92.11 toks/s, output: 615.62 toks/s]Processed prompts:  43%|████▎     | 213/500 [25:25<13:34,  2.84s/it, est. speed input: 92.11 toks/s, output: 615.01 toks/s]Processed prompts:  43%|████▎     | 214/500 [25:30<16:57,  3.56s/it, est. speed input: 92.69 toks/s, output: 617.55 toks/s]Processed prompts:  43%|████▎     | 215/500 [25:33<16:08,  3.40s/it, est. speed input: 92.82 toks/s, output: 624.00 toks/s]Processed prompts:  43%|████▎     | 216/500 [25:34<13:24,  2.83s/it, est. speed input: 93.59 toks/s, output: 623.69 toks/s]Processed prompts:  43%|████▎     | 217/500 [25:36<11:42,  2.48s/it, est. speed input: 93.83 toks/s, output: 625.12 toks/s]Processed prompts:  44%|████▎     | 218/500 [25:44<19:55,  4.24s/it, est. speed input: 94.00 toks/s, output: 626.97 toks/s]Processed prompts:  44%|████▍     | 219/500 [25:46<16:38,  3.55s/it, est. speed input: 94.28 toks/s, output: 626.46 toks/s]Processed prompts:  44%|████▍     | 220/500 [25:53<21:36,  4.63s/it, est. speed input: 94.38 toks/s, output: 624.43 toks/s]Processed prompts:  44%|████▍     | 221/500 [26:22<54:38, 11.75s/it, est. speed input: 93.17 toks/s, output: 615.84 toks/s]Processed prompts:  44%|████▍     | 222/500 [26:30<48:53, 10.55s/it, est. speed input: 93.05 toks/s, output: 613.51 toks/s]Processed prompts:  45%|████▍     | 223/500 [26:34<39:50,  8.63s/it, est. speed input: 93.07 toks/s, output: 616.16 toks/s]Processed prompts:  45%|████▍     | 224/500 [26:46<44:33,  9.69s/it, est. speed input: 92.65 toks/s, output: 612.24 toks/s]Processed prompts:  45%|████▌     | 225/500 [27:02<52:59, 11.56s/it, est. speed input: 92.01 toks/s, output: 607.64 toks/s]Processed prompts:  45%|████▌     | 226/500 [27:11<49:10, 10.77s/it, est. speed input: 92.45 toks/s, output: 607.32 toks/s]Processed prompts:  45%|████▌     | 227/500 [27:12<36:43,  8.07s/it, est. speed input: 92.48 toks/s, output: 607.70 toks/s]Processed prompts:  46%|████▌     | 228/500 [27:16<30:18,  6.69s/it, est. speed input: 93.37 toks/s, output: 607.48 toks/s]Processed prompts:  46%|████▌     | 229/500 [27:17<22:06,  4.90s/it, est. speed input: 93.57 toks/s, output: 608.27 toks/s]Processed prompts:  46%|████▌     | 230/500 [27:17<16:05,  3.58s/it, est. speed input: 93.79 toks/s, output: 609.12 toks/s]Processed prompts:  46%|████▌     | 231/500 [27:24<20:37,  4.60s/it, est. speed input: 93.67 toks/s, output: 607.45 toks/s]WARNING 04-04 11:31:41 scheduler.py:1555] Sequence group 262 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  46%|████▋     | 232/500 [28:04<1:07:13, 15.05s/it, est. speed input: 91.71 toks/s, output: 595.48 toks/s]Processed prompts:  47%|████▋     | 233/500 [28:13<59:56, 13.47s/it, est. speed input: 91.31 toks/s, output: 594.73 toks/s]  Processed prompts:  47%|████▋     | 234/500 [28:15<43:48,  9.88s/it, est. speed input: 91.40 toks/s, output: 597.16 toks/s]Processed prompts:  47%|████▋     | 235/500 [28:16<31:25,  7.12s/it, est. speed input: 91.50 toks/s, output: 600.19 toks/s]Processed prompts:  47%|████▋     | 236/500 [28:19<26:05,  5.93s/it, est. speed input: 91.51 toks/s, output: 600.38 toks/s]Processed prompts:  47%|████▋     | 237/500 [28:24<24:59,  5.70s/it, est. speed input: 91.36 toks/s, output: 600.57 toks/s]Processed prompts:  48%|████▊     | 238/500 [28:25<19:17,  4.42s/it, est. speed input: 91.51 toks/s, output: 601.65 toks/s]Processed prompts:  48%|████▊     | 239/500 [28:38<29:42,  6.83s/it, est. speed input: 92.03 toks/s, output: 603.94 toks/s]Processed prompts:  48%|████▊     | 240/500 [28:43<27:38,  6.38s/it, est. speed input: 91.92 toks/s, output: 603.83 toks/s]Processed prompts:  48%|████▊     | 241/500 [28:45<21:30,  4.98s/it, est. speed input: 92.01 toks/s, output: 605.97 toks/s]Processed prompts:  48%|████▊     | 242/500 [29:03<38:58,  9.06s/it, est. speed input: 91.34 toks/s, output: 602.07 toks/s]Processed prompts:  49%|████▊     | 243/500 [29:08<32:48,  7.66s/it, est. speed input: 91.35 toks/s, output: 601.59 toks/s]Processed prompts:  49%|████▉     | 244/500 [29:08<23:17,  5.46s/it, est. speed input: 92.03 toks/s, output: 603.53 toks/s]Processed prompts:  49%|████▉     | 245/500 [29:22<34:11,  8.04s/it, est. speed input: 91.49 toks/s, output: 600.87 toks/s]Processed prompts:  49%|████▉     | 246/500 [29:23<25:28,  6.02s/it, est. speed input: 91.97 toks/s, output: 602.33 toks/s]Processed prompts:  49%|████▉     | 247/500 [29:44<43:13, 10.25s/it, est. speed input: 91.35 toks/s, output: 597.85 toks/s]Processed prompts:  50%|████▉     | 248/500 [29:51<39:52,  9.49s/it, est. speed input: 91.32 toks/s, output: 597.63 toks/s]Processed prompts:  50%|████▉     | 249/500 [30:17<1:00:20, 14.42s/it, est. speed input: 90.18 toks/s, output: 591.38 toks/s]Processed prompts:  50%|█████     | 250/500 [30:42<1:12:36, 17.42s/it, est. speed input: 89.24 toks/s, output: 586.28 toks/s]Processed prompts:  50%|█████     | 251/500 [30:59<1:11:54, 17.33s/it, est. speed input: 89.15 toks/s, output: 583.76 toks/s]Processed prompts:  50%|█████     | 252/500 [31:28<1:26:35, 20.95s/it, est. speed input: 88.17 toks/s, output: 577.38 toks/s]Processed prompts:  51%|█████     | 253/500 [31:37<1:10:57, 17.24s/it, est. speed input: 88.03 toks/s, output: 577.93 toks/s]Processed prompts:  51%|█████     | 254/500 [45:15<17:35:24, 257.42s/it, est. speed input: 62.13 toks/s, output: 415.91 toks/s]Processed prompts:  51%|█████     | 255/500 [45:37<12:42:58, 186.85s/it, est. speed input: 62.22 toks/s, output: 424.51 toks/s]Processed prompts:  51%|█████     | 256/500 [47:06<10:41:02, 157.63s/it, est. speed input: 61.06 toks/s, output: 422.67 toks/s]Processed prompts:  51%|█████▏    | 257/500 [48:57<9:42:03, 143.72s/it, est. speed input: 59.29 toks/s, output: 417.82 toks/s] Processed prompts:  52%|█████▏    | 258/500 [49:44<7:41:41, 114.47s/it, est. speed input: 58.81 toks/s, output: 422.33 toks/s]Processed prompts:  52%|█████▏    | 259/500 [50:02<5:44:06, 85.67s/it, est. speed input: 59.09 toks/s, output: 430.64 toks/s] Processed prompts:  52%|█████▏    | 260/500 [50:19<4:20:06, 65.03s/it, est. speed input: 58.97 toks/s, output: 439.09 toks/s]Processed prompts:  52%|█████▏    | 261/500 [50:29<3:13:01, 48.46s/it, est. speed input: 59.15 toks/s, output: 443.49 toks/s]WARNING 04-04 11:54:33 scheduler.py:1555] Sequence group 321 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  52%|█████▏    | 262/500 [53:10<5:26:25, 82.29s/it, est. speed input: 56.67 toks/s, output: 431.34 toks/s]WARNING 04-04 11:58:20 scheduler.py:1555] Sequence group 282 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  53%|█████▎    | 263/500 [57:04<8:25:05, 127.87s/it, est. speed input: 52.95 toks/s, output: 411.41 toks/s]Processed prompts:  53%|█████▎    | 264/500 [57:04<5:52:16, 89.56s/it, est. speed input: 53.35 toks/s, output: 412.97 toks/s] Processed prompts:  53%|█████▎    | 265/500 [1:01:01<8:43:13, 133.59s/it, est. speed input: 50.28 toks/s, output: 395.27 toks/s]Processed prompts:  53%|█████▎    | 266/500 [1:03:03<8:27:34, 130.15s/it, est. speed input: 48.76 toks/s, output: 391.17 toks/s]Processed prompts:  53%|█████▎    | 267/500 [1:04:46<7:53:37, 121.96s/it, est. speed input: 47.87 toks/s, output: 385.38 toks/s]Processed prompts:  54%|█████▎    | 268/500 [1:11:50<13:42:21, 212.68s/it, est. speed input: 43.35 toks/s, output: 355.04 toks/s]Processed prompts:  54%|█████▍    | 269/500 [1:13:40<11:40:19, 181.90s/it, est. speed input: 42.48 toks/s, output: 353.62 toks/s]Processed prompts:  54%|█████▍    | 270/500 [1:14:25<8:59:31, 140.75s/it, est. speed input: 42.10 toks/s, output: 357.41 toks/s] Processed prompts:  54%|█████▍    | 271/500 [1:15:12<7:09:45, 112.60s/it, est. speed input: 41.82 toks/s, output: 360.96 toks/s]Processed prompts:  54%|█████▍    | 272/500 [1:16:07<6:02:23, 95.37s/it, est. speed input: 41.49 toks/s, output: 363.77 toks/s] Processed prompts:  55%|█████▍    | 273/500 [1:16:07<4:13:06, 66.90s/it, est. speed input: 41.80 toks/s, output: 364.02 toks/s]Processed prompts:  55%|█████▍    | 274/500 [1:16:45<3:39:15, 58.21s/it, est. speed input: 41.55 toks/s, output: 368.13 toks/s]WARNING 04-04 12:20:57 scheduler.py:1555] Sequence group 313 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  55%|█████▌    | 275/500 [1:17:29<3:22:00, 53.87s/it, est. speed input: 41.24 toks/s, output: 364.93 toks/s]Processed prompts:  55%|█████▌    | 276/500 [1:18:15<3:11:47, 51.37s/it, est. speed input: 40.95 toks/s, output: 368.37 toks/s]Processed prompts:  55%|█████▌    | 277/500 [1:18:16<2:14:55, 36.30s/it, est. speed input: 41.08 toks/s, output: 368.44 toks/s]Processed prompts:  56%|█████▌    | 278/500 [1:18:33<1:53:27, 30.67s/it, est. speed input: 40.99 toks/s, output: 367.39 toks/s]Processed prompts:  56%|█████▌    | 279/500 [1:18:36<1:21:54, 22.24s/it, est. speed input: 41.02 toks/s, output: 367.37 toks/s]Processed prompts:  56%|█████▌    | 280/500 [1:21:14<3:51:05, 63.03s/it, est. speed input: 39.85 toks/s, output: 362.17 toks/s]WARNING 04-04 12:28:27 scheduler.py:1555] Sequence group 288 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  56%|█████▌    | 281/500 [1:30:27<12:46:36, 210.03s/it, est. speed input: 35.87 toks/s, output: 331.30 toks/s]Processed prompts:  56%|█████▋    | 282/500 [1:31:07<9:37:29, 158.94s/it, est. speed input: 35.66 toks/s, output: 334.89 toks/s] Processed prompts:  57%|█████▋    | 283/500 [1:32:15<7:55:48, 131.56s/it, est. speed input: 35.26 toks/s, output: 336.71 toks/s]Processed prompts:  57%|█████▋    | 284/500 [1:34:32<7:59:29, 133.19s/it, est. speed input: 34.51 toks/s, output: 334.36 toks/s]Processed prompts:  57%|█████▋    | 285/500 [1:37:48<9:05:37, 152.27s/it, est. speed input: 33.59 toks/s, output: 328.73 toks/s]Processed prompts:  57%|█████▋    | 286/500 [1:43:01<11:55:08, 200.51s/it, est. speed input: 32.04 toks/s, output: 317.38 toks/s]Processed prompts:  57%|█████▋    | 287/500 [1:43:50<9:09:36, 154.82s/it, est. speed input: 31.84 toks/s, output: 320.19 toks/s] Processed prompts:  58%|█████▊    | 288/500 [1:44:15<6:50:08, 116.08s/it, est. speed input: 31.74 toks/s, output: 324.11 toks/s]Processed prompts:  58%|█████▊    | 289/500 [1:44:55<5:27:10, 93.04s/it, est. speed input: 31.78 toks/s, output: 327.29 toks/s] Processed prompts:  58%|█████▊    | 290/500 [1:44:55<3:48:53, 65.40s/it, est. speed input: 31.81 toks/s, output: 327.35 toks/s]Processed prompts:  58%|█████▊    | 291/500 [1:47:35<5:26:25, 93.71s/it, est. speed input: 31.22 toks/s, output: 324.33 toks/s]WARNING 04-04 12:51:53 scheduler.py:1555] Sequence group 307 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  58%|█████▊    | 292/500 [1:50:10<6:28:40, 112.12s/it, est. speed input: 30.72 toks/s, output: 321.68 toks/s]Processed prompts:  59%|█████▊    | 293/500 [1:50:24<4:44:59, 82.61s/it, est. speed input: 30.69 toks/s, output: 325.95 toks/s] Processed prompts:  59%|█████▉    | 294/500 [1:54:08<7:09:15, 125.02s/it, est. speed input: 29.72 toks/s, output: 320.08 toks/s]WARNING 04-04 13:01:47 scheduler.py:1555] Sequence group 299 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  59%|█████▉    | 295/500 [2:01:38<12:40:11, 222.49s/it, est. speed input: 27.91 toks/s, output: 304.84 toks/s]Processed prompts:  59%|█████▉    | 296/500 [2:03:20<10:33:21, 186.28s/it, est. speed input: 27.63 toks/s, output: 305.07 toks/s]Processed prompts:  59%|█████▉    | 297/500 [2:04:01<8:02:33, 142.63s/it, est. speed input: 27.52 toks/s, output: 307.80 toks/s] Processed prompts:  60%|█████▉    | 298/500 [2:07:58<9:35:55, 171.07s/it, est. speed input: 26.93 toks/s, output: 302.55 toks/s]Processed prompts:  60%|█████▉    | 299/500 [2:10:46<9:30:04, 170.17s/it, est. speed input: 26.40 toks/s, output: 300.25 toks/s]Processed prompts:  60%|██████    | 300/500 [2:11:33<7:24:27, 133.34s/it, est. speed input: 26.28 toks/s, output: 302.60 toks/s]Processed prompts:  60%|██████    | 301/500 [2:12:15<5:51:01, 105.84s/it, est. speed input: 26.17 toks/s, output: 305.14 toks/s]Processed prompts:  60%|██████    | 302/500 [2:13:14<5:02:59, 91.81s/it, est. speed input: 26.14 toks/s, output: 306.98 toks/s] WARNING 04-04 13:17:34 scheduler.py:1555] Sequence group 340 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  61%|██████    | 303/500 [2:14:50<5:04:56, 92.87s/it, est. speed input: 25.97 toks/s, output: 307.41 toks/s]Processed prompts:  61%|██████    | 304/500 [2:20:38<9:13:38, 169.48s/it, est. speed input: 25.04 toks/s, output: 298.61 toks/s]WARNING 04-04 13:29:07 scheduler.py:1555] Sequence group 312 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  61%|██████    | 305/500 [2:25:20<11:00:59, 203.38s/it, est. speed input: 24.33 toks/s, output: 292.69 toks/s]Processed prompts:  61%|██████    | 306/500 [2:26:11<8:29:53, 157.70s/it, est. speed input: 24.22 toks/s, output: 294.73 toks/s] Processed prompts:  61%|██████▏   | 307/500 [2:28:10<7:49:52, 146.08s/it, est. speed input: 24.01 toks/s, output: 294.47 toks/s]Processed prompts:  62%|██████▏   | 308/500 [2:33:17<10:21:20, 194.17s/it, est. speed input: 23.24 toks/s, output: 288.22 toks/s]Processed prompts:  62%|██████▏   | 309/500 [2:33:36<7:31:26, 141.81s/it, est. speed input: 23.36 toks/s, output: 291.16 toks/s] Processed prompts:  62%|██████▏   | 310/500 [2:39:17<10:37:59, 201.47s/it, est. speed input: 22.56 toks/s, output: 284.21 toks/s]Processed prompts:  62%|██████▏   | 311/500 [2:40:17<8:20:46, 158.98s/it, est. speed input: 22.47 toks/s, output: 285.85 toks/s] Processed prompts:  62%|██████▏   | 312/500 [2:41:02<6:31:21, 124.90s/it, est. speed input: 22.39 toks/s, output: 287.90 toks/s]Processed prompts:  63%|██████▎   | 313/500 [2:41:57<5:23:14, 103.72s/it, est. speed input: 22.34 toks/s, output: 289.66 toks/s]Processed prompts:  63%|██████▎   | 314/500 [2:42:31<4:17:29, 83.06s/it, est. speed input: 22.32 toks/s, output: 291.99 toks/s] WARNING 04-04 13:47:36 scheduler.py:1555] Sequence group 337 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  63%|██████▎   | 315/500 [2:44:39<4:57:38, 96.53s/it, est. speed input: 22.09 toks/s, output: 291.52 toks/s]Processed prompts:  63%|██████▎   | 316/500 [2:49:21<7:46:42, 152.19s/it, est. speed input: 21.50 toks/s, output: 286.66 toks/s]Processed prompts:  63%|██████▎   | 317/500 [2:54:46<10:21:43, 203.85s/it, est. speed input: 20.88 toks/s, output: 280.91 toks/s]Processed prompts:  64%|██████▎   | 318/500 [2:55:10<7:34:57, 149.99s/it, est. speed input: 20.89 toks/s, output: 283.38 toks/s] Processed prompts:  64%|██████▍   | 319/500 [2:56:36<6:34:28, 130.77s/it, est. speed input: 20.77 toks/s, output: 284.18 toks/s]Processed prompts:  64%|██████▍   | 320/500 [3:03:36<10:52:10, 217.39s/it, est. speed input: 20.05 toks/s, output: 276.33 toks/s]Processed prompts:  64%|██████▍   | 321/500 [3:04:06<8:01:06, 161.26s/it, est. speed input: 20.06 toks/s, output: 278.54 toks/s] Processed prompts:  64%|██████▍   | 322/500 [3:08:18<9:19:00, 188.43s/it, est. speed input: 19.69 toks/s, output: 275.23 toks/s]Processed prompts:  65%|██████▍   | 323/500 [3:09:07<7:13:11, 146.84s/it, est. speed input: 19.65 toks/s, output: 276.91 toks/s]Processed prompts:  65%|██████▍   | 324/500 [3:09:29<5:20:19, 109.20s/it, est. speed input: 19.64 toks/s, output: 279.27 toks/s]WARNING 04-04 14:13:36 scheduler.py:1555] Sequence group 346 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  65%|██████▌   | 325/500 [3:09:57<4:07:12, 84.76s/it, est. speed input: 19.61 toks/s, output: 281.47 toks/s] Processed prompts:  65%|██████▌   | 326/500 [3:11:11<3:57:10, 81.78s/it, est. speed input: 19.51 toks/s, output: 282.49 toks/s]WARNING 04-04 14:17:39 scheduler.py:1555] Sequence group 344 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  65%|██████▌   | 327/500 [3:15:54<6:49:55, 142.17s/it, est. speed input: 19.17 toks/s, output: 278.47 toks/s]Processed prompts:  66%|██████▌   | 328/500 [3:16:42<5:26:05, 113.75s/it, est. speed input: 19.12 toks/s, output: 280.13 toks/s]Processed prompts:  66%|██████▌   | 329/500 [3:22:26<8:41:23, 182.95s/it, est. speed input: 18.66 toks/s, output: 274.88 toks/s]Processed prompts:  66%|██████▌   | 330/500 [3:25:11<8:23:10, 177.59s/it, est. speed input: 18.43 toks/s, output: 273.86 toks/s]Processed prompts:  66%|██████▌   | 331/500 [3:29:27<9:26:23, 201.09s/it, est. speed input: 18.08 toks/s, output: 270.89 toks/s]Processed prompts:  66%|██████▋   | 332/500 [3:31:57<8:39:31, 185.54s/it, est. speed input: 17.88 toks/s, output: 270.29 toks/s]Processed prompts:  67%|██████▋   | 333/500 [3:35:35<9:04:07, 195.50s/it, est. speed input: 17.60 toks/s, output: 268.25 toks/s]Processed prompts:  67%|██████▋   | 334/500 [3:36:50<7:20:24, 159.19s/it, est. speed input: 17.57 toks/s, output: 269.23 toks/s]Processed prompts:  67%|██████▋   | 335/500 [3:37:35<5:43:49, 125.02s/it, est. speed input: 17.55 toks/s, output: 270.81 toks/s]Processed prompts:  67%|██████▋   | 336/500 [3:38:48<4:58:40, 109.27s/it, est. speed input: 17.61 toks/s, output: 271.81 toks/s]Processed prompts:  67%|██████▋   | 337/500 [3:39:23<3:56:30, 87.06s/it, est. speed input: 17.63 toks/s, output: 273.57 toks/s] WARNING 04-04 14:43:43 scheduler.py:1555] Sequence group 365 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  68%|██████▊   | 338/500 [3:40:02<3:16:00, 72.60s/it, est. speed input: 17.65 toks/s, output: 275.25 toks/s]WARNING 04-04 14:46:31 scheduler.py:1555] Sequence group 357 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  68%|██████▊   | 339/500 [3:45:01<6:17:35, 140.72s/it, est. speed input: 17.28 toks/s, output: 271.56 toks/s]Processed prompts:  68%|██████▊   | 340/500 [3:49:48<8:11:59, 184.49s/it, est. speed input: 16.96 toks/s, output: 268.30 toks/s]Processed prompts:  68%|██████▊   | 341/500 [3:51:29<7:02:22, 159.39s/it, est. speed input: 16.86 toks/s, output: 268.71 toks/s]Processed prompts:  68%|██████▊   | 342/500 [3:52:23<5:36:23, 127.74s/it, est. speed input: 16.86 toks/s, output: 270.02 toks/s]Processed prompts:  69%|██████▊   | 343/500 [4:01:28<11:01:56, 252.97s/it, est. speed input: 16.31 toks/s, output: 262.12 toks/s]Processed prompts:  69%|██████▉   | 344/500 [4:02:25<8:25:12, 194.31s/it, est. speed input: 16.30 toks/s, output: 262.00 toks/s] Processed prompts:  69%|██████▉   | 345/500 [4:03:00<6:18:26, 146.49s/it, est. speed input: 16.28 toks/s, output: 263.62 toks/s]Processed prompts:  69%|██████▉   | 346/500 [4:04:40<5:39:46, 132.38s/it, est. speed input: 16.21 toks/s, output: 264.07 toks/s]Processed prompts:  69%|██████▉   | 347/500 [4:05:30<4:35:08, 107.90s/it, est. speed input: 16.20 toks/s, output: 265.38 toks/s]Processed prompts:  70%|██████▉   | 348/500 [4:06:09<3:40:23, 87.00s/it, est. speed input: 16.21 toks/s, output: 266.91 toks/s] Processed prompts:  70%|██████▉   | 349/500 [4:07:07<3:17:15, 78.38s/it, est. speed input: 16.18 toks/s, output: 268.08 toks/s]WARNING 04-04 15:11:44 scheduler.py:1555] Sequence group 373 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
Processed prompts:  70%|███████   | 350/500 [4:07:55<2:53:14, 69.30s/it, est. speed input: 16.14 toks/s, output: 269.41 toks/s]Processed prompts:  70%|███████   | 351/500 [4:10:50<4:10:57, 101.06s/it, est. speed input: 15.98 toks/s, output: 268.45 toks/s]Processed prompts:  70%|███████   | 352/500 [4:13:57<5:12:34, 126.72s/it, est. speed input: 15.91 toks/s, output: 267.32 toks/s]WARNING 04-04 15:18:58 scheduler.py:1555] Sequence group 367 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301
Processed prompts:  71%|███████   | 353/500 [4:19:28<7:40:22, 187.91s/it, est. speed input: 15.60 toks/s, output: 263.74 toks/s]Processed prompts:  71%|███████   | 354/500 [4:24:45<9:12:00, 226.86s/it, est. speed input: 15.37 toks/s, output: 260.53 toks/s]Processed prompts:  71%|███████   | 355/500 [4:29:55<10:08:11, 251.66s/it, est. speed input: 15.19 toks/s, output: 257.57 toks/s]Processed prompts:  71%|███████   | 356/500 [4:31:49<8:25:11, 210.50s/it, est. speed input: 15.14 toks/s, output: 257.78 toks/s] Processed prompts:  71%|███████▏  | 357/500 [4:33:43<7:12:52, 181.62s/it, est. speed input: 15.15 toks/s, output: 257.98 toks/s]Processed prompts:  72%|███████▏  | 358/500 [4:34:34<5:36:50, 142.33s/it, est. speed input: 15.22 toks/s, output: 259.17 toks/s]Processed prompts:  72%|███████▏  | 359/500 [4:35:03<4:14:42, 108.39s/it, est. speed input: 15.27 toks/s, output: 260.70 toks/s]Processed prompts:  72%|███████▏  | 360/500 [4:35:16<3:05:52, 79.66s/it, est. speed input: 15.28 toks/s, output: 262.49 toks/s] Processed prompts:  72%|███████▏  | 361/500 [4:35:42<2:27:29, 63.66s/it, est. speed input: 15.29 toks/s, output: 264.05 toks/s]WARNING 04-04 15:40:16 scheduler.py:1555] Sequence group 399 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351
Processed prompts:  72%|███████▏  | 362/500 [4:37:38<3:02:27, 79.33s/it, est. speed input: 15.20 toks/s, output: 264.18 toks/s]Processed prompts:  73%|███████▎  | 363/500 [4:46:22<8:05:17, 212.53s/it, est. speed input: 14.77 toks/s, output: 258.04 toks/s]Processed prompts:  73%|███████▎  | 364/500 [4:47:45<6:33:56, 173.80s/it, est. speed input: 14.77 toks/s, output: 258.69 toks/s]WARNING 04-04 15:54:21 scheduler.py:1555] Sequence group 372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401
Processed prompts:  73%|███████▎  | 365/500 [4:51:01<6:45:52, 180.39s/it, est. speed input: 14.65 toks/s, output: 257.67 toks/s]Processed prompts:  73%|███████▎  | 366/500 [4:53:07<6:06:39, 164.18s/it, est. speed input: 14.65 toks/s, output: 257.68 toks/s]Processed prompts:  73%|███████▎  | 367/500 [4:56:42<6:37:44, 179.44s/it, est. speed input: 14.58 toks/s, output: 256.41 toks/s]Processed prompts:  74%|███████▎  | 368/500 [4:59:28<6:25:53, 175.41s/it, est. speed input: 14.46 toks/s, output: 255.86 toks/s]Processed prompts:  74%|███████▍  | 369/500 [5:01:16<5:38:29, 155.04s/it, est. speed input: 14.41 toks/s, output: 256.15 toks/s]Processed prompts:  74%|███████▍  | 370/500 [5:02:38<4:48:47, 133.29s/it, est. speed input: 14.40 toks/s, output: 256.79 toks/s]Processed prompts:  74%|███████▍  | 371/500 [5:03:46<4:04:23, 113.67s/it, est. speed input: 14.39 toks/s, output: 257.63 toks/s]Processed prompts:  74%|███████▍  | 372/500 [5:04:42<3:25:33, 96.35s/it, est. speed input: 14.40 toks/s, output: 258.64 toks/s] Processed prompts:  75%|███████▍  | 373/500 [5:05:22<2:48:22, 79.55s/it, est. speed input: 14.38 toks/s, output: 258.12 toks/s]WARNING 04-04 16:10:31 scheduler.py:1555] Sequence group 392 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451
Processed prompts:  75%|███████▍  | 374/500 [5:09:08<4:19:06, 123.39s/it, est. speed input: 14.22 toks/s, output: 256.74 toks/s]Processed prompts:  75%|███████▌  | 375/500 [5:13:53<5:58:14, 171.96s/it, est. speed input: 14.02 toks/s, output: 254.59 toks/s]Processed prompts:  75%|███████▌  | 376/500 [5:17:14<6:13:01, 180.50s/it, est. speed input: 13.89 toks/s, output: 253.64 toks/s]Processed prompts:  75%|███████▌  | 377/500 [5:18:21<5:00:10, 146.43s/it, est. speed input: 13.92 toks/s, output: 254.46 toks/s]Processed prompts:  76%|███████▌  | 378/500 [5:20:28<4:45:59, 140.65s/it, est. speed input: 13.84 toks/s, output: 254.48 toks/s]Processed prompts:  76%|███████▌  | 379/500 [5:25:58<6:38:30, 197.60s/it, est. speed input: 13.63 toks/s, output: 251.86 toks/s]Processed prompts:  76%|███████▌  | 380/500 [5:27:01<5:14:30, 157.25s/it, est. speed input: 13.62 toks/s, output: 251.77 toks/s]Processed prompts:  76%|███████▌  | 381/500 [5:27:21<3:49:59, 115.97s/it, est. speed input: 13.67 toks/s, output: 253.19 toks/s]Processed prompts:  76%|███████▋  | 382/500 [5:28:50<3:32:11, 107.89s/it, est. speed input: 13.65 toks/s, output: 253.71 toks/s]Processed prompts:  77%|███████▋  | 383/500 [5:29:26<2:48:06, 86.21s/it, est. speed input: 13.68 toks/s, output: 254.91 toks/s] Processed prompts:  77%|███████▋  | 384/500 [5:30:17<2:26:24, 75.73s/it, est. speed input: 13.66 toks/s, output: 255.90 toks/s]WARNING 04-04 16:35:04 scheduler.py:1555] Sequence group 415 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501
Processed prompts:  77%|███████▋  | 385/500 [5:31:47<2:33:25, 80.04s/it, est. speed input: 13.69 toks/s, output: 256.39 toks/s]Processed prompts:  77%|███████▋  | 386/500 [5:34:31<3:20:09, 105.35s/it, est. speed input: 13.59 toks/s, output: 255.92 toks/s]Processed prompts:  77%|███████▋  | 387/500 [5:39:52<5:19:44, 169.77s/it, est. speed input: 13.43 toks/s, output: 253.51 toks/s]Processed prompts:  78%|███████▊  | 388/500 [5:43:19<5:37:56, 181.04s/it, est. speed input: 13.30 toks/s, output: 252.55 toks/s]Processed prompts:  78%|███████▊  | 389/500 [5:49:18<7:13:51, 234.51s/it, est. speed input: 13.10 toks/s, output: 249.79 toks/s]Processed prompts:  78%|███████▊  | 390/500 [5:53:51<7:30:56, 245.96s/it, est. speed input: 12.94 toks/s, output: 248.12 toks/s]Processed prompts:  78%|███████▊  | 391/500 [5:53:55<5:15:13, 173.52s/it, est. speed input: 12.96 toks/s, output: 249.02 toks/s]Processed prompts:  78%|███████▊  | 392/500 [5:55:07<4:17:15, 142.92s/it, est. speed input: 12.93 toks/s, output: 249.72 toks/s]Processed prompts:  79%|███████▊  | 393/500 [5:56:31<3:43:38, 125.40s/it, est. speed input: 12.93 toks/s, output: 250.27 toks/s]Processed prompts:  79%|███████▉  | 394/500 [5:57:23<3:02:23, 103.24s/it, est. speed input: 12.93 toks/s, output: 251.19 toks/s]WARNING 04-04 17:01:39 scheduler.py:1555] Sequence group 407 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551
Processed prompts:  79%|███████▉  | 395/500 [5:58:03<2:27:21, 84.20s/it, est. speed input: 12.92 toks/s, output: 252.25 toks/s] Processed prompts:  79%|███████▉  | 396/500 [5:58:44<2:03:39, 71.34s/it, est. speed input: 12.92 toks/s, output: 253.29 toks/s]Processed prompts:  79%|███████▉  | 397/500 [5:59:13<1:40:44, 58.69s/it, est. speed input: 12.92 toks/s, output: 254.47 toks/s]Processed prompts:  80%|███████▉  | 398/500 [6:03:11<3:11:02, 112.37s/it, est. speed input: 12.80 toks/s, output: 253.20 toks/s]WARNING 04-04 17:08:34 scheduler.py:1555] Sequence group 414 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601
Processed prompts:  80%|███████▉  | 399/500 [6:08:08<4:42:20, 167.72s/it, est. speed input: 12.64 toks/s, output: 251.28 toks/s]Processed prompts:  80%|████████  | 400/500 [6:13:25<5:54:33, 212.73s/it, est. speed input: 12.47 toks/s, output: 249.18 toks/s]Processed prompts:  80%|████████  | 401/500 [6:14:33<4:39:09, 169.18s/it, est. speed input: 12.45 toks/s, output: 249.07 toks/s]Processed prompts:  80%|████████  | 402/500 [6:16:02<3:56:48, 144.98s/it, est. speed input: 12.49 toks/s, output: 249.55 toks/s]Processed prompts:  81%|████████  | 403/500 [6:19:57<4:38:26, 172.23s/it, est. speed input: 12.40 toks/s, output: 248.40 toks/s]Processed prompts:  81%|████████  | 404/500 [6:21:16<3:50:41, 144.19s/it, est. speed input: 12.37 toks/s, output: 248.98 toks/s]Processed prompts:  81%|████████  | 405/500 [6:22:53<3:25:34, 129.84s/it, est. speed input: 12.41 toks/s, output: 249.36 toks/s]Processed prompts:  81%|████████  | 406/500 [6:23:35<2:42:26, 103.69s/it, est. speed input: 12.40 toks/s, output: 250.32 toks/s]Processed prompts:  81%|████████▏ | 407/500 [6:24:16<2:11:35, 84.89s/it, est. speed input: 12.39 toks/s, output: 251.30 toks/s] Processed prompts:  82%|████████▏ | 408/500 [6:24:31<1:38:00, 63.91s/it, est. speed input: 12.40 toks/s, output: 251.44 toks/s]Processed prompts:  82%|████████▏ | 409/500 [6:25:14<1:27:15, 57.54s/it, est. speed input: 12.40 toks/s, output: 252.40 toks/s]WARNING 04-04 17:30:08 scheduler.py:1555] Sequence group 450 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651
Processed prompts:  82%|████████▏ | 410/500 [6:26:23<1:31:37, 61.09s/it, est. speed input: 12.37 toks/s, output: 253.05 toks/s]Processed prompts:  82%|████████▏ | 411/500 [6:26:24<1:03:37, 42.89s/it, est. speed input: 12.39 toks/s, output: 253.08 toks/s]Processed prompts:  82%|████████▏ | 412/500 [6:29:45<2:12:27, 90.31s/it, est. speed input: 12.30 toks/s, output: 251.80 toks/s]Processed prompts:  83%|████████▎ | 413/500 [6:29:46<1:32:24, 63.73s/it, est. speed input: 12.32 toks/s, output: 252.48 toks/s]Processed prompts:  83%|████████▎ | 414/500 [6:32:33<2:15:45, 94.72s/it, est. speed input: 12.25 toks/s, output: 252.08 toks/s]Processed prompts:  83%|████████▎ | 415/500 [6:35:05<2:38:23, 111.81s/it, est. speed input: 12.18 toks/s, output: 251.85 toks/s]Processed prompts:  83%|████████▎ | 416/500 [6:37:33<2:51:45, 122.69s/it, est. speed input: 12.12 toks/s, output: 251.19 toks/s]WARNING 04-04 17:42:33 scheduler.py:1555] Sequence group 429 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701
Processed prompts:  83%|████████▎ | 417/500 [6:49:50<7:04:46, 307.07s/it, est. speed input: 11.77 toks/s, output: 244.99 toks/s]Processed prompts:  84%|████████▎ | 418/500 [6:51:17<5:29:16, 240.93s/it, est. speed input: 11.74 toks/s, output: 245.46 toks/s]Processed prompts:  84%|████████▍ | 419/500 [6:51:26<3:51:13, 171.28s/it, est. speed input: 11.83 toks/s, output: 246.31 toks/s]Processed prompts:  84%|████████▍ | 420/500 [6:52:19<3:01:06, 135.83s/it, est. speed input: 11.81 toks/s, output: 247.10 toks/s]Processed prompts:  84%|████████▍ | 421/500 [6:55:12<3:13:33, 147.01s/it, est. speed input: 11.81 toks/s, output: 246.70 toks/s]Processed prompts:  84%|████████▍ | 422/500 [6:55:23<2:18:08, 106.26s/it, est. speed input: 11.81 toks/s, output: 247.90 toks/s]Processed prompts:  85%|████████▍ | 423/500 [6:55:39<1:41:27, 79.06s/it, est. speed input: 11.84 toks/s, output: 249.06 toks/s] Processed prompts:  85%|████████▍ | 424/500 [6:55:49<1:14:04, 58.48s/it, est. speed input: 11.88 toks/s, output: 250.27 toks/s]Processed prompts:  85%|████████▌ | 425/500 [6:56:26<1:05:02, 52.03s/it, est. speed input: 11.89 toks/s, output: 251.21 toks/s]Processed prompts:  85%|████████▌ | 426/500 [7:04:01<3:33:06, 172.79s/it, est. speed input: 11.73 toks/s, output: 248.01 toks/s]Processed prompts:  85%|████████▌ | 427/500 [7:05:33<3:00:42, 148.52s/it, est. speed input: 11.70 toks/s, output: 247.65 toks/s]Processed prompts:  86%|████████▌ | 428/500 [7:07:02<2:36:56, 130.79s/it, est. speed input: 11.67 toks/s, output: 248.07 toks/s]Processed prompts:  86%|████████▌ | 429/500 [7:07:30<1:58:25, 100.08s/it, est. speed input: 11.67 toks/s, output: 249.07 toks/s]WARNING 04-04 18:14:07 scheduler.py:1555] Sequence group 440 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751
Processed prompts:  86%|████████▌ | 430/500 [7:10:33<2:25:31, 124.74s/it, est. speed input: 11.60 toks/s, output: 248.58 toks/s]Processed prompts:  86%|████████▌ | 431/500 [7:12:49<2:27:35, 128.34s/it, est. speed input: 11.56 toks/s, output: 248.53 toks/s]Processed prompts:  86%|████████▋ | 432/500 [7:14:48<2:21:57, 125.26s/it, est. speed input: 11.54 toks/s, output: 248.67 toks/s]Processed prompts:  87%|████████▋ | 433/500 [7:19:05<3:03:59, 164.77s/it, est. speed input: 11.44 toks/s, output: 247.48 toks/s]Processed prompts:  87%|████████▋ | 434/500 [7:20:59<2:44:29, 149.54s/it, est. speed input: 11.42 toks/s, output: 247.66 toks/s]Processed prompts:  87%|████████▋ | 435/500 [7:22:15<2:18:10, 127.54s/it, est. speed input: 11.41 toks/s, output: 248.18 toks/s]Processed prompts:  87%|████████▋ | 436/500 [7:23:13<1:53:56, 106.81s/it, est. speed input: 11.40 toks/s, output: 248.87 toks/s]Processed prompts:  87%|████████▋ | 437/500 [7:28:10<2:52:00, 163.81s/it, est. speed input: 11.28 toks/s, output: 247.34 toks/s]Processed prompts:  88%|████████▊ | 438/500 [7:30:09<2:35:20, 150.32s/it, est. speed input: 11.24 toks/s, output: 247.46 toks/s]Processed prompts:  88%|████████▊ | 439/500 [7:30:48<1:58:58, 117.02s/it, est. speed input: 11.23 toks/s, output: 248.32 toks/s]Processed prompts:  88%|████████▊ | 440/500 [7:37:07<3:15:35, 195.59s/it, est. speed input: 11.09 toks/s, output: 246.08 toks/s]Processed prompts:  88%|████████▊ | 441/500 [7:40:01<3:05:48, 188.96s/it, est. speed input: 11.04 toks/s, output: 245.72 toks/s]Processed prompts:  88%|████████▊ | 442/500 [7:40:32<2:17:02, 141.77s/it, est. speed input: 11.09 toks/s, output: 246.62 toks/s]WARNING 04-04 18:45:02 scheduler.py:1555] Sequence group 440 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801
Processed prompts:  89%|████████▊ | 443/500 [7:42:20<2:05:04, 131.66s/it, est. speed input: 11.07 toks/s, output: 246.29 toks/s]Processed prompts:  89%|████████▉ | 444/500 [7:43:25<1:44:04, 111.51s/it, est. speed input: 11.05 toks/s, output: 246.90 toks/s]Processed prompts:  89%|████████▉ | 445/500 [7:45:41<1:48:59, 118.89s/it, est. speed input: 11.01 toks/s, output: 246.87 toks/s]Processed prompts:  89%|████████▉ | 446/500 [7:46:50<1:33:40, 104.07s/it, est. speed input: 11.05 toks/s, output: 247.42 toks/s]WARNING 04-04 18:52:38 scheduler.py:1555] Sequence group 474 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851
Processed prompts:  89%|████████▉ | 447/500 [7:49:29<1:46:19, 120.38s/it, est. speed input: 11.00 toks/s, output: 246.22 toks/s]Processed prompts:  90%|████████▉ | 448/500 [7:50:10<1:23:42, 96.58s/it, est. speed input: 11.01 toks/s, output: 246.64 toks/s] Processed prompts:  90%|████████▉ | 449/500 [7:51:02<1:10:51, 83.36s/it, est. speed input: 10.99 toks/s, output: 247.35 toks/s]Processed prompts:  90%|█████████ | 450/500 [7:51:41<58:19, 70.00s/it, est. speed input: 10.99 toks/s, output: 248.16 toks/s]  Processed prompts:  90%|█████████ | 451/500 [7:53:25<1:05:20, 80.01s/it, est. speed input: 10.98 toks/s, output: 248.41 toks/s]WARNING 04-04 18:58:06 scheduler.py:1555] Sequence group 480 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901
Processed prompts:  90%|█████████ | 452/500 [7:55:02<1:08:14, 85.30s/it, est. speed input: 10.97 toks/s, output: 248.71 toks/s]Processed prompts:  91%|█████████ | 453/500 [8:05:04<3:08:08, 240.17s/it, est. speed input: 10.77 toks/s, output: 244.70 toks/s]Processed prompts:  91%|█████████ | 454/500 [8:07:51<2:47:28, 218.44s/it, est. speed input: 10.77 toks/s, output: 244.42 toks/s]Processed prompts:  91%|█████████ | 455/500 [8:16:46<3:54:57, 313.28s/it, est. speed input: 10.59 toks/s, output: 241.13 toks/s]Processed prompts:  91%|█████████ | 456/500 [8:16:50<2:41:47, 220.62s/it, est. speed input: 10.61 toks/s, output: 242.20 toks/s]Processed prompts:  91%|█████████▏| 457/500 [8:17:01<1:52:57, 157.62s/it, est. speed input: 10.62 toks/s, output: 243.21 toks/s]Processed prompts:  92%|█████████▏| 458/500 [8:17:16<1:20:26, 114.92s/it, est. speed input: 10.65 toks/s, output: 244.18 toks/s]Processed prompts:  92%|█████████▏| 459/500 [8:17:23<56:25, 82.57s/it, est. speed input: 10.65 toks/s, output: 245.22 toks/s]   Processed prompts:  92%|█████████▏| 460/500 [8:17:37<41:12, 61.80s/it, est. speed input: 10.71 toks/s, output: 246.21 toks/s]Processed prompts:  92%|█████████▏| 461/500 [8:20:20<59:51, 92.09s/it, est. speed input: 10.68 toks/s, output: 245.97 toks/s]Processed prompts:  92%|█████████▏| 462/500 [8:21:22<52:45, 83.30s/it, est. speed input: 10.71 toks/s, output: 245.72 toks/s]WARNING 04-04 19:26:35 scheduler.py:1555] Sequence group 474 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951
Processed prompts:  93%|█████████▎| 463/500 [8:23:48<1:02:49, 101.89s/it, est. speed input: 10.67 toks/s, output: 245.62 toks/s]Processed prompts:  93%|█████████▎| 464/500 [8:28:57<1:38:27, 164.10s/it, est. speed input: 10.60 toks/s, output: 243.76 toks/s]Processed prompts:  93%|█████████▎| 465/500 [8:30:19<1:21:23, 139.53s/it, est. speed input: 10.60 toks/s, output: 244.18 toks/s]Processed prompts:  93%|█████████▎| 466/500 [8:30:44<59:36, 105.18s/it, est. speed input: 10.60 toks/s, output: 245.05 toks/s]  Processed prompts:  93%|█████████▎| 467/500 [8:34:10<1:14:30, 135.48s/it, est. speed input: 10.55 toks/s, output: 244.47 toks/s]Processed prompts:  94%|█████████▎| 468/500 [8:38:07<1:28:24, 165.76s/it, est. speed input: 10.48 toks/s, output: 243.67 toks/s]Processed prompts:  94%|█████████▍| 469/500 [8:39:27<1:12:26, 140.21s/it, est. speed input: 10.46 toks/s, output: 244.09 toks/s]Processed prompts:  94%|█████████▍| 470/500 [8:40:25<57:46, 115.54s/it, est. speed input: 10.45 toks/s, output: 244.68 toks/s]  Processed prompts:  94%|█████████▍| 471/500 [8:41:13<46:00, 95.18s/it, est. speed input: 10.45 toks/s, output: 245.36 toks/s] Processed prompts:  94%|█████████▍| 472/500 [8:42:13<39:27, 84.57s/it, est. speed input: 10.44 toks/s, output: 245.94 toks/s]Processed prompts:  95%|█████████▍| 473/500 [8:43:47<39:23, 87.54s/it, est. speed input: 10.41 toks/s, output: 245.25 toks/s]Processed prompts:  95%|█████████▍| 474/500 [8:45:44<41:42, 96.23s/it, est. speed input: 10.40 toks/s, output: 245.38 toks/s]WARNING 04-04 19:50:18 scheduler.py:1555] Sequence group 495 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001
Processed prompts:  95%|█████████▌| 475/500 [8:51:22<1:10:22, 168.90s/it, est. speed input: 10.30 toks/s, output: 243.80 toks/s]Processed prompts:  95%|█████████▌| 476/500 [8:53:29<1:02:30, 156.28s/it, est. speed input: 10.27 toks/s, output: 243.86 toks/s]Processed prompts:  95%|█████████▌| 477/500 [8:54:32<49:08, 128.21s/it, est. speed input: 10.28 toks/s, output: 244.41 toks/s]  Processed prompts:  96%|█████████▌| 478/500 [8:56:44<47:26, 129.37s/it, est. speed input: 10.25 toks/s, output: 243.83 toks/s]Processed prompts:  96%|█████████▌| 479/500 [8:57:50<38:37, 110.37s/it, est. speed input: 10.25 toks/s, output: 244.35 toks/s]Processed prompts:  96%|█████████▌| 480/500 [9:00:06<39:22, 118.13s/it, est. speed input: 10.22 toks/s, output: 244.33 toks/s]Processed prompts:  96%|█████████▌| 481/500 [9:01:48<35:51, 113.23s/it, est. speed input: 10.19 toks/s, output: 244.21 toks/s]Processed prompts:  96%|█████████▋| 482/500 [9:02:50<29:23, 97.99s/it, est. speed input: 10.18 toks/s, output: 244.75 toks/s] Processed prompts:  97%|█████████▋| 483/500 [9:09:07<51:24, 181.46s/it, est. speed input: 10.07 toks/s, output: 242.95 toks/s]Processed prompts:  97%|█████████▋| 484/500 [9:10:28<40:21, 151.34s/it, est. speed input: 10.12 toks/s, output: 243.35 toks/s]Processed prompts:  97%|█████████▋| 485/500 [9:11:01<28:59, 115.98s/it, est. speed input: 10.12 toks/s, output: 244.09 toks/s]Processed prompts:  97%|█████████▋| 486/500 [9:11:25<20:38, 88.49s/it, est. speed input: 10.12 toks/s, output: 244.90 toks/s] Processed prompts:  97%|█████████▋| 487/500 [9:11:26<13:27, 62.08s/it, est. speed input: 10.16 toks/s, output: 245.55 toks/s]Processed prompts:  98%|█████████▊| 488/500 [9:11:45<09:51, 49.29s/it, est. speed input: 10.16 toks/s, output: 246.40 toks/s]Processed prompts:  98%|█████████▊| 489/500 [9:12:02<07:13, 39.37s/it, est. speed input: 10.18 toks/s, output: 246.45 toks/s]Processed prompts:  98%|█████████▊| 490/500 [9:14:54<13:13, 79.30s/it, est. speed input: 10.14 toks/s, output: 246.16 toks/s]Processed prompts:  98%|█████████▊| 491/500 [9:18:34<18:12, 121.36s/it, est. speed input: 10.14 toks/s, output: 245.52 toks/s]Processed prompts:  98%|█████████▊| 492/500 [9:21:50<19:11, 143.90s/it, est. speed input: 10.10 toks/s, output: 245.06 toks/s]Processed prompts:  99%|█████████▊| 493/500 [9:23:54<16:05, 137.93s/it, est. speed input: 10.10 toks/s, output: 245.14 toks/s]Processed prompts:  99%|█████████▉| 494/500 [9:28:31<17:58, 179.76s/it, est. speed input: 10.02 toks/s, output: 244.10 toks/s]Processed prompts:  99%|█████████▉| 495/500 [9:28:40<10:42, 128.47s/it, est. speed input: 10.03 toks/s, output: 245.00 toks/s]Processed prompts:  99%|█████████▉| 496/500 [9:32:16<10:18, 154.69s/it, est. speed input: 9.98 toks/s, output: 244.41 toks/s] Processed prompts:  99%|█████████▉| 497/500 [9:33:26<06:28, 129.35s/it, est. speed input: 9.96 toks/s, output: 244.87 toks/s]Processed prompts: 100%|█████████▉| 498/500 [9:35:06<04:01, 120.58s/it, est. speed input: 9.94 toks/s, output: 245.11 toks/s]Processed prompts: 100%|█████████▉| 499/500 [9:35:24<01:29, 89.56s/it, est. speed input: 9.94 toks/s, output: 245.93 toks/s] Processed prompts: 100%|██████████| 500/500 [9:35:38<00:00, 67.00s/it, est. speed input: 9.95 toks/s, output: 246.78 toks/s]Processed prompts: 100%|██████████| 500/500 [9:35:38<00:00, 69.08s/it, est. speed input: 9.95 toks/s, output: 246.78 toks/s]
INFO 04-04 20:39:33 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2050851)[0;0m INFO 04-04 20:39:33 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2050852)[0;0m INFO 04-04 20:39:33 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2050853)[0;0m INFO 04-04 20:39:33 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W404 20:39:46.815737294 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-04 20:40:01 config.py:510] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 04-04 20:40:02 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-04 20:40:02 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-04 20:40:02 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-04 20:40:02 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-04 20:40:02 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-04 20:40:02 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:03 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:03 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:03 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:03 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:03 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:03 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-04 20:40:03 selector.py:120] Using Flash Attention backend.
INFO 04-04 20:40:05 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:05 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:05 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:05 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-04 20:40:05 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:05 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:05 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:05 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2062966)[0;0m WARNING 04-04 20:40:05 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2062964)[0;0m WARNING 04-04 20:40:05 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2062965)[0;0m WARNING 04-04 20:40:05 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-04 20:40:05 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-04 20:40:05 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_95a1ecff'), local_subscribe_port=35559, remote_subscribe_port=None)
INFO 04-04 20:40:05 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:05 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:05 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:05 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.49it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.62it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.04it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.87it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.83it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:03<00:04,  1.80it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.80it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.80it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.79it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.80it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.78it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.88it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.85it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.83it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.88it/s]

[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:13 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:13 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-04 20:40:13 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:14 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:16 worker.py:241] Memory profiling takes 2.66 seconds
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:16 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:16 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:16 worker.py:241] Memory profiling takes 2.66 seconds
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:16 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:16 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:16 worker.py:241] Memory profiling takes 2.66 seconds
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:16 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:16 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
INFO 04-04 20:40:17 worker.py:241] Memory profiling takes 3.17 seconds
INFO 04-04 20:40:17 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-04 20:40:17 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-04 20:40:17 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-04 20:40:17 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
INFO 04-04 20:40:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:40:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:40:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:40:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:46,  1.28s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:27,  1.14s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:21,  1.11s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:18,  1.09s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:16,  1.09s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:15,  1.08s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:13,  1.08s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:11,  1.07s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<02:10,  1.07s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<02:09,  1.07s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:11<02:07,  1.06s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:12<02:06,  1.06s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:14<02:04,  1.05s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:15<02:02,  1.05s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:16<02:01,  1.05s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:17<02:01,  1.05s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:18<01:59,  1.05s/it]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:19<01:56,  1.03s/it]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:20<01:54,  1.02s/it]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:21<01:53,  1.03s/it]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:22<01:52,  1.02s/it]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:23<01:50,  1.01s/it]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:24<01:49,  1.01s/it]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:25<01:47,  1.01s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:26<01:47,  1.01s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:27<01:45,  1.01s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:28<01:44,  1.01s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:29<01:44,  1.01s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:30<01:43,  1.01s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:31<01:42,  1.01s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:32<01:40,  1.01s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:33<01:39,  1.00s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:34<01:37,  1.01it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:35<01:35,  1.02it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:36<01:34,  1.02it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:37<01:31,  1.04it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:38<01:30,  1.04it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:39<01:29,  1.04it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:40<01:28,  1.04it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:40<01:26,  1.05it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:41<01:25,  1.05it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:42<01:24,  1.06it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:43<01:22,  1.06it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:44<01:22,  1.06it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:45<01:20,  1.07it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:46<01:19,  1.07it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:47<01:18,  1.08it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:48<01:17,  1.07it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:49<01:16,  1.07it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:50<01:14,  1.08it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:51<01:14,  1.08it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:52<01:12,  1.09it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:53<01:12,  1.08it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:53<01:11,  1.08it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:54<01:10,  1.08it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:55<01:08,  1.09it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:56<01:07,  1.10it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:57<01:06,  1.09it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:58<01:05,  1.09it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:59<01:04,  1.09it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:00<01:03,  1.10it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:01<01:02,  1.11it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:02<01:01,  1.11it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:03<01:00,  1.10it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:03<00:58,  1.13it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:04<00:56,  1.14it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:05<00:55,  1.16it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:06<00:53,  1.17it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:07<00:52,  1.17it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:08<00:51,  1.19it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:08<00:50,  1.20it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:09<00:49,  1.20it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:10<00:48,  1.20it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:11<00:47,  1.20it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:12<00:46,  1.20it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:13<00:45,  1.20it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:13<00:44,  1.20it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:14<00:43,  1.21it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:15<00:43,  1.21it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:16<00:42,  1.21it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:17<00:40,  1.23it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:17<00:39,  1.25it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:18<00:37,  1.27it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:19<00:36,  1.27it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:20<00:36,  1.27it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:20<00:35,  1.29it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:21<00:34,  1.29it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:22<00:33,  1.30it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:23<00:32,  1.30it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:24<00:31,  1.30it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:24<00:30,  1.30it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:25<00:30,  1.30it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:26<00:29,  1.30it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:27<00:28,  1.30it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:27<00:27,  1.30it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:28<00:26,  1.30it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:29<00:26,  1.31it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:30<00:25,  1.32it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:30<00:24,  1.32it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:31<00:23,  1.33it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:32<00:22,  1.34it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:33<00:21,  1.36it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:33<00:20,  1.36it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:34<00:19,  1.37it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:35<00:18,  1.37it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:35<00:18,  1.38it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:36<00:17,  1.38it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:37<00:16,  1.39it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:38<00:15,  1.40it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:38<00:15,  1.40it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:39<00:14,  1.40it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:40<00:13,  1.40it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:40<00:12,  1.42it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:41<00:11,  1.43it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:42<00:11,  1.43it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:42<00:10,  1.45it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:43<00:09,  1.45it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:44<00:08,  1.48it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:45<00:08,  1.47it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:45<00:07,  1.47it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:46<00:06,  1.48it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:47<00:06,  1.48it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:47<00:05,  1.48it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:48<00:04,  1.47it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:49<00:04,  1.48it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:49<00:03,  1.51it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:50<00:02,  1.51it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:51<00:01,  1.52it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:51<00:01,  1.51it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:52<00:00,  1.51it/s][1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-04 20:42:24 model_runner.py:1535] Graph capturing finished in 113 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-04 20:42:24 model_runner.py:1535] Graph capturing finished in 113 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-04 20:42:24 model_runner.py:1535] Graph capturing finished in 113 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:53<00:00,  1.32it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:53<00:00,  1.16it/s]
INFO 04-04 20:42:25 model_runner.py:1535] Graph capturing finished in 113 secs, took 8.20 GiB
INFO 04-04 20:42:25 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 131.09 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: topology
Generating answers for task: topology
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-04 20:43:27 scheduler.py:1555] Sequence group 358 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-04 20:43:43 scheduler.py:1555] Sequence group 308 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-04 20:44:01 scheduler.py:1555] Sequence group 258 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
WARNING 04-04 20:44:30 scheduler.py:1555] Sequence group 208 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
WARNING 04-04 20:45:09 scheduler.py:1555] Sequence group 158 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
WARNING 04-04 20:46:14 scheduler.py:1555] Sequence group 108 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:   0%|          | 1/500 [06:07<50:55:10, 367.36s/it, est. speed input: 0.58 toks/s, output: 8.89 toks/s]WARNING 04-04 20:48:41 scheduler.py:1555] Sequence group 58 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:   0%|          | 2/500 [06:15<21:33:36, 155.86s/it, est. speed input: 1.14 toks/s, output: 17.65 toks/s]Processed prompts:   1%|          | 3/500 [07:11<15:14:28, 110.40s/it, est. speed input: 1.53 toks/s, output: 24.84 toks/s]Processed prompts:   1%|          | 4/500 [07:20<9:40:55, 70.27s/it, est. speed input: 2.01 toks/s, output: 33.92 toks/s]  Processed prompts:   1%|          | 5/500 [07:45<7:25:05, 53.95s/it, est. speed input: 2.40 toks/s, output: 41.91 toks/s]Processed prompts:   1%|          | 6/500 [07:47<4:58:51, 36.30s/it, est. speed input: 2.88 toks/s, output: 51.58 toks/s]Processed prompts:   1%|▏         | 7/500 [08:17<4:43:00, 34.44s/it, est. speed input: 3.19 toks/s, output: 58.54 toks/s]Processed prompts:   2%|▏         | 8/500 [09:05<5:15:41, 38.50s/it, est. speed input: 3.34 toks/s, output: 64.03 toks/s]Processed prompts:   2%|▏         | 9/500 [09:17<4:09:00, 30.43s/it, est. speed input: 3.68 toks/s, output: 73.24 toks/s]Processed prompts:   2%|▏         | 10/500 [09:26<3:14:19, 23.79s/it, est. speed input: 4.03 toks/s, output: 82.82 toks/s]Processed prompts:   2%|▏         | 11/500 [09:38<2:45:04, 20.25s/it, est. speed input: 4.34 toks/s, output: 91.89 toks/s]Processed prompts:   2%|▏         | 12/500 [09:52<2:27:39, 18.15s/it, est. speed input: 6.84 toks/s, output: 100.77 toks/s]Processed prompts:   3%|▎         | 13/500 [09:56<1:54:03, 14.05s/it, est. speed input: 7.18 toks/s, output: 110.96 toks/s]Processed prompts:   3%|▎         | 14/500 [10:04<1:38:22, 12.15s/it, est. speed input: 9.09 toks/s, output: 120.58 toks/s]Processed prompts:   3%|▎         | 15/500 [10:16<1:36:45, 11.97s/it, est. speed input: 11.43 toks/s, output: 129.45 toks/s]Processed prompts:   3%|▎         | 16/500 [10:19<1:14:21,  9.22s/it, est. speed input: 11.75 toks/s, output: 140.01 toks/s]Processed prompts:   3%|▎         | 17/500 [10:53<2:15:50, 16.88s/it, est. speed input: 11.61 toks/s, output: 143.97 toks/s]Processed prompts:   4%|▎         | 18/500 [10:57<1:42:58, 12.82s/it, est. speed input: 11.98 toks/s, output: 154.65 toks/s]Processed prompts:   4%|▍         | 19/500 [10:59<1:17:52,  9.71s/it, est. speed input: 12.29 toks/s, output: 165.50 toks/s]Processed prompts:   4%|▍         | 21/500 [11:35<1:47:43, 13.49s/it, est. speed input: 12.45 toks/s, output: 179.48 toks/s]Processed prompts:   4%|▍         | 22/500 [12:52<3:54:14, 29.40s/it, est. speed input: 13.12 toks/s, output: 173.59 toks/s]Processed prompts:   5%|▍         | 23/500 [12:56<2:59:19, 22.56s/it, est. speed input: 13.49 toks/s, output: 185.01 toks/s]Processed prompts:   5%|▍         | 24/500 [13:36<3:36:34, 27.30s/it, est. speed input: 14.90 toks/s, output: 188.31 toks/s]Processed prompts:   5%|▌         | 25/500 [13:38<2:41:26, 20.39s/it, est. speed input: 15.36 toks/s, output: 200.09 toks/s]Processed prompts:   5%|▌         | 26/500 [14:16<3:20:01, 25.32s/it, est. speed input: 16.69 toks/s, output: 202.43 toks/s]Processed prompts:   5%|▌         | 27/500 [14:45<3:28:33, 26.45s/it, est. speed input: 18.12 toks/s, output: 208.46 toks/s]Processed prompts:   6%|▌         | 28/500 [14:46<2:27:58, 18.81s/it, est. speed input: 18.37 toks/s, output: 216.40 toks/s]Processed prompts:   6%|▌         | 29/500 [14:57<2:11:01, 16.69s/it, est. speed input: 18.48 toks/s, output: 226.34 toks/s]Processed prompts:   6%|▌         | 30/500 [15:08<1:56:40, 14.90s/it, est. speed input: 19.08 toks/s, output: 236.46 toks/s]Processed prompts:   6%|▌         | 31/500 [15:14<1:36:56, 12.40s/it, est. speed input: 20.15 toks/s, output: 247.59 toks/s]Processed prompts:   6%|▋         | 32/500 [15:28<1:40:29, 12.88s/it, est. speed input: 21.24 toks/s, output: 256.55 toks/s]Processed prompts:   7%|▋         | 33/500 [15:39<1:34:10, 12.10s/it, est. speed input: 22.30 toks/s, output: 266.65 toks/s]Processed prompts:   7%|▋         | 34/500 [16:17<2:36:08, 20.10s/it, est. speed input: 22.89 toks/s, output: 269.08 toks/s]Processed prompts:   7%|▋         | 35/500 [16:18<1:49:43, 14.16s/it, est. speed input: 23.46 toks/s, output: 282.05 toks/s]Processed prompts:   7%|▋         | 36/500 [17:38<4:22:07, 33.90s/it, est. speed input: 22.91 toks/s, output: 266.67 toks/s]Processed prompts:   7%|▋         | 37/500 [17:55<3:43:18, 28.94s/it, est. speed input: 23.26 toks/s, output: 275.70 toks/s]WARNING 04-04 21:01:10 scheduler.py:1555] Sequence group 54 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:   8%|▊         | 38/500 [18:59<5:03:02, 39.36s/it, est. speed input: 22.54 toks/s, output: 273.79 toks/s]Processed prompts:   8%|▊         | 39/500 [19:30<4:43:48, 36.94s/it, est. speed input: 22.94 toks/s, output: 280.07 toks/s]Processed prompts:   8%|▊         | 40/500 [20:23<5:20:56, 41.86s/it, est. speed input: 22.61 toks/s, output: 281.60 toks/s]Processed prompts:   8%|▊         | 41/500 [20:36<4:13:50, 33.18s/it, est. speed input: 23.09 toks/s, output: 286.67 toks/s]Processed prompts:   8%|▊         | 42/500 [20:40<3:05:30, 24.30s/it, est. speed input: 24.22 toks/s, output: 299.62 toks/s]Processed prompts:   9%|▊         | 43/500 [20:41<2:11:29, 17.26s/it, est. speed input: 24.73 toks/s, output: 302.09 toks/s]Processed prompts:   9%|▉         | 44/500 [20:49<1:51:13, 14.64s/it, est. speed input: 25.08 toks/s, output: 308.89 toks/s]Processed prompts:   9%|▉         | 45/500 [21:11<2:07:15, 16.78s/it, est. speed input: 24.83 toks/s, output: 306.07 toks/s]Processed prompts:   9%|▉         | 46/500 [21:19<1:46:53, 14.13s/it, est. speed input: 25.44 toks/s, output: 318.02 toks/s]Processed prompts:   9%|▉         | 47/500 [22:02<2:52:34, 22.86s/it, est. speed input: 25.07 toks/s, output: 316.35 toks/s]Processed prompts:  10%|▉         | 48/500 [22:55<3:59:57, 31.85s/it, est. speed input: 24.81 toks/s, output: 318.21 toks/s]Processed prompts:  10%|▉         | 49/500 [23:25<3:53:58, 31.13s/it, est. speed input: 24.71 toks/s, output: 315.45 toks/s]Processed prompts:  10%|█         | 50/500 [24:38<5:29:09, 43.89s/it, est. speed input: 23.95 toks/s, output: 313.91 toks/s]Processed prompts:  10%|█         | 51/500 [25:00<4:38:37, 37.23s/it, est. speed input: 24.19 toks/s, output: 323.56 toks/s]Processed prompts:  10%|█         | 52/500 [25:03<3:22:38, 27.14s/it, est. speed input: 24.64 toks/s, output: 336.99 toks/s]Processed prompts:  11%|█         | 53/500 [25:10<2:36:10, 20.96s/it, est. speed input: 24.68 toks/s, output: 344.47 toks/s]Processed prompts:  11%|█         | 54/500 [28:11<8:33:35, 69.09s/it, est. speed input: 22.25 toks/s, output: 316.76 toks/s]Processed prompts:  11%|█         | 55/500 [30:25<10:56:04, 88.46s/it, est. speed input: 21.58 toks/s, output: 302.26 toks/s]WARNING 04-04 21:16:47 scheduler.py:1555] Sequence group 63 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  11%|█         | 56/500 [38:51<26:20:19, 213.56s/it, est. speed input: 17.37 toks/s, output: 250.78 toks/s]Processed prompts:  11%|█▏        | 57/500 [41:45<24:50:44, 201.91s/it, est. speed input: 16.25 toks/s, output: 246.37 toks/s]Processed prompts:  12%|█▏        | 58/500 [43:35<21:23:05, 174.18s/it, est. speed input: 15.66 toks/s, output: 248.59 toks/s]Processed prompts:  12%|█▏        | 59/500 [44:07<16:07:25, 131.62s/it, est. speed input: 15.62 toks/s, output: 257.93 toks/s]Processed prompts:  12%|█▏        | 60/500 [44:39<12:24:59, 101.59s/it, est. speed input: 15.80 toks/s, output: 267.13 toks/s]Processed prompts:  12%|█▏        | 61/500 [48:23<16:53:21, 138.50s/it, est. speed input: 14.87 toks/s, output: 257.75 toks/s]Processed prompts:  12%|█▏        | 62/500 [49:23<13:59:44, 115.03s/it, est. speed input: 14.79 toks/s, output: 263.56 toks/s]Processed prompts:  13%|█▎        | 63/500 [50:00<11:05:47, 91.41s/it, est. speed input: 14.91 toks/s, output: 271.29 toks/s] Processed prompts:  13%|█▎        | 64/500 [54:14<16:58:40, 140.18s/it, est. speed input: 13.87 toks/s, output: 260.19 toks/s]Processed prompts:  13%|█▎        | 65/500 [56:11<16:06:22, 133.29s/it, est. speed input: 13.58 toks/s, output: 260.86 toks/s]Processed prompts:  13%|█▎        | 66/500 [59:39<18:47:04, 155.82s/it, est. speed input: 13.29 toks/s, output: 254.83 toks/s]Processed prompts:  13%|█▎        | 67/500 [1:00:16<14:26:17, 120.04s/it, est. speed input: 13.22 toks/s, output: 261.32 toks/s]Processed prompts:  14%|█▎        | 68/500 [1:01:00<11:40:53, 97.35s/it, est. speed input: 13.12 toks/s, output: 258.73 toks/s] WARNING 04-04 21:44:06 scheduler.py:1555] Sequence group 83 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  14%|█▍        | 69/500 [1:03:14<12:58:41, 108.40s/it, est. speed input: 12.76 toks/s, output: 258.22 toks/s]Processed prompts:  14%|█▍        | 70/500 [1:07:13<17:36:48, 147.46s/it, est. speed input: 12.14 toks/s, output: 251.07 toks/s]Processed prompts:  14%|█▍        | 71/500 [1:12:22<23:21:32, 196.02s/it, est. speed input: 11.33 toks/s, output: 240.73 toks/s]Processed prompts:  14%|█▍        | 72/500 [1:14:46<21:26:51, 180.40s/it, est. speed input: 11.02 toks/s, output: 240.31 toks/s]Processed prompts:  15%|█▍        | 73/500 [1:16:32<18:43:39, 157.89s/it, est. speed input: 10.81 toks/s, output: 241.93 toks/s]Processed prompts:  15%|█▍        | 74/500 [1:17:09<14:23:11, 121.58s/it, est. speed input: 10.77 toks/s, output: 247.08 toks/s]Processed prompts:  15%|█▌        | 75/500 [1:17:49<11:28:44, 97.23s/it, est. speed input: 10.75 toks/s, output: 251.96 toks/s] Processed prompts:  15%|█▌        | 76/500 [1:19:34<11:43:54, 99.61s/it, est. speed input: 10.81 toks/s, output: 253.28 toks/s]Processed prompts:  15%|█▌        | 77/500 [1:21:03<11:20:13, 96.49s/it, est. speed input: 10.72 toks/s, output: 255.37 toks/s]WARNING 04-04 22:05:30 scheduler.py:1555] Sequence group 91 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  16%|█▌        | 78/500 [1:26:22<19:06:20, 162.99s/it, est. speed input: 10.11 toks/s, output: 246.01 toks/s]Processed prompts:  16%|█▌        | 79/500 [1:28:14<17:18:01, 147.94s/it, est. speed input: 9.96 toks/s, output: 246.96 toks/s] Processed prompts:  16%|█▌        | 80/500 [1:29:17<14:16:47, 122.40s/it, est. speed input: 9.88 toks/s, output: 248.63 toks/s]Processed prompts:  16%|█▌        | 81/500 [1:30:11<11:50:48, 101.79s/it, est. speed input: 10.10 toks/s, output: 252.22 toks/s]Processed prompts:  16%|█▋        | 82/500 [1:34:29<17:16:03, 148.72s/it, est. speed input: 9.68 toks/s, output: 246.51 toks/s] Processed prompts:  17%|█▋        | 83/500 [1:34:57<13:02:17, 112.56s/it, est. speed input: 9.75 toks/s, output: 251.04 toks/s]Processed prompts:  17%|█▋        | 84/500 [1:37:19<14:00:57, 121.29s/it, est. speed input: 9.79 toks/s, output: 250.56 toks/s]Processed prompts:  17%|█▋        | 85/500 [1:43:33<22:44:25, 197.27s/it, est. speed input: 9.37 toks/s, output: 240.73 toks/s]WARNING 04-04 22:28:45 scheduler.py:1555] Sequence group 95 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  17%|█▋        | 86/500 [1:46:35<22:08:06, 192.48s/it, est. speed input: 9.16 toks/s, output: 239.03 toks/s]Processed prompts:  17%|█▋        | 87/500 [1:47:14<16:48:39, 146.54s/it, est. speed input: 9.38 toks/s, output: 242.66 toks/s]Processed prompts:  18%|█▊        | 88/500 [1:49:57<17:20:08, 151.48s/it, est. speed input: 9.40 toks/s, output: 241.63 toks/s]Processed prompts:  18%|█▊        | 89/500 [1:51:34<15:24:53, 135.02s/it, est. speed input: 9.35 toks/s, output: 243.04 toks/s]Processed prompts:  18%|█▊        | 90/500 [1:53:05<13:52:40, 121.85s/it, est. speed input: 9.26 toks/s, output: 244.61 toks/s]Processed prompts:  18%|█▊        | 91/500 [1:54:27<12:29:22, 109.93s/it, est. speed input: 9.18 toks/s, output: 246.45 toks/s]Processed prompts:  18%|█▊        | 92/500 [1:56:22<12:37:49, 111.44s/it, est. speed input: 9.12 toks/s, output: 247.09 toks/s]Processed prompts:  19%|█▊        | 93/500 [1:59:40<15:32:03, 137.40s/it, est. speed input: 8.90 toks/s, output: 244.84 toks/s]WARNING 04-04 22:43:54 scheduler.py:1555] Sequence group 105 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  19%|█▉        | 94/500 [2:03:28<18:33:52, 164.61s/it, est. speed input: 8.86 toks/s, output: 241.72 toks/s]Processed prompts:  19%|█▉        | 95/500 [2:06:01<18:07:54, 161.17s/it, est. speed input: 8.71 toks/s, output: 241.16 toks/s]Processed prompts:  19%|█▉        | 96/500 [2:06:52<14:22:41, 128.12s/it, est. speed input: 8.74 toks/s, output: 243.85 toks/s]Processed prompts:  19%|█▉        | 97/500 [2:13:08<22:39:50, 202.46s/it, est. speed input: 8.47 toks/s, output: 236.48 toks/s]Processed prompts:  20%|█▉        | 98/500 [2:14:49<19:11:57, 171.93s/it, est. speed input: 8.39 toks/s, output: 237.58 toks/s]Processed prompts:  20%|█▉        | 99/500 [2:17:10<18:07:32, 162.72s/it, est. speed input: 8.29 toks/s, output: 237.49 toks/s]Processed prompts:  20%|██        | 100/500 [2:18:56<16:10:37, 145.59s/it, est. speed input: 8.23 toks/s, output: 238.41 toks/s]Processed prompts:  20%|██        | 101/500 [2:19:21<12:08:41, 109.58s/it, est. speed input: 8.24 toks/s, output: 238.25 toks/s]Processed prompts:  20%|██        | 102/500 [2:20:11<10:07:40, 91.61s/it, est. speed input: 8.22 toks/s, output: 240.74 toks/s] Processed prompts:  21%|██        | 103/500 [2:21:25<9:30:59, 86.30s/it, est. speed input: 8.18 toks/s, output: 242.50 toks/s] Processed prompts:  21%|██        | 104/500 [2:22:18<8:24:35, 76.45s/it, est. speed input: 8.16 toks/s, output: 244.82 toks/s]WARNING 04-04 23:05:24 scheduler.py:1555] Sequence group 130 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  21%|██        | 105/500 [2:23:14<7:43:16, 70.37s/it, est. speed input: 8.13 toks/s, output: 247.03 toks/s]Processed prompts:  21%|██        | 106/500 [2:30:16<19:13:59, 175.73s/it, est. speed input: 7.81 toks/s, output: 239.12 toks/s]Processed prompts:  21%|██▏       | 107/500 [2:31:10<15:12:30, 139.31s/it, est. speed input: 7.87 toks/s, output: 241.30 toks/s]Processed prompts:  22%|██▏       | 108/500 [2:35:25<18:56:17, 173.92s/it, est. speed input: 7.71 toks/s, output: 238.22 toks/s]Processed prompts:  22%|██▏       | 109/500 [2:38:40<19:34:30, 180.23s/it, est. speed input: 7.64 toks/s, output: 236.78 toks/s]Processed prompts:  22%|██▏       | 110/500 [2:42:06<20:21:45, 187.96s/it, est. speed input: 7.61 toks/s, output: 235.14 toks/s]Processed prompts:  22%|██▏       | 111/500 [2:45:46<21:21:17, 197.63s/it, est. speed input: 7.50 toks/s, output: 233.23 toks/s]Processed prompts:  22%|██▏       | 112/500 [2:48:08<19:29:05, 180.79s/it, est. speed input: 7.44 toks/s, output: 233.20 toks/s]Processed prompts:  23%|██▎       | 113/500 [2:48:55<15:08:16, 140.82s/it, est. speed input: 7.42 toks/s, output: 235.34 toks/s]Processed prompts:  23%|██▎       | 114/500 [2:49:49<12:18:50, 114.85s/it, est. speed input: 7.45 toks/s, output: 237.31 toks/s]WARNING 04-04 23:32:59 scheduler.py:1555] Sequence group 128 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  23%|██▎       | 115/500 [2:50:40<10:12:43, 95.49s/it, est. speed input: 7.44 toks/s, output: 239.34 toks/s] Processed prompts:  23%|██▎       | 116/500 [2:50:56<7:39:01, 71.72s/it, est. speed input: 7.53 toks/s, output: 242.16 toks/s] Processed prompts:  23%|██▎       | 117/500 [2:51:47<6:57:10, 65.35s/it, est. speed input: 7.65 toks/s, output: 244.15 toks/s]WARNING 04-04 23:40:50 scheduler.py:1555] Sequence group 129 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  24%|██▎       | 118/500 [3:00:46<22:02:24, 207.71s/it, est. speed input: 7.40 toks/s, output: 235.02 toks/s]Processed prompts:  24%|██▍       | 119/500 [3:02:23<18:26:25, 174.24s/it, est. speed input: 7.41 toks/s, output: 235.95 toks/s]Processed prompts:  24%|██▍       | 120/500 [3:02:55<13:53:19, 131.58s/it, est. speed input: 7.49 toks/s, output: 238.24 toks/s]Processed prompts:  24%|██▍       | 121/500 [3:13:00<28:48:48, 273.69s/it, est. speed input: 7.24 toks/s, output: 228.62 toks/s]Processed prompts:  24%|██▍       | 122/500 [3:14:27<22:51:04, 217.63s/it, est. speed input: 7.25 toks/s, output: 229.73 toks/s]Processed prompts:  25%|██▍       | 123/500 [3:15:32<18:00:23, 171.95s/it, est. speed input: 7.25 toks/s, output: 231.24 toks/s]Processed prompts:  25%|██▍       | 124/500 [3:16:18<14:01:26, 134.27s/it, est. speed input: 7.37 toks/s, output: 233.11 toks/s]Processed prompts:  25%|██▌       | 125/500 [3:17:28<11:57:48, 114.85s/it, est. speed input: 7.42 toks/s, output: 234.51 toks/s]Processed prompts:  25%|██▌       | 126/500 [3:18:11<9:41:43, 93.32s/it, est. speed input: 7.41 toks/s, output: 236.42 toks/s]  Processed prompts:  25%|██▌       | 127/500 [3:18:29<7:19:40, 70.72s/it, est. speed input: 7.42 toks/s, output: 238.81 toks/s]Processed prompts:  26%|██▌       | 128/500 [3:20:27<8:46:38, 84.94s/it, est. speed input: 7.42 toks/s, output: 239.19 toks/s]Processed prompts:  26%|██▌       | 129/500 [3:26:10<16:44:25, 162.44s/it, est. speed input: 7.23 toks/s, output: 235.20 toks/s]WARNING 04-05 00:12:32 scheduler.py:1555] Sequence group 138 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  26%|██▌       | 130/500 [3:31:36<21:43:17, 211.34s/it, est. speed input: 7.10 toks/s, output: 231.75 toks/s]Processed prompts:  26%|██▌       | 131/500 [3:31:59<15:52:54, 154.94s/it, est. speed input: 7.10 toks/s, output: 233.90 toks/s]Processed prompts:  26%|██▋       | 132/500 [3:35:07<16:50:58, 164.83s/it, est. speed input: 7.11 toks/s, output: 233.04 toks/s]Processed prompts:  27%|██▋       | 133/500 [3:39:25<19:39:41, 192.87s/it, est. speed input: 6.99 toks/s, output: 230.96 toks/s]Processed prompts:  27%|██▋       | 134/500 [3:41:24<17:20:38, 170.60s/it, est. speed input: 7.05 toks/s, output: 231.36 toks/s]Processed prompts:  27%|██▋       | 135/500 [3:41:51<12:56:11, 127.59s/it, est. speed input: 7.06 toks/s, output: 233.35 toks/s]Processed prompts:  27%|██▋       | 136/500 [3:43:36<12:12:42, 120.78s/it, est. speed input: 7.02 toks/s, output: 233.97 toks/s]Processed prompts:  27%|██▋       | 137/500 [3:44:23<9:55:54, 98.50s/it, est. speed input: 7.01 toks/s, output: 235.59 toks/s]  Processed prompts:  28%|██▊       | 138/500 [3:44:23<6:56:33, 69.04s/it, est. speed input: 7.04 toks/s, output: 235.76 toks/s]Processed prompts:  28%|██▊       | 139/500 [3:44:58<5:53:58, 58.83s/it, est. speed input: 7.12 toks/s, output: 237.58 toks/s]WARNING 04-05 00:29:38 scheduler.py:1555] Sequence group 157 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  28%|██▊       | 140/500 [3:47:37<8:52:46, 88.79s/it, est. speed input: 7.09 toks/s, output: 237.22 toks/s]Processed prompts:  28%|██▊       | 141/500 [3:50:05<10:37:34, 106.56s/it, est. speed input: 7.03 toks/s, output: 237.05 toks/s]Processed prompts:  28%|██▊       | 142/500 [3:58:47<22:59:59, 231.28s/it, est. speed input: 6.79 toks/s, output: 230.69 toks/s]Processed prompts:  29%|██▊       | 143/500 [4:00:23<18:54:30, 190.67s/it, est. speed input: 6.77 toks/s, output: 231.43 toks/s]Processed prompts:  29%|██▉       | 144/500 [4:03:13<18:15:17, 184.60s/it, est. speed input: 6.79 toks/s, output: 230.97 toks/s]Processed prompts:  29%|██▉       | 145/500 [4:03:31<13:15:02, 134.37s/it, est. speed input: 6.86 toks/s, output: 232.94 toks/s]Processed prompts:  29%|██▉       | 146/500 [4:07:27<16:13:26, 164.99s/it, est. speed input: 6.76 toks/s, output: 231.44 toks/s]Processed prompts:  29%|██▉       | 147/500 [4:08:55<13:54:25, 141.83s/it, est. speed input: 6.79 toks/s, output: 232.28 toks/s]Processed prompts:  30%|██▉       | 148/500 [4:10:27<12:23:55, 126.80s/it, est. speed input: 6.86 toks/s, output: 233.04 toks/s]Processed prompts:  30%|██▉       | 149/500 [4:11:31<10:32:22, 108.10s/it, est. speed input: 6.87 toks/s, output: 234.21 toks/s]Processed prompts:  30%|███       | 150/500 [4:12:29<9:03:13, 93.13s/it, est. speed input: 6.86 toks/s, output: 235.48 toks/s]  WARNING 04-05 00:55:08 scheduler.py:1555] Sequence group 180 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  30%|███       | 151/500 [4:14:58<10:38:51, 109.83s/it, est. speed input: 6.81 toks/s, output: 235.33 toks/s]Processed prompts:  30%|███       | 152/500 [4:19:32<15:22:21, 159.03s/it, est. speed input: 6.72 toks/s, output: 233.30 toks/s]Processed prompts:  31%|███       | 153/500 [4:22:15<15:26:10, 160.15s/it, est. speed input: 6.67 toks/s, output: 232.96 toks/s]Processed prompts:  31%|███       | 154/500 [4:25:56<17:09:24, 178.51s/it, est. speed input: 6.68 toks/s, output: 231.79 toks/s]Processed prompts:  31%|███       | 155/500 [4:27:51<15:17:07, 159.50s/it, est. speed input: 6.65 toks/s, output: 232.16 toks/s]Processed prompts:  31%|███       | 156/500 [4:30:55<15:56:38, 166.86s/it, est. speed input: 6.61 toks/s, output: 231.55 toks/s]Processed prompts:  31%|███▏      | 157/500 [4:33:10<14:58:24, 157.16s/it, est. speed input: 6.57 toks/s, output: 231.65 toks/s]WARNING 04-05 01:17:13 scheduler.py:1555] Sequence group 168 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  32%|███▏      | 158/500 [4:36:04<15:24:55, 162.27s/it, est. speed input: 6.60 toks/s, output: 231.19 toks/s]Processed prompts:  32%|███▏      | 159/500 [4:37:11<12:40:27, 133.81s/it, est. speed input: 6.59 toks/s, output: 232.23 toks/s]Processed prompts:  32%|███▏      | 160/500 [4:38:38<11:18:42, 119.77s/it, est. speed input: 6.57 toks/s, output: 232.98 toks/s]Processed prompts:  32%|███▏      | 161/500 [4:39:25<9:13:49, 98.02s/it, est. speed input: 6.57 toks/s, output: 234.28 toks/s]  Processed prompts:  32%|███▏      | 162/500 [4:40:34<8:22:34, 89.22s/it, est. speed input: 6.55 toks/s, output: 235.27 toks/s]Processed prompts:  33%|███▎      | 163/500 [4:40:35<5:53:02, 62.86s/it, est. speed input: 6.57 toks/s, output: 235.28 toks/s]WARNING 04-05 01:25:02 scheduler.py:1555] Sequence group 181 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  33%|███▎      | 164/500 [4:45:33<12:26:18, 133.27s/it, est. speed input: 6.50 toks/s, output: 233.11 toks/s]Processed prompts:  33%|███▎      | 165/500 [4:50:38<17:10:57, 184.65s/it, est. speed input: 6.40 toks/s, output: 230.92 toks/s]Processed prompts:  33%|███▎      | 166/500 [4:53:17<16:25:27, 177.03s/it, est. speed input: 6.37 toks/s, output: 230.69 toks/s]Processed prompts:  33%|███▎      | 167/500 [4:56:46<17:15:56, 186.66s/it, est. speed input: 6.33 toks/s, output: 229.82 toks/s]Processed prompts:  34%|███▎      | 168/500 [4:59:23<16:23:50, 177.80s/it, est. speed input: 6.34 toks/s, output: 229.64 toks/s]Processed prompts:  34%|███▍      | 169/500 [5:02:48<17:05:09, 185.83s/it, est. speed input: 6.29 toks/s, output: 228.85 toks/s]Processed prompts:  34%|███▍      | 170/500 [5:03:56<13:48:06, 150.56s/it, est. speed input: 6.28 toks/s, output: 229.79 toks/s]Processed prompts:  34%|███▍      | 171/500 [5:05:25<12:04:56, 132.21s/it, est. speed input: 6.29 toks/s, output: 230.46 toks/s]Processed prompts:  34%|███▍      | 172/500 [5:07:31<11:51:42, 130.19s/it, est. speed input: 6.26 toks/s, output: 230.67 toks/s]Processed prompts:  35%|███▍      | 173/500 [5:08:13<9:26:06, 103.87s/it, est. speed input: 6.25 toks/s, output: 231.91 toks/s] Processed prompts:  35%|███▍      | 174/500 [5:08:48<7:31:48, 83.15s/it, est. speed input: 6.26 toks/s, output: 233.24 toks/s] Processed prompts:  35%|███▌      | 175/500 [5:09:29<6:21:26, 70.42s/it, est. speed input: 6.25 toks/s, output: 234.50 toks/s]WARNING 04-05 01:52:08 scheduler.py:1555] Sequence group 224 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  35%|███▌      | 176/500 [5:16:04<15:06:57, 167.96s/it, est. speed input: 6.20 toks/s, output: 230.20 toks/s]Processed prompts:  35%|███▌      | 177/500 [5:16:40<11:29:46, 128.13s/it, est. speed input: 6.25 toks/s, output: 231.50 toks/s]Processed prompts:  36%|███▌      | 178/500 [5:17:35<9:30:25, 106.29s/it, est. speed input: 6.26 toks/s, output: 232.55 toks/s] Processed prompts:  36%|███▌      | 179/500 [5:21:01<12:08:16, 136.13s/it, est. speed input: 6.25 toks/s, output: 231.76 toks/s]Processed prompts:  36%|███▌      | 180/500 [5:21:50<9:46:51, 110.04s/it, est. speed input: 6.32 toks/s, output: 232.87 toks/s] WARNING 04-05 02:05:45 scheduler.py:1555] Sequence group 192 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  36%|███▌      | 181/500 [5:27:18<15:33:12, 175.52s/it, est. speed input: 6.28 toks/s, output: 230.64 toks/s]Processed prompts:  36%|███▋      | 182/500 [5:34:33<22:22:09, 253.24s/it, est. speed input: 6.18 toks/s, output: 227.28 toks/s]Processed prompts:  37%|███▋      | 183/500 [5:35:30<17:07:31, 194.48s/it, est. speed input: 6.19 toks/s, output: 228.26 toks/s]Processed prompts:  37%|███▋      | 184/500 [5:36:23<13:21:00, 152.09s/it, est. speed input: 6.22 toks/s, output: 229.29 toks/s]Processed prompts:  37%|███▋      | 185/500 [5:37:46<11:29:01, 131.24s/it, est. speed input: 6.21 toks/s, output: 229.97 toks/s]Processed prompts:  37%|███▋      | 186/500 [5:38:23<8:59:29, 103.09s/it, est. speed input: 6.23 toks/s, output: 231.16 toks/s] Processed prompts:  37%|███▋      | 187/500 [5:38:40<6:43:08, 77.28s/it, est. speed input: 6.29 toks/s, output: 232.58 toks/s] Processed prompts:  38%|███▊      | 188/500 [5:39:39<6:12:29, 71.63s/it, est. speed input: 6.28 toks/s, output: 233.52 toks/s]WARNING 04-05 02:23:35 scheduler.py:1555] Sequence group 212 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  38%|███▊      | 189/500 [5:42:49<9:15:59, 107.27s/it, est. speed input: 6.30 toks/s, output: 232.95 toks/s]Processed prompts:  38%|███▊      | 190/500 [5:49:56<17:30:15, 203.28s/it, est. speed input: 6.19 toks/s, output: 229.77 toks/s]Processed prompts:  38%|███▊      | 191/500 [5:51:50<15:07:47, 176.27s/it, est. speed input: 6.16 toks/s, output: 230.09 toks/s]Processed prompts:  38%|███▊      | 192/500 [5:54:28<14:36:59, 170.84s/it, est. speed input: 6.13 toks/s, output: 229.92 toks/s]Processed prompts:  39%|███▊      | 193/500 [5:56:02<12:36:26, 147.84s/it, est. speed input: 6.13 toks/s, output: 230.44 toks/s]Processed prompts:  39%|███▉      | 194/500 [6:02:46<19:06:21, 224.78s/it, est. speed input: 6.05 toks/s, output: 227.66 toks/s]Processed prompts:  39%|███▉      | 195/500 [6:04:20<15:43:11, 185.55s/it, est. speed input: 6.04 toks/s, output: 228.18 toks/s]Processed prompts:  39%|███▉      | 196/500 [6:05:37<12:54:20, 152.83s/it, est. speed input: 6.07 toks/s, output: 228.88 toks/s]Processed prompts:  39%|███▉      | 197/500 [6:06:14<9:56:39, 118.15s/it, est. speed input: 6.07 toks/s, output: 229.99 toks/s] Processed prompts:  40%|███▉      | 198/500 [6:07:24<8:42:34, 103.82s/it, est. speed input: 6.11 toks/s, output: 230.74 toks/s]Processed prompts:  40%|███▉      | 199/500 [6:07:56<6:52:28, 82.22s/it, est. speed input: 6.13 toks/s, output: 231.89 toks/s] WARNING 04-05 02:51:00 scheduler.py:1555] Sequence group 223 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  40%|████      | 200/500 [6:08:54<6:13:43, 74.74s/it, est. speed input: 6.18 toks/s, output: 232.77 toks/s]Processed prompts:  40%|████      | 201/500 [6:13:18<10:56:42, 131.78s/it, est. speed input: 6.12 toks/s, output: 231.48 toks/s]Processed prompts:  40%|████      | 202/500 [6:20:41<18:37:00, 224.90s/it, est. speed input: 6.07 toks/s, output: 228.43 toks/s]Processed prompts:  41%|████      | 203/500 [6:22:03<15:01:42, 182.16s/it, est. speed input: 6.12 toks/s, output: 229.04 toks/s]Processed prompts:  41%|████      | 204/500 [6:22:12<10:42:41, 130.28s/it, est. speed input: 6.13 toks/s, output: 230.38 toks/s]WARNING 04-05 03:08:22 scheduler.py:1555] Sequence group 212 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
Processed prompts:  41%|████      | 205/500 [6:28:12<16:18:46, 199.07s/it, est. speed input: 6.10 toks/s, output: 228.23 toks/s]Processed prompts:  41%|████      | 206/500 [6:31:09<15:43:49, 192.62s/it, est. speed input: 6.07 toks/s, output: 227.90 toks/s]Processed prompts:  41%|████▏     | 207/500 [6:32:46<13:20:02, 163.83s/it, est. speed input: 6.06 toks/s, output: 228.35 toks/s]Processed prompts:  42%|████▏     | 208/500 [6:33:29<10:21:23, 127.68s/it, est. speed input: 6.06 toks/s, output: 229.32 toks/s]Processed prompts:  42%|████▏     | 209/500 [6:34:06<8:06:38, 100.34s/it, est. speed input: 6.06 toks/s, output: 230.35 toks/s] Processed prompts:  42%|████▏     | 210/500 [6:35:17<7:22:14, 91.50s/it, est. speed input: 6.09 toks/s, output: 231.05 toks/s] Processed prompts:  42%|████▏     | 211/500 [6:39:26<11:08:01, 138.69s/it, est. speed input: 6.05 toks/s, output: 230.02 toks/s]Processed prompts:  42%|████▏     | 212/500 [6:40:52<9:50:34, 123.03s/it, est. speed input: 6.04 toks/s, output: 230.55 toks/s] Processed prompts:  43%|████▎     | 213/500 [6:43:48<11:03:51, 138.79s/it, est. speed input: 6.00 toks/s, output: 230.23 toks/s]WARNING 04-05 03:28:40 scheduler.py:1555] Sequence group 226 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301
Processed prompts:  43%|████▎     | 214/500 [6:49:05<15:17:11, 192.42s/it, est. speed input: 5.95 toks/s, output: 228.59 toks/s]Processed prompts:  43%|████▎     | 215/500 [6:49:32<11:17:53, 142.71s/it, est. speed input: 5.95 toks/s, output: 229.67 toks/s]Processed prompts:  43%|████▎     | 216/500 [6:51:58<11:19:34, 143.57s/it, est. speed input: 5.97 toks/s, output: 229.65 toks/s]Processed prompts:  43%|████▎     | 217/500 [6:55:47<13:18:14, 169.24s/it, est. speed input: 5.98 toks/s, output: 228.85 toks/s]Processed prompts:  44%|████▎     | 218/500 [7:00:49<16:22:45, 209.10s/it, est. speed input: 5.94 toks/s, output: 227.41 toks/s]Processed prompts:  44%|████▍     | 219/500 [7:01:39<12:35:47, 161.38s/it, est. speed input: 5.94 toks/s, output: 228.26 toks/s]Processed prompts:  44%|████▍     | 220/500 [7:02:01<9:18:39, 119.71s/it, est. speed input: 5.94 toks/s, output: 229.35 toks/s] Processed prompts:  44%|████▍     | 221/500 [7:02:29<7:08:17, 92.10s/it, est. speed input: 5.96 toks/s, output: 230.39 toks/s] WARNING 04-05 03:45:24 scheduler.py:1555] Sequence group 257 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351
Processed prompts:  44%|████▍     | 222/500 [7:03:08<5:52:28, 76.07s/it, est. speed input: 5.96 toks/s, output: 231.33 toks/s]WARNING 04-05 03:47:44 scheduler.py:1555] Sequence group 245 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401
Processed prompts:  45%|████▍     | 223/500 [7:06:29<8:44:41, 113.65s/it, est. speed input: 5.96 toks/s, output: 230.79 toks/s]Processed prompts:  45%|████▍     | 224/500 [7:12:25<14:17:35, 186.43s/it, est. speed input: 5.89 toks/s, output: 228.88 toks/s]Processed prompts:  45%|████▌     | 225/500 [7:14:29<12:47:49, 167.53s/it, est. speed input: 5.87 toks/s, output: 229.06 toks/s]Processed prompts:  45%|████▌     | 226/500 [7:20:41<17:25:56, 229.04s/it, est. speed input: 5.80 toks/s, output: 227.07 toks/s]Processed prompts:  45%|████▌     | 227/500 [7:22:45<14:58:12, 197.41s/it, est. speed input: 5.80 toks/s, output: 227.25 toks/s]Processed prompts:  46%|████▌     | 228/500 [7:23:52<11:58:19, 158.45s/it, est. speed input: 5.85 toks/s, output: 227.90 toks/s]Processed prompts:  46%|████▌     | 229/500 [7:25:16<10:13:59, 135.94s/it, est. speed input: 5.84 toks/s, output: 228.41 toks/s]Processed prompts:  46%|████▌     | 230/500 [7:26:50<9:15:47, 123.51s/it, est. speed input: 5.88 toks/s, output: 228.83 toks/s] Processed prompts:  46%|████▌     | 231/500 [7:28:11<8:15:37, 110.55s/it, est. speed input: 5.89 toks/s, output: 229.37 toks/s]WARNING 04-05 04:12:35 scheduler.py:1555] Sequence group 243 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451
Processed prompts:  46%|████▋     | 232/500 [7:31:23<10:03:53, 135.20s/it, est. speed input: 5.86 toks/s, output: 228.94 toks/s]Processed prompts:  47%|████▋     | 233/500 [7:32:09<8:01:50, 108.28s/it, est. speed input: 5.85 toks/s, output: 229.77 toks/s] Processed prompts:  47%|████▋     | 234/500 [7:36:01<10:45:08, 145.52s/it, est. speed input: 5.87 toks/s, output: 229.01 toks/s]Processed prompts:  47%|████▋     | 235/500 [7:39:38<12:17:43, 167.03s/it, est. speed input: 5.87 toks/s, output: 228.40 toks/s]Processed prompts:  47%|████▋     | 236/500 [7:43:02<13:02:39, 177.88s/it, est. speed input: 5.84 toks/s, output: 227.91 toks/s]Processed prompts:  47%|████▋     | 237/500 [7:45:39<12:32:30, 171.67s/it, est. speed input: 5.83 toks/s, output: 227.80 toks/s]Processed prompts:  48%|████▊     | 238/500 [7:45:43<8:50:18, 121.44s/it, est. speed input: 5.88 toks/s, output: 228.94 toks/s] Processed prompts:  48%|████▊     | 239/500 [7:50:18<12:09:12, 167.63s/it, est. speed input: 5.84 toks/s, output: 227.86 toks/s]Processed prompts:  48%|████▊     | 240/500 [7:51:30<10:01:15, 138.75s/it, est. speed input: 5.83 toks/s, output: 228.45 toks/s]Processed prompts:  48%|████▊     | 241/500 [7:52:52<8:46:14, 121.91s/it, est. speed input: 5.83 toks/s, output: 228.94 toks/s] WARNING 04-05 04:35:30 scheduler.py:1555] Sequence group 265 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501
Processed prompts:  48%|████▊     | 242/500 [7:54:11<7:47:47, 108.79s/it, est. speed input: 5.86 toks/s, output: 229.46 toks/s]Processed prompts:  49%|████▊     | 243/500 [7:56:21<8:13:27, 115.20s/it, est. speed input: 5.90 toks/s, output: 229.56 toks/s]Processed prompts:  49%|████▉     | 244/500 [8:01:37<12:28:27, 175.42s/it, est. speed input: 5.86 toks/s, output: 228.19 toks/s]Processed prompts:  49%|████▉     | 245/500 [8:04:10<11:57:48, 168.90s/it, est. speed input: 5.87 toks/s, output: 228.11 toks/s]Processed prompts:  49%|████▉     | 246/500 [8:05:38<10:11:25, 144.43s/it, est. speed input: 5.86 toks/s, output: 228.55 toks/s]Processed prompts:  49%|████▉     | 247/500 [8:05:41<7:10:08, 102.01s/it, est. speed input: 5.87 toks/s, output: 228.69 toks/s] Processed prompts:  50%|████▉     | 248/500 [8:06:30<6:02:31, 86.32s/it, est. speed input: 5.91 toks/s, output: 229.42 toks/s] WARNING 04-05 04:49:08 scheduler.py:1555] Sequence group 270 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551
Processed prompts:  50%|████▉     | 249/500 [8:14:16<13:57:08, 200.11s/it, est. speed input: 5.83 toks/s, output: 226.92 toks/s]Processed prompts:  50%|█████     | 250/500 [8:16:04<11:58:34, 172.46s/it, est. speed input: 5.84 toks/s, output: 227.20 toks/s]Processed prompts:  50%|█████     | 251/500 [8:17:32<10:10:27, 147.10s/it, est. speed input: 5.83 toks/s, output: 227.63 toks/s]Processed prompts:  50%|█████     | 252/500 [8:18:58<8:52:26, 128.81s/it, est. speed input: 5.84 toks/s, output: 228.07 toks/s] Processed prompts:  51%|█████     | 253/500 [8:20:10<7:40:09, 111.78s/it, est. speed input: 5.87 toks/s, output: 228.61 toks/s]Processed prompts:  51%|█████     | 254/500 [8:21:07<6:31:13, 95.42s/it, est. speed input: 5.90 toks/s, output: 229.27 toks/s] WARNING 04-05 05:03:47 scheduler.py:1555] Sequence group 297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601
Processed prompts:  51%|█████     | 255/500 [8:22:20<6:01:45, 88.60s/it, est. speed input: 5.90 toks/s, output: 229.80 toks/s]WARNING 04-05 05:07:04 scheduler.py:1555] Sequence group 274 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651
Processed prompts:  51%|█████     | 256/500 [8:25:03<7:31:07, 110.93s/it, est. speed input: 5.87 toks/s, output: 229.65 toks/s]Processed prompts:  51%|█████▏    | 257/500 [8:31:51<13:29:52, 199.97s/it, est. speed input: 5.80 toks/s, output: 227.66 toks/s]Processed prompts:  52%|█████▏    | 258/500 [8:32:38<10:22:10, 154.26s/it, est. speed input: 5.80 toks/s, output: 228.38 toks/s]Processed prompts:  52%|█████▏    | 259/500 [8:38:00<13:41:14, 204.46s/it, est. speed input: 5.76 toks/s, output: 227.07 toks/s]Processed prompts:  52%|█████▏    | 260/500 [8:39:19<11:07:25, 166.86s/it, est. speed input: 5.75 toks/s, output: 227.54 toks/s]Processed prompts:  52%|█████▏    | 261/500 [8:43:20<12:33:22, 189.13s/it, est. speed input: 5.75 toks/s, output: 226.84 toks/s]Processed prompts:  52%|█████▏    | 262/500 [8:45:22<11:09:27, 168.77s/it, est. speed input: 5.75 toks/s, output: 227.01 toks/s]Processed prompts:  53%|█████▎    | 263/500 [8:47:17<10:02:57, 152.65s/it, est. speed input: 5.74 toks/s, output: 227.22 toks/s]Processed prompts:  53%|█████▎    | 264/500 [8:48:26<8:21:44, 127.56s/it, est. speed input: 5.73 toks/s, output: 227.76 toks/s] Processed prompts:  53%|█████▎    | 265/500 [8:49:17<6:50:24, 104.79s/it, est. speed input: 5.73 toks/s, output: 228.42 toks/s]WARNING 04-05 05:32:53 scheduler.py:1555] Sequence group 288 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701
Processed prompts:  53%|█████▎    | 266/500 [8:50:28<6:08:51, 94.58s/it, est. speed input: 5.76 toks/s, output: 228.94 toks/s] Processed prompts:  53%|█████▎    | 267/500 [8:53:28<7:47:21, 120.35s/it, est. speed input: 5.74 toks/s, output: 228.67 toks/s]Processed prompts:  54%|█████▎    | 268/500 [8:59:45<12:42:57, 197.32s/it, est. speed input: 5.68 toks/s, output: 227.02 toks/s]Processed prompts:  54%|█████▍    | 269/500 [8:59:49<8:55:43, 139.15s/it, est. speed input: 5.71 toks/s, output: 228.01 toks/s] Processed prompts:  54%|█████▍    | 270/500 [9:07:00<14:29:25, 226.80s/it, est. speed input: 5.66 toks/s, output: 226.01 toks/s]Processed prompts:  54%|█████▍    | 271/500 [9:07:47<11:00:07, 172.96s/it, est. speed input: 5.65 toks/s, output: 226.68 toks/s]WARNING 04-05 05:52:47 scheduler.py:1555] Sequence group 279 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751
Processed prompts:  54%|█████▍    | 272/500 [9:12:12<12:41:21, 200.36s/it, est. speed input: 5.64 toks/s, output: 225.86 toks/s]Processed prompts:  55%|█████▍    | 273/500 [9:13:36<10:26:48, 165.68s/it, est. speed input: 5.64 toks/s, output: 226.27 toks/s]Processed prompts:  55%|█████▍    | 274/500 [9:15:14<9:06:52, 145.19s/it, est. speed input: 5.63 toks/s, output: 226.60 toks/s] Processed prompts:  55%|█████▌    | 275/500 [9:16:02<7:15:03, 116.01s/it, est. speed input: 5.66 toks/s, output: 227.25 toks/s]Processed prompts:  55%|█████▌    | 276/500 [9:16:57<6:04:39, 97.67s/it, est. speed input: 5.65 toks/s, output: 227.86 toks/s] Processed prompts:  55%|█████▌    | 277/500 [9:18:18<5:45:17, 92.90s/it, est. speed input: 5.66 toks/s, output: 228.28 toks/s]Processed prompts:  56%|█████▌    | 278/500 [9:18:19<4:01:08, 65.17s/it, est. speed input: 5.69 toks/s, output: 228.33 toks/s]Processed prompts:  56%|█████▌    | 279/500 [9:19:49<4:27:09, 72.53s/it, est. speed input: 5.68 toks/s, output: 228.70 toks/s]Processed prompts:  56%|█████▌    | 280/500 [9:25:17<9:07:25, 149.30s/it, est. speed input: 5.64 toks/s, output: 227.45 toks/s]Processed prompts:  56%|█████▌    | 281/500 [9:26:51<8:04:11, 132.65s/it, est. speed input: 5.63 toks/s, output: 227.79 toks/s]WARNING 04-05 06:09:38 scheduler.py:1555] Sequence group 295 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801
Processed prompts:  56%|█████▋    | 282/500 [9:32:58<12:17:31, 202.99s/it, est. speed input: 5.58 toks/s, output: 226.31 toks/s]Processed prompts:  57%|█████▋    | 283/500 [9:33:49<9:28:45, 157.26s/it, est. speed input: 5.57 toks/s, output: 226.93 toks/s] Processed prompts:  57%|█████▋    | 284/500 [9:39:23<12:37:36, 210.45s/it, est. speed input: 5.56 toks/s, output: 225.68 toks/s]Processed prompts:  57%|█████▋    | 285/500 [9:41:10<10:42:56, 179.42s/it, est. speed input: 5.57 toks/s, output: 225.93 toks/s]Processed prompts:  57%|█████▋    | 286/500 [9:42:45<9:09:51, 154.16s/it, est. speed input: 5.56 toks/s, output: 226.25 toks/s] Processed prompts:  57%|█████▋    | 287/500 [9:43:54<7:36:37, 128.62s/it, est. speed input: 5.56 toks/s, output: 226.74 toks/s]Processed prompts:  58%|█████▊    | 288/500 [9:44:50<6:17:05, 106.72s/it, est. speed input: 5.56 toks/s, output: 227.32 toks/s]Processed prompts:  58%|█████▊    | 289/500 [9:45:40<5:15:05, 89.60s/it, est. speed input: 5.58 toks/s, output: 227.93 toks/s] Processed prompts:  58%|█████▊    | 290/500 [9:46:37<4:40:10, 80.05s/it, est. speed input: 5.61 toks/s, output: 228.49 toks/s]WARNING 04-05 06:29:28 scheduler.py:1555] Sequence group 341 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851
Processed prompts:  58%|█████▊    | 291/500 [9:49:43<6:29:30, 111.82s/it, est. speed input: 5.60 toks/s, output: 227.33 toks/s]Processed prompts:  58%|█████▊    | 292/500 [9:53:01<7:56:40, 137.50s/it, est. speed input: 5.58 toks/s, output: 226.99 toks/s]WARNING 04-05 06:35:49 scheduler.py:1555] Sequence group 306 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901
Processed prompts:  59%|█████▊    | 293/500 [9:56:23<9:00:53, 156.78s/it, est. speed input: 5.55 toks/s, output: 226.63 toks/s]Processed prompts:  59%|█████▉    | 294/500 [9:58:05<8:02:26, 140.52s/it, est. speed input: 5.54 toks/s, output: 226.23 toks/s]Processed prompts:  59%|█████▉    | 295/500 [9:58:36<6:08:14, 107.78s/it, est. speed input: 5.58 toks/s, output: 226.95 toks/s]Processed prompts:  59%|█████▉    | 296/500 [10:03:51<9:37:03, 169.72s/it, est. speed input: 5.53 toks/s, output: 225.88 toks/s]Processed prompts:  59%|█████▉    | 297/500 [10:05:04<7:56:20, 140.79s/it, est. speed input: 5.55 toks/s, output: 226.33 toks/s]Processed prompts:  60%|█████▉    | 298/500 [10:11:35<12:06:13, 215.71s/it, est. speed input: 5.50 toks/s, output: 224.81 toks/s]Processed prompts:  60%|█████▉    | 299/500 [10:13:28<10:20:18, 185.17s/it, est. speed input: 5.51 toks/s, output: 225.01 toks/s]Processed prompts:  60%|██████    | 300/500 [10:14:19<8:03:00, 144.90s/it, est. speed input: 5.52 toks/s, output: 225.59 toks/s] Processed prompts:  60%|██████    | 301/500 [10:14:52<6:08:49, 111.20s/it, est. speed input: 5.52 toks/s, output: 226.27 toks/s]Processed prompts:  60%|██████    | 302/500 [10:15:20<4:44:36, 86.25s/it, est. speed input: 5.53 toks/s, output: 226.99 toks/s] Processed prompts:  61%|██████    | 303/500 [10:16:11<4:08:05, 75.56s/it, est. speed input: 5.53 toks/s, output: 227.57 toks/s]Processed prompts:  61%|██████    | 304/500 [10:16:14<2:56:20, 53.98s/it, est. speed input: 5.53 toks/s, output: 227.55 toks/s]WARNING 04-05 06:58:57 scheduler.py:1555] Sequence group 342 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951
Processed prompts:  61%|██████    | 305/500 [10:16:53<2:40:14, 49.30s/it, est. speed input: 5.53 toks/s, output: 228.20 toks/s]WARNING 04-05 07:02:18 scheduler.py:1555] Sequence group 323 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001
Processed prompts:  61%|██████    | 306/500 [10:20:25<5:17:50, 98.30s/it, est. speed input: 5.51 toks/s, output: 227.09 toks/s]Processed prompts:  61%|██████▏   | 307/500 [10:27:49<10:49:21, 201.87s/it, est. speed input: 5.47 toks/s, output: 225.28 toks/s]Processed prompts:  62%|██████▏   | 308/500 [10:29:56<9:34:24, 179.51s/it, est. speed input: 5.46 toks/s, output: 225.39 toks/s] Processed prompts:  62%|██████▏   | 309/500 [10:31:30<8:09:59, 153.93s/it, est. speed input: 5.46 toks/s, output: 225.70 toks/s]Processed prompts:  62%|██████▏   | 310/500 [10:32:22<6:30:25, 123.29s/it, est. speed input: 5.46 toks/s, output: 226.25 toks/s]Processed prompts:  62%|██████▏   | 311/500 [10:32:56<5:03:56, 96.49s/it, est. speed input: 5.46 toks/s, output: 226.24 toks/s] Processed prompts:  62%|██████▏   | 312/500 [10:32:56<3:31:44, 67.58s/it, est. speed input: 5.50 toks/s, output: 227.10 toks/s]Processed prompts:  63%|██████▎   | 313/500 [10:34:54<4:17:09, 82.51s/it, est. speed input: 5.51 toks/s, output: 226.60 toks/s]Processed prompts:  63%|██████▎   | 314/500 [10:35:22<3:25:17, 66.22s/it, est. speed input: 5.53 toks/s, output: 227.29 toks/s]Processed prompts:  63%|██████▎   | 315/500 [10:36:58<3:51:31, 75.09s/it, est. speed input: 5.55 toks/s, output: 227.58 toks/s]Processed prompts:  63%|██████▎   | 316/500 [10:36:58<2:41:45, 52.75s/it, est. speed input: 5.59 toks/s, output: 227.66 toks/s]Processed prompts:  63%|██████▎   | 317/500 [10:45:11<9:23:49, 184.86s/it, est. speed input: 5.55 toks/s, output: 225.61 toks/s]Processed prompts:  64%|██████▎   | 318/500 [10:45:45<7:03:08, 139.50s/it, est. speed input: 5.55 toks/s, output: 226.26 toks/s]Processed prompts:  64%|██████▍   | 319/500 [10:46:11<5:18:06, 105.45s/it, est. speed input: 5.55 toks/s, output: 226.95 toks/s]Processed prompts:  64%|██████▍   | 320/500 [10:46:57<4:22:57, 87.65s/it, est. speed input: 5.58 toks/s, output: 227.53 toks/s] WARNING 04-05 07:29:43 scheduler.py:1555] Sequence group 343 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2051
Processed prompts:  64%|██████▍   | 321/500 [10:49:25<5:15:25, 105.73s/it, est. speed input: 5.57 toks/s, output: 227.50 toks/s]Processed prompts:  64%|██████▍   | 322/500 [10:52:16<6:11:22, 125.18s/it, est. speed input: 5.55 toks/s, output: 227.35 toks/s]Processed prompts:  65%|██████▍   | 323/500 [10:54:45<6:30:38, 132.42s/it, est. speed input: 5.54 toks/s, output: 227.32 toks/s]Processed prompts:  65%|██████▍   | 324/500 [10:58:44<8:02:36, 164.52s/it, est. speed input: 5.51 toks/s, output: 226.77 toks/s]Processed prompts:  65%|██████▌   | 325/500 [11:02:01<8:27:35, 174.03s/it, est. speed input: 5.49 toks/s, output: 226.48 toks/s]Processed prompts:  65%|██████▌   | 326/500 [11:03:55<7:32:56, 156.19s/it, est. speed input: 5.48 toks/s, output: 226.65 toks/s]Processed prompts:  65%|██████▌   | 327/500 [11:06:34<7:32:26, 156.92s/it, est. speed input: 5.47 toks/s, output: 226.57 toks/s]Processed prompts:  66%|██████▌   | 328/500 [11:08:30<6:54:38, 144.64s/it, est. speed input: 5.46 toks/s, output: 226.73 toks/s]Processed prompts:  66%|██████▌   | 329/500 [11:09:51<5:57:46, 125.54s/it, est. speed input: 5.45 toks/s, output: 227.09 toks/s]WARNING 04-05 07:52:38 scheduler.py:1555] Sequence group 345 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2101
Processed prompts:  66%|██████▌   | 330/500 [11:11:53<5:53:09, 124.65s/it, est. speed input: 5.44 toks/s, output: 227.21 toks/s]Processed prompts:  66%|██████▌   | 331/500 [11:13:10<5:10:48, 110.35s/it, est. speed input: 5.44 toks/s, output: 227.59 toks/s]WARNING 04-05 07:57:33 scheduler.py:1555] Sequence group 349 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2151
Processed prompts:  66%|██████▋   | 332/500 [11:15:11<5:17:49, 113.51s/it, est. speed input: 5.44 toks/s, output: 227.72 toks/s]Processed prompts:  67%|██████▋   | 333/500 [11:22:46<10:00:40, 215.81s/it, est. speed input: 5.38 toks/s, output: 225.99 toks/s]Processed prompts:  67%|██████▋   | 334/500 [11:24:13<8:10:36, 177.33s/it, est. speed input: 5.38 toks/s, output: 226.31 toks/s] Processed prompts:  67%|██████▋   | 335/500 [11:26:01<7:10:15, 156.46s/it, est. speed input: 5.37 toks/s, output: 226.51 toks/s]Processed prompts:  67%|██████▋   | 336/500 [11:30:19<8:30:46, 186.87s/it, est. speed input: 5.34 toks/s, output: 225.89 toks/s]Processed prompts:  67%|██████▋   | 337/500 [11:33:32<8:32:55, 188.81s/it, est. speed input: 5.36 toks/s, output: 225.63 toks/s]Processed prompts:  68%|██████▊   | 338/500 [11:36:46<8:33:32, 190.20s/it, est. speed input: 5.35 toks/s, output: 225.37 toks/s]Processed prompts:  68%|██████▊   | 339/500 [11:37:29<6:32:26, 146.25s/it, est. speed input: 5.36 toks/s, output: 225.92 toks/s]Processed prompts:  68%|██████▊   | 340/500 [11:38:14<5:08:45, 115.79s/it, est. speed input: 5.37 toks/s, output: 226.46 toks/s]Processed prompts:  68%|██████▊   | 341/500 [11:38:15<3:35:12, 81.21s/it, est. speed input: 5.39 toks/s, output: 226.49 toks/s] Processed prompts:  68%|██████▊   | 342/500 [11:39:04<3:09:05, 71.81s/it, est. speed input: 5.42 toks/s, output: 227.00 toks/s]Processed prompts:  69%|██████▊   | 343/500 [11:39:27<2:29:02, 56.96s/it, est. speed input: 5.44 toks/s, output: 227.66 toks/s]WARNING 04-05 08:22:21 scheduler.py:1555] Sequence group 390 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2201
Processed prompts:  69%|██████▉   | 344/500 [11:41:19<3:11:01, 73.47s/it, est. speed input: 5.43 toks/s, output: 227.08 toks/s]Processed prompts:  69%|██████▉   | 345/500 [11:42:26<3:04:40, 71.48s/it, est. speed input: 5.43 toks/s, output: 227.49 toks/s]WARNING 04-05 08:25:26 scheduler.py:1555] Sequence group 372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2251
Processed prompts:  69%|██████▉   | 346/500 [11:46:06<4:57:54, 116.07s/it, est. speed input: 5.44 toks/s, output: 227.09 toks/s]Processed prompts:  69%|██████▉   | 347/500 [11:54:57<10:13:30, 240.59s/it, est. speed input: 5.38 toks/s, output: 225.04 toks/s]Processed prompts:  70%|██████▉   | 348/500 [11:55:46<7:43:57, 183.14s/it, est. speed input: 5.42 toks/s, output: 225.54 toks/s] Processed prompts:  70%|██████▉   | 349/500 [11:55:49<5:24:58, 129.13s/it, est. speed input: 5.45 toks/s, output: 226.29 toks/s]Processed prompts:  70%|███████   | 350/500 [11:56:47<4:29:32, 107.82s/it, est. speed input: 5.47 toks/s, output: 226.36 toks/s]Processed prompts:  70%|███████   | 351/500 [12:03:23<8:02:28, 194.28s/it, est. speed input: 5.42 toks/s, output: 225.05 toks/s]Processed prompts:  70%|███████   | 352/500 [12:04:40<6:32:34, 159.15s/it, est. speed input: 5.45 toks/s, output: 225.40 toks/s]Processed prompts:  71%|███████   | 353/500 [12:05:39<5:15:45, 128.88s/it, est. speed input: 5.47 toks/s, output: 225.85 toks/s]Processed prompts:  71%|███████   | 354/500 [12:06:32<4:18:37, 106.28s/it, est. speed input: 5.47 toks/s, output: 226.33 toks/s]Processed prompts:  71%|███████   | 355/500 [12:07:35<3:45:15, 93.21s/it, est. speed input: 5.48 toks/s, output: 226.75 toks/s] Processed prompts:  71%|███████   | 356/500 [12:08:08<3:00:09, 75.06s/it, est. speed input: 5.48 toks/s, output: 227.33 toks/s]WARNING 04-05 08:51:04 scheduler.py:1555] Sequence group 380 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2301
Processed prompts:  71%|███████▏  | 357/500 [12:10:51<4:02:12, 101.62s/it, est. speed input: 5.47 toks/s, output: 227.23 toks/s]Processed prompts:  72%|███████▏  | 358/500 [12:15:43<6:15:33, 158.68s/it, est. speed input: 5.45 toks/s, output: 226.47 toks/s]Processed prompts:  72%|███████▏  | 359/500 [12:16:57<5:13:23, 133.36s/it, est. speed input: 5.47 toks/s, output: 226.68 toks/s]WARNING 04-05 09:00:16 scheduler.py:1555] Sequence group 372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2351
Processed prompts:  72%|███████▏  | 360/500 [12:20:22<6:01:04, 154.75s/it, est. speed input: 5.47 toks/s, output: 226.37 toks/s]Processed prompts:  72%|███████▏  | 361/500 [12:27:24<9:04:20, 234.97s/it, est. speed input: 5.42 toks/s, output: 224.97 toks/s]Processed prompts:  72%|███████▏  | 362/500 [12:27:47<6:34:10, 171.38s/it, est. speed input: 5.45 toks/s, output: 225.58 toks/s]Processed prompts:  73%|███████▎  | 363/500 [12:30:32<6:26:50, 169.42s/it, est. speed input: 5.45 toks/s, output: 225.49 toks/s]Processed prompts:  73%|███████▎  | 364/500 [12:33:07<6:14:05, 165.04s/it, est. speed input: 5.44 toks/s, output: 225.44 toks/s]Processed prompts:  73%|███████▎  | 365/500 [12:34:59<5:36:00, 149.33s/it, est. speed input: 5.43 toks/s, output: 225.60 toks/s]Processed prompts:  73%|███████▎  | 366/500 [12:35:54<4:30:23, 121.07s/it, est. speed input: 5.43 toks/s, output: 226.05 toks/s]Processed prompts:  73%|███████▎  | 367/500 [12:36:36<3:35:12, 97.09s/it, est. speed input: 5.43 toks/s, output: 226.57 toks/s] Processed prompts:  74%|███████▎  | 368/500 [12:37:12<2:53:27, 78.84s/it, est. speed input: 5.46 toks/s, output: 227.11 toks/s]Processed prompts:  74%|███████▍  | 369/500 [12:39:14<3:20:19, 91.75s/it, est. speed input: 5.45 toks/s, output: 227.22 toks/s]WARNING 04-05 09:28:36 scheduler.py:1555] Sequence group 383 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2401
Processed prompts:  74%|███████▍  | 370/500 [12:47:49<7:53:50, 218.70s/it, est. speed input: 5.39 toks/s, output: 225.39 toks/s]Processed prompts:  74%|███████▍  | 371/500 [12:51:50<8:04:31, 225.36s/it, est. speed input: 5.38 toks/s, output: 224.93 toks/s]Processed prompts:  74%|███████▍  | 372/500 [12:52:07<5:47:54, 163.08s/it, est. speed input: 5.40 toks/s, output: 225.55 toks/s]Processed prompts:  75%|███████▍  | 373/500 [13:00:10<9:08:15, 259.02s/it, est. speed input: 5.35 toks/s, output: 223.92 toks/s]Processed prompts:  75%|███████▍  | 374/500 [13:01:47<7:21:30, 210.24s/it, est. speed input: 5.37 toks/s, output: 224.16 toks/s]Processed prompts:  75%|███████▌  | 375/500 [13:02:39<5:39:33, 162.99s/it, est. speed input: 5.37 toks/s, output: 224.60 toks/s]Processed prompts:  75%|███████▌  | 376/500 [13:04:09<4:51:20, 140.97s/it, est. speed input: 5.37 toks/s, output: 224.87 toks/s]Processed prompts:  75%|███████▌  | 377/500 [13:04:37<3:39:48, 107.23s/it, est. speed input: 5.37 toks/s, output: 225.43 toks/s]Processed prompts:  76%|███████▌  | 378/500 [13:05:13<2:54:09, 85.65s/it, est. speed input: 5.40 toks/s, output: 225.96 toks/s] Processed prompts:  76%|███████▌  | 379/500 [13:06:18<2:40:06, 79.39s/it, est. speed input: 5.41 toks/s, output: 226.34 toks/s]Processed prompts:  76%|███████▌  | 380/500 [13:11:26<4:56:19, 148.16s/it, est. speed input: 5.40 toks/s, output: 225.56 toks/s]Processed prompts:  76%|███████▌  | 381/500 [13:13:14<4:30:05, 136.18s/it, est. speed input: 5.39 toks/s, output: 225.74 toks/s]Processed prompts:  76%|███████▋  | 382/500 [13:16:58<5:19:25, 162.42s/it, est. speed input: 5.39 toks/s, output: 225.37 toks/s]Processed prompts:  77%|███████▋  | 383/500 [13:20:01<5:28:39, 168.55s/it, est. speed input: 5.38 toks/s, output: 225.19 toks/s]Processed prompts:  77%|███████▋  | 384/500 [13:21:41<4:46:21, 148.11s/it, est. speed input: 5.39 toks/s, output: 225.40 toks/s]Processed prompts:  77%|███████▋  | 385/500 [13:27:35<6:41:49, 209.65s/it, est. speed input: 5.36 toks/s, output: 224.44 toks/s]Processed prompts:  77%|███████▋  | 386/500 [13:28:48<5:20:53, 168.89s/it, est. speed input: 5.36 toks/s, output: 224.77 toks/s]Processed prompts:  77%|███████▋  | 387/500 [13:29:24<4:02:57, 129.00s/it, est. speed input: 5.38 toks/s, output: 225.28 toks/s]Processed prompts:  78%|███████▊  | 388/500 [13:29:26<2:49:35, 90.85s/it, est. speed input: 5.40 toks/s, output: 225.35 toks/s] WARNING 04-05 10:12:42 scheduler.py:1555] Sequence group 402 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2451
Processed prompts:  78%|███████▊  | 389/500 [13:30:17<2:25:56, 78.88s/it, est. speed input: 5.41 toks/s, output: 225.79 toks/s]Processed prompts:  78%|███████▊  | 390/500 [13:30:41<1:54:40, 62.55s/it, est. speed input: 5.42 toks/s, output: 226.35 toks/s]Processed prompts:  78%|███████▊  | 391/500 [13:31:12<1:35:55, 52.80s/it, est. speed input: 5.43 toks/s, output: 226.88 toks/s]Processed prompts:  78%|███████▊  | 392/500 [13:32:32<1:50:03, 61.14s/it, est. speed input: 5.42 toks/s, output: 227.18 toks/s]WARNING 04-05 10:15:06 scheduler.py:1555] Sequence group 444 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2501
Processed prompts:  79%|███████▊  | 393/500 [13:34:26<2:17:00, 76.83s/it, est. speed input: 5.41 toks/s, output: 226.71 toks/s]Processed prompts:  79%|███████▉  | 394/500 [13:39:07<4:04:06, 138.18s/it, est. speed input: 5.41 toks/s, output: 226.08 toks/s]Processed prompts:  79%|███████▉  | 395/500 [13:42:16<4:28:34, 153.47s/it, est. speed input: 5.40 toks/s, output: 225.88 toks/s]Processed prompts:  79%|███████▉  | 396/500 [13:44:28<4:14:39, 146.92s/it, est. speed input: 5.39 toks/s, output: 225.94 toks/s]Processed prompts:  79%|███████▉  | 397/500 [13:47:55<4:43:31, 165.16s/it, est. speed input: 5.39 toks/s, output: 225.65 toks/s]Processed prompts:  80%|███████▉  | 398/500 [13:47:56<3:16:38, 115.68s/it, est. speed input: 5.42 toks/s, output: 225.90 toks/s]WARNING 04-05 10:31:46 scheduler.py:1555] Sequence group 412 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2551
Processed prompts:  80%|███████▉  | 399/500 [13:52:12<4:26:00, 158.03s/it, est. speed input: 5.39 toks/s, output: 225.39 toks/s]Processed prompts:  80%|████████  | 400/500 [13:55:20<4:38:08, 166.89s/it, est. speed input: 5.40 toks/s, output: 225.20 toks/s]Processed prompts:  80%|████████  | 401/500 [13:55:51<3:27:51, 125.98s/it, est. speed input: 5.44 toks/s, output: 225.16 toks/s]Processed prompts:  80%|████████  | 402/500 [13:57:35<3:15:24, 119.63s/it, est. speed input: 5.44 toks/s, output: 225.34 toks/s]Processed prompts:  81%|████████  | 403/500 [13:58:18<2:35:55, 96.45s/it, est. speed input: 5.44 toks/s, output: 225.80 toks/s] Processed prompts:  81%|████████  | 404/500 [13:59:39<2:26:57, 91.85s/it, est. speed input: 5.44 toks/s, output: 226.09 toks/s]Processed prompts:  81%|████████  | 405/500 [14:00:20<2:01:06, 76.49s/it, est. speed input: 5.47 toks/s, output: 226.56 toks/s]Processed prompts:  81%|████████  | 406/500 [14:02:06<2:13:46, 85.38s/it, est. speed input: 5.48 toks/s, output: 226.15 toks/s]WARNING 04-05 10:45:02 scheduler.py:1555] Sequence group 428 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2601
Processed prompts:  81%|████████▏ | 407/500 [14:05:22<3:04:09, 118.81s/it, est. speed input: 5.48 toks/s, output: 225.92 toks/s]Processed prompts:  82%|████████▏ | 408/500 [14:05:58<2:23:43, 93.73s/it, est. speed input: 5.50 toks/s, output: 226.41 toks/s] Processed prompts:  82%|████████▏ | 409/500 [14:10:15<3:36:34, 142.79s/it, est. speed input: 5.48 toks/s, output: 225.91 toks/s]Processed prompts:  82%|████████▏ | 410/500 [14:15:35<4:53:45, 195.84s/it, est. speed input: 5.45 toks/s, output: 224.91 toks/s]Processed prompts:  82%|████████▏ | 411/500 [14:18:06<4:30:39, 182.46s/it, est. speed input: 5.44 toks/s, output: 224.88 toks/s]Processed prompts:  82%|████████▏ | 412/500 [14:18:57<3:30:00, 143.19s/it, est. speed input: 5.44 toks/s, output: 225.30 toks/s]Processed prompts:  83%|████████▎ | 413/500 [14:20:54<3:15:59, 135.17s/it, est. speed input: 5.46 toks/s, output: 225.42 toks/s]Processed prompts:  83%|████████▎ | 414/500 [14:22:39<3:00:45, 126.11s/it, est. speed input: 5.45 toks/s, output: 225.60 toks/s]Processed prompts:  83%|████████▎ | 415/500 [14:27:46<4:15:30, 180.36s/it, est. speed input: 5.42 toks/s, output: 224.90 toks/s]Processed prompts:  83%|████████▎ | 416/500 [14:29:06<3:30:30, 150.37s/it, est. speed input: 5.42 toks/s, output: 225.18 toks/s]Processed prompts:  83%|████████▎ | 417/500 [14:29:24<2:33:14, 110.77s/it, est. speed input: 5.44 toks/s, output: 225.73 toks/s]Processed prompts:  84%|████████▎ | 418/500 [14:29:32<1:49:11, 79.89s/it, est. speed input: 5.46 toks/s, output: 226.32 toks/s] WARNING 04-05 11:12:56 scheduler.py:1555] Sequence group 450 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2651
Processed prompts:  84%|████████▍ | 419/500 [14:32:43<2:32:43, 113.13s/it, est. speed input: 5.44 toks/s, output: 226.12 toks/s]Processed prompts:  84%|████████▍ | 420/500 [14:34:31<2:28:56, 111.71s/it, est. speed input: 5.44 toks/s, output: 226.28 toks/s]Processed prompts:  84%|████████▍ | 421/500 [14:39:08<3:32:05, 161.08s/it, est. speed input: 5.42 toks/s, output: 225.72 toks/s]Processed prompts:  84%|████████▍ | 422/500 [14:42:01<3:34:12, 164.77s/it, est. speed input: 5.41 toks/s, output: 225.60 toks/s]Processed prompts:  85%|████████▍ | 423/500 [14:43:05<2:52:48, 134.65s/it, est. speed input: 5.41 toks/s, output: 225.94 toks/s]Processed prompts:  85%|████████▍ | 424/500 [14:49:08<4:17:18, 203.14s/it, est. speed input: 5.38 toks/s, output: 225.02 toks/s]Processed prompts:  85%|████████▌ | 425/500 [14:50:52<3:36:31, 173.22s/it, est. speed input: 5.39 toks/s, output: 225.20 toks/s]Processed prompts:  85%|████████▌ | 426/500 [14:52:24<3:03:43, 148.96s/it, est. speed input: 5.38 toks/s, output: 225.42 toks/s]WARNING 04-05 11:36:14 scheduler.py:1555] Sequence group 432 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2701
Processed prompts:  85%|████████▌ | 427/500 [14:56:53<3:44:55, 184.87s/it, est. speed input: 5.36 toks/s, output: 224.90 toks/s]Processed prompts:  86%|████████▌ | 428/500 [14:58:36<3:12:35, 160.49s/it, est. speed input: 5.36 toks/s, output: 225.08 toks/s]Processed prompts:  86%|████████▌ | 429/500 [14:59:09<2:24:33, 122.16s/it, est. speed input: 5.37 toks/s, output: 225.55 toks/s]Processed prompts:  86%|████████▌ | 430/500 [14:59:39<1:50:06, 94.38s/it, est. speed input: 5.38 toks/s, output: 226.03 toks/s] Processed prompts:  86%|████████▌ | 431/500 [15:00:12<1:27:26, 76.04s/it, est. speed input: 5.39 toks/s, output: 226.50 toks/s]Processed prompts:  86%|████████▋ | 432/500 [15:03:20<2:04:06, 109.51s/it, est. speed input: 5.38 toks/s, output: 226.32 toks/s]WARNING 04-05 11:48:09 scheduler.py:1555] Sequence group 449 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2751
Processed prompts:  87%|████████▋ | 433/500 [15:10:03<3:40:42, 197.66s/it, est. speed input: 5.34 toks/s, output: 225.25 toks/s]Processed prompts:  87%|████████▋ | 434/500 [15:11:14<2:55:32, 159.58s/it, est. speed input: 5.35 toks/s, output: 225.56 toks/s]Processed prompts:  87%|████████▋ | 435/500 [15:12:39<2:28:44, 137.30s/it, est. speed input: 5.35 toks/s, output: 225.80 toks/s]Processed prompts:  87%|████████▋ | 436/500 [15:15:47<2:42:47, 152.62s/it, est. speed input: 5.36 toks/s, output: 225.63 toks/s]Processed prompts:  87%|████████▋ | 437/500 [15:22:15<3:54:15, 223.10s/it, est. speed input: 5.34 toks/s, output: 224.64 toks/s]Processed prompts:  88%|████████▊ | 438/500 [15:23:10<2:58:32, 172.78s/it, est. speed input: 5.35 toks/s, output: 225.01 toks/s]Processed prompts:  88%|████████▊ | 439/500 [15:26:18<3:00:13, 177.27s/it, est. speed input: 5.35 toks/s, output: 224.83 toks/s]Processed prompts:  88%|████████▊ | 440/500 [15:28:34<2:45:00, 165.01s/it, est. speed input: 5.34 toks/s, output: 224.87 toks/s]Processed prompts:  88%|████████▊ | 441/500 [15:29:27<2:09:13, 131.42s/it, est. speed input: 5.37 toks/s, output: 225.25 toks/s]Processed prompts:  88%|████████▊ | 442/500 [15:29:49<1:35:14, 98.52s/it, est. speed input: 5.37 toks/s, output: 225.75 toks/s] Processed prompts:  89%|████████▊ | 443/500 [15:30:42<1:20:31, 84.76s/it, est. speed input: 5.37 toks/s, output: 226.12 toks/s]Processed prompts:  89%|████████▉ | 444/500 [15:32:10<1:19:58, 85.69s/it, est. speed input: 5.39 toks/s, output: 226.35 toks/s]Processed prompts:  89%|████████▉ | 445/500 [15:35:35<1:51:28, 121.60s/it, est. speed input: 5.39 toks/s, output: 226.11 toks/s]WARNING 04-05 12:19:45 scheduler.py:1555] Sequence group 461 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2801
Processed prompts:  89%|████████▉ | 446/500 [15:43:23<3:23:00, 225.57s/it, est. speed input: 5.35 toks/s, output: 224.81 toks/s]Processed prompts:  89%|████████▉ | 447/500 [15:43:33<2:22:07, 160.89s/it, est. speed input: 5.36 toks/s, output: 225.35 toks/s]Processed prompts:  90%|████████▉ | 448/500 [15:45:52<2:13:41, 154.26s/it, est. speed input: 5.35 toks/s, output: 225.38 toks/s]Processed prompts:  90%|████████▉ | 449/500 [15:50:04<2:35:55, 183.45s/it, est. speed input: 5.34 toks/s, output: 224.96 toks/s]Processed prompts:  90%|█████████ | 450/500 [15:55:16<3:05:10, 222.21s/it, est. speed input: 5.32 toks/s, output: 224.30 toks/s]Processed prompts:  90%|█████████ | 451/500 [15:56:36<2:26:37, 179.55s/it, est. speed input: 5.32 toks/s, output: 224.56 toks/s]Processed prompts:  90%|█████████ | 452/500 [15:57:08<1:48:15, 135.31s/it, est. speed input: 5.33 toks/s, output: 225.01 toks/s]Processed prompts:  91%|█████████ | 453/500 [15:57:36<1:20:44, 103.08s/it, est. speed input: 5.33 toks/s, output: 225.47 toks/s]Processed prompts:  91%|█████████ | 454/500 [15:57:59<1:00:29, 78.90s/it, est. speed input: 5.33 toks/s, output: 225.95 toks/s] Processed prompts:  91%|█████████ | 455/500 [15:58:14<44:54, 59.88s/it, est. speed input: 5.33 toks/s, output: 225.98 toks/s]  Processed prompts:  91%|█████████ | 456/500 [15:58:28<33:51, 46.16s/it, est. speed input: 5.34 toks/s, output: 226.50 toks/s]Processed prompts:  91%|█████████▏| 457/500 [15:59:08<31:43, 44.28s/it, est. speed input: 5.34 toks/s, output: 226.91 toks/s]Processed prompts:  92%|█████████▏| 458/500 [16:02:02<58:16, 83.25s/it, est. speed input: 5.33 toks/s, output: 226.28 toks/s]WARNING 04-05 12:44:39 scheduler.py:1555] Sequence group 478 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2851
Processed prompts:  92%|█████████▏| 459/500 [16:02:46<48:40, 71.24s/it, est. speed input: 5.33 toks/s, output: 226.18 toks/s]Processed prompts:  92%|█████████▏| 460/500 [16:03:26<41:21, 62.03s/it, est. speed input: 5.33 toks/s, output: 226.59 toks/s]Processed prompts:  92%|█████████▏| 461/500 [16:03:37<30:22, 46.74s/it, est. speed input: 5.35 toks/s, output: 227.12 toks/s]Processed prompts:  92%|█████████▏| 462/500 [16:03:49<22:58, 36.27s/it, est. speed input: 5.35 toks/s, output: 227.16 toks/s]Processed prompts:  93%|█████████▎| 463/500 [16:05:21<32:39, 52.96s/it, est. speed input: 5.35 toks/s, output: 226.91 toks/s]Processed prompts:  93%|█████████▎| 464/500 [16:15:22<2:10:26, 217.41s/it, est. speed input: 5.30 toks/s, output: 225.14 toks/s]Processed prompts:  93%|█████████▎| 465/500 [16:15:41<1:32:09, 157.99s/it, est. speed input: 5.32 toks/s, output: 225.63 toks/s]Processed prompts:  93%|█████████▎| 466/500 [16:15:56<1:05:13, 115.11s/it, est. speed input: 5.32 toks/s, output: 226.13 toks/s]Processed prompts:  93%|█████████▎| 467/500 [16:19:29<1:19:27, 144.47s/it, est. speed input: 5.33 toks/s, output: 225.87 toks/s]Processed prompts:  94%|█████████▎| 468/500 [16:23:30<1:32:24, 173.27s/it, est. speed input: 5.33 toks/s, output: 225.50 toks/s]Processed prompts:  94%|█████████▍| 469/500 [16:24:18<1:10:02, 135.57s/it, est. speed input: 5.33 toks/s, output: 225.87 toks/s]Processed prompts:  94%|█████████▍| 470/500 [16:25:34<58:58, 117.96s/it, est. speed input: 5.34 toks/s, output: 226.13 toks/s]  Processed prompts:  94%|█████████▍| 471/500 [16:26:34<48:29, 100.33s/it, est. speed input: 5.34 toks/s, output: 226.04 toks/s]Processed prompts:  94%|█████████▍| 472/500 [16:26:44<34:11, 73.26s/it, est. speed input: 5.34 toks/s, output: 226.55 toks/s] WARNING 04-05 13:10:01 scheduler.py:1555] Sequence group 488 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2901
Processed prompts:  95%|█████████▍| 473/500 [16:28:55<40:47, 90.63s/it, est. speed input: 5.36 toks/s, output: 226.60 toks/s]Processed prompts:  95%|█████████▍| 474/500 [16:28:55<27:32, 63.55s/it, est. speed input: 5.38 toks/s, output: 226.68 toks/s]Processed prompts:  95%|█████████▌| 475/500 [16:31:32<38:08, 91.55s/it, est. speed input: 5.37 toks/s, output: 226.23 toks/s]Processed prompts:  95%|█████████▌| 476/500 [16:33:44<41:26, 103.62s/it, est. speed input: 5.38 toks/s, output: 226.28 toks/s]Processed prompts:  95%|█████████▌| 477/500 [16:35:56<43:02, 112.30s/it, est. speed input: 5.38 toks/s, output: 226.33 toks/s]Processed prompts:  96%|█████████▌| 478/500 [16:37:01<35:54, 97.94s/it, est. speed input: 5.38 toks/s, output: 226.63 toks/s] Processed prompts:  96%|█████████▌| 479/500 [16:41:10<50:09, 143.33s/it, est. speed input: 5.37 toks/s, output: 226.24 toks/s]Processed prompts:  96%|█████████▌| 480/500 [16:42:50<43:28, 130.40s/it, est. speed input: 5.37 toks/s, output: 226.41 toks/s]Processed prompts:  96%|█████████▌| 481/500 [16:45:30<44:04, 139.19s/it, est. speed input: 5.37 toks/s, output: 226.35 toks/s]WARNING 04-05 13:28:29 scheduler.py:1555] Sequence group 499 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2951
Processed prompts:  96%|█████████▋| 482/500 [16:47:12<38:25, 128.06s/it, est. speed input: 5.37 toks/s, output: 226.51 toks/s]Processed prompts:  97%|█████████▋| 483/500 [16:47:15<25:38, 90.48s/it, est. speed input: 5.38 toks/s, output: 226.56 toks/s] Processed prompts:  97%|█████████▋| 484/500 [16:50:48<33:57, 127.31s/it, est. speed input: 5.36 toks/s, output: 226.31 toks/s]Processed prompts:  97%|█████████▋| 485/500 [16:52:48<31:17, 125.13s/it, est. speed input: 5.35 toks/s, output: 226.40 toks/s]Processed prompts:  97%|█████████▋| 486/500 [16:53:32<23:29, 100.66s/it, est. speed input: 5.37 toks/s, output: 226.77 toks/s]Processed prompts:  97%|█████████▋| 487/500 [16:56:42<27:39, 127.66s/it, est. speed input: 5.37 toks/s, output: 226.60 toks/s]Processed prompts:  98%|█████████▊| 488/500 [17:00:10<30:18, 151.50s/it, est. speed input: 5.36 toks/s, output: 226.37 toks/s]Processed prompts:  98%|█████████▊| 489/500 [17:02:43<27:53, 152.13s/it, est. speed input: 5.35 toks/s, output: 226.34 toks/s]Processed prompts:  98%|█████████▊| 490/500 [17:05:35<26:20, 158.03s/it, est. speed input: 5.35 toks/s, output: 226.24 toks/s]Processed prompts:  98%|█████████▊| 491/500 [17:07:53<22:47, 151.90s/it, est. speed input: 5.35 toks/s, output: 226.27 toks/s]Processed prompts:  98%|█████████▊| 492/500 [17:10:06<19:31, 146.48s/it, est. speed input: 5.35 toks/s, output: 226.31 toks/s]Processed prompts:  99%|█████████▊| 493/500 [17:11:33<14:59, 128.55s/it, est. speed input: 5.35 toks/s, output: 226.52 toks/s]Processed prompts:  99%|█████████▉| 494/500 [17:13:15<12:02, 120.44s/it, est. speed input: 5.34 toks/s, output: 226.68 toks/s]Processed prompts:  99%|█████████▉| 495/500 [17:14:50<09:24, 112.85s/it, est. speed input: 5.34 toks/s, output: 226.86 toks/s]Processed prompts:  99%|█████████▉| 496/500 [17:17:19<08:14, 123.61s/it, est. speed input: 5.34 toks/s, output: 226.84 toks/s]Processed prompts:  99%|█████████▉| 497/500 [17:18:06<05:02, 100.68s/it, est. speed input: 5.34 toks/s, output: 227.20 toks/s]Processed prompts: 100%|█████████▉| 498/500 [17:18:56<02:51, 85.57s/it, est. speed input: 5.34 toks/s, output: 227.54 toks/s] Processed prompts: 100%|█████████▉| 499/500 [17:20:26<01:26, 86.97s/it, est. speed input: 5.36 toks/s, output: 227.73 toks/s]Processed prompts: 100%|██████████| 500/500 [17:21:10<00:00, 74.14s/it, est. speed input: 5.37 toks/s, output: 228.10 toks/s]Processed prompts: 100%|██████████| 500/500 [17:21:10<00:00, 124.94s/it, est. speed input: 5.37 toks/s, output: 228.10 toks/s]
INFO 04-05 14:03:38 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2062965)[0;0m INFO 04-05 14:03:38 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2062966)[0;0m INFO 04-05 14:03:38 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2062964)[0;0m INFO 04-05 14:03:38 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W405 14:03:51.159863779 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-05 14:04:07 config.py:510] This model supports multiple tasks: {'embed', 'reward', 'classify', 'score', 'generate'}. Defaulting to 'generate'.
INFO 04-05 14:04:08 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-05 14:04:08 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-05 14:04:08 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-05 14:04:08 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-05 14:04:08 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-05 14:04:08 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-05 14:04:09 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:09 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:09 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:09 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:09 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:09 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:09 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-05 14:04:10 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:10 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:10 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-05 14:04:10 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:10 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:10 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:10 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:10 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2151089)[0;0m WARNING 04-05 14:04:11 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-05 14:04:11 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2151090)[0;0m WARNING 04-05 14:04:11 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2151091)[0;0m WARNING 04-05 14:04:11 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-05 14:04:11 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_59e172f3'), local_subscribe_port=40639, remote_subscribe_port=None)
INFO 04-05 14:04:11 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:11 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:11 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:11 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.52it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.72it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.16it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.98it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.90it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.84it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.84it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.84it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.84it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.98it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.94it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.92it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.96it/s]

[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:18 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-05 14:04:18 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:18 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:20 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:22 worker.py:241] Memory profiling takes 2.59 seconds
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:22 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:22 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:22 worker.py:241] Memory profiling takes 2.63 seconds
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:22 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:22 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:22 worker.py:241] Memory profiling takes 2.65 seconds
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:22 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:22 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-05 14:04:22 worker.py:241] Memory profiling takes 2.71 seconds
INFO 04-05 14:04:22 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-05 14:04:22 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-05 14:04:23 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-05 14:04:23 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:04:37 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-05 14:04:37 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:04:37 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:04:37 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<02:06,  1.03it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:12,  1.03s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:10,  1.02s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:09,  1.02s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:07,  1.02s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:07,  1.02s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:03,  1.00it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:03,  1.01s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<02:02,  1.00s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<02:01,  1.00s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:11<01:59,  1.00it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:12<01:58,  1.00it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:13<01:56,  1.01it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:14<01:55,  1.02it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:15<01:55,  1.00it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:16<01:54,  1.00it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:16<01:51,  1.02it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:17<01:49,  1.03it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:18<01:47,  1.04it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:19<01:46,  1.05it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:20<01:45,  1.04it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:21<01:44,  1.05it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:22<01:44,  1.04it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:23<01:42,  1.04it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:24<01:42,  1.04it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:25<01:39,  1.05it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:26<01:38,  1.06it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:27<01:37,  1.06it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:28<01:34,  1.08it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:29<01:34,  1.06it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:30<01:32,  1.08it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:31<01:32,  1.07it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:32<01:30,  1.08it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:32<01:28,  1.10it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:33<01:26,  1.11it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:34<01:25,  1.11it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:35<01:24,  1.12it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:36<01:22,  1.13it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:37<01:21,  1.13it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:38<01:20,  1.14it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:39<01:19,  1.14it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:39<01:18,  1.13it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:40<01:17,  1.14it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:41<01:15,  1.15it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:42<01:14,  1.16it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:43<01:14,  1.15it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:44<01:13,  1.15it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:45<01:12,  1.14it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:46<01:10,  1.16it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:46<01:08,  1.18it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:47<01:08,  1.18it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:48<01:07,  1.17it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:49<01:06,  1.17it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:50<01:05,  1.17it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:51<01:03,  1.19it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:51<01:03,  1.19it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:52<01:02,  1.19it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:53<01:00,  1.20it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:54<00:59,  1.20it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:55<00:58,  1.21it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:55<00:57,  1.22it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:56<00:56,  1.22it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:57<00:55,  1.22it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:58<00:55,  1.22it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:59<00:53,  1.24it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:00<00:52,  1.24it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:00<00:50,  1.26it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:01<00:48,  1.29it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:02<00:47,  1.31it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:03<00:47,  1.29it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:03<00:46,  1.30it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:04<00:44,  1.32it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:05<00:45,  1.29it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:06<00:43,  1.32it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:06<00:42,  1.32it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:07<00:41,  1.33it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:08<00:40,  1.32it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:09<00:39,  1.33it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:09<00:38,  1.34it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:10<00:37,  1.35it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:11<00:36,  1.36it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:11<00:35,  1.37it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:12<00:34,  1.39it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:13<00:33,  1.39it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:14<00:32,  1.40it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:14<00:32,  1.40it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:15<00:31,  1.42it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:16<00:30,  1.42it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:16<00:29,  1.43it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:17<00:28,  1.44it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:18<00:27,  1.44it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:18<00:27,  1.44it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:19<00:26,  1.45it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:20<00:25,  1.44it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:21<00:24,  1.46it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:21<00:23,  1.46it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:22<00:23,  1.47it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:23<00:22,  1.46it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:23<00:21,  1.48it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:24<00:20,  1.49it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:25<00:19,  1.52it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:25<00:18,  1.54it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:26<00:18,  1.55it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:26<00:17,  1.52it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:27<00:16,  1.55it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:28<00:16,  1.54it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:28<00:15,  1.55it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:29<00:14,  1.56it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:30<00:14,  1.56it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:30<00:13,  1.58it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:31<00:12,  1.60it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:31<00:11,  1.60it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:32<00:11,  1.62it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:33<00:10,  1.61it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:33<00:09,  1.62it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:34<00:09,  1.65it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:35<00:08,  1.63it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:35<00:07,  1.64it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:36<00:07,  1.66it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:36<00:06,  1.67it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:37<00:05,  1.67it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:38<00:05,  1.66it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:38<00:04,  1.68it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:39<00:04,  1.70it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:39<00:03,  1.69it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:40<00:02,  1.71it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:40<00:02,  1.70it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:41<00:01,  1.73it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:42<00:01,  1.73it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:42<00:00,  1.72it/s][1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-05 14:06:20 model_runner.py:1535] Graph capturing finished in 104 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:43<00:00,  1.50it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:43<00:00,  1.27it/s]
INFO 04-05 14:06:20 model_runner.py:1535] Graph capturing finished in 104 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-05 14:06:20 model_runner.py:1535] Graph capturing finished in 104 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-05 14:06:20 model_runner.py:1535] Graph capturing finished in 104 secs, took 8.20 GiB
INFO 04-05 14:06:20 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 120.60 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: shortest
Generating answers for task: shortest
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-05 14:07:24 scheduler.py:1555] Sequence group 466 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-05 14:07:35 scheduler.py:1555] Sequence group 416 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-05 14:07:48 scheduler.py:1555] Sequence group 366 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
WARNING 04-05 14:08:02 scheduler.py:1555] Sequence group 316 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
WARNING 04-05 14:08:23 scheduler.py:1555] Sequence group 266 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:   0%|          | 1/500 [02:19<19:21:12, 139.62s/it, est. speed input: 1.58 toks/s, output: 3.97 toks/s]WARNING 04-05 14:08:54 scheduler.py:1555] Sequence group 216 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:   0%|          | 2/500 [02:35<9:13:26, 66.68s/it, est. speed input: 2.83 toks/s, output: 8.05 toks/s]  WARNING 04-05 14:09:32 scheduler.py:1555] Sequence group 166 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:   1%|          | 3/500 [03:21<7:56:19, 57.50s/it, est. speed input: 3.27 toks/s, output: 11.60 toks/s]Processed prompts:   1%|          | 4/500 [03:23<4:52:32, 35.39s/it, est. speed input: 4.32 toks/s, output: 17.05 toks/s]Processed prompts:   1%|          | 5/500 [03:39<3:53:49, 28.34s/it, est. speed input: 5.01 toks/s, output: 21.55 toks/s]Processed prompts:   1%|          | 6/500 [04:00<3:34:48, 26.09s/it, est. speed input: 5.50 toks/s, output: 25.76 toks/s]WARNING 04-05 14:10:40 scheduler.py:1555] Sequence group 116 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:   1%|▏         | 7/500 [04:31<3:46:31, 27.57s/it, est. speed input: 5.79 toks/s, output: 29.59 toks/s]Processed prompts:   2%|▏         | 8/500 [04:50<3:22:58, 24.75s/it, est. speed input: 6.27 toks/s, output: 34.77 toks/s]Processed prompts:   2%|▏         | 9/500 [05:29<3:59:26, 29.26s/it, est. speed input: 6.25 toks/s, output: 38.29 toks/s]Processed prompts:   2%|▏         | 10/500 [05:47<3:30:30, 25.78s/it, est. speed input: 6.60 toks/s, output: 44.20 toks/s]Processed prompts:   2%|▏         | 11/500 [06:19<3:45:19, 27.65s/it, est. speed input: 6.77 toks/s, output: 48.78 toks/s]Processed prompts:   2%|▏         | 12/500 [06:30<3:04:47, 22.72s/it, est. speed input: 7.24 toks/s, output: 55.78 toks/s]Processed prompts:   3%|▎         | 13/500 [06:39<2:29:40, 18.44s/it, est. speed input: 7.71 toks/s, output: 63.08 toks/s]Processed prompts:   3%|▎         | 14/500 [06:42<1:51:52, 13.81s/it, est. speed input: 8.25 toks/s, output: 71.14 toks/s]Processed prompts:   3%|▎         | 15/500 [06:56<1:53:29, 14.04s/it, est. speed input: 8.57 toks/s, output: 77.35 toks/s]WARNING 04-05 14:13:33 scheduler.py:1555] Sequence group 64 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:   3%|▎         | 16/500 [07:30<2:40:22, 19.88s/it, est. speed input: 8.67 toks/s, output: 80.63 toks/s]Processed prompts:   3%|▎         | 17/500 [07:34<2:02:42, 15.24s/it, est. speed input: 9.16 toks/s, output: 88.90 toks/s]Processed prompts:   4%|▎         | 18/500 [07:36<1:29:09, 11.10s/it, est. speed input: 9.92 toks/s, output: 97.71 toks/s]Processed prompts:   4%|▍         | 19/500 [08:00<2:01:13, 15.12s/it, est. speed input: 10.08 toks/s, output: 102.03 toks/s]Processed prompts:   4%|▍         | 20/500 [08:22<2:15:50, 16.98s/it, est. speed input: 10.25 toks/s, output: 107.18 toks/s]Processed prompts:   4%|▍         | 21/500 [08:22<1:35:35, 11.97s/it, est. speed input: 11.01 toks/s, output: 116.62 toks/s]Processed prompts:   4%|▍         | 22/500 [08:30<1:26:28, 10.85s/it, est. speed input: 11.43 toks/s, output: 124.31 toks/s]Processed prompts:   5%|▍         | 23/500 [08:32<1:05:09,  8.20s/it, est. speed input: 11.92 toks/s, output: 133.42 toks/s]Processed prompts:   5%|▍         | 24/500 [08:38<59:22,  7.48s/it, est. speed input: 12.32 toks/s, output: 141.56 toks/s]  Processed prompts:   5%|▌         | 25/500 [08:41<49:00,  6.19s/it, est. speed input: 12.90 toks/s, output: 150.38 toks/s]Processed prompts:   5%|▌         | 26/500 [08:47<49:02,  6.21s/it, est. speed input: 13.32 toks/s, output: 158.33 toks/s]Processed prompts:   5%|▌         | 27/500 [08:57<58:01,  7.36s/it, est. speed input: 13.56 toks/s, output: 165.20 toks/s]Processed prompts:   6%|▌         | 28/500 [09:21<1:36:19, 12.25s/it, est. speed input: 13.56 toks/s, output: 168.28 toks/s]Processed prompts:   6%|▌         | 29/500 [09:27<1:20:03, 10.20s/it, est. speed input: 13.88 toks/s, output: 176.76 toks/s]Processed prompts:   6%|▌         | 30/500 [09:32<1:08:40,  8.77s/it, est. speed input: 14.36 toks/s, output: 185.21 toks/s]Processed prompts:   6%|▌         | 31/500 [09:34<52:29,  6.71s/it, est. speed input: 15.17 toks/s, output: 194.73 toks/s]  Processed prompts:   6%|▋         | 32/500 [09:46<1:05:55,  8.45s/it, est. speed input: 15.37 toks/s, output: 200.83 toks/s]Processed prompts:   7%|▋         | 33/500 [09:49<51:14,  6.58s/it, est. speed input: 15.85 toks/s, output: 210.35 toks/s]  Processed prompts:   7%|▋         | 34/500 [09:51<41:20,  5.32s/it, est. speed input: 16.53 toks/s, output: 219.79 toks/s]Processed prompts:   7%|▋         | 35/500 [09:53<34:29,  4.45s/it, est. speed input: 17.25 toks/s, output: 229.19 toks/s]Processed prompts:   7%|▋         | 36/500 [09:59<36:30,  4.72s/it, est. speed input: 17.56 toks/s, output: 237.49 toks/s]Processed prompts:   7%|▋         | 37/500 [10:01<31:43,  4.11s/it, est. speed input: 18.18 toks/s, output: 246.80 toks/s]Processed prompts:   8%|▊         | 38/500 [10:06<32:49,  4.26s/it, est. speed input: 18.54 toks/s, output: 255.31 toks/s]Processed prompts:   8%|▊         | 39/500 [10:35<1:28:50, 11.56s/it, est. speed input: 18.24 toks/s, output: 254.42 toks/s]Processed prompts:   8%|▊         | 40/500 [10:45<1:25:23, 11.14s/it, est. speed input: 18.71 toks/s, output: 261.11 toks/s]Processed prompts:   8%|▊         | 41/500 [10:45<1:00:00,  7.84s/it, est. speed input: 19.12 toks/s, output: 271.73 toks/s]Processed prompts:   8%|▊         | 42/500 [10:46<43:56,  5.76s/it, est. speed input: 19.66 toks/s, output: 279.89 toks/s]  Processed prompts:   9%|▊         | 43/500 [10:48<36:08,  4.75s/it, est. speed input: 20.04 toks/s, output: 289.57 toks/s]Processed prompts:   9%|▉         | 44/500 [11:01<55:11,  7.26s/it, est. speed input: 20.12 toks/s, output: 294.64 toks/s]Processed prompts:   9%|▉         | 45/500 [11:07<50:16,  6.63s/it, est. speed input: 20.40 toks/s, output: 299.93 toks/s]Processed prompts:   9%|▉         | 46/500 [11:15<53:15,  7.04s/it, est. speed input: 20.92 toks/s, output: 307.27 toks/s]Processed prompts:   9%|▉         | 47/500 [11:39<1:31:30, 12.12s/it, est. speed input: 20.87 toks/s, output: 307.77 toks/s]Processed prompts:  10%|▉         | 48/500 [11:47<1:23:23, 11.07s/it, est. speed input: 21.16 toks/s, output: 315.13 toks/s]Processed prompts:  10%|▉         | 49/500 [12:16<2:02:13, 16.26s/it, est. speed input: 20.82 toks/s, output: 314.26 toks/s]Processed prompts:  10%|█         | 50/500 [12:17<1:28:40, 11.82s/it, est. speed input: 21.11 toks/s, output: 323.78 toks/s]Processed prompts:  10%|█         | 51/500 [12:24<1:18:01, 10.43s/it, est. speed input: 21.71 toks/s, output: 331.98 toks/s]Processed prompts:  10%|█         | 52/500 [12:47<1:45:56, 14.19s/it, est. speed input: 21.57 toks/s, output: 330.08 toks/s]Processed prompts:  11%|█         | 53/500 [12:54<1:30:21, 12.13s/it, est. speed input: 22.04 toks/s, output: 338.47 toks/s]Processed prompts:  11%|█         | 54/500 [13:33<2:29:45, 20.15s/it, est. speed input: 21.64 toks/s, output: 329.85 toks/s]Processed prompts:  11%|█         | 55/500 [13:40<1:59:56, 16.17s/it, est. speed input: 22.17 toks/s, output: 338.82 toks/s]Processed prompts:  11%|█         | 56/500 [14:09<2:27:29, 19.93s/it, est. speed input: 21.95 toks/s, output: 339.24 toks/s]Processed prompts:  11%|█▏        | 57/500 [14:09<1:44:01, 14.09s/it, est. speed input: 22.61 toks/s, output: 348.55 toks/s]Processed prompts:  12%|█▏        | 58/500 [14:09<1:12:52,  9.89s/it, est. speed input: 23.62 toks/s, output: 360.38 toks/s]Processed prompts:  12%|█▏        | 59/500 [14:12<57:23,  7.81s/it, est. speed input: 24.19 toks/s, output: 371.02 toks/s]  Processed prompts:  12%|█▏        | 60/500 [14:13<42:14,  5.76s/it, est. speed input: 24.44 toks/s, output: 379.81 toks/s]Processed prompts:  12%|█▏        | 61/500 [14:21<45:16,  6.19s/it, est. speed input: 24.56 toks/s, output: 385.79 toks/s]Processed prompts:  12%|█▏        | 62/500 [14:26<44:33,  6.10s/it, est. speed input: 24.93 toks/s, output: 395.10 toks/s]Processed prompts:  13%|█▎        | 63/500 [15:21<2:30:01, 20.60s/it, est. speed input: 24.17 toks/s, output: 383.91 toks/s]Processed prompts:  13%|█▎        | 64/500 [15:25<1:52:45, 15.52s/it, est. speed input: 24.46 toks/s, output: 394.55 toks/s]Processed prompts:  13%|█▎        | 65/500 [15:26<1:22:38, 11.40s/it, est. speed input: 25.10 toks/s, output: 401.75 toks/s]Processed prompts:  13%|█▎        | 66/500 [15:29<1:02:48,  8.68s/it, est. speed input: 25.31 toks/s, output: 407.20 toks/s]Processed prompts:  13%|█▎        | 67/500 [15:30<46:32,  6.45s/it, est. speed input: 26.30 toks/s, output: 414.75 toks/s]  Processed prompts:  14%|█▎        | 68/500 [16:02<1:42:13, 14.20s/it, est. speed input: 26.17 toks/s, output: 413.13 toks/s]WARNING 04-05 14:22:32 scheduler.py:1555] Sequence group 99 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  14%|█▍        | 69/500 [16:13<1:34:55, 13.22s/it, est. speed input: 26.19 toks/s, output: 415.96 toks/s]Processed prompts:  14%|█▍        | 70/500 [16:32<1:45:49, 14.77s/it, est. speed input: 26.27 toks/s, output: 416.41 toks/s]Processed prompts:  14%|█▍        | 71/500 [16:40<1:32:40, 12.96s/it, est. speed input: 26.58 toks/s, output: 425.17 toks/s]Processed prompts:  14%|█▍        | 72/500 [16:51<1:28:15, 12.37s/it, est. speed input: 26.84 toks/s, output: 424.14 toks/s]Processed prompts:  15%|█▍        | 73/500 [16:53<1:04:30,  9.06s/it, est. speed input: 27.47 toks/s, output: 436.00 toks/s]Processed prompts:  15%|█▍        | 74/500 [16:59<57:58,  8.17s/it, est. speed input: 27.62 toks/s, output: 438.32 toks/s]  Processed prompts:  15%|█▌        | 75/500 [17:22<1:30:42, 12.81s/it, est. speed input: 27.36 toks/s, output: 430.76 toks/s]Processed prompts:  15%|█▌        | 76/500 [17:49<2:00:25, 17.04s/it, est. speed input: 27.87 toks/s, output: 432.50 toks/s]Processed prompts:  15%|█▌        | 77/500 [17:53<1:32:30, 13.12s/it, est. speed input: 28.43 toks/s, output: 443.46 toks/s]Processed prompts:  16%|█▌        | 78/500 [18:26<2:14:45, 19.16s/it, est. speed input: 27.80 toks/s, output: 436.70 toks/s]Processed prompts:  16%|█▌        | 79/500 [18:44<2:11:17, 18.71s/it, est. speed input: 27.65 toks/s, output: 435.81 toks/s]Processed prompts:  16%|█▌        | 80/500 [18:57<1:58:37, 16.95s/it, est. speed input: 28.22 toks/s, output: 437.28 toks/s]Processed prompts:  16%|█▌        | 81/500 [19:06<1:41:10, 14.49s/it, est. speed input: 28.50 toks/s, output: 440.25 toks/s]Processed prompts:  16%|█▋        | 82/500 [19:09<1:17:28, 11.12s/it, est. speed input: 29.25 toks/s, output: 451.78 toks/s]Processed prompts:  17%|█▋        | 83/500 [19:48<2:15:17, 19.47s/it, est. speed input: 28.70 toks/s, output: 449.83 toks/s]Processed prompts:  17%|█▋        | 84/500 [19:56<1:51:23, 16.07s/it, est. speed input: 28.79 toks/s, output: 452.29 toks/s]Processed prompts:  17%|█▋        | 85/500 [20:39<2:47:19, 24.19s/it, est. speed input: 28.10 toks/s, output: 444.57 toks/s]Processed prompts:  17%|█▋        | 86/500 [21:06<2:52:05, 24.94s/it, est. speed input: 28.96 toks/s, output: 448.24 toks/s]Processed prompts:  17%|█▋        | 87/500 [21:53<3:37:41, 31.63s/it, est. speed input: 28.16 toks/s, output: 439.59 toks/s]Processed prompts:  18%|█▊        | 88/500 [22:05<2:57:26, 25.84s/it, est. speed input: 28.11 toks/s, output: 442.81 toks/s]Processed prompts:  18%|█▊        | 89/500 [22:23<2:39:43, 23.32s/it, est. speed input: 29.21 toks/s, output: 444.33 toks/s]Processed prompts:  18%|█▊        | 90/500 [22:26<1:58:53, 17.40s/it, est. speed input: 29.44 toks/s, output: 446.02 toks/s]Processed prompts:  18%|█▊        | 91/500 [22:34<1:38:49, 14.50s/it, est. speed input: 29.51 toks/s, output: 449.63 toks/s]Processed prompts:  18%|█▊        | 92/500 [22:46<1:33:24, 13.74s/it, est. speed input: 29.61 toks/s, output: 456.71 toks/s]WARNING 04-05 14:29:15 scheduler.py:1555] Sequence group 123 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  19%|█▊        | 93/500 [22:56<1:24:25, 12.45s/it, est. speed input: 30.29 toks/s, output: 460.56 toks/s]Processed prompts:  19%|█▉        | 94/500 [23:06<1:20:18, 11.87s/it, est. speed input: 30.75 toks/s, output: 458.39 toks/s]Processed prompts:  19%|█▉        | 95/500 [23:29<1:41:37, 15.06s/it, est. speed input: 31.14 toks/s, output: 456.51 toks/s]Processed prompts:  19%|█▉        | 96/500 [23:37<1:28:48, 13.19s/it, est. speed input: 31.46 toks/s, output: 458.43 toks/s]Processed prompts:  19%|█▉        | 97/500 [24:23<2:33:14, 22.81s/it, est. speed input: 30.77 toks/s, output: 449.72 toks/s]Processed prompts:  20%|█▉        | 98/500 [24:40<2:22:45, 21.31s/it, est. speed input: 30.58 toks/s, output: 452.02 toks/s]Processed prompts:  20%|█▉        | 99/500 [24:51<2:00:14, 17.99s/it, est. speed input: 30.61 toks/s, output: 457.29 toks/s]Processed prompts:  20%|██        | 100/500 [26:12<4:06:01, 36.90s/it, est. speed input: 29.23 toks/s, output: 437.53 toks/s]Processed prompts:  20%|██        | 101/500 [26:41<3:50:44, 34.70s/it, est. speed input: 28.84 toks/s, output: 436.56 toks/s]Processed prompts:  20%|██        | 102/500 [26:42<2:42:37, 24.52s/it, est. speed input: 29.18 toks/s, output: 439.70 toks/s]Processed prompts:  21%|██        | 103/500 [27:45<3:57:44, 35.93s/it, est. speed input: 28.25 toks/s, output: 429.06 toks/s]Processed prompts:  21%|██        | 104/500 [28:10<3:35:45, 32.69s/it, est. speed input: 28.06 toks/s, output: 430.65 toks/s]Processed prompts:  21%|██        | 105/500 [28:59<4:07:30, 37.60s/it, est. speed input: 27.41 toks/s, output: 423.70 toks/s]Processed prompts:  21%|██        | 106/500 [29:01<2:57:25, 27.02s/it, est. speed input: 28.60 toks/s, output: 436.79 toks/s]Processed prompts:  21%|██▏       | 107/500 [31:00<5:57:19, 54.55s/it, est. speed input: 27.02 toks/s, output: 414.08 toks/s]Processed prompts:  22%|██▏       | 108/500 [40:38<23:02:41, 211.64s/it, est. speed input: 20.80 toks/s, output: 329.34 toks/s]Processed prompts:  22%|██▏       | 109/500 [44:12<23:03:04, 212.24s/it, est. speed input: 19.22 toks/s, output: 315.17 toks/s]Processed prompts:  22%|██▏       | 110/500 [44:24<16:28:41, 152.11s/it, est. speed input: 19.32 toks/s, output: 326.07 toks/s]Processed prompts:  22%|██▏       | 111/500 [44:55<12:30:57, 115.83s/it, est. speed input: 19.61 toks/s, output: 334.46 toks/s]Processed prompts:  22%|██▏       | 112/500 [45:55<10:40:15, 99.01s/it, est. speed input: 19.68 toks/s, output: 339.10 toks/s] Processed prompts:  23%|██▎       | 113/500 [45:59<7:36:17, 70.74s/it, est. speed input: 19.85 toks/s, output: 340.00 toks/s] Processed prompts:  23%|██▎       | 114/500 [46:03<5:26:06, 50.69s/it, est. speed input: 20.00 toks/s, output: 351.38 toks/s]Processed prompts:  23%|██▎       | 115/500 [46:05<3:52:04, 36.17s/it, est. speed input: 20.22 toks/s, output: 351.90 toks/s]Processed prompts:  23%|██▎       | 116/500 [46:07<2:44:37, 25.72s/it, est. speed input: 20.74 toks/s, output: 352.32 toks/s]Processed prompts:  23%|██▎       | 117/500 [46:07<1:55:31, 18.10s/it, est. speed input: 20.91 toks/s, output: 352.79 toks/s]Processed prompts:  24%|██▎       | 118/500 [46:12<1:29:44, 14.09s/it, est. speed input: 21.05 toks/s, output: 364.00 toks/s]Processed prompts:  24%|██▍       | 119/500 [46:24<1:25:45, 13.50s/it, est. speed input: 21.05 toks/s, output: 362.88 toks/s]WARNING 04-05 14:52:50 scheduler.py:1555] Sequence group 165 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  24%|██▍       | 120/500 [46:34<1:18:10, 12.34s/it, est. speed input: 21.11 toks/s, output: 362.18 toks/s]Processed prompts:  24%|██▍       | 121/500 [46:43<1:12:43, 11.51s/it, est. speed input: 21.17 toks/s, output: 361.53 toks/s]Processed prompts:  24%|██▍       | 122/500 [47:12<1:45:34, 16.76s/it, est. speed input: 21.05 toks/s, output: 358.58 toks/s]Processed prompts:  25%|██▍       | 123/500 [47:18<1:24:38, 13.47s/it, est. speed input: 21.11 toks/s, output: 369.39 toks/s]Processed prompts:  25%|██▍       | 124/500 [47:20<1:02:41, 10.00s/it, est. speed input: 21.19 toks/s, output: 369.69 toks/s]Processed prompts:  25%|██▌       | 125/500 [47:30<1:02:27,  9.99s/it, est. speed input: 21.22 toks/s, output: 369.24 toks/s]Processed prompts:  25%|██▌       | 126/500 [47:39<1:00:18,  9.68s/it, est. speed input: 21.30 toks/s, output: 368.99 toks/s]Processed prompts:  25%|██▌       | 127/500 [47:43<50:08,  8.06s/it, est. speed input: 21.36 toks/s, output: 368.90 toks/s]  Processed prompts:  26%|██▌       | 128/500 [48:09<1:22:25, 13.29s/it, est. speed input: 21.26 toks/s, output: 366.64 toks/s]Processed prompts:  26%|██▌       | 129/500 [48:52<2:18:04, 22.33s/it, est. speed input: 21.07 toks/s, output: 362.39 toks/s]Processed prompts:  26%|██▌       | 130/500 [49:47<3:18:45, 32.23s/it, est. speed input: 20.88 toks/s, output: 357.16 toks/s]Processed prompts:  26%|██▌       | 131/500 [54:53<11:42:33, 114.24s/it, est. speed input: 19.03 toks/s, output: 333.97 toks/s]Processed prompts:  26%|██▋       | 132/500 [54:53<8:11:16, 80.10s/it, est. speed input: 19.11 toks/s, output: 336.28 toks/s]  Processed prompts:  27%|██▋       | 133/500 [57:23<10:17:10, 100.90s/it, est. speed input: 18.36 toks/s, output: 331.21 toks/s]Processed prompts:  27%|██▋       | 134/500 [57:23<7:11:29, 70.74s/it, est. speed input: 18.47 toks/s, output: 333.47 toks/s]  WARNING 04-05 15:05:29 scheduler.py:1555] Sequence group 134 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  27%|██▋       | 135/500 [1:00:52<11:22:32, 112.20s/it, est. speed input: 17.50 toks/s, output: 323.36 toks/s]Processed prompts:  27%|██▋       | 136/500 [1:02:56<11:41:16, 115.59s/it, est. speed input: 17.12 toks/s, output: 321.46 toks/s]Processed prompts:  27%|██▋       | 137/500 [1:04:18<10:38:11, 105.48s/it, est. speed input: 16.84 toks/s, output: 323.13 toks/s]Processed prompts:  28%|██▊       | 138/500 [1:07:23<13:00:38, 129.39s/it, est. speed input: 16.15 toks/s, output: 316.44 toks/s]Processed prompts:  28%|██▊       | 139/500 [1:12:53<19:00:25, 189.54s/it, est. speed input: 15.01 toks/s, output: 300.06 toks/s]Processed prompts:  28%|██▊       | 140/500 [1:13:57<15:11:18, 151.88s/it, est. speed input: 14.92 toks/s, output: 303.12 toks/s]Processed prompts:  28%|██▊       | 141/500 [1:15:15<12:56:01, 129.70s/it, est. speed input: 14.73 toks/s, output: 305.14 toks/s]Processed prompts:  28%|██▊       | 142/500 [1:15:28<9:24:54, 94.68s/it, est. speed input: 14.74 toks/s, output: 305.34 toks/s]  Processed prompts:  29%|██▊       | 143/500 [1:16:04<7:38:58, 77.14s/it, est. speed input: 14.85 toks/s, output: 310.10 toks/s]Processed prompts:  29%|██▉       | 144/500 [1:17:18<7:32:50, 76.32s/it, est. speed input: 14.67 toks/s, output: 312.19 toks/s]Processed prompts:  29%|██▉       | 145/500 [1:17:19<5:17:51, 53.72s/it, est. speed input: 14.75 toks/s, output: 319.18 toks/s]WARNING 04-05 15:26:36 scheduler.py:1555] Sequence group 158 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  29%|██▉       | 146/500 [1:24:00<15:31:49, 157.94s/it, est. speed input: 13.65 toks/s, output: 300.29 toks/s]Processed prompts:  29%|██▉       | 147/500 [1:24:52<12:21:55, 126.11s/it, est. speed input: 13.56 toks/s, output: 303.66 toks/s]Processed prompts:  30%|██▉       | 148/500 [1:29:23<16:35:22, 169.67s/it, est. speed input: 12.91 toks/s, output: 294.41 toks/s]Processed prompts:  30%|██▉       | 149/500 [1:30:34<13:38:53, 139.98s/it, est. speed input: 12.87 toks/s, output: 296.61 toks/s]Processed prompts:  30%|███       | 150/500 [1:33:31<14:41:16, 151.08s/it, est. speed input: 12.52 toks/s, output: 293.10 toks/s]Processed prompts:  30%|███       | 151/500 [1:37:27<17:07:16, 176.61s/it, est. speed input: 12.15 toks/s, output: 286.86 toks/s]Processed prompts:  30%|███       | 152/500 [1:39:41<15:49:12, 163.66s/it, est. speed input: 12.20 toks/s, output: 282.12 toks/s]Processed prompts:  31%|███       | 153/500 [1:39:45<11:10:35, 115.95s/it, est. speed input: 12.40 toks/s, output: 287.38 toks/s]Processed prompts:  31%|███       | 154/500 [1:41:05<10:06:09, 105.11s/it, est. speed input: 12.29 toks/s, output: 289.00 toks/s]Processed prompts:  31%|███       | 155/500 [1:41:09<7:09:20, 74.67s/it, est. speed input: 12.46 toks/s, output: 289.28 toks/s]  Processed prompts:  31%|███       | 156/500 [1:43:45<9:27:59, 99.07s/it, est. speed input: 12.40 toks/s, output: 287.30 toks/s]Processed prompts:  31%|███▏      | 157/500 [1:44:23<7:42:30, 80.90s/it, est. speed input: 12.37 toks/s, output: 290.76 toks/s]Processed prompts:  32%|███▏      | 158/500 [1:44:40<5:52:10, 61.78s/it, est. speed input: 12.38 toks/s, output: 295.18 toks/s]WARNING 04-05 15:51:22 scheduler.py:1555] Sequence group 203 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  32%|███▏      | 159/500 [1:46:20<6:55:51, 73.17s/it, est. speed input: 12.22 toks/s, output: 295.70 toks/s]WARNING 04-05 15:58:57 scheduler.py:1555] Sequence group 170 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  32%|███▏      | 160/500 [1:52:44<15:41:58, 166.23s/it, est. speed input: 11.62 toks/s, output: 283.79 toks/s]Processed prompts:  32%|███▏      | 161/500 [1:54:56<14:42:32, 156.20s/it, est. speed input: 11.44 toks/s, output: 283.08 toks/s]Processed prompts:  32%|███▏      | 162/500 [1:56:00<12:03:29, 128.43s/it, est. speed input: 11.39 toks/s, output: 285.20 toks/s]Processed prompts:  33%|███▎      | 163/500 [1:59:23<14:07:09, 150.83s/it, est. speed input: 11.23 toks/s, output: 281.68 toks/s]Processed prompts:  33%|███▎      | 164/500 [2:07:36<23:40:05, 253.59s/it, est. speed input: 10.54 toks/s, output: 267.81 toks/s]Processed prompts:  33%|███▎      | 165/500 [2:08:40<18:17:52, 196.63s/it, est. speed input: 10.51 toks/s, output: 269.85 toks/s]Processed prompts:  33%|███▎      | 166/500 [2:10:15<15:24:23, 166.06s/it, est. speed input: 10.43 toks/s, output: 270.77 toks/s]Processed prompts:  33%|███▎      | 167/500 [2:11:28<12:47:28, 138.28s/it, est. speed input: 10.38 toks/s, output: 272.40 toks/s]Processed prompts:  34%|███▎      | 168/500 [2:11:51<9:33:11, 103.59s/it, est. speed input: 10.72 toks/s, output: 275.76 toks/s] Processed prompts:  34%|███▍      | 169/500 [2:13:02<8:38:14, 93.94s/it, est. speed input: 10.76 toks/s, output: 277.40 toks/s] Processed prompts:  34%|███▍      | 170/500 [2:13:46<7:13:02, 78.73s/it, est. speed input: 10.74 toks/s, output: 279.99 toks/s]Processed prompts:  34%|███▍      | 171/500 [2:15:35<8:02:12, 87.94s/it, est. speed input: 10.72 toks/s, output: 280.25 toks/s]WARNING 04-05 16:22:11 scheduler.py:1555] Sequence group 198 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  34%|███▍      | 172/500 [2:20:56<14:23:12, 157.90s/it, est. speed input: 10.36 toks/s, output: 273.48 toks/s]Processed prompts:  35%|███▍      | 173/500 [2:27:39<21:00:55, 231.36s/it, est. speed input: 9.95 toks/s, output: 264.75 toks/s] Processed prompts:  35%|███▍      | 174/500 [2:27:50<14:57:44, 165.23s/it, est. speed input: 10.00 toks/s, output: 268.12 toks/s]Processed prompts:  35%|███▌      | 175/500 [2:28:01<10:44:18, 118.95s/it, est. speed input: 10.02 toks/s, output: 271.48 toks/s]Processed prompts:  35%|███▌      | 176/500 [2:35:44<19:59:55, 222.21s/it, est. speed input: 9.63 toks/s, output: 261.53 toks/s] Processed prompts:  35%|███▌      | 177/500 [2:37:24<16:39:04, 185.59s/it, est. speed input: 9.56 toks/s, output: 262.22 toks/s]Processed prompts:  36%|███▌      | 178/500 [2:38:16<13:01:11, 145.56s/it, est. speed input: 9.63 toks/s, output: 264.23 toks/s]Processed prompts:  36%|███▌      | 179/500 [2:39:06<10:25:02, 116.83s/it, est. speed input: 9.60 toks/s, output: 266.29 toks/s]Processed prompts:  36%|███▌      | 180/500 [2:39:24<7:44:31, 87.10s/it, est. speed input: 9.61 toks/s, output: 269.22 toks/s]  Processed prompts:  36%|███▌      | 181/500 [2:40:08<6:33:41, 74.05s/it, est. speed input: 9.59 toks/s, output: 271.41 toks/s]WARNING 04-05 16:46:49 scheduler.py:1555] Sequence group 220 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  36%|███▋      | 182/500 [2:43:02<9:11:29, 104.06s/it, est. speed input: 9.67 toks/s, output: 269.93 toks/s]Processed prompts:  37%|███▋      | 183/500 [2:46:42<12:13:36, 138.85s/it, est. speed input: 9.49 toks/s, output: 267.27 toks/s]Processed prompts:  37%|███▋      | 184/500 [2:49:49<13:27:18, 153.29s/it, est. speed input: 9.37 toks/s, output: 265.58 toks/s]Processed prompts:  37%|███▋      | 185/500 [2:55:38<18:33:57, 212.18s/it, est. speed input: 9.09 toks/s, output: 259.88 toks/s]Processed prompts:  37%|███▋      | 186/500 [2:55:59<13:29:38, 154.71s/it, est. speed input: 9.11 toks/s, output: 260.56 toks/s]Processed prompts:  37%|███▋      | 187/500 [2:56:49<10:43:56, 123.44s/it, est. speed input: 9.09 toks/s, output: 262.40 toks/s]WARNING 04-05 17:06:06 scheduler.py:1555] Sequence group 194 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  38%|███▊      | 188/500 [3:01:45<15:10:05, 175.02s/it, est. speed input: 8.86 toks/s, output: 258.30 toks/s]Processed prompts:  38%|███▊      | 189/500 [3:03:02<12:34:35, 145.58s/it, est. speed input: 8.82 toks/s, output: 259.48 toks/s]Processed prompts:  38%|███▊      | 190/500 [3:04:39<11:16:56, 131.02s/it, est. speed input: 8.77 toks/s, output: 260.16 toks/s]Processed prompts:  38%|███▊      | 191/500 [3:06:23<10:33:33, 123.02s/it, est. speed input: 8.75 toks/s, output: 260.66 toks/s]Processed prompts:  38%|███▊      | 192/500 [3:07:09<8:32:13, 99.78s/it, est. speed input: 8.73 toks/s, output: 262.53 toks/s]  Processed prompts:  39%|███▊      | 193/500 [3:07:47<6:56:02, 81.31s/it, est. speed input: 8.73 toks/s, output: 264.54 toks/s]Processed prompts:  39%|███▉      | 194/500 [3:08:25<5:48:44, 68.38s/it, est. speed input: 8.72 toks/s, output: 266.55 toks/s]WARNING 04-05 17:15:44 scheduler.py:1555] Sequence group 228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  39%|███▉      | 195/500 [3:10:36<7:23:13, 87.19s/it, est. speed input: 8.64 toks/s, output: 266.36 toks/s]Processed prompts:  39%|███▉      | 196/500 [3:17:39<15:52:52, 188.07s/it, est. speed input: 8.37 toks/s, output: 259.61 toks/s]Processed prompts:  39%|███▉      | 197/500 [3:21:19<16:36:55, 197.41s/it, est. speed input: 8.24 toks/s, output: 257.61 toks/s]Processed prompts:  40%|███▉      | 198/500 [3:24:24<16:15:17, 193.77s/it, est. speed input: 8.14 toks/s, output: 256.39 toks/s]Processed prompts:  40%|███▉      | 199/500 [3:30:01<19:47:49, 236.77s/it, est. speed input: 7.98 toks/s, output: 252.13 toks/s]Processed prompts:  40%|████      | 200/500 [3:31:00<15:16:43, 183.35s/it, est. speed input: 7.99 toks/s, output: 252.30 toks/s]Processed prompts:  40%|████      | 201/500 [3:31:35<11:31:48, 138.82s/it, est. speed input: 8.01 toks/s, output: 254.19 toks/s]Processed prompts:  40%|████      | 202/500 [3:33:18<10:36:24, 128.14s/it, est. speed input: 7.98 toks/s, output: 254.70 toks/s]Processed prompts:  41%|████      | 203/500 [3:34:14<8:47:34, 106.58s/it, est. speed input: 7.98 toks/s, output: 256.14 toks/s] Processed prompts:  41%|████      | 204/500 [3:35:05<7:23:07, 89.82s/it, est. speed input: 7.98 toks/s, output: 257.67 toks/s] Processed prompts:  41%|████      | 205/500 [3:35:33<5:50:34, 71.30s/it, est. speed input: 8.00 toks/s, output: 259.64 toks/s]WARNING 04-05 17:42:16 scheduler.py:1555] Sequence group 227 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  41%|████      | 206/500 [3:36:27<5:23:29, 66.02s/it, est. speed input: 8.02 toks/s, output: 261.09 toks/s]Processed prompts:  41%|████▏     | 207/500 [3:37:17<4:59:48, 61.39s/it, est. speed input: 8.04 toks/s, output: 262.59 toks/s]Processed prompts:  42%|████▏     | 208/500 [3:44:48<14:27:41, 178.29s/it, est. speed input: 7.80 toks/s, output: 256.24 toks/s]Processed prompts:  42%|████▏     | 209/500 [3:48:44<15:47:33, 195.37s/it, est. speed input: 7.69 toks/s, output: 254.24 toks/s]WARNING 04-05 17:55:27 scheduler.py:1555] Sequence group 218 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  42%|████▏     | 210/500 [3:55:02<20:09:39, 250.28s/it, est. speed input: 7.50 toks/s, output: 249.74 toks/s]Processed prompts:  42%|████▏     | 211/500 [3:57:05<17:01:58, 212.17s/it, est. speed input: 7.46 toks/s, output: 249.88 toks/s]Processed prompts:  42%|████▏     | 212/500 [3:57:44<12:48:30, 160.11s/it, est. speed input: 7.47 toks/s, output: 251.50 toks/s]Processed prompts:  43%|████▎     | 213/500 [3:59:24<11:19:27, 142.05s/it, est. speed input: 7.51 toks/s, output: 252.03 toks/s]Processed prompts:  43%|████▎     | 214/500 [3:59:58<8:42:34, 109.63s/it, est. speed input: 7.51 toks/s, output: 253.71 toks/s] Processed prompts:  43%|████▎     | 215/500 [4:00:32<6:53:51, 87.13s/it, est. speed input: 7.54 toks/s, output: 255.37 toks/s] Processed prompts:  43%|████▎     | 216/500 [4:01:24<6:02:18, 76.54s/it, est. speed input: 7.54 toks/s, output: 256.72 toks/s]Processed prompts:  43%|████▎     | 217/500 [4:02:21<5:33:07, 70.63s/it, est. speed input: 7.53 toks/s, output: 257.97 toks/s]Processed prompts:  44%|████▎     | 218/500 [4:08:00<11:50:07, 151.09s/it, est. speed input: 7.45 toks/s, output: 254.30 toks/s]WARNING 04-05 18:15:27 scheduler.py:1555] Sequence group 230 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  44%|████▍     | 219/500 [4:14:58<18:03:27, 231.34s/it, est. speed input: 7.32 toks/s, output: 249.48 toks/s]Processed prompts:  44%|████▍     | 220/500 [4:15:06<12:45:36, 164.06s/it, est. speed input: 7.35 toks/s, output: 251.51 toks/s]Processed prompts:  44%|████▍     | 221/500 [4:15:07<8:56:25, 115.36s/it, est. speed input: 7.38 toks/s, output: 253.62 toks/s] Processed prompts:  44%|████▍     | 222/500 [4:21:51<15:35:21, 201.88s/it, est. speed input: 7.29 toks/s, output: 249.19 toks/s]Processed prompts:  45%|████▍     | 223/500 [4:23:37<13:19:37, 173.20s/it, est. speed input: 7.32 toks/s, output: 249.59 toks/s]Processed prompts:  45%|████▍     | 224/500 [4:24:56<11:06:47, 144.95s/it, est. speed input: 7.33 toks/s, output: 250.41 toks/s]Processed prompts:  45%|████▌     | 225/500 [4:25:48<8:56:20, 117.02s/it, est. speed input: 7.33 toks/s, output: 251.65 toks/s] Processed prompts:  45%|████▌     | 226/500 [4:26:34<7:16:14, 95.53s/it, est. speed input: 7.34 toks/s, output: 252.98 toks/s] Processed prompts:  45%|████▌     | 227/500 [4:28:03<7:06:18, 93.69s/it, est. speed input: 7.32 toks/s, output: 253.61 toks/s]WARNING 04-05 18:35:03 scheduler.py:1555] Sequence group 250 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  46%|████▌     | 228/500 [4:30:43<8:35:02, 113.61s/it, est. speed input: 7.28 toks/s, output: 253.13 toks/s]Processed prompts:  46%|████▌     | 229/500 [4:33:12<9:20:41, 124.14s/it, est. speed input: 7.25 toks/s, output: 252.83 toks/s]Processed prompts:  46%|████▌     | 230/500 [4:38:18<13:24:21, 178.75s/it, est. speed input: 7.16 toks/s, output: 250.16 toks/s]Processed prompts:  46%|████▌     | 231/500 [4:42:08<14:30:36, 194.19s/it, est. speed input: 7.11 toks/s, output: 248.69 toks/s]Processed prompts:  46%|████▋     | 232/500 [4:42:34<10:42:09, 143.77s/it, est. speed input: 7.11 toks/s, output: 250.24 toks/s]Processed prompts:  47%|████▋     | 233/500 [4:43:14<8:21:16, 112.65s/it, est. speed input: 7.17 toks/s, output: 250.47 toks/s] Processed prompts:  47%|████▋     | 234/500 [4:48:28<12:47:04, 173.02s/it, est. speed input: 7.07 toks/s, output: 247.82 toks/s]Processed prompts:  47%|████▋     | 235/500 [4:50:06<11:04:48, 150.52s/it, est. speed input: 7.04 toks/s, output: 248.31 toks/s]Processed prompts:  47%|████▋     | 236/500 [4:51:25<9:27:46, 129.04s/it, est. speed input: 7.04 toks/s, output: 249.06 toks/s] Processed prompts:  47%|████▋     | 237/500 [4:51:27<6:38:38, 90.94s/it, est. speed input: 7.06 toks/s, output: 249.12 toks/s] Processed prompts:  48%|████▊     | 238/500 [4:52:56<6:34:57, 90.45s/it, est. speed input: 7.06 toks/s, output: 249.72 toks/s]WARNING 04-05 18:59:32 scheduler.py:1555] Sequence group 264 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  48%|████▊     | 239/500 [4:54:02<6:01:17, 83.05s/it, est. speed input: 7.05 toks/s, output: 250.64 toks/s]Processed prompts:  48%|████▊     | 240/500 [4:54:36<4:56:18, 68.38s/it, est. speed input: 7.05 toks/s, output: 252.01 toks/s]Processed prompts:  48%|████▊     | 241/500 [4:55:12<4:13:10, 58.65s/it, est. speed input: 7.06 toks/s, output: 253.35 toks/s]WARNING 04-05 19:01:46 scheduler.py:1555] Sequence group 313 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
WARNING 04-05 19:04:53 scheduler.py:1555] Sequence group 263 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301
Processed prompts:  48%|████▊     | 242/500 [5:02:08<11:53:15, 165.87s/it, est. speed input: 6.95 toks/s, output: 249.35 toks/s]Processed prompts:  49%|████▊     | 243/500 [5:02:12<8:21:56, 117.18s/it, est. speed input: 6.96 toks/s, output: 251.10 toks/s] Processed prompts:  49%|████▉     | 244/500 [5:09:40<15:23:22, 216.42s/it, est. speed input: 6.90 toks/s, output: 246.81 toks/s]Processed prompts:  49%|████▉     | 245/500 [5:13:12<15:14:02, 215.07s/it, est. speed input: 6.83 toks/s, output: 245.77 toks/s]Processed prompts:  49%|████▉     | 246/500 [5:16:15<14:30:24, 205.61s/it, est. speed input: 6.82 toks/s, output: 245.12 toks/s]Processed prompts:  49%|████▉     | 247/500 [5:17:11<11:17:44, 160.73s/it, est. speed input: 6.82 toks/s, output: 245.22 toks/s]Processed prompts:  50%|████▉     | 248/500 [5:19:55<11:18:31, 161.55s/it, est. speed input: 6.86 toks/s, output: 244.84 toks/s]Processed prompts:  50%|████▉     | 249/500 [5:21:14<9:31:46, 136.68s/it, est. speed input: 6.84 toks/s, output: 245.54 toks/s] Processed prompts:  50%|█████     | 250/500 [5:22:06<7:43:42, 111.29s/it, est. speed input: 6.86 toks/s, output: 246.58 toks/s]Processed prompts:  50%|█████     | 251/500 [5:22:47<6:14:28, 90.24s/it, est. speed input: 6.86 toks/s, output: 247.74 toks/s] Processed prompts:  50%|█████     | 252/500 [5:23:41<5:28:43, 79.53s/it, est. speed input: 6.94 toks/s, output: 248.73 toks/s]Processed prompts:  51%|█████     | 253/500 [5:24:12<4:27:25, 64.96s/it, est. speed input: 6.96 toks/s, output: 250.02 toks/s]Processed prompts:  51%|█████     | 254/500 [5:24:38<3:38:45, 53.35s/it, est. speed input: 6.97 toks/s, output: 251.37 toks/s]WARNING 04-05 19:31:19 scheduler.py:1555] Sequence group 295 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351
Processed prompts:  51%|█████     | 255/500 [5:34:02<14:03:14, 206.51s/it, est. speed input: 6.79 toks/s, output: 245.93 toks/s]Processed prompts:  51%|█████     | 256/500 [5:34:38<10:31:11, 155.21s/it, est. speed input: 6.79 toks/s, output: 247.13 toks/s]Processed prompts:  51%|█████▏    | 257/500 [5:34:59<7:46:03, 115.08s/it, est. speed input: 6.81 toks/s, output: 247.57 toks/s] Processed prompts:  52%|█████▏    | 258/500 [5:43:02<15:09:19, 225.45s/it, est. speed input: 6.68 toks/s, output: 243.36 toks/s]Processed prompts:  52%|█████▏    | 259/500 [5:44:30<12:19:30, 184.11s/it, est. speed input: 6.68 toks/s, output: 243.91 toks/s]Processed prompts:  52%|█████▏    | 260/500 [5:45:55<10:18:10, 154.55s/it, est. speed input: 6.68 toks/s, output: 244.48 toks/s]Processed prompts:  52%|█████▏    | 261/500 [5:47:35<9:10:09, 138.11s/it, est. speed input: 6.67 toks/s, output: 244.88 toks/s] Processed prompts:  52%|█████▏    | 262/500 [5:48:20<7:17:13, 110.22s/it, est. speed input: 6.68 toks/s, output: 245.92 toks/s]Processed prompts:  53%|█████▎    | 263/500 [5:49:00<5:52:04, 89.13s/it, est. speed input: 6.68 toks/s, output: 247.02 toks/s] Processed prompts:  53%|█████▎    | 264/500 [5:49:45<4:58:03, 75.78s/it, est. speed input: 6.68 toks/s, output: 248.06 toks/s]WARNING 04-05 19:56:27 scheduler.py:1555] Sequence group 286 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401
Processed prompts:  53%|█████▎    | 265/500 [5:50:48<4:41:33, 71.89s/it, est. speed input: 6.67 toks/s, output: 248.87 toks/s]Processed prompts:  53%|█████▎    | 266/500 [5:55:47<9:06:21, 140.09s/it, est. speed input: 6.61 toks/s, output: 246.92 toks/s]Processed prompts:  53%|█████▎    | 267/500 [6:01:36<13:07:31, 202.80s/it, est. speed input: 6.52 toks/s, output: 244.46 toks/s]Processed prompts:  54%|█████▎    | 268/500 [6:03:34<11:25:56, 177.40s/it, est. speed input: 6.50 toks/s, output: 244.63 toks/s]Processed prompts:  54%|█████▍    | 269/500 [6:04:20<8:50:28, 137.78s/it, est. speed input: 6.51 toks/s, output: 245.63 toks/s] Processed prompts:  54%|█████▍    | 270/500 [6:07:56<10:19:08, 161.52s/it, est. speed input: 6.45 toks/s, output: 243.70 toks/s]Processed prompts:  54%|█████▍    | 271/500 [6:08:04<7:20:11, 115.33s/it, est. speed input: 6.49 toks/s, output: 245.10 toks/s] Processed prompts:  54%|█████▍    | 272/500 [6:12:02<9:37:31, 151.98s/it, est. speed input: 6.46 toks/s, output: 243.96 toks/s]Processed prompts:  55%|█████▍    | 273/500 [6:13:20<8:11:45, 129.98s/it, est. speed input: 6.45 toks/s, output: 244.56 toks/s]Processed prompts:  55%|█████▍    | 274/500 [6:13:40<6:04:43, 96.83s/it, est. speed input: 6.46 toks/s, output: 244.85 toks/s] Processed prompts:  55%|█████▌    | 275/500 [6:13:54<4:30:32, 72.14s/it, est. speed input: 6.48 toks/s, output: 246.16 toks/s]Processed prompts:  55%|█████▌    | 276/500 [6:14:28<3:45:51, 60.50s/it, est. speed input: 6.50 toks/s, output: 247.25 toks/s]WARNING 04-05 20:20:59 scheduler.py:1555] Sequence group 332 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451
Processed prompts:  55%|█████▌    | 277/500 [6:15:16<3:31:23, 56.88s/it, est. speed input: 6.50 toks/s, output: 248.17 toks/s]WARNING 04-05 20:22:19 scheduler.py:1555] Sequence group 320 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501
Processed prompts:  56%|█████▌    | 278/500 [6:17:52<5:20:53, 86.73s/it, est. speed input: 6.48 toks/s, output: 247.91 toks/s]Processed prompts:  56%|█████▌    | 279/500 [6:21:54<8:10:10, 133.08s/it, est. speed input: 6.43 toks/s, output: 246.73 toks/s]Processed prompts:  56%|█████▌    | 280/500 [6:23:59<7:59:10, 130.68s/it, est. speed input: 6.41 toks/s, output: 246.81 toks/s]WARNING 04-05 20:34:16 scheduler.py:1555] Sequence group 296 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551
Processed prompts:  56%|█████▌    | 281/500 [6:30:52<13:06:33, 215.50s/it, est. speed input: 6.31 toks/s, output: 243.86 toks/s]Processed prompts:  56%|█████▋    | 282/500 [6:39:02<18:02:31, 297.94s/it, est. speed input: 6.20 toks/s, output: 240.23 toks/s]Processed prompts:  57%|█████▋    | 283/500 [6:40:04<13:41:07, 227.04s/it, est. speed input: 6.20 toks/s, output: 240.98 toks/s]Processed prompts:  57%|█████▋    | 284/500 [6:41:18<10:52:04, 181.13s/it, est. speed input: 6.23 toks/s, output: 241.60 toks/s]Processed prompts:  57%|█████▋    | 285/500 [6:41:54<8:12:44, 137.51s/it, est. speed input: 6.24 toks/s, output: 242.60 toks/s] Processed prompts:  57%|█████▋    | 286/500 [6:42:44<6:37:31, 111.46s/it, est. speed input: 6.24 toks/s, output: 243.45 toks/s]Processed prompts:  57%|█████▋    | 287/500 [6:43:17<5:11:56, 87.87s/it, est. speed input: 6.24 toks/s, output: 244.47 toks/s] Processed prompts:  58%|█████▊    | 288/500 [6:43:58<4:20:27, 73.72s/it, est. speed input: 6.25 toks/s, output: 245.41 toks/s]Processed prompts:  58%|█████▊    | 289/500 [6:45:36<4:45:26, 81.17s/it, est. speed input: 6.23 toks/s, output: 245.77 toks/s]Processed prompts:  58%|█████▊    | 290/500 [6:49:42<7:37:09, 130.62s/it, est. speed input: 6.19 toks/s, output: 244.64 toks/s]Processed prompts:  58%|█████▊    | 291/500 [6:55:08<10:58:51, 189.15s/it, est. speed input: 6.13 toks/s, output: 242.76 toks/s]Processed prompts:  58%|█████▊    | 292/500 [6:56:04<8:36:39, 149.04s/it, est. speed input: 6.12 toks/s, output: 243.53 toks/s] Processed prompts:  59%|█████▊    | 293/500 [6:58:47<8:49:24, 153.45s/it, est. speed input: 6.12 toks/s, output: 243.25 toks/s]Processed prompts:  59%|█████▉    | 294/500 [7:00:09<7:32:32, 131.81s/it, est. speed input: 6.11 toks/s, output: 243.76 toks/s]Processed prompts:  59%|█████▉    | 295/500 [7:01:07<6:15:14, 109.83s/it, est. speed input: 6.12 toks/s, output: 243.96 toks/s]WARNING 04-05 21:07:58 scheduler.py:1555] Sequence group 309 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601
Processed prompts:  59%|█████▉    | 296/500 [7:02:22<5:37:51, 99.37s/it, est. speed input: 6.16 toks/s, output: 244.53 toks/s] Processed prompts:  59%|█████▉    | 297/500 [7:04:30<6:04:46, 107.81s/it, est. speed input: 6.15 toks/s, output: 244.60 toks/s]Processed prompts:  60%|█████▉    | 298/500 [7:06:42<6:27:37, 115.13s/it, est. speed input: 6.18 toks/s, output: 244.61 toks/s]Processed prompts:  60%|█████▉    | 299/500 [7:09:21<7:09:46, 128.29s/it, est. speed input: 6.16 toks/s, output: 244.37 toks/s]Processed prompts:  60%|██████    | 300/500 [7:10:02<5:40:18, 102.09s/it, est. speed input: 6.16 toks/s, output: 244.20 toks/s]Processed prompts:  60%|██████    | 301/500 [7:10:32<4:27:06, 80.53s/it, est. speed input: 6.21 toks/s, output: 245.18 toks/s] WARNING 04-05 21:17:33 scheduler.py:1555] Sequence group 322 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651
Processed prompts:  60%|██████    | 302/500 [7:15:51<8:22:05, 152.15s/it, est. speed input: 6.16 toks/s, output: 243.44 toks/s]Processed prompts:  61%|██████    | 303/500 [7:16:46<6:43:24, 122.87s/it, est. speed input: 6.17 toks/s, output: 244.19 toks/s]Processed prompts:  61%|██████    | 304/500 [7:23:28<11:14:43, 206.55s/it, est. speed input: 6.10 toks/s, output: 241.73 toks/s]Processed prompts:  61%|██████    | 305/500 [7:23:31<7:53:01, 145.55s/it, est. speed input: 6.12 toks/s, output: 242.93 toks/s] Processed prompts:  61%|██████    | 306/500 [7:26:47<8:40:06, 160.86s/it, est. speed input: 6.08 toks/s, output: 241.64 toks/s]Processed prompts:  61%|██████▏   | 307/500 [7:26:54<6:08:54, 114.69s/it, est. speed input: 6.10 toks/s, output: 242.80 toks/s]Processed prompts:  62%|██████▏   | 308/500 [7:28:03<5:22:54, 100.91s/it, est. speed input: 6.09 toks/s, output: 243.40 toks/s]Processed prompts:  62%|██████▏   | 309/500 [7:29:08<4:46:42, 90.06s/it, est. speed input: 6.11 toks/s, output: 244.03 toks/s] WARNING 04-05 21:35:41 scheduler.py:1555] Sequence group 351 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701
Processed prompts:  62%|██████▏   | 310/500 [7:30:24<4:31:51, 85.85s/it, est. speed input: 6.11 toks/s, output: 244.55 toks/s]Processed prompts:  62%|██████▏   | 311/500 [7:31:35<4:16:03, 81.29s/it, est. speed input: 6.10 toks/s, output: 245.12 toks/s]WARNING 04-05 21:38:05 scheduler.py:1555] Sequence group 356 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751
Processed prompts:  62%|██████▏   | 312/500 [7:33:04<4:22:39, 83.83s/it, est. speed input: 6.09 toks/s, output: 245.52 toks/s]Processed prompts:  63%|██████▎   | 313/500 [7:40:03<9:34:25, 184.31s/it, est. speed input: 6.01 toks/s, output: 242.98 toks/s]WARNING 04-05 21:46:43 scheduler.py:1555] Sequence group 326 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801
Processed prompts:  63%|██████▎   | 314/500 [7:42:05<8:33:01, 165.49s/it, est. speed input: 6.00 toks/s, output: 243.10 toks/s]Processed prompts:  63%|██████▎   | 315/500 [7:46:35<10:07:32, 197.04s/it, est. speed input: 5.98 toks/s, output: 241.92 toks/s]Processed prompts:  63%|██████▎   | 316/500 [7:47:39<8:01:15, 156.93s/it, est. speed input: 5.98 toks/s, output: 241.82 toks/s] Processed prompts:  63%|██████▎   | 317/500 [7:52:22<9:54:01, 194.76s/it, est. speed input: 5.95 toks/s, output: 240.57 toks/s]Processed prompts:  64%|██████▎   | 318/500 [7:54:19<8:40:06, 171.46s/it, est. speed input: 5.94 toks/s, output: 240.73 toks/s]Processed prompts:  64%|██████▍   | 319/500 [7:56:19<7:50:37, 156.01s/it, est. speed input: 5.92 toks/s, output: 240.86 toks/s]Processed prompts:  64%|██████▍   | 320/500 [7:57:30<6:31:23, 130.46s/it, est. speed input: 5.91 toks/s, output: 241.41 toks/s]Processed prompts:  64%|██████▍   | 321/500 [7:58:16<5:13:38, 105.13s/it, est. speed input: 5.92 toks/s, output: 242.17 toks/s]Processed prompts:  64%|██████▍   | 322/500 [7:58:47<4:05:49, 82.86s/it, est. speed input: 5.92 toks/s, output: 243.05 toks/s] Processed prompts:  65%|██████▍   | 323/500 [7:59:10<3:11:34, 64.94s/it, est. speed input: 5.93 toks/s, output: 243.99 toks/s]Processed prompts:  65%|██████▍   | 324/500 [7:59:24<2:26:14, 49.86s/it, est. speed input: 5.94 toks/s, output: 245.01 toks/s]WARNING 04-05 22:06:20 scheduler.py:1555] Sequence group 396 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851
Processed prompts:  65%|██████▌   | 325/500 [8:01:02<3:07:38, 64.33s/it, est. speed input: 5.93 toks/s, output: 244.41 toks/s]WARNING 04-05 22:08:53 scheduler.py:1555] Sequence group 348 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901
Processed prompts:  65%|██████▌   | 326/500 [8:04:50<5:28:17, 113.20s/it, est. speed input: 5.90 toks/s, output: 243.62 toks/s]Processed prompts:  65%|██████▌   | 327/500 [8:07:24<6:01:43, 125.45s/it, est. speed input: 5.91 toks/s, output: 242.71 toks/s]Processed prompts:  66%|██████▌   | 328/500 [8:09:47<6:14:38, 130.69s/it, est. speed input: 5.89 toks/s, output: 242.64 toks/s]Processed prompts:  66%|██████▌   | 329/500 [8:10:18<4:47:44, 100.96s/it, est. speed input: 5.89 toks/s, output: 243.07 toks/s]Processed prompts:  66%|██████▌   | 330/500 [8:10:50<3:47:10, 80.18s/it, est. speed input: 5.89 toks/s, output: 243.23 toks/s] Processed prompts:  66%|██████▌   | 331/500 [8:12:28<4:00:42, 85.46s/it, est. speed input: 5.89 toks/s, output: 243.54 toks/s]Processed prompts:  66%|██████▋   | 332/500 [8:13:15<3:27:03, 73.95s/it, est. speed input: 5.90 toks/s, output: 243.52 toks/s]Processed prompts:  67%|██████▋   | 333/500 [8:21:01<8:53:04, 191.53s/it, est. speed input: 5.82 toks/s, output: 240.84 toks/s]Processed prompts:  67%|██████▋   | 334/500 [8:22:49<7:41:04, 166.66s/it, est. speed input: 5.82 toks/s, output: 241.05 toks/s]Processed prompts:  67%|██████▋   | 335/500 [8:24:03<6:21:44, 138.81s/it, est. speed input: 5.84 toks/s, output: 241.55 toks/s]Processed prompts:  67%|██████▋   | 336/500 [8:25:00<5:12:35, 114.36s/it, est. speed input: 5.85 toks/s, output: 242.17 toks/s]Processed prompts:  67%|██████▋   | 337/500 [8:25:35<4:05:53, 90.51s/it, est. speed input: 5.87 toks/s, output: 242.98 toks/s] Processed prompts:  68%|██████▊   | 338/500 [8:26:01<3:11:55, 71.09s/it, est. speed input: 5.87 toks/s, output: 243.85 toks/s]WARNING 04-05 22:32:55 scheduler.py:1555] Sequence group 370 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951
Processed prompts:  68%|██████▊   | 339/500 [8:26:45<2:48:28, 62.79s/it, est. speed input: 5.87 toks/s, output: 243.79 toks/s]Processed prompts:  68%|██████▊   | 340/500 [8:27:55<2:53:36, 65.10s/it, est. speed input: 5.88 toks/s, output: 244.30 toks/s]Processed prompts:  68%|██████▊   | 341/500 [8:28:47<2:42:01, 61.14s/it, est. speed input: 5.89 toks/s, output: 244.96 toks/s]WARNING 04-05 22:38:46 scheduler.py:1555] Sequence group 358 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001
Processed prompts:  68%|██████▊   | 342/500 [8:34:46<6:36:26, 150.55s/it, est. speed input: 5.83 toks/s, output: 243.17 toks/s]Processed prompts:  69%|██████▊   | 343/500 [8:34:57<4:44:08, 108.59s/it, est. speed input: 5.84 toks/s, output: 243.39 toks/s]Processed prompts:  69%|██████▉   | 344/500 [8:40:40<7:45:22, 178.99s/it, est. speed input: 5.81 toks/s, output: 241.27 toks/s]Processed prompts:  69%|██████▉   | 345/500 [8:42:02<6:27:16, 149.91s/it, est. speed input: 5.83 toks/s, output: 241.68 toks/s]Processed prompts:  69%|██████▉   | 346/500 [8:42:50<5:06:07, 119.27s/it, est. speed input: 5.83 toks/s, output: 242.36 toks/s]Processed prompts:  69%|██████▉   | 347/500 [8:43:50<4:19:16, 101.68s/it, est. speed input: 5.83 toks/s, output: 242.94 toks/s]Processed prompts:  70%|██████▉   | 348/500 [8:52:09<9:19:02, 220.67s/it, est. speed input: 5.74 toks/s, output: 240.17 toks/s]Processed prompts:  70%|██████▉   | 349/500 [8:52:17<6:34:49, 156.88s/it, est. speed input: 5.76 toks/s, output: 240.86 toks/s]Processed prompts:  70%|███████   | 350/500 [8:53:34<5:32:13, 132.89s/it, est. speed input: 5.76 toks/s, output: 241.31 toks/s]Processed prompts:  70%|███████   | 351/500 [8:53:53<4:05:34, 98.89s/it, est. speed input: 5.77 toks/s, output: 242.18 toks/s] Processed prompts:  70%|███████   | 352/500 [8:54:08<3:01:22, 73.53s/it, est. speed input: 5.77 toks/s, output: 243.10 toks/s]Processed prompts:  71%|███████   | 353/500 [8:54:26<2:19:34, 56.97s/it, est. speed input: 5.78 toks/s, output: 243.98 toks/s]Processed prompts:  71%|███████   | 354/500 [8:54:43<1:49:39, 45.07s/it, est. speed input: 5.79 toks/s, output: 244.29 toks/s]Processed prompts:  71%|███████   | 355/500 [8:55:05<1:31:57, 38.05s/it, est. speed input: 5.80 toks/s, output: 245.15 toks/s]WARNING 04-05 23:01:38 scheduler.py:1555] Sequence group 442 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2051
WARNING 04-05 23:03:00 scheduler.py:1555] Sequence group 392 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2101
Processed prompts:  71%|███████   | 356/500 [8:58:07<3:14:44, 81.14s/it, est. speed input: 5.78 toks/s, output: 244.05 toks/s]Processed prompts:  71%|███████▏  | 357/500 [8:58:30<2:32:02, 63.79s/it, est. speed input: 5.79 toks/s, output: 244.89 toks/s]Processed prompts:  72%|███████▏  | 358/500 [9:02:42<4:44:30, 120.22s/it, est. speed input: 5.75 toks/s, output: 243.40 toks/s]Processed prompts:  72%|███████▏  | 359/500 [9:06:45<6:09:23, 157.19s/it, est. speed input: 5.72 toks/s, output: 242.59 toks/s]Processed prompts:  72%|███████▏  | 360/500 [9:06:55<4:23:23, 112.89s/it, est. speed input: 5.74 toks/s, output: 242.94 toks/s]Processed prompts:  72%|███████▏  | 361/500 [9:12:38<7:01:45, 182.05s/it, est. speed input: 5.70 toks/s, output: 241.41 toks/s]Processed prompts:  72%|███████▏  | 362/500 [9:13:33<5:31:10, 143.99s/it, est. speed input: 5.69 toks/s, output: 242.00 toks/s]Processed prompts:  73%|███████▎  | 363/500 [9:13:43<3:56:30, 103.58s/it, est. speed input: 5.70 toks/s, output: 242.34 toks/s]WARNING 04-05 23:24:11 scheduler.py:1555] Sequence group 372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2151
Processed prompts:  73%|███████▎  | 364/500 [9:19:23<6:35:28, 174.48s/it, est. speed input: 5.65 toks/s, output: 240.87 toks/s]Processed prompts:  73%|███████▎  | 365/500 [9:20:42<5:28:21, 145.94s/it, est. speed input: 5.69 toks/s, output: 241.27 toks/s]Processed prompts:  73%|███████▎  | 366/500 [9:22:26<4:57:55, 133.40s/it, est. speed input: 5.68 toks/s, output: 241.50 toks/s]Processed prompts:  73%|███████▎  | 367/500 [9:22:50<3:43:03, 100.63s/it, est. speed input: 5.68 toks/s, output: 242.30 toks/s]Processed prompts:  74%|███████▎  | 368/500 [9:23:23<2:56:29, 80.22s/it, est. speed input: 5.69 toks/s, output: 243.03 toks/s] Processed prompts:  74%|███████▍  | 369/500 [9:23:49<2:19:25, 63.86s/it, est. speed input: 5.69 toks/s, output: 243.81 toks/s]Processed prompts:  74%|███████▍  | 370/500 [9:24:16<1:54:32, 52.86s/it, est. speed input: 5.70 toks/s, output: 244.59 toks/s]Processed prompts:  74%|███████▍  | 371/500 [9:31:24<5:55:27, 165.33s/it, est. speed input: 5.64 toks/s, output: 242.49 toks/s]WARNING 04-05 23:37:57 scheduler.py:1555] Sequence group 384 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2201
Processed prompts:  74%|███████▍  | 372/500 [9:31:52<4:24:56, 124.19s/it, est. speed input: 5.65 toks/s, output: 243.25 toks/s]Processed prompts:  75%|███████▍  | 373/500 [9:32:25<3:25:23, 97.04s/it, est. speed input: 5.65 toks/s, output: 243.35 toks/s] Processed prompts:  75%|███████▍  | 374/500 [9:32:54<2:40:40, 76.51s/it, est. speed input: 5.66 toks/s, output: 243.41 toks/s]Processed prompts:  75%|███████▌  | 375/500 [9:37:33<4:45:37, 137.10s/it, est. speed input: 5.62 toks/s, output: 242.06 toks/s]Processed prompts:  75%|███████▌  | 376/500 [9:39:39<4:36:47, 133.93s/it, est. speed input: 5.61 toks/s, output: 242.12 toks/s]Processed prompts:  75%|███████▌  | 377/500 [9:40:42<3:51:12, 112.79s/it, est. speed input: 5.60 toks/s, output: 242.10 toks/s]Processed prompts:  76%|███████▌  | 378/500 [9:40:55<2:48:09, 82.70s/it, est. speed input: 5.61 toks/s, output: 242.95 toks/s] Processed prompts:  76%|███████▌  | 379/500 [9:41:53<2:31:44, 75.24s/it, est. speed input: 5.62 toks/s, output: 242.87 toks/s]Processed prompts:  76%|███████▌  | 380/500 [9:45:43<4:03:36, 121.80s/it, est. speed input: 5.63 toks/s, output: 242.21 toks/s]Processed prompts:  76%|███████▌  | 381/500 [9:47:58<4:09:22, 125.74s/it, est. speed input: 5.64 toks/s, output: 242.21 toks/s]Processed prompts:  76%|███████▋  | 382/500 [9:49:09<3:34:57, 109.30s/it, est. speed input: 5.63 toks/s, output: 242.65 toks/s]Processed prompts:  77%|███████▋  | 383/500 [9:49:31<2:41:47, 82.97s/it, est. speed input: 5.64 toks/s, output: 243.43 toks/s] Processed prompts:  77%|███████▋  | 384/500 [9:49:54<2:05:45, 65.05s/it, est. speed input: 5.64 toks/s, output: 244.20 toks/s]WARNING 04-05 23:56:39 scheduler.py:1555] Sequence group 433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2251
Processed prompts:  77%|███████▋  | 385/500 [9:50:49<1:59:00, 62.09s/it, est. speed input: 5.64 toks/s, output: 244.74 toks/s]WARNING 04-05 23:58:01 scheduler.py:1555] Sequence group 425 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2301
Processed prompts:  77%|███████▋  | 386/500 [9:52:21<2:14:52, 70.99s/it, est. speed input: 5.64 toks/s, output: 245.03 toks/s]Processed prompts:  77%|███████▋  | 387/500 [9:59:22<5:31:48, 176.18s/it, est. speed input: 5.60 toks/s, output: 243.07 toks/s]WARNING 04-06 00:10:37 scheduler.py:1555] Sequence group 397 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2351
Processed prompts:  78%|███████▊  | 388/500 [10:07:40<8:28:49, 272.59s/it, est. speed input: 5.53 toks/s, output: 240.65 toks/s]Processed prompts:  78%|███████▊  | 389/500 [10:11:22<7:56:14, 257.43s/it, est. speed input: 5.51 toks/s, output: 240.09 toks/s]Processed prompts:  78%|███████▊  | 390/500 [10:11:26<5:32:46, 181.51s/it, est. speed input: 5.52 toks/s, output: 240.55 toks/s]Processed prompts:  78%|███████▊  | 391/500 [10:11:53<4:05:29, 135.13s/it, est. speed input: 5.55 toks/s, output: 241.27 toks/s]Processed prompts:  78%|███████▊  | 392/500 [10:13:02<3:27:10, 115.09s/it, est. speed input: 5.55 toks/s, output: 241.22 toks/s]Processed prompts:  79%|███████▊  | 393/500 [10:14:10<3:00:02, 100.96s/it, est. speed input: 5.58 toks/s, output: 241.30 toks/s]Processed prompts:  79%|███████▉  | 394/500 [10:14:44<2:23:08, 81.02s/it, est. speed input: 5.58 toks/s, output: 241.96 toks/s] Processed prompts:  79%|███████▉  | 395/500 [10:17:04<2:52:42, 98.69s/it, est. speed input: 5.57 toks/s, output: 241.93 toks/s]Processed prompts:  79%|███████▉  | 396/500 [10:17:44<2:20:16, 80.93s/it, est. speed input: 5.58 toks/s, output: 242.56 toks/s]Processed prompts:  79%|███████▉  | 397/500 [10:18:16<1:54:11, 66.52s/it, est. speed input: 5.58 toks/s, output: 243.23 toks/s]Processed prompts:  80%|███████▉  | 398/500 [10:18:32<1:27:04, 51.22s/it, est. speed input: 5.59 toks/s, output: 244.01 toks/s]Processed prompts:  80%|███████▉  | 399/500 [10:18:47<1:07:49, 40.29s/it, est. speed input: 5.60 toks/s, output: 244.79 toks/s]WARNING 04-06 00:26:09 scheduler.py:1555] Sequence group 433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2401
Processed prompts:  80%|████████  | 400/500 [10:25:12<3:59:49, 143.90s/it, est. speed input: 5.58 toks/s, output: 242.70 toks/s]Processed prompts:  80%|████████  | 401/500 [10:25:21<2:50:32, 103.36s/it, est. speed input: 5.58 toks/s, output: 243.51 toks/s]Processed prompts:  80%|████████  | 402/500 [10:33:11<5:48:25, 213.32s/it, est. speed input: 5.53 toks/s, output: 241.08 toks/s]Processed prompts:  81%|████████  | 403/500 [10:33:53<4:21:54, 162.01s/it, est. speed input: 5.54 toks/s, output: 241.68 toks/s]Processed prompts:  81%|████████  | 404/500 [10:36:30<4:16:29, 160.31s/it, est. speed input: 5.53 toks/s, output: 241.54 toks/s]Processed prompts:  81%|████████  | 405/500 [10:38:33<3:56:22, 149.29s/it, est. speed input: 5.52 toks/s, output: 241.62 toks/s]Processed prompts:  81%|████████  | 406/500 [10:38:42<2:47:43, 107.06s/it, est. speed input: 5.57 toks/s, output: 242.13 toks/s]Processed prompts:  81%|████████▏ | 407/500 [10:39:56<2:30:52, 97.34s/it, est. speed input: 5.56 toks/s, output: 242.51 toks/s] Processed prompts:  82%|████████▏ | 408/500 [10:42:36<2:57:58, 116.07s/it, est. speed input: 5.56 toks/s, output: 242.36 toks/s]Processed prompts:  82%|████████▏ | 409/500 [10:44:17<2:48:59, 111.42s/it, est. speed input: 5.55 toks/s, output: 242.58 toks/s]Processed prompts:  82%|████████▏ | 410/500 [10:44:37<2:06:06, 84.07s/it, est. speed input: 5.56 toks/s, output: 243.30 toks/s] Processed prompts:  82%|████████▏ | 411/500 [10:45:07<1:40:28, 67.74s/it, est. speed input: 5.58 toks/s, output: 243.96 toks/s]WARNING 04-06 00:51:37 scheduler.py:1555] Sequence group 459 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2451
Processed prompts:  82%|████████▏ | 412/500 [10:49:17<2:59:44, 122.55s/it, est. speed input: 5.56 toks/s, output: 242.92 toks/s]Processed prompts:  83%|████████▎ | 413/500 [10:49:32<2:10:51, 90.25s/it, est. speed input: 5.57 toks/s, output: 243.67 toks/s] Processed prompts:  83%|████████▎ | 414/500 [10:50:37<1:58:30, 82.68s/it, est. speed input: 5.57 toks/s, output: 243.56 toks/s]Processed prompts:  83%|████████▎ | 415/500 [10:54:10<2:52:29, 121.75s/it, est. speed input: 5.55 toks/s, output: 243.07 toks/s]WARNING 04-06 01:02:39 scheduler.py:1555] Sequence group 428 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2501
Processed prompts:  83%|████████▎ | 416/500 [10:56:24<2:55:33, 125.40s/it, est. speed input: 5.54 toks/s, output: 242.61 toks/s]Processed prompts:  83%|████████▎ | 417/500 [10:57:04<2:18:01, 99.78s/it, est. speed input: 5.55 toks/s, output: 242.90 toks/s] Processed prompts:  84%|████████▎ | 418/500 [10:58:26<2:08:58, 94.37s/it, est. speed input: 5.55 toks/s, output: 243.22 toks/s]Processed prompts:  84%|████████▍ | 419/500 [11:02:24<3:05:50, 137.66s/it, est. speed input: 5.53 toks/s, output: 242.59 toks/s]Processed prompts:  84%|████████▍ | 420/500 [11:04:12<2:51:41, 128.77s/it, est. speed input: 5.52 toks/s, output: 242.75 toks/s]Processed prompts:  84%|████████▍ | 421/500 [11:06:57<3:03:34, 139.42s/it, est. speed input: 5.50 toks/s, output: 242.57 toks/s]Processed prompts:  84%|████████▍ | 422/500 [11:08:55<2:52:57, 133.05s/it, est. speed input: 5.49 toks/s, output: 242.38 toks/s]Processed prompts:  85%|████████▍ | 423/500 [11:10:14<2:29:59, 116.87s/it, est. speed input: 5.49 toks/s, output: 242.72 toks/s]Processed prompts:  85%|████████▍ | 424/500 [11:12:49<2:42:27, 128.25s/it, est. speed input: 5.50 toks/s, output: 242.60 toks/s]Processed prompts:  85%|████████▌ | 425/500 [11:13:14<2:01:47, 97.44s/it, est. speed input: 5.51 toks/s, output: 243.26 toks/s] Processed prompts:  85%|████████▌ | 426/500 [11:13:40<1:33:29, 75.80s/it, est. speed input: 5.51 toks/s, output: 243.92 toks/s]WARNING 04-06 01:20:32 scheduler.py:1555] Sequence group 493 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2551
Processed prompts:  85%|████████▌ | 427/500 [11:14:42<1:27:25, 71.85s/it, est. speed input: 5.52 toks/s, output: 244.35 toks/s]WARNING 04-06 01:21:44 scheduler.py:1555] Sequence group 477 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2601
Processed prompts:  86%|████████▌ | 428/500 [11:24:40<4:35:39, 229.71s/it, est. speed input: 5.45 toks/s, output: 241.30 toks/s]Processed prompts:  86%|████████▌ | 429/500 [11:25:37<3:30:27, 177.86s/it, est. speed input: 5.46 toks/s, output: 241.77 toks/s]Processed prompts:  86%|████████▌ | 430/500 [11:27:04<2:55:42, 150.60s/it, est. speed input: 5.48 toks/s, output: 242.05 toks/s]Processed prompts:  86%|████████▌ | 431/500 [11:28:36<2:33:05, 133.12s/it, est. speed input: 5.47 toks/s, output: 241.80 toks/s]Processed prompts:  86%|████████▋ | 432/500 [11:28:37<1:45:52, 93.41s/it, est. speed input: 5.48 toks/s, output: 242.59 toks/s] WARNING 04-06 01:35:40 scheduler.py:1555] Sequence group 447 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2651
Processed prompts:  87%|████████▋ | 433/500 [11:34:01<3:01:37, 162.64s/it, est. speed input: 5.44 toks/s, output: 241.49 toks/s]Processed prompts:  87%|████████▋ | 434/500 [11:35:51<2:41:29, 146.80s/it, est. speed input: 5.44 toks/s, output: 241.50 toks/s]Processed prompts:  87%|████████▋ | 435/500 [11:37:31<2:23:38, 132.59s/it, est. speed input: 5.44 toks/s, output: 241.71 toks/s]Processed prompts:  87%|████████▋ | 436/500 [11:38:06<1:50:19, 103.44s/it, est. speed input: 5.44 toks/s, output: 241.91 toks/s]Processed prompts:  87%|████████▋ | 437/500 [11:42:09<2:32:36, 145.34s/it, est. speed input: 5.42 toks/s, output: 241.29 toks/s]Processed prompts:  88%|████████▊ | 438/500 [11:43:00<2:00:57, 117.06s/it, est. speed input: 5.42 toks/s, output: 241.78 toks/s]Processed prompts:  88%|████████▊ | 439/500 [11:43:38<1:34:40, 93.13s/it, est. speed input: 5.42 toks/s, output: 242.34 toks/s] Processed prompts:  88%|████████▊ | 440/500 [11:44:07<1:13:56, 73.94s/it, est. speed input: 5.43 toks/s, output: 242.95 toks/s]Processed prompts:  88%|████████▊ | 441/500 [11:46:02<1:24:47, 86.22s/it, est. speed input: 5.45 toks/s, output: 243.06 toks/s]Processed prompts:  88%|████████▊ | 442/500 [11:48:14<1:36:50, 100.18s/it, est. speed input: 5.44 toks/s, output: 243.07 toks/s]Processed prompts:  89%|████████▊ | 443/500 [11:50:49<1:50:40, 116.50s/it, est. speed input: 5.43 toks/s, output: 242.46 toks/s]WARNING 04-06 01:57:58 scheduler.py:1555] Sequence group 458 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2701
Processed prompts:  89%|████████▉ | 444/500 [11:54:34<2:19:08, 149.08s/it, est. speed input: 5.41 toks/s, output: 241.95 toks/s]Processed prompts:  89%|████████▉ | 445/500 [11:57:54<2:30:40, 164.37s/it, est. speed input: 5.39 toks/s, output: 241.59 toks/s]Processed prompts:  89%|████████▉ | 446/500 [12:01:03<2:34:32, 171.71s/it, est. speed input: 5.38 toks/s, output: 241.29 toks/s]Processed prompts:  89%|████████▉ | 447/500 [12:03:53<2:31:11, 171.15s/it, est. speed input: 5.36 toks/s, output: 241.11 toks/s]Processed prompts:  90%|████████▉ | 448/500 [12:04:36<1:54:59, 132.68s/it, est. speed input: 5.37 toks/s, output: 241.18 toks/s]Processed prompts:  90%|████████▉ | 449/500 [12:06:52<1:53:40, 133.73s/it, est. speed input: 5.37 toks/s, output: 241.18 toks/s]Processed prompts:  90%|█████████ | 450/500 [12:08:59<1:49:46, 131.73s/it, est. speed input: 5.36 toks/s, output: 241.23 toks/s]Processed prompts:  90%|█████████ | 451/500 [12:10:09<1:32:34, 113.35s/it, est. speed input: 5.36 toks/s, output: 241.59 toks/s]Processed prompts:  90%|█████████ | 452/500 [12:10:10<1:03:42, 79.63s/it, est. speed input: 5.38 toks/s, output: 241.66 toks/s] Processed prompts:  91%|█████████ | 453/500 [12:10:46<52:08, 66.57s/it, est. speed input: 5.38 toks/s, output: 242.21 toks/s]  Processed prompts:  91%|█████████ | 454/500 [12:11:23<44:03, 57.46s/it, est. speed input: 5.39 toks/s, output: 242.02 toks/s]Processed prompts:  91%|█████████ | 455/500 [12:12:24<44:03, 58.73s/it, est. speed input: 5.39 toks/s, output: 242.42 toks/s]Processed prompts:  91%|█████████ | 456/500 [12:13:03<38:37, 52.67s/it, est. speed input: 5.40 toks/s, output: 242.96 toks/s]Processed prompts:  91%|█████████▏| 457/500 [12:13:22<30:31, 42.60s/it, est. speed input: 5.40 toks/s, output: 243.60 toks/s]Processed prompts:  92%|█████████▏| 458/500 [12:13:33<23:08, 33.07s/it, est. speed input: 5.41 toks/s, output: 243.67 toks/s]WARNING 04-06 02:20:51 scheduler.py:1555] Sequence group 493 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2751
Processed prompts:  92%|█████████▏| 459/500 [12:17:36<1:05:39, 96.09s/it, est. speed input: 5.39 toks/s, output: 242.64 toks/s]Processed prompts:  92%|█████████▏| 460/500 [12:23:29<1:55:32, 173.31s/it, est. speed input: 5.35 toks/s, output: 241.45 toks/s]Processed prompts:  92%|█████████▏| 461/500 [12:23:50<1:22:56, 127.60s/it, est. speed input: 5.36 toks/s, output: 242.07 toks/s]Processed prompts:  92%|█████████▏| 462/500 [12:29:15<1:58:10, 186.59s/it, est. speed input: 5.32 toks/s, output: 241.06 toks/s]Processed prompts:  93%|█████████▎| 463/500 [12:33:51<2:11:42, 213.59s/it, est. speed input: 5.31 toks/s, output: 240.31 toks/s]Processed prompts:  93%|█████████▎| 464/500 [12:34:00<1:31:16, 152.14s/it, est. speed input: 5.32 toks/s, output: 240.59 toks/s]WARNING 04-06 02:41:55 scheduler.py:1555] Sequence group 473 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2801
Processed prompts:  93%|█████████▎| 465/500 [12:37:40<1:40:34, 172.42s/it, est. speed input: 5.30 toks/s, output: 240.14 toks/s]Processed prompts:  93%|█████████▎| 466/500 [12:39:15<1:24:33, 149.23s/it, est. speed input: 5.31 toks/s, output: 240.36 toks/s]Processed prompts:  93%|█████████▎| 467/500 [12:40:10<1:06:32, 120.99s/it, est. speed input: 5.31 toks/s, output: 240.79 toks/s]Processed prompts:  94%|█████████▎| 468/500 [12:40:45<50:48, 95.28s/it, est. speed input: 5.31 toks/s, output: 241.32 toks/s]   Processed prompts:  94%|█████████▍| 469/500 [12:41:11<38:28, 74.48s/it, est. speed input: 5.35 toks/s, output: 241.90 toks/s]Processed prompts:  94%|█████████▍| 470/500 [12:41:38<30:09, 60.31s/it, est. speed input: 5.37 toks/s, output: 242.47 toks/s]Processed prompts:  94%|█████████▍| 471/500 [12:42:52<31:03, 64.26s/it, est. speed input: 5.37 toks/s, output: 242.80 toks/s]Processed prompts:  94%|█████████▍| 472/500 [12:44:36<35:35, 76.27s/it, est. speed input: 5.38 toks/s, output: 242.50 toks/s]Processed prompts:  95%|█████████▍| 473/500 [12:48:09<52:48, 117.34s/it, est. speed input: 5.36 toks/s, output: 241.65 toks/s]Processed prompts:  95%|█████████▍| 474/500 [12:48:10<35:39, 82.30s/it, est. speed input: 5.37 toks/s, output: 242.36 toks/s] Processed prompts:  95%|█████████▌| 475/500 [12:52:01<52:51, 126.86s/it, est. speed input: 5.35 toks/s, output: 241.86 toks/s]Processed prompts:  95%|█████████▌| 476/500 [12:52:05<36:04, 90.18s/it, est. speed input: 5.35 toks/s, output: 242.07 toks/s] Processed prompts:  95%|█████████▌| 477/500 [12:52:59<30:19, 79.11s/it, est. speed input: 5.36 toks/s, output: 242.08 toks/s]Processed prompts:  96%|█████████▌| 478/500 [12:54:29<30:16, 82.56s/it, est. speed input: 5.36 toks/s, output: 242.06 toks/s]Processed prompts:  96%|█████████▌| 479/500 [12:57:40<40:17, 115.14s/it, est. speed input: 5.35 toks/s, output: 241.77 toks/s]Processed prompts:  96%|█████████▌| 480/500 [13:02:36<56:23, 169.16s/it, est. speed input: 5.32 toks/s, output: 240.95 toks/s]Processed prompts:  96%|█████████▌| 481/500 [13:04:18<47:16, 149.29s/it, est. speed input: 5.31 toks/s, output: 241.11 toks/s]Processed prompts:  96%|█████████▋| 482/500 [13:04:27<32:04, 106.93s/it, est. speed input: 5.32 toks/s, output: 241.53 toks/s]WARNING 04-06 03:11:06 scheduler.py:1555] Sequence group 494 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2851
Processed prompts:  97%|█████████▋| 483/500 [13:07:03<34:28, 121.66s/it, est. speed input: 5.31 toks/s, output: 241.43 toks/s]Processed prompts:  97%|█████████▋| 484/500 [13:07:19<24:01, 90.06s/it, est. speed input: 5.31 toks/s, output: 241.70 toks/s] Processed prompts:  97%|█████████▋| 485/500 [13:08:21<20:23, 81.58s/it, est. speed input: 5.31 toks/s, output: 242.07 toks/s]Processed prompts:  97%|█████████▋| 486/500 [13:08:38<14:32, 62.32s/it, est. speed input: 5.32 toks/s, output: 242.68 toks/s]Processed prompts:  97%|█████████▋| 487/500 [13:09:01<10:56, 50.53s/it, est. speed input: 5.32 toks/s, output: 243.25 toks/s]Processed prompts:  98%|█████████▊| 488/500 [13:09:38<09:17, 46.50s/it, est. speed input: 5.33 toks/s, output: 243.75 toks/s]Processed prompts:  98%|█████████▊| 489/500 [13:09:54<06:50, 37.27s/it, est. speed input: 5.34 toks/s, output: 244.36 toks/s]Processed prompts:  98%|█████████▊| 490/500 [13:15:01<19:43, 118.35s/it, est. speed input: 5.32 toks/s, output: 243.47 toks/s]Processed prompts:  98%|█████████▊| 491/500 [13:21:30<29:55, 199.50s/it, est. speed input: 5.28 toks/s, output: 242.19 toks/s]Processed prompts:  98%|█████████▊| 492/500 [13:24:39<26:09, 196.24s/it, est. speed input: 5.28 toks/s, output: 241.92 toks/s]Processed prompts:  99%|█████████▊| 493/500 [13:29:53<27:00, 231.53s/it, est. speed input: 5.25 toks/s, output: 241.03 toks/s]Processed prompts:  99%|█████████▉| 494/500 [13:31:30<19:06, 191.14s/it, est. speed input: 5.25 toks/s, output: 241.22 toks/s]Processed prompts:  99%|█████████▉| 495/500 [13:32:27<12:34, 150.88s/it, est. speed input: 5.25 toks/s, output: 241.62 toks/s]Processed prompts:  99%|█████████▉| 496/500 [13:33:06<07:50, 117.53s/it, est. speed input: 5.25 toks/s, output: 242.09 toks/s]Processed prompts:  99%|█████████▉| 497/500 [13:33:41<04:38, 92.76s/it, est. speed input: 5.26 toks/s, output: 242.59 toks/s] Processed prompts: 100%|█████████▉| 498/500 [13:33:58<02:19, 69.93s/it, est. speed input: 5.27 toks/s, output: 243.18 toks/s]Processed prompts: 100%|█████████▉| 499/500 [13:34:18<00:54, 54.94s/it, est. speed input: 5.27 toks/s, output: 243.75 toks/s]Processed prompts: 100%|██████████| 500/500 [13:34:59<00:00, 50.83s/it, est. speed input: 5.29 toks/s, output: 244.21 toks/s]Processed prompts: 100%|██████████| 500/500 [13:34:59<00:00, 97.80s/it, est. speed input: 5.29 toks/s, output: 244.21 toks/s]
INFO 04-06 03:41:23 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2151089)[0;0m INFO 04-06 03:41:23 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2151090)[0;0m INFO 04-06 03:41:23 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2151091)[0;0m INFO 04-06 03:41:23 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W406 03:41:36.698078038 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-06 03:41:51 config.py:510] This model supports multiple tasks: {'score', 'embed', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 04-06 03:41:51 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-06 03:41:51 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-06 03:41:51 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-06 03:41:51 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-06 03:41:52 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-06 03:41:52 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-06 03:41:53 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:41:53 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:41:53 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:41:53 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:41:53 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:41:53 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:41:53 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:41:54 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:41:54 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-06 03:41:54 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:41:54 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:41:54 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-06 03:41:54 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:41:54 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:41:54 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2189753)[0;0m WARNING 04-06 03:41:55 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2189754)[0;0m WARNING 04-06 03:41:55 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2189755)[0;0m WARNING 04-06 03:41:55 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-06 03:41:55 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-06 03:41:55 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_6a172ca9'), local_subscribe_port=56397, remote_subscribe_port=None)
INFO 04-06 03:41:55 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:41:55 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:41:55 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:41:55 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.47it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.69it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.13it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.97it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.91it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.88it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.86it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.84it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.96it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.92it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.90it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.95it/s]

INFO 04-06 03:42:02 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:42:02 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:42:02 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:42:02 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:42:05 worker.py:241] Memory profiling takes 2.64 seconds
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:42:05 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:42:05 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:42:05 worker.py:241] Memory profiling takes 2.65 seconds
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:42:05 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:42:05 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:42:05 worker.py:241] Memory profiling takes 2.71 seconds
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:42:05 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:42:05 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-06 03:42:05 worker.py:241] Memory profiling takes 2.76 seconds
INFO 04-06 03:42:05 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-06 03:42:05 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-06 03:42:05 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-06 03:42:05 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:42:20 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-06 03:42:20 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:42:20 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:42:20 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:11,  1.01s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:13,  1.04s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:11,  1.03s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:09,  1.02s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:08,  1.02s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:06,  1.01s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:05,  1.01s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:03,  1.01s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<02:02,  1.01s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<02:00,  1.00it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:11<02:01,  1.01s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:12<01:59,  1.01s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:13<01:58,  1.01s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:14<01:57,  1.00s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:15<01:56,  1.00s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:16<01:54,  1.00it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:17<01:52,  1.01it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:18<01:50,  1.02it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:18<01:48,  1.03it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:19<01:46,  1.04it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:20<01:45,  1.04it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:21<01:44,  1.04it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:22<01:43,  1.05it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:23<01:41,  1.05it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:24<01:40,  1.06it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:25<01:39,  1.05it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:26<01:38,  1.06it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:27<01:36,  1.06it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:28<01:36,  1.06it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:29<01:34,  1.07it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:30<01:34,  1.06it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:31<01:33,  1.06it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:32<01:31,  1.07it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:33<01:31,  1.06it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:34<01:30,  1.06it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:34<01:27,  1.08it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:35<01:26,  1.09it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:36<01:24,  1.10it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:37<01:22,  1.11it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:38<01:21,  1.12it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:39<01:19,  1.13it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:40<01:18,  1.13it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:41<01:17,  1.13it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:42<01:16,  1.13it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:42<01:15,  1.14it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:43<01:14,  1.15it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:44<01:13,  1.14it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:45<01:12,  1.15it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:46<01:11,  1.15it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:47<01:09,  1.16it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:48<01:09,  1.16it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:48<01:08,  1.16it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:49<01:07,  1.15it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:50<01:06,  1.16it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:51<01:05,  1.16it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:52<01:04,  1.17it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:53<01:03,  1.17it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:54<01:02,  1.16it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:54<01:01,  1.17it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:55<01:00,  1.17it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:56<00:59,  1.17it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:57<00:57,  1.19it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:58<00:56,  1.20it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:59<00:55,  1.20it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:59<00:54,  1.22it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:00<00:52,  1.24it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:01<00:51,  1.24it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:02<00:49,  1.27it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:02<00:48,  1.27it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:03<00:47,  1.28it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:04<00:46,  1.28it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:05<00:45,  1.29it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:06<00:45,  1.27it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:06<00:43,  1.30it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:07<00:42,  1.31it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:08<00:42,  1.29it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:09<00:41,  1.30it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:09<00:40,  1.30it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:10<00:39,  1.30it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:11<00:38,  1.32it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:12<00:37,  1.34it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:12<00:36,  1.33it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:13<00:36,  1.33it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:14<00:35,  1.34it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:15<00:34,  1.35it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:15<00:33,  1.36it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:16<00:31,  1.38it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:17<00:30,  1.40it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:17<00:30,  1.39it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:18<00:29,  1.41it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:19<00:28,  1.41it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:20<00:27,  1.42it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:20<00:26,  1.43it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:21<00:25,  1.42it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:22<00:25,  1.44it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:22<00:24,  1.41it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:23<00:24,  1.41it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:24<00:23,  1.41it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:24<00:22,  1.42it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:25<00:21,  1.43it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:26<00:20,  1.43it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:27<00:19,  1.46it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:27<00:18,  1.48it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:28<00:18,  1.48it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:28<00:17,  1.50it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:29<00:16,  1.47it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:30<00:16,  1.49it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:31<00:15,  1.48it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:31<00:14,  1.50it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:32<00:13,  1.51it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:32<00:13,  1.53it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:33<00:12,  1.51it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:34<00:11,  1.51it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:34<00:11,  1.53it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:35<00:10,  1.56it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:36<00:09,  1.55it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:36<00:09,  1.53it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:37<00:08,  1.55it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:38<00:07,  1.58it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:38<00:07,  1.55it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:39<00:06,  1.56it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:40<00:05,  1.55it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:40<00:05,  1.57it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:41<00:04,  1.59it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:41<00:03,  1.57it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:42<00:03,  1.59it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:43<00:02,  1.62it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:43<00:01,  1.63it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:44<00:01,  1.66it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:44<00:00,  1.65it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:45<00:00,  1.45it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:45<00:00,  1.24it/s]
INFO 04-06 03:44:05 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 03:44:05 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 03:44:05 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 03:44:05 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
INFO 04-06 03:44:05 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 122.97 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: triangle
Generating answers for task: triangle
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-06 03:45:31 scheduler.py:1555] Sequence group 499 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-06 03:45:42 scheduler.py:1555] Sequence group 449 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-06 03:45:55 scheduler.py:1555] Sequence group 399 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
WARNING 04-06 03:46:10 scheduler.py:1555] Sequence group 349 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
WARNING 04-06 03:46:27 scheduler.py:1555] Sequence group 299 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
WARNING 04-06 03:46:51 scheduler.py:1555] Sequence group 249 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
WARNING 04-06 03:47:20 scheduler.py:1555] Sequence group 199 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:   0%|          | 1/500 [03:15<27:07:45, 195.72s/it, est. speed input: 1.27 toks/s, output: 5.23 toks/s]Processed prompts:   0%|          | 2/500 [03:40<13:11:41, 95.38s/it, est. speed input: 2.25 toks/s, output: 10.20 toks/s]Processed prompts:   1%|          | 3/500 [03:45<7:26:11, 53.87s/it, est. speed input: 3.31 toks/s, output: 15.69 toks/s] Processed prompts:   1%|          | 4/500 [03:46<4:34:00, 33.15s/it, est. speed input: 4.38 toks/s, output: 21.31 toks/s]Processed prompts:   1%|          | 5/500 [03:53<3:15:30, 23.70s/it, est. speed input: 5.32 toks/s, output: 26.48 toks/s]WARNING 04-06 03:48:09 scheduler.py:1555] Sequence group 149 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:   1%|          | 6/500 [04:07<2:46:12, 20.19s/it, est. speed input: 6.03 toks/s, output: 31.07 toks/s]Processed prompts:   1%|▏         | 7/500 [04:11<2:02:38, 14.93s/it, est. speed input: 6.92 toks/s, output: 36.66 toks/s]Processed prompts:   2%|▏         | 8/500 [04:14<1:31:52, 11.20s/it, est. speed input: 7.81 toks/s, output: 42.31 toks/s]Processed prompts:   2%|▏         | 9/500 [04:17<1:09:58,  8.55s/it, est. speed input: 8.70 toks/s, output: 48.02 toks/s]Processed prompts:   2%|▏         | 10/500 [04:21<59:18,  7.26s/it, est. speed input: 9.50 toks/s, output: 53.42 toks/s] Processed prompts:   2%|▏         | 11/500 [04:24<48:00,  5.89s/it, est. speed input: 10.34 toks/s, output: 59.13 toks/s]Processed prompts:   2%|▏         | 12/500 [04:26<38:12,  4.70s/it, est. speed input: 11.20 toks/s, output: 64.98 toks/s]Processed prompts:   3%|▎         | 13/500 [04:29<35:22,  4.36s/it, est. speed input: 11.98 toks/s, output: 70.50 toks/s]Processed prompts:   3%|▎         | 14/500 [04:30<26:49,  3.31s/it, est. speed input: 12.85 toks/s, output: 76.68 toks/s]Processed prompts:   3%|▎         | 15/500 [04:33<26:26,  3.27s/it, est. speed input: 13.61 toks/s, output: 82.24 toks/s]Processed prompts:   3%|▎         | 17/500 [04:35<16:50,  2.09s/it, est. speed input: 15.34 toks/s, output: 94.69 toks/s]Processed prompts:   4%|▎         | 18/500 [04:37<17:33,  2.19s/it, est. speed input: 16.10 toks/s, output: 100.37 toks/s]Processed prompts:   4%|▍         | 19/500 [04:41<20:18,  2.53s/it, est. speed input: 16.78 toks/s, output: 105.67 toks/s]Processed prompts:   4%|▍         | 20/500 [04:43<20:39,  2.58s/it, est. speed input: 17.49 toks/s, output: 111.29 toks/s]Processed prompts:   4%|▍         | 21/500 [04:49<27:09,  3.40s/it, est. speed input: 18.01 toks/s, output: 115.87 toks/s]Processed prompts:   4%|▍         | 22/500 [04:50<21:31,  2.70s/it, est. speed input: 18.81 toks/s, output: 122.25 toks/s]Processed prompts:   5%|▍         | 23/500 [04:53<21:11,  2.66s/it, est. speed input: 19.49 toks/s, output: 127.96 toks/s]Processed prompts:   5%|▍         | 24/500 [04:55<21:07,  2.66s/it, est. speed input: 20.16 toks/s, output: 133.62 toks/s]Processed prompts:   5%|▌         | 25/500 [04:57<19:01,  2.40s/it, est. speed input: 20.87 toks/s, output: 139.67 toks/s]Processed prompts:   5%|▌         | 26/500 [05:00<20:53,  2.65s/it, est. speed input: 21.47 toks/s, output: 145.08 toks/s]Processed prompts:   5%|▌         | 27/500 [05:02<19:14,  2.44s/it, est. speed input: 22.15 toks/s, output: 151.07 toks/s]Processed prompts:   6%|▌         | 28/500 [05:03<15:15,  1.94s/it, est. speed input: 22.92 toks/s, output: 157.63 toks/s]Processed prompts:   6%|▌         | 30/500 [05:06<13:38,  1.74s/it, est. speed input: 24.32 toks/s, output: 169.95 toks/s]Processed prompts:   6%|▌         | 31/500 [05:07<12:22,  1.58s/it, est. speed input: 25.04 toks/s, output: 176.34 toks/s]Processed prompts:   6%|▋         | 32/500 [05:11<16:24,  2.10s/it, est. speed input: 25.55 toks/s, output: 181.38 toks/s]Processed prompts:   7%|▋         | 33/500 [05:14<20:05,  2.58s/it, est. speed input: 26.03 toks/s, output: 186.29 toks/s]Processed prompts:   7%|▋         | 34/500 [05:15<16:16,  2.10s/it, est. speed input: 26.74 toks/s, output: 192.91 toks/s]Processed prompts:   7%|▋         | 35/500 [05:15<12:01,  1.55s/it, est. speed input: 27.51 toks/s, output: 199.93 toks/s]Processed prompts:   7%|▋         | 36/500 [05:17<10:50,  1.40s/it, est. speed input: 28.20 toks/s, output: 206.42 toks/s]Processed prompts:   7%|▋         | 37/500 [05:23<21:35,  2.80s/it, est. speed input: 28.43 toks/s, output: 209.72 toks/s]Processed prompts:   8%|▊         | 38/500 [05:32<35:28,  4.61s/it, est. speed input: 28.41 toks/s, output: 211.42 toks/s]Processed prompts:   8%|▊         | 40/500 [05:33<20:43,  2.70s/it, est. speed input: 29.83 toks/s, output: 225.52 toks/s]Processed prompts:   8%|▊         | 41/500 [05:41<31:55,  4.17s/it, est. speed input: 29.80 toks/s, output: 227.27 toks/s]Processed prompts:   8%|▊         | 42/500 [05:41<23:52,  3.13s/it, est. speed input: 30.51 toks/s, output: 234.62 toks/s]Processed prompts:   9%|▊         | 43/500 [05:48<31:07,  4.09s/it, est. speed input: 30.64 toks/s, output: 237.71 toks/s]Processed prompts:   9%|▉         | 45/500 [05:49<19:05,  2.52s/it, est. speed input: 32.21 toks/s, output: 252.16 toks/s]Processed prompts:   9%|▉         | 46/500 [05:56<27:10,  3.59s/it, est. speed input: 32.27 toks/s, output: 254.86 toks/s]Processed prompts:   9%|▉         | 47/500 [05:58<23:16,  3.08s/it, est. speed input: 32.82 toks/s, output: 261.43 toks/s]Processed prompts:  10%|▉         | 48/500 [06:02<25:02,  3.32s/it, est. speed input: 33.15 toks/s, output: 266.29 toks/s]Processed prompts:  10%|▉         | 49/500 [06:04<23:30,  3.13s/it, est. speed input: 33.59 toks/s, output: 272.17 toks/s]Processed prompts:  10%|█         | 51/500 [06:06<15:52,  2.12s/it, est. speed input: 34.86 toks/s, output: 286.45 toks/s]Processed prompts:  10%|█         | 52/500 [06:07<14:06,  1.89s/it, est. speed input: 35.53 toks/s, output: 293.37 toks/s]Processed prompts:  11%|█         | 53/500 [06:12<20:18,  2.73s/it, est. speed input: 35.89 toks/s, output: 297.20 toks/s]Processed prompts:  11%|█         | 54/500 [06:15<20:09,  2.71s/it, est. speed input: 36.30 toks/s, output: 302.66 toks/s]Processed prompts:  11%|█         | 55/500 [06:16<16:47,  2.26s/it, est. speed input: 36.86 toks/s, output: 309.72 toks/s]Processed prompts:  11%|█         | 56/500 [06:18<16:57,  2.29s/it, est. speed input: 37.28 toks/s, output: 315.76 toks/s]Processed prompts:  11%|█▏        | 57/500 [06:21<17:24,  2.36s/it, est. speed input: 37.69 toks/s, output: 321.68 toks/s]Processed prompts:  12%|█▏        | 59/500 [06:22<11:26,  1.56s/it, est. speed input: 38.87 toks/s, output: 336.68 toks/s]Processed prompts:  12%|█▏        | 60/500 [06:26<16:06,  2.20s/it, est. speed input: 39.10 toks/s, output: 341.10 toks/s]Processed prompts:  12%|█▏        | 61/500 [06:26<12:22,  1.69s/it, est. speed input: 39.71 toks/s, output: 348.97 toks/s]Processed prompts:  12%|█▏        | 62/500 [06:28<12:11,  1.67s/it, est. speed input: 40.19 toks/s, output: 355.58 toks/s]Processed prompts:  13%|█▎        | 63/500 [06:29<09:50,  1.35s/it, est. speed input: 40.77 toks/s, output: 363.20 toks/s]Processed prompts:  13%|█▎        | 64/500 [06:29<07:37,  1.05s/it, est. speed input: 41.38 toks/s, output: 371.03 toks/s]Processed prompts:  13%|█▎        | 65/500 [06:29<06:15,  1.16it/s, est. speed input: 41.98 toks/s, output: 378.73 toks/s]Processed prompts:  13%|█▎        | 66/500 [06:36<18:56,  2.62s/it, est. speed input: 41.88 toks/s, output: 380.32 toks/s]Processed prompts:  13%|█▎        | 67/500 [06:37<15:39,  2.17s/it, est. speed input: 42.39 toks/s, output: 387.45 toks/s]Processed prompts:  14%|█▎        | 68/500 [06:38<12:32,  1.74s/it, est. speed input: 42.99 toks/s, output: 394.92 toks/s]Processed prompts:  14%|█▍        | 69/500 [06:40<12:05,  1.68s/it, est. speed input: 43.45 toks/s, output: 401.59 toks/s]Processed prompts:  14%|█▍        | 70/500 [06:46<21:54,  3.06s/it, est. speed input: 43.38 toks/s, output: 402.38 toks/s]Processed prompts:  14%|█▍        | 71/500 [06:48<20:54,  2.92s/it, est. speed input: 43.71 toks/s, output: 408.10 toks/s]Processed prompts:  14%|█▍        | 72/500 [06:54<25:46,  3.61s/it, est. speed input: 43.76 toks/s, output: 411.32 toks/s]Processed prompts:  15%|█▍        | 73/500 [06:54<18:55,  2.66s/it, est. speed input: 44.37 toks/s, output: 419.25 toks/s]Processed prompts:  15%|█▍        | 74/500 [06:58<21:59,  3.10s/it, est. speed input: 44.67 toks/s, output: 423.52 toks/s]Processed prompts:  15%|█▌        | 75/500 [06:59<16:03,  2.27s/it, est. speed input: 45.23 toks/s, output: 431.60 toks/s]Processed prompts:  15%|█▌        | 76/500 [07:00<13:24,  1.90s/it, est. speed input: 45.83 toks/s, output: 437.36 toks/s]Processed prompts:  15%|█▌        | 77/500 [07:03<16:57,  2.40s/it, est. speed input: 46.02 toks/s, output: 442.09 toks/s]Processed prompts:  16%|█▌        | 78/500 [07:16<38:39,  5.50s/it, est. speed input: 45.25 toks/s, output: 437.78 toks/s]WARNING 04-06 03:51:27 scheduler.py:1555] Sequence group 139 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  16%|█▌        | 79/500 [07:29<54:27,  7.76s/it, est. speed input: 44.49 toks/s, output: 433.77 toks/s]Processed prompts:  16%|█▌        | 80/500 [07:31<41:50,  5.98s/it, est. speed input: 44.90 toks/s, output: 440.73 toks/s]Processed prompts:  16%|█▌        | 81/500 [07:32<32:12,  4.61s/it, est. speed input: 45.33 toks/s, output: 445.47 toks/s]Processed prompts:  16%|█▋        | 82/500 [07:37<32:26,  4.66s/it, est. speed input: 45.43 toks/s, output: 449.60 toks/s]Processed prompts:  17%|█▋        | 83/500 [07:38<24:38,  3.55s/it, est. speed input: 45.87 toks/s, output: 457.44 toks/s]Processed prompts:  17%|█▋        | 84/500 [07:40<20:41,  2.98s/it, est. speed input: 46.25 toks/s, output: 460.77 toks/s]Processed prompts:  17%|█▋        | 85/500 [07:40<15:56,  2.30s/it, est. speed input: 46.77 toks/s, output: 468.85 toks/s]Processed prompts:  17%|█▋        | 86/500 [07:42<13:55,  2.02s/it, est. speed input: 47.19 toks/s, output: 473.41 toks/s]Processed prompts:  17%|█▋        | 87/500 [07:43<12:33,  1.82s/it, est. speed input: 47.59 toks/s, output: 475.86 toks/s]Processed prompts:  18%|█▊        | 88/500 [07:46<15:32,  2.26s/it, est. speed input: 47.79 toks/s, output: 481.33 toks/s]Processed prompts:  18%|█▊        | 89/500 [07:47<13:00,  1.90s/it, est. speed input: 48.21 toks/s, output: 486.33 toks/s]Processed prompts:  18%|█▊        | 90/500 [07:54<23:24,  3.43s/it, est. speed input: 48.03 toks/s, output: 488.07 toks/s]Processed prompts:  18%|█▊        | 91/500 [07:55<18:39,  2.74s/it, est. speed input: 48.57 toks/s, output: 495.83 toks/s]Processed prompts:  18%|█▊        | 92/500 [07:56<14:14,  2.09s/it, est. speed input: 49.03 toks/s, output: 504.13 toks/s]Processed prompts:  19%|█▊        | 93/500 [08:01<19:24,  2.86s/it, est. speed input: 49.07 toks/s, output: 508.21 toks/s]Processed prompts:  19%|█▉        | 94/500 [08:12<37:21,  5.52s/it, est. speed input: 48.46 toks/s, output: 505.17 toks/s]Processed prompts:  19%|█▉        | 95/500 [08:14<30:03,  4.45s/it, est. speed input: 48.82 toks/s, output: 512.22 toks/s]Processed prompts:  19%|█▉        | 96/500 [08:17<25:36,  3.80s/it, est. speed input: 49.09 toks/s, output: 518.93 toks/s]Processed prompts:  19%|█▉        | 97/500 [08:21<27:07,  4.04s/it, est. speed input: 49.19 toks/s, output: 523.29 toks/s]Processed prompts:  20%|█▉        | 98/500 [08:28<33:06,  4.94s/it, est. speed input: 49.09 toks/s, output: 525.20 toks/s]Processed prompts:  20%|█▉        | 99/500 [08:29<23:32,  3.52s/it, est. speed input: 49.71 toks/s, output: 534.13 toks/s]Processed prompts:  20%|██        | 100/500 [08:39<37:55,  5.69s/it, est. speed input: 49.20 toks/s, output: 529.23 toks/s]Processed prompts:  20%|██        | 101/500 [08:43<33:39,  5.06s/it, est. speed input: 49.49 toks/s, output: 534.86 toks/s]Processed prompts:  20%|██        | 102/500 [08:45<27:04,  4.08s/it, est. speed input: 49.82 toks/s, output: 542.30 toks/s]Processed prompts:  21%|██        | 103/500 [08:50<29:05,  4.40s/it, est. speed input: 49.81 toks/s, output: 546.35 toks/s]Processed prompts:  21%|██        | 104/500 [08:52<23:58,  3.63s/it, est. speed input: 50.15 toks/s, output: 553.76 toks/s]Processed prompts:  21%|██        | 105/500 [08:53<19:27,  2.96s/it, est. speed input: 50.63 toks/s, output: 561.65 toks/s]Processed prompts:  21%|██        | 106/500 [08:55<17:08,  2.61s/it, est. speed input: 50.98 toks/s, output: 569.09 toks/s]Processed prompts:  21%|██▏       | 107/500 [08:59<19:48,  3.02s/it, est. speed input: 51.11 toks/s, output: 574.23 toks/s]Processed prompts:  22%|██▏       | 108/500 [09:05<25:18,  3.87s/it, est. speed input: 51.02 toks/s, output: 572.82 toks/s]Processed prompts:  22%|██▏       | 109/500 [09:19<45:10,  6.93s/it, est. speed input: 50.25 toks/s, output: 567.89 toks/s]Processed prompts:  22%|██▏       | 110/500 [09:26<46:38,  7.18s/it, est. speed input: 50.00 toks/s, output: 564.10 toks/s]Processed prompts:  22%|██▏       | 111/500 [09:29<37:45,  5.82s/it, est. speed input: 50.20 toks/s, output: 570.97 toks/s]Processed prompts:  22%|██▏       | 112/500 [09:38<43:11,  6.68s/it, est. speed input: 49.88 toks/s, output: 567.44 toks/s]Processed prompts:  23%|██▎       | 113/500 [09:44<42:21,  6.57s/it, est. speed input: 49.77 toks/s, output: 570.93 toks/s]Processed prompts:  23%|██▎       | 114/500 [09:44<30:07,  4.68s/it, est. speed input: 50.24 toks/s, output: 580.26 toks/s]Processed prompts:  23%|██▎       | 115/500 [09:51<32:57,  5.14s/it, est. speed input: 50.13 toks/s, output: 579.29 toks/s]Processed prompts:  23%|██▎       | 116/500 [09:58<36:18,  5.67s/it, est. speed input: 49.97 toks/s, output: 579.00 toks/s]Processed prompts:  23%|██▎       | 117/500 [10:14<56:19,  8.82s/it, est. speed input: 49.13 toks/s, output: 573.53 toks/s]Processed prompts:  24%|██▎       | 118/500 [10:15<41:07,  6.46s/it, est. speed input: 49.56 toks/s, output: 582.44 toks/s]Processed prompts:  24%|██▍       | 119/500 [10:18<35:47,  5.64s/it, est. speed input: 49.70 toks/s, output: 588.74 toks/s]Processed prompts:  24%|██▍       | 120/500 [10:23<33:27,  5.28s/it, est. speed input: 49.81 toks/s, output: 594.36 toks/s]Processed prompts:  24%|██▍       | 121/500 [10:24<24:47,  3.92s/it, est. speed input: 50.15 toks/s, output: 599.55 toks/s]Processed prompts:  24%|██▍       | 122/500 [10:25<20:28,  3.25s/it, est. speed input: 50.41 toks/s, output: 599.82 toks/s]Processed prompts:  25%|██▍       | 123/500 [10:40<41:44,  6.64s/it, est. speed input: 49.65 toks/s, output: 593.81 toks/s]Processed prompts:  25%|██▍       | 124/500 [10:45<38:54,  6.21s/it, est. speed input: 49.66 toks/s, output: 597.57 toks/s]Processed prompts:  25%|██▌       | 125/500 [10:46<29:41,  4.75s/it, est. speed input: 49.98 toks/s, output: 604.04 toks/s]Processed prompts:  25%|██▌       | 126/500 [10:48<24:14,  3.89s/it, est. speed input: 50.22 toks/s, output: 612.24 toks/s]Processed prompts:  25%|██▌       | 127/500 [10:59<37:55,  6.10s/it, est. speed input: 49.74 toks/s, output: 610.13 toks/s]Processed prompts:  26%|██▌       | 128/500 [11:11<47:45,  7.70s/it, est. speed input: 49.35 toks/s, output: 607.48 toks/s]Processed prompts:  26%|██▌       | 129/500 [11:16<42:34,  6.89s/it, est. speed input: 49.35 toks/s, output: 608.06 toks/s]Processed prompts:  26%|██▌       | 130/500 [11:19<34:29,  5.59s/it, est. speed input: 49.53 toks/s, output: 611.80 toks/s]Processed prompts:  26%|██▌       | 131/500 [11:24<34:57,  5.68s/it, est. speed input: 49.47 toks/s, output: 614.85 toks/s]WARNING 04-06 03:55:37 scheduler.py:1555] Sequence group 181 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  26%|██▋       | 132/500 [11:32<37:30,  6.12s/it, est. speed input: 49.35 toks/s, output: 618.66 toks/s]Processed prompts:  27%|██▋       | 133/500 [11:43<47:03,  7.69s/it, est. speed input: 48.91 toks/s, output: 613.63 toks/s]Processed prompts:  27%|██▋       | 134/500 [11:58<1:00:28,  9.91s/it, est. speed input: 48.29 toks/s, output: 607.08 toks/s]Processed prompts:  27%|██▋       | 135/500 [12:00<46:06,  7.58s/it, est. speed input: 48.53 toks/s, output: 615.57 toks/s]  Processed prompts:  27%|██▋       | 136/500 [12:03<36:46,  6.06s/it, est. speed input: 48.79 toks/s, output: 623.72 toks/s]Processed prompts:  27%|██▋       | 137/500 [12:10<39:08,  6.47s/it, est. speed input: 48.64 toks/s, output: 624.15 toks/s]Processed prompts:  28%|██▊       | 138/500 [12:13<32:11,  5.34s/it, est. speed input: 48.83 toks/s, output: 627.99 toks/s]Processed prompts:  28%|██▊       | 139/500 [12:16<28:52,  4.80s/it, est. speed input: 49.00 toks/s, output: 628.92 toks/s]Processed prompts:  28%|██▊       | 140/500 [12:22<31:12,  5.20s/it, est. speed input: 49.04 toks/s, output: 634.09 toks/s]Processed prompts:  28%|██▊       | 141/500 [12:23<23:13,  3.88s/it, est. speed input: 49.44 toks/s, output: 643.77 toks/s]Processed prompts:  28%|██▊       | 142/500 [12:27<22:08,  3.71s/it, est. speed input: 49.55 toks/s, output: 648.39 toks/s]Processed prompts:  29%|██▊       | 143/500 [12:33<27:01,  4.54s/it, est. speed input: 49.54 toks/s, output: 648.56 toks/s]Processed prompts:  29%|██▉       | 144/500 [12:46<41:53,  7.06s/it, est. speed input: 49.03 toks/s, output: 644.19 toks/s]Processed prompts:  29%|██▉       | 145/500 [12:51<37:59,  6.42s/it, est. speed input: 49.04 toks/s, output: 646.74 toks/s]Processed prompts:  29%|██▉       | 146/500 [13:03<47:22,  8.03s/it, est. speed input: 48.65 toks/s, output: 647.48 toks/s]Processed prompts:  29%|██▉       | 147/500 [13:04<35:23,  6.02s/it, est. speed input: 48.95 toks/s, output: 656.87 toks/s]Processed prompts:  30%|██▉       | 148/500 [13:11<36:37,  6.24s/it, est. speed input: 48.84 toks/s, output: 656.96 toks/s]Processed prompts:  30%|██▉       | 149/500 [13:12<27:26,  4.69s/it, est. speed input: 49.15 toks/s, output: 666.57 toks/s]Processed prompts:  30%|███       | 150/500 [13:41<1:09:41, 11.95s/it, est. speed input: 47.83 toks/s, output: 653.69 toks/s]Processed prompts:  30%|███       | 151/500 [13:43<51:52,  8.92s/it, est. speed input: 48.08 toks/s, output: 659.89 toks/s]  Processed prompts:  30%|███       | 152/500 [13:45<40:00,  6.90s/it, est. speed input: 48.34 toks/s, output: 668.73 toks/s]Processed prompts:  31%|███       | 153/500 [13:46<29:48,  5.15s/it, est. speed input: 48.57 toks/s, output: 672.08 toks/s]Processed prompts:  31%|███       | 154/500 [13:47<22:58,  3.98s/it, est. speed input: 48.83 toks/s, output: 675.37 toks/s]Processed prompts:  31%|███       | 155/500 [14:02<41:15,  7.18s/it, est. speed input: 48.31 toks/s, output: 666.51 toks/s]WARNING 04-06 03:58:13 scheduler.py:1555] Sequence group 212 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  31%|███       | 156/500 [14:10<43:18,  7.55s/it, est. speed input: 48.12 toks/s, output: 666.27 toks/s]Processed prompts:  31%|███▏      | 157/500 [14:18<43:34,  7.62s/it, est. speed input: 47.99 toks/s, output: 667.56 toks/s]Processed prompts:  32%|███▏      | 158/500 [14:21<36:04,  6.33s/it, est. speed input: 48.09 toks/s, output: 671.50 toks/s]Processed prompts:  32%|███▏      | 159/500 [14:22<27:11,  4.78s/it, est. speed input: 48.41 toks/s, output: 681.24 toks/s]Processed prompts:  32%|███▏      | 160/500 [14:32<35:10,  6.21s/it, est. speed input: 48.25 toks/s, output: 680.75 toks/s]Processed prompts:  32%|███▏      | 161/500 [14:33<26:54,  4.76s/it, est. speed input: 48.49 toks/s, output: 690.33 toks/s]Processed prompts:  32%|███▏      | 162/500 [14:49<44:43,  7.94s/it, est. speed input: 47.93 toks/s, output: 681.93 toks/s]Processed prompts:  33%|███▎      | 163/500 [14:56<43:40,  7.78s/it, est. speed input: 47.81 toks/s, output: 682.89 toks/s]Processed prompts:  33%|███▎      | 164/500 [15:07<48:03,  8.58s/it, est. speed input: 47.61 toks/s, output: 685.74 toks/s]Processed prompts:  33%|███▎      | 165/500 [15:09<36:59,  6.63s/it, est. speed input: 47.82 toks/s, output: 691.14 toks/s]Processed prompts:  33%|███▎      | 166/500 [15:10<27:53,  5.01s/it, est. speed input: 48.10 toks/s, output: 695.45 toks/s]Processed prompts:  33%|███▎      | 167/500 [15:17<30:32,  5.50s/it, est. speed input: 48.04 toks/s, output: 695.88 toks/s]Processed prompts:  34%|███▎      | 168/500 [15:25<35:40,  6.45s/it, est. speed input: 47.92 toks/s, output: 699.77 toks/s]Processed prompts:  34%|███▍      | 169/500 [15:58<1:19:15, 14.37s/it, est. speed input: 46.59 toks/s, output: 686.61 toks/s]Processed prompts:  34%|███▍      | 170/500 [16:08<1:11:45, 13.05s/it, est. speed input: 46.45 toks/s, output: 690.38 toks/s]Processed prompts:  34%|███▍      | 171/500 [16:09<51:00,  9.30s/it, est. speed input: 46.68 toks/s, output: 692.45 toks/s]  WARNING 04-06 04:00:22 scheduler.py:1555] Sequence group 228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  34%|███▍      | 172/500 [16:16<47:27,  8.68s/it, est. speed input: 46.64 toks/s, output: 691.31 toks/s]Processed prompts:  35%|███▍      | 173/500 [16:26<49:52,  9.15s/it, est. speed input: 46.40 toks/s, output: 688.25 toks/s]Processed prompts:  35%|███▍      | 174/500 [16:29<38:59,  7.18s/it, est. speed input: 46.58 toks/s, output: 691.94 toks/s]Processed prompts:  35%|███▌      | 175/500 [16:31<30:34,  5.65s/it, est. speed input: 46.74 toks/s, output: 696.97 toks/s]Processed prompts:  35%|███▌      | 176/500 [16:31<22:22,  4.14s/it, est. speed input: 46.96 toks/s, output: 703.36 toks/s]Processed prompts:  35%|███▌      | 177/500 [16:44<36:18,  6.75s/it, est. speed input: 46.60 toks/s, output: 701.60 toks/s]Processed prompts:  36%|███▌      | 178/500 [16:52<38:28,  7.17s/it, est. speed input: 46.48 toks/s, output: 701.24 toks/s]Processed prompts:  36%|███▌      | 179/500 [16:58<35:58,  6.72s/it, est. speed input: 46.46 toks/s, output: 702.07 toks/s]Processed prompts:  36%|███▌      | 180/500 [17:01<30:11,  5.66s/it, est. speed input: 46.56 toks/s, output: 705.83 toks/s]Processed prompts:  36%|███▌      | 181/500 [17:24<57:24, 10.80s/it, est. speed input: 45.85 toks/s, output: 701.40 toks/s]Processed prompts:  36%|███▋      | 182/500 [17:32<52:18,  9.87s/it, est. speed input: 45.81 toks/s, output: 699.98 toks/s]Processed prompts:  37%|███▋      | 183/500 [17:39<47:43,  9.03s/it, est. speed input: 45.74 toks/s, output: 701.45 toks/s]Processed prompts:  37%|███▋      | 184/500 [17:40<34:42,  6.59s/it, est. speed input: 45.95 toks/s, output: 703.04 toks/s]Processed prompts:  37%|███▋      | 185/500 [17:44<30:46,  5.86s/it, est. speed input: 46.02 toks/s, output: 702.28 toks/s]Processed prompts:  37%|███▋      | 186/500 [17:48<27:34,  5.27s/it, est. speed input: 46.15 toks/s, output: 704.73 toks/s]Processed prompts:  37%|███▋      | 187/500 [17:52<26:24,  5.06s/it, est. speed input: 46.18 toks/s, output: 706.18 toks/s]Processed prompts:  38%|███▊      | 188/500 [17:54<20:34,  3.96s/it, est. speed input: 46.36 toks/s, output: 707.70 toks/s]Processed prompts:  38%|███▊      | 189/500 [18:08<37:14,  7.18s/it, est. speed input: 45.98 toks/s, output: 704.99 toks/s]Processed prompts:  38%|███▊      | 190/500 [18:09<27:11,  5.26s/it, est. speed input: 46.24 toks/s, output: 715.52 toks/s]Processed prompts:  38%|███▊      | 191/500 [18:13<25:07,  4.88s/it, est. speed input: 46.34 toks/s, output: 718.91 toks/s]Processed prompts:  38%|███▊      | 192/500 [18:23<33:01,  6.43s/it, est. speed input: 46.14 toks/s, output: 717.35 toks/s]WARNING 04-06 04:02:41 scheduler.py:1555] Sequence group 252 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  39%|███▊      | 193/500 [18:38<46:17,  9.05s/it, est. speed input: 45.74 toks/s, output: 712.07 toks/s]Processed prompts:  39%|███▉      | 194/500 [18:58<1:02:34, 12.27s/it, est. speed input: 45.17 toks/s, output: 704.89 toks/s]Processed prompts:  39%|███▉      | 195/500 [19:04<52:16, 10.28s/it, est. speed input: 45.16 toks/s, output: 705.87 toks/s]  Processed prompts:  39%|███▉      | 196/500 [19:05<38:58,  7.69s/it, est. speed input: 45.31 toks/s, output: 709.06 toks/s]Processed prompts:  39%|███▉      | 197/500 [19:06<28:03,  5.56s/it, est. speed input: 45.52 toks/s, output: 710.53 toks/s]Processed prompts:  40%|███▉      | 198/500 [19:09<23:41,  4.71s/it, est. speed input: 45.67 toks/s, output: 709.94 toks/s]Processed prompts:  40%|███▉      | 199/500 [19:23<37:29,  7.47s/it, est. speed input: 45.39 toks/s, output: 705.93 toks/s]Processed prompts:  40%|████      | 200/500 [19:24<28:52,  5.78s/it, est. speed input: 45.56 toks/s, output: 709.52 toks/s]Processed prompts:  40%|████      | 201/500 [19:28<25:57,  5.21s/it, est. speed input: 45.62 toks/s, output: 711.30 toks/s]Processed prompts:  40%|████      | 202/500 [19:29<18:35,  3.74s/it, est. speed input: 45.86 toks/s, output: 718.64 toks/s]Processed prompts:  41%|████      | 203/500 [19:38<27:27,  5.55s/it, est. speed input: 45.69 toks/s, output: 718.19 toks/s]Processed prompts:  41%|████      | 204/500 [19:39<20:26,  4.14s/it, est. speed input: 45.87 toks/s, output: 723.66 toks/s]Processed prompts:  41%|████      | 205/500 [19:48<26:41,  5.43s/it, est. speed input: 45.76 toks/s, output: 722.82 toks/s]Processed prompts:  41%|████      | 206/500 [19:51<23:33,  4.81s/it, est. speed input: 45.83 toks/s, output: 726.61 toks/s]Processed prompts:  41%|████▏     | 207/500 [20:07<39:24,  8.07s/it, est. speed input: 45.44 toks/s, output: 721.98 toks/s]Processed prompts:  42%|████▏     | 208/500 [20:07<28:37,  5.88s/it, est. speed input: 45.62 toks/s, output: 723.68 toks/s]Processed prompts:  42%|████▏     | 209/500 [20:16<32:55,  6.79s/it, est. speed input: 45.55 toks/s, output: 724.75 toks/s]Processed prompts:  42%|████▏     | 210/500 [20:18<24:36,  5.09s/it, est. speed input: 45.75 toks/s, output: 725.19 toks/s]Processed prompts:  42%|████▏     | 211/500 [20:33<38:50,  8.07s/it, est. speed input: 45.42 toks/s, output: 720.87 toks/s]Processed prompts:  42%|████▏     | 212/500 [20:35<30:25,  6.34s/it, est. speed input: 45.53 toks/s, output: 724.23 toks/s]Processed prompts:  43%|████▎     | 213/500 [20:40<28:45,  6.01s/it, est. speed input: 45.54 toks/s, output: 726.10 toks/s]Processed prompts:  43%|████▎     | 214/500 [20:40<20:29,  4.30s/it, est. speed input: 45.73 toks/s, output: 731.75 toks/s]WARNING 04-06 04:04:54 scheduler.py:1555] Sequence group 278 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  43%|████▎     | 215/500 [20:49<26:51,  5.65s/it, est. speed input: 45.60 toks/s, output: 729.23 toks/s]Processed prompts:  43%|████▎     | 216/500 [20:51<21:24,  4.52s/it, est. speed input: 45.73 toks/s, output: 730.59 toks/s]Processed prompts:  43%|████▎     | 217/500 [20:52<16:48,  3.56s/it, est. speed input: 45.91 toks/s, output: 735.51 toks/s]Processed prompts:  44%|████▎     | 218/500 [20:53<13:09,  2.80s/it, est. speed input: 46.07 toks/s, output: 740.82 toks/s]Processed prompts:  44%|████▍     | 219/500 [20:55<11:43,  2.50s/it, est. speed input: 46.21 toks/s, output: 745.10 toks/s]Processed prompts:  44%|████▍     | 220/500 [21:06<22:40,  4.86s/it, est. speed input: 46.08 toks/s, output: 740.94 toks/s]Processed prompts:  44%|████▍     | 221/500 [21:11<23:49,  5.12s/it, est. speed input: 46.11 toks/s, output: 738.41 toks/s]Processed prompts:  44%|████▍     | 222/500 [21:16<22:44,  4.91s/it, est. speed input: 46.15 toks/s, output: 742.18 toks/s]Processed prompts:  45%|████▍     | 223/500 [21:33<39:26,  8.54s/it, est. speed input: 45.76 toks/s, output: 734.96 toks/s]Processed prompts:  45%|████▍     | 224/500 [21:39<36:02,  7.84s/it, est. speed input: 45.74 toks/s, output: 735.68 toks/s]Processed prompts:  45%|████▌     | 225/500 [21:46<34:33,  7.54s/it, est. speed input: 45.70 toks/s, output: 733.86 toks/s]Processed prompts:  45%|████▌     | 226/500 [21:46<24:57,  5.47s/it, est. speed input: 45.86 toks/s, output: 737.50 toks/s]Processed prompts:  45%|████▌     | 227/500 [21:49<20:26,  4.49s/it, est. speed input: 45.97 toks/s, output: 738.66 toks/s]Processed prompts:  46%|████▌     | 228/500 [21:58<26:44,  5.90s/it, est. speed input: 45.84 toks/s, output: 738.56 toks/s]Processed prompts:  46%|████▌     | 229/500 [22:02<24:55,  5.52s/it, est. speed input: 45.87 toks/s, output: 738.07 toks/s]Processed prompts:  46%|████▌     | 230/500 [22:03<18:20,  4.07s/it, est. speed input: 46.03 toks/s, output: 738.92 toks/s]Processed prompts:  46%|████▌     | 231/500 [22:09<20:50,  4.65s/it, est. speed input: 46.07 toks/s, output: 737.01 toks/s]Processed prompts:  46%|████▋     | 232/500 [22:12<17:52,  4.00s/it, est. speed input: 46.17 toks/s, output: 737.55 toks/s]Processed prompts:  47%|████▋     | 233/500 [22:15<17:09,  3.85s/it, est. speed input: 46.25 toks/s, output: 736.97 toks/s]Processed prompts:  47%|████▋     | 234/500 [22:18<15:22,  3.47s/it, est. speed input: 46.34 toks/s, output: 736.99 toks/s]Processed prompts:  47%|████▋     | 235/500 [22:20<13:30,  3.06s/it, est. speed input: 46.47 toks/s, output: 737.76 toks/s]Processed prompts:  47%|████▋     | 236/500 [22:24<14:53,  3.38s/it, est. speed input: 46.52 toks/s, output: 736.87 toks/s]Processed prompts:  47%|████▋     | 237/500 [22:28<15:58,  3.64s/it, est. speed input: 46.55 toks/s, output: 737.59 toks/s]Processed prompts:  48%|████▊     | 238/500 [22:31<15:23,  3.53s/it, est. speed input: 46.64 toks/s, output: 741.02 toks/s]Processed prompts:  48%|████▊     | 239/500 [22:44<27:40,  6.36s/it, est. speed input: 46.38 toks/s, output: 736.45 toks/s]Processed prompts:  48%|████▊     | 240/500 [22:52<29:06,  6.72s/it, est. speed input: 46.34 toks/s, output: 738.30 toks/s]Processed prompts:  48%|████▊     | 241/500 [22:53<21:41,  5.03s/it, est. speed input: 46.48 toks/s, output: 739.14 toks/s]Processed prompts:  48%|████▊     | 242/500 [22:57<19:38,  4.57s/it, est. speed input: 46.54 toks/s, output: 743.69 toks/s]Processed prompts:  49%|████▊     | 243/500 [23:02<21:14,  4.96s/it, est. speed input: 46.56 toks/s, output: 743.20 toks/s]Processed prompts:  49%|████▉     | 244/500 [23:05<18:38,  4.37s/it, est. speed input: 46.67 toks/s, output: 743.20 toks/s]Processed prompts:  49%|████▉     | 245/500 [23:07<15:10,  3.57s/it, est. speed input: 46.79 toks/s, output: 745.68 toks/s]WARNING 04-06 04:07:20 scheduler.py:1555] Sequence group 304 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  49%|████▉     | 246/500 [23:20<26:41,  6.31s/it, est. speed input: 46.54 toks/s, output: 742.28 toks/s]Processed prompts:  49%|████▉     | 247/500 [23:25<25:38,  6.08s/it, est. speed input: 46.54 toks/s, output: 741.55 toks/s]Processed prompts:  50%|████▉     | 248/500 [23:29<22:21,  5.32s/it, est. speed input: 46.59 toks/s, output: 741.50 toks/s]Processed prompts:  50%|████▉     | 249/500 [23:29<16:04,  3.84s/it, est. speed input: 46.76 toks/s, output: 743.89 toks/s]Processed prompts:  50%|█████     | 250/500 [23:37<21:14,  5.10s/it, est. speed input: 46.69 toks/s, output: 741.61 toks/s]Processed prompts:  50%|█████     | 251/500 [23:48<28:37,  6.90s/it, est. speed input: 46.50 toks/s, output: 738.48 toks/s]Processed prompts:  50%|█████     | 252/500 [24:02<37:14,  9.01s/it, est. speed input: 46.27 toks/s, output: 733.49 toks/s]Processed prompts:  51%|█████     | 253/500 [24:15<41:00,  9.96s/it, est. speed input: 46.08 toks/s, output: 729.61 toks/s]Processed prompts:  51%|█████     | 254/500 [24:16<30:50,  7.52s/it, est. speed input: 46.20 toks/s, output: 731.58 toks/s]Processed prompts:  51%|█████     | 255/500 [24:18<23:52,  5.84s/it, est. speed input: 46.31 toks/s, output: 735.40 toks/s]Processed prompts:  51%|█████     | 256/500 [24:25<24:50,  6.11s/it, est. speed input: 46.26 toks/s, output: 734.46 toks/s]Processed prompts:  51%|█████▏    | 257/500 [24:34<27:56,  6.90s/it, est. speed input: 46.16 toks/s, output: 734.66 toks/s]Processed prompts:  52%|█████▏    | 258/500 [24:37<23:33,  5.84s/it, est. speed input: 46.22 toks/s, output: 735.20 toks/s]Processed prompts:  52%|█████▏    | 259/500 [24:48<29:29,  7.34s/it, est. speed input: 46.10 toks/s, output: 732.32 toks/s]Processed prompts:  52%|█████▏    | 260/500 [24:58<31:57,  7.99s/it, est. speed input: 45.99 toks/s, output: 734.84 toks/s]Processed prompts:  52%|█████▏    | 261/500 [25:04<29:54,  7.51s/it, est. speed input: 45.96 toks/s, output: 734.33 toks/s]Processed prompts:  52%|█████▏    | 262/500 [25:05<22:43,  5.73s/it, est. speed input: 46.08 toks/s, output: 740.57 toks/s]Processed prompts:  53%|█████▎    | 263/500 [25:12<23:01,  5.83s/it, est. speed input: 46.07 toks/s, output: 741.19 toks/s]Processed prompts:  53%|█████▎    | 264/500 [25:12<16:46,  4.26s/it, est. speed input: 46.23 toks/s, output: 747.63 toks/s]Processed prompts:  53%|█████▎    | 265/500 [25:22<22:59,  5.87s/it, est. speed input: 46.10 toks/s, output: 749.72 toks/s]Processed prompts:  53%|█████▎    | 266/500 [25:24<18:32,  4.76s/it, est. speed input: 46.23 toks/s, output: 753.36 toks/s]Processed prompts:  53%|█████▎    | 267/500 [25:27<16:20,  4.21s/it, est. speed input: 46.30 toks/s, output: 752.40 toks/s]Processed prompts:  54%|█████▎    | 268/500 [25:28<12:30,  3.23s/it, est. speed input: 46.45 toks/s, output: 755.80 toks/s]Processed prompts:  54%|█████▍    | 269/500 [25:30<10:43,  2.79s/it, est. speed input: 46.56 toks/s, output: 757.77 toks/s]WARNING 04-06 04:09:52 scheduler.py:1555] Sequence group 346 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  54%|█████▍    | 270/500 [25:45<25:25,  6.63s/it, est. speed input: 46.25 toks/s, output: 754.26 toks/s]Processed prompts:  54%|█████▍    | 271/500 [25:49<21:52,  5.73s/it, est. speed input: 46.32 toks/s, output: 754.18 toks/s]Processed prompts:  54%|█████▍    | 272/500 [25:53<20:35,  5.42s/it, est. speed input: 46.37 toks/s, output: 754.75 toks/s]Processed prompts:  55%|█████▍    | 273/500 [25:56<16:46,  4.44s/it, est. speed input: 46.48 toks/s, output: 754.35 toks/s]Processed prompts:  55%|█████▍    | 274/500 [26:00<16:07,  4.28s/it, est. speed input: 46.52 toks/s, output: 753.38 toks/s]Processed prompts:  55%|█████▌    | 275/500 [26:01<12:23,  3.31s/it, est. speed input: 46.66 toks/s, output: 754.96 toks/s]Processed prompts:  55%|█████▌    | 276/500 [26:07<16:19,  4.37s/it, est. speed input: 46.62 toks/s, output: 753.54 toks/s]Processed prompts:  55%|█████▌    | 277/500 [26:34<40:35, 10.92s/it, est. speed input: 46.01 toks/s, output: 742.05 toks/s]Processed prompts:  56%|█████▌    | 278/500 [26:34<28:27,  7.69s/it, est. speed input: 46.20 toks/s, output: 745.54 toks/s]Processed prompts:  56%|█████▌    | 279/500 [26:44<30:36,  8.31s/it, est. speed input: 46.07 toks/s, output: 741.93 toks/s]Processed prompts:  56%|█████▌    | 280/500 [26:49<27:14,  7.43s/it, est. speed input: 46.07 toks/s, output: 740.53 toks/s]Processed prompts:  56%|█████▌    | 281/500 [26:49<19:14,  5.27s/it, est. speed input: 46.22 toks/s, output: 743.87 toks/s]Processed prompts:  56%|█████▋    | 282/500 [26:54<18:46,  5.17s/it, est. speed input: 46.23 toks/s, output: 742.71 toks/s]Processed prompts:  57%|█████▋    | 283/500 [26:59<17:56,  4.96s/it, est. speed input: 46.30 toks/s, output: 741.74 toks/s]Processed prompts:  57%|█████▋    | 284/500 [27:01<15:34,  4.32s/it, est. speed input: 46.38 toks/s, output: 746.82 toks/s]Processed prompts:  57%|█████▋    | 285/500 [27:08<17:44,  4.95s/it, est. speed input: 46.34 toks/s, output: 746.47 toks/s]Processed prompts:  57%|█████▋    | 286/500 [27:08<12:33,  3.52s/it, est. speed input: 46.49 toks/s, output: 747.59 toks/s]Processed prompts:  57%|█████▋    | 287/500 [27:08<09:00,  2.54s/it, est. speed input: 46.65 toks/s, output: 752.84 toks/s]Processed prompts:  58%|█████▊    | 288/500 [27:13<11:32,  3.27s/it, est. speed input: 46.66 toks/s, output: 751.78 toks/s]Processed prompts:  58%|█████▊    | 289/500 [27:14<08:42,  2.48s/it, est. speed input: 46.81 toks/s, output: 757.86 toks/s]Processed prompts:  58%|█████▊    | 291/500 [27:21<10:11,  2.93s/it, est. speed input: 46.91 toks/s, output: 761.89 toks/s]Processed prompts:  58%|█████▊    | 292/500 [27:24<10:02,  2.90s/it, est. speed input: 47.02 toks/s, output: 764.57 toks/s]Processed prompts:  59%|█████▊    | 293/500 [27:25<08:43,  2.53s/it, est. speed input: 47.13 toks/s, output: 764.44 toks/s]Processed prompts:  59%|█████▉    | 294/500 [27:26<07:35,  2.21s/it, est. speed input: 47.29 toks/s, output: 765.05 toks/s]Processed prompts:  59%|█████▉    | 295/500 [27:35<13:49,  4.04s/it, est. speed input: 47.19 toks/s, output: 761.85 toks/s]Processed prompts:  59%|█████▉    | 296/500 [27:38<12:37,  3.71s/it, est. speed input: 47.26 toks/s, output: 763.75 toks/s]Processed prompts:  59%|█████▉    | 297/500 [27:38<09:04,  2.68s/it, est. speed input: 47.40 toks/s, output: 764.91 toks/s]WARNING 04-06 04:11:51 scheduler.py:1555] Sequence group 378 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  60%|█████▉    | 298/500 [27:44<12:05,  3.59s/it, est. speed input: 47.39 toks/s, output: 763.42 toks/s]Processed prompts:  60%|█████▉    | 299/500 [27:56<20:38,  6.16s/it, est. speed input: 47.19 toks/s, output: 758.37 toks/s]Processed prompts:  60%|██████    | 300/500 [27:59<16:48,  5.04s/it, est. speed input: 47.27 toks/s, output: 763.59 toks/s]Processed prompts:  60%|██████    | 301/500 [28:06<18:44,  5.65s/it, est. speed input: 47.26 toks/s, output: 761.92 toks/s]Processed prompts:  60%|██████    | 302/500 [28:11<18:10,  5.51s/it, est. speed input: 47.27 toks/s, output: 764.30 toks/s]Processed prompts:  61%|██████    | 303/500 [28:18<20:02,  6.10s/it, est. speed input: 47.21 toks/s, output: 761.65 toks/s]Processed prompts:  61%|██████    | 304/500 [28:22<17:43,  5.43s/it, est. speed input: 47.25 toks/s, output: 761.03 toks/s]Processed prompts:  61%|██████    | 306/500 [28:32<16:24,  5.07s/it, est. speed input: 47.28 toks/s, output: 760.07 toks/s]Processed prompts:  61%|██████▏   | 307/500 [28:36<15:22,  4.78s/it, est. speed input: 47.33 toks/s, output: 764.08 toks/s]Processed prompts:  62%|██████▏   | 308/500 [28:44<18:33,  5.80s/it, est. speed input: 47.25 toks/s, output: 761.11 toks/s]Processed prompts:  62%|██████▏   | 309/500 [28:47<15:47,  4.96s/it, est. speed input: 47.32 toks/s, output: 761.75 toks/s]Processed prompts:  62%|██████▏   | 310/500 [28:49<13:05,  4.13s/it, est. speed input: 47.41 toks/s, output: 762.59 toks/s]Processed prompts:  62%|██████▏   | 311/500 [28:54<13:48,  4.39s/it, est. speed input: 47.41 toks/s, output: 761.69 toks/s]Processed prompts:  62%|██████▏   | 312/500 [28:55<10:20,  3.30s/it, est. speed input: 47.54 toks/s, output: 762.70 toks/s]Processed prompts:  63%|██████▎   | 313/500 [28:59<11:17,  3.62s/it, est. speed input: 47.56 toks/s, output: 762.61 toks/s]Processed prompts:  63%|██████▎   | 314/500 [29:02<10:52,  3.51s/it, est. speed input: 47.62 toks/s, output: 763.06 toks/s]Processed prompts:  63%|██████▎   | 315/500 [29:08<12:31,  4.06s/it, est. speed input: 47.63 toks/s, output: 762.53 toks/s]Processed prompts:  63%|██████▎   | 316/500 [29:14<14:22,  4.69s/it, est. speed input: 47.64 toks/s, output: 762.91 toks/s]Processed prompts:  63%|██████▎   | 317/500 [29:26<20:46,  6.81s/it, est. speed input: 47.48 toks/s, output: 764.29 toks/s]Processed prompts:  64%|██████▎   | 318/500 [29:40<27:11,  8.96s/it, est. speed input: 47.24 toks/s, output: 759.50 toks/s]Processed prompts:  64%|██████▍   | 319/500 [29:40<19:39,  6.51s/it, est. speed input: 47.36 toks/s, output: 761.21 toks/s]Processed prompts:  64%|██████▍   | 320/500 [29:46<19:04,  6.36s/it, est. speed input: 47.37 toks/s, output: 760.73 toks/s]WARNING 04-06 04:14:00 scheduler.py:1555] Sequence group 373 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  64%|██████▍   | 321/500 [30:00<25:04,  8.40s/it, est. speed input: 47.19 toks/s, output: 758.65 toks/s]Processed prompts:  64%|██████▍   | 322/500 [30:04<21:40,  7.30s/it, est. speed input: 47.23 toks/s, output: 758.34 toks/s]Processed prompts:  65%|██████▍   | 323/500 [30:08<18:04,  6.13s/it, est. speed input: 47.29 toks/s, output: 758.06 toks/s]Processed prompts:  65%|██████▍   | 324/500 [30:11<15:24,  5.25s/it, est. speed input: 47.35 toks/s, output: 758.14 toks/s]Processed prompts:  65%|██████▌   | 325/500 [30:11<11:05,  3.81s/it, est. speed input: 47.47 toks/s, output: 759.31 toks/s]Processed prompts:  65%|██████▌   | 326/500 [30:19<14:10,  4.89s/it, est. speed input: 47.42 toks/s, output: 757.73 toks/s]Processed prompts:  65%|██████▌   | 327/500 [30:21<12:01,  4.17s/it, est. speed input: 47.49 toks/s, output: 758.97 toks/s]Processed prompts:  66%|██████▌   | 328/500 [30:29<15:24,  5.38s/it, est. speed input: 47.42 toks/s, output: 757.91 toks/s]Processed prompts:  66%|██████▌   | 329/500 [30:33<14:07,  4.95s/it, est. speed input: 47.48 toks/s, output: 758.78 toks/s]Processed prompts:  66%|██████▌   | 330/500 [30:34<10:26,  3.69s/it, est. speed input: 47.60 toks/s, output: 762.18 toks/s]Processed prompts:  66%|██████▌   | 331/500 [30:36<08:59,  3.19s/it, est. speed input: 47.68 toks/s, output: 763.24 toks/s]Processed prompts:  66%|██████▋   | 332/500 [30:40<09:07,  3.26s/it, est. speed input: 47.73 toks/s, output: 766.78 toks/s]Processed prompts:  67%|██████▋   | 333/500 [30:42<08:19,  2.99s/it, est. speed input: 47.80 toks/s, output: 770.44 toks/s]Processed prompts:  67%|██████▋   | 334/500 [31:02<22:41,  8.20s/it, est. speed input: 47.43 toks/s, output: 764.18 toks/s]Processed prompts:  67%|██████▋   | 335/500 [31:09<21:32,  7.83s/it, est. speed input: 47.39 toks/s, output: 763.03 toks/s]Processed prompts:  67%|██████▋   | 336/500 [31:17<21:25,  7.84s/it, est. speed input: 47.32 toks/s, output: 761.65 toks/s]Processed prompts:  67%|██████▋   | 337/500 [31:19<16:19,  6.01s/it, est. speed input: 47.42 toks/s, output: 761.70 toks/s]Processed prompts:  68%|██████▊   | 338/500 [31:21<13:04,  4.84s/it, est. speed input: 47.50 toks/s, output: 762.13 toks/s]Processed prompts:  68%|██████▊   | 339/500 [31:23<10:58,  4.09s/it, est. speed input: 47.59 toks/s, output: 763.33 toks/s]Processed prompts:  68%|██████▊   | 340/500 [31:31<13:49,  5.19s/it, est. speed input: 47.52 toks/s, output: 765.32 toks/s]Processed prompts:  68%|██████▊   | 341/500 [31:31<09:52,  3.73s/it, est. speed input: 47.65 toks/s, output: 765.73 toks/s]Processed prompts:  68%|██████▊   | 342/500 [31:39<12:49,  4.87s/it, est. speed input: 47.60 toks/s, output: 763.33 toks/s]WARNING 04-06 04:15:57 scheduler.py:1555] Sequence group 395 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  69%|██████▊   | 343/500 [31:49<17:01,  6.51s/it, est. speed input: 47.48 toks/s, output: 761.40 toks/s]Processed prompts:  69%|██████▉   | 344/500 [31:55<16:35,  6.38s/it, est. speed input: 47.47 toks/s, output: 759.69 toks/s]Processed prompts:  69%|██████▉   | 345/500 [31:58<13:52,  5.37s/it, est. speed input: 47.55 toks/s, output: 759.29 toks/s]Processed prompts:  69%|██████▉   | 346/500 [31:59<10:03,  3.92s/it, est. speed input: 47.68 toks/s, output: 763.32 toks/s]Processed prompts:  69%|██████▉   | 347/500 [32:17<20:52,  8.18s/it, est. speed input: 47.36 toks/s, output: 757.04 toks/s]Processed prompts:  70%|██████▉   | 348/500 [32:20<16:30,  6.52s/it, est. speed input: 47.47 toks/s, output: 758.09 toks/s]Processed prompts:  70%|██████▉   | 349/500 [32:23<14:14,  5.66s/it, est. speed input: 47.51 toks/s, output: 757.56 toks/s]Processed prompts:  70%|███████   | 350/500 [32:25<11:18,  4.52s/it, est. speed input: 47.60 toks/s, output: 759.40 toks/s]Processed prompts:  70%|███████   | 351/500 [32:30<11:15,  4.53s/it, est. speed input: 47.64 toks/s, output: 760.54 toks/s]Processed prompts:  70%|███████   | 352/500 [32:32<09:36,  3.89s/it, est. speed input: 47.71 toks/s, output: 762.08 toks/s]Processed prompts:  71%|███████   | 353/500 [32:37<09:58,  4.07s/it, est. speed input: 47.74 toks/s, output: 763.39 toks/s]Processed prompts:  71%|███████   | 354/500 [32:37<07:25,  3.05s/it, est. speed input: 47.85 toks/s, output: 765.42 toks/s]Processed prompts:  71%|███████   | 355/500 [32:39<06:28,  2.68s/it, est. speed input: 47.93 toks/s, output: 765.53 toks/s]Processed prompts:  71%|███████   | 356/500 [32:45<08:46,  3.66s/it, est. speed input: 47.92 toks/s, output: 766.23 toks/s]Processed prompts:  71%|███████▏  | 357/500 [32:46<06:50,  2.87s/it, est. speed input: 48.05 toks/s, output: 766.84 toks/s]Processed prompts:  72%|███████▏  | 358/500 [32:47<05:05,  2.15s/it, est. speed input: 48.17 toks/s, output: 767.67 toks/s]Processed prompts:  72%|███████▏  | 359/500 [32:48<04:28,  1.91s/it, est. speed input: 48.27 toks/s, output: 772.51 toks/s]Processed prompts:  72%|███████▏  | 360/500 [32:48<03:29,  1.50s/it, est. speed input: 48.39 toks/s, output: 773.31 toks/s]Processed prompts:  72%|███████▏  | 361/500 [32:52<04:57,  2.14s/it, est. speed input: 48.42 toks/s, output: 774.14 toks/s]Processed prompts:  72%|███████▏  | 362/500 [32:54<05:04,  2.21s/it, est. speed input: 48.49 toks/s, output: 775.45 toks/s]Processed prompts:  73%|███████▎  | 363/500 [33:10<14:31,  6.36s/it, est. speed input: 48.23 toks/s, output: 771.97 toks/s]Processed prompts:  73%|███████▎  | 364/500 [33:16<14:09,  6.25s/it, est. speed input: 48.21 toks/s, output: 770.47 toks/s]Processed prompts:  73%|███████▎  | 365/500 [33:30<19:04,  8.48s/it, est. speed input: 48.00 toks/s, output: 768.64 toks/s]Processed prompts:  73%|███████▎  | 366/500 [33:33<15:30,  6.94s/it, est. speed input: 48.09 toks/s, output: 769.68 toks/s]WARNING 04-06 04:17:45 scheduler.py:1555] Sequence group 441 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  73%|███████▎  | 367/500 [33:52<23:15, 10.49s/it, est. speed input: 47.80 toks/s, output: 763.28 toks/s]Processed prompts:  74%|███████▎  | 368/500 [33:54<17:12,  7.82s/it, est. speed input: 47.88 toks/s, output: 763.55 toks/s]Processed prompts:  74%|███████▍  | 369/500 [34:06<19:40,  9.01s/it, est. speed input: 47.73 toks/s, output: 763.22 toks/s]Processed prompts:  74%|███████▍  | 370/500 [34:07<14:37,  6.75s/it, est. speed input: 47.81 toks/s, output: 764.03 toks/s]Processed prompts:  74%|███████▍  | 371/500 [34:10<12:16,  5.71s/it, est. speed input: 47.89 toks/s, output: 766.17 toks/s]Processed prompts:  74%|███████▍  | 372/500 [34:22<15:44,  7.38s/it, est. speed input: 47.74 toks/s, output: 762.65 toks/s]Processed prompts:  75%|███████▍  | 373/500 [34:23<11:40,  5.52s/it, est. speed input: 47.85 toks/s, output: 762.98 toks/s]Processed prompts:  75%|███████▍  | 374/500 [34:24<09:02,  4.31s/it, est. speed input: 47.93 toks/s, output: 765.11 toks/s]Processed prompts:  75%|███████▌  | 375/500 [34:28<08:19,  4.00s/it, est. speed input: 48.00 toks/s, output: 767.34 toks/s]Processed prompts:  75%|███████▌  | 376/500 [34:34<09:39,  4.67s/it, est. speed input: 47.97 toks/s, output: 765.71 toks/s]Processed prompts:  75%|███████▌  | 377/500 [34:35<07:17,  3.55s/it, est. speed input: 48.07 toks/s, output: 766.96 toks/s]Processed prompts:  76%|███████▌  | 378/500 [34:36<05:37,  2.76s/it, est. speed input: 48.17 toks/s, output: 767.55 toks/s]Processed prompts:  76%|███████▌  | 379/500 [34:40<06:30,  3.23s/it, est. speed input: 48.20 toks/s, output: 766.84 toks/s]Processed prompts:  76%|███████▌  | 380/500 [34:45<07:17,  3.65s/it, est. speed input: 48.22 toks/s, output: 766.34 toks/s]Processed prompts:  76%|███████▌  | 381/500 [34:49<07:39,  3.86s/it, est. speed input: 48.25 toks/s, output: 765.52 toks/s]Processed prompts:  76%|███████▋  | 382/500 [34:52<07:02,  3.58s/it, est. speed input: 48.30 toks/s, output: 768.42 toks/s]Processed prompts:  77%|███████▋  | 383/500 [34:57<07:55,  4.07s/it, est. speed input: 48.30 toks/s, output: 770.40 toks/s]Processed prompts:  77%|███████▋  | 384/500 [35:20<18:40,  9.66s/it, est. speed input: 47.90 toks/s, output: 763.34 toks/s]Processed prompts:  77%|███████▋  | 385/500 [35:23<14:41,  7.67s/it, est. speed input: 47.96 toks/s, output: 765.87 toks/s]Processed prompts:  77%|███████▋  | 386/500 [35:29<13:29,  7.10s/it, est. speed input: 47.99 toks/s, output: 764.82 toks/s]Processed prompts:  77%|███████▋  | 387/500 [35:32<11:12,  5.95s/it, est. speed input: 48.03 toks/s, output: 764.79 toks/s]Processed prompts:  78%|███████▊  | 388/500 [35:39<11:43,  6.28s/it, est. speed input: 47.99 toks/s, output: 764.23 toks/s]Processed prompts:  78%|███████▊  | 389/500 [35:49<13:36,  7.35s/it, est. speed input: 47.92 toks/s, output: 761.98 toks/s]Processed prompts:  78%|███████▊  | 390/500 [35:56<13:11,  7.20s/it, est. speed input: 47.88 toks/s, output: 760.63 toks/s]Processed prompts:  78%|███████▊  | 391/500 [35:57<09:54,  5.45s/it, est. speed input: 47.98 toks/s, output: 761.10 toks/s]WARNING 04-06 04:20:12 scheduler.py:1555] Sequence group 433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  78%|███████▊  | 392/500 [36:06<11:44,  6.53s/it, est. speed input: 47.92 toks/s, output: 759.27 toks/s]Processed prompts:  79%|███████▊  | 393/500 [36:08<09:10,  5.14s/it, est. speed input: 48.00 toks/s, output: 759.84 toks/s]Processed prompts:  79%|███████▉  | 394/500 [36:38<22:13, 12.58s/it, est. speed input: 47.46 toks/s, output: 751.03 toks/s]Processed prompts:  79%|███████▉  | 395/500 [36:38<15:35,  8.91s/it, est. speed input: 47.58 toks/s, output: 752.58 toks/s]Processed prompts:  79%|███████▉  | 396/500 [36:51<17:39, 10.18s/it, est. speed input: 47.41 toks/s, output: 749.72 toks/s]Processed prompts:  79%|███████▉  | 397/500 [36:57<15:16,  8.90s/it, est. speed input: 47.40 toks/s, output: 750.02 toks/s]Processed prompts:  80%|███████▉  | 398/500 [36:58<10:45,  6.33s/it, est. speed input: 47.51 toks/s, output: 751.25 toks/s]Processed prompts:  80%|███████▉  | 399/500 [37:05<11:04,  6.58s/it, est. speed input: 47.47 toks/s, output: 750.54 toks/s]Processed prompts:  80%|████████  | 400/500 [37:07<09:00,  5.41s/it, est. speed input: 47.52 toks/s, output: 751.53 toks/s]Processed prompts:  80%|████████  | 401/500 [37:27<15:54,  9.65s/it, est. speed input: 47.25 toks/s, output: 747.58 toks/s]Processed prompts:  80%|████████  | 402/500 [37:35<15:03,  9.22s/it, est. speed input: 47.19 toks/s, output: 746.63 toks/s]Processed prompts:  81%|████████  | 403/500 [37:39<12:07,  7.50s/it, est. speed input: 47.23 toks/s, output: 747.38 toks/s]Processed prompts:  81%|████████  | 404/500 [37:40<09:06,  5.70s/it, est. speed input: 47.31 toks/s, output: 749.42 toks/s]Processed prompts:  81%|████████  | 405/500 [37:44<07:59,  5.04s/it, est. speed input: 47.34 toks/s, output: 750.75 toks/s]Processed prompts:  81%|████████  | 406/500 [37:53<09:54,  6.32s/it, est. speed input: 47.26 toks/s, output: 749.56 toks/s]Processed prompts:  81%|████████▏ | 407/500 [38:03<11:33,  7.46s/it, est. speed input: 47.17 toks/s, output: 748.21 toks/s]Processed prompts:  82%|████████▏ | 408/500 [38:07<09:50,  6.42s/it, est. speed input: 47.19 toks/s, output: 748.92 toks/s]Processed prompts:  82%|████████▏ | 409/500 [38:12<09:14,  6.09s/it, est. speed input: 47.20 toks/s, output: 750.99 toks/s]Processed prompts:  82%|████████▏ | 410/500 [38:15<07:25,  4.95s/it, est. speed input: 47.26 toks/s, output: 751.77 toks/s]Processed prompts:  82%|████████▏ | 411/500 [38:16<05:53,  3.97s/it, est. speed input: 47.34 toks/s, output: 753.37 toks/s]Processed prompts:  82%|████████▏ | 412/500 [38:19<05:10,  3.53s/it, est. speed input: 47.42 toks/s, output: 756.80 toks/s]Processed prompts:  83%|████████▎ | 413/500 [38:29<08:02,  5.55s/it, est. speed input: 47.34 toks/s, output: 755.50 toks/s]Processed prompts:  83%|████████▎ | 414/500 [38:34<07:33,  5.27s/it, est. speed input: 47.37 toks/s, output: 757.81 toks/s]Processed prompts:  83%|████████▎ | 415/500 [38:42<08:36,  6.08s/it, est. speed input: 47.31 toks/s, output: 755.46 toks/s]Processed prompts:  83%|████████▎ | 416/500 [38:45<07:14,  5.18s/it, est. speed input: 47.36 toks/s, output: 755.15 toks/s]Processed prompts:  84%|████████▎ | 418/500 [38:47<04:28,  3.28s/it, est. speed input: 47.56 toks/s, output: 757.74 toks/s]Processed prompts:  84%|████████▍ | 419/500 [39:03<08:41,  6.44s/it, est. speed input: 47.34 toks/s, output: 754.79 toks/s]Processed prompts:  84%|████████▍ | 421/500 [39:09<06:39,  5.06s/it, est. speed input: 47.43 toks/s, output: 757.22 toks/s]Processed prompts:  84%|████████▍ | 422/500 [39:11<05:35,  4.30s/it, est. speed input: 47.50 toks/s, output: 759.38 toks/s]WARNING 04-06 04:23:23 scheduler.py:1555] Sequence group 497 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  85%|████████▍ | 423/500 [39:20<06:59,  5.45s/it, est. speed input: 47.46 toks/s, output: 758.72 toks/s]Processed prompts:  85%|████████▍ | 424/500 [39:26<07:02,  5.57s/it, est. speed input: 47.44 toks/s, output: 757.21 toks/s]Processed prompts:  85%|████████▌ | 425/500 [39:28<05:57,  4.77s/it, est. speed input: 47.49 toks/s, output: 759.79 toks/s]Processed prompts:  85%|████████▌ | 426/500 [39:33<05:38,  4.57s/it, est. speed input: 47.53 toks/s, output: 758.87 toks/s]Processed prompts:  85%|████████▌ | 427/500 [39:38<05:42,  4.69s/it, est. speed input: 47.53 toks/s, output: 757.81 toks/s]Processed prompts:  86%|████████▌ | 428/500 [39:42<05:38,  4.71s/it, est. speed input: 47.54 toks/s, output: 756.81 toks/s]Processed prompts:  86%|████████▌ | 429/500 [39:43<04:07,  3.49s/it, est. speed input: 47.63 toks/s, output: 757.93 toks/s]Processed prompts:  86%|████████▌ | 430/500 [39:45<03:45,  3.22s/it, est. speed input: 47.71 toks/s, output: 757.58 toks/s]Processed prompts:  86%|████████▌ | 431/500 [39:50<04:07,  3.59s/it, est. speed input: 47.73 toks/s, output: 756.77 toks/s]Processed prompts:  86%|████████▋ | 432/500 [39:54<04:08,  3.66s/it, est. speed input: 47.75 toks/s, output: 759.58 toks/s]Processed prompts:  87%|████████▋ | 433/500 [39:56<03:40,  3.30s/it, est. speed input: 47.81 toks/s, output: 760.57 toks/s]Processed prompts:  87%|████████▋ | 434/500 [39:59<03:34,  3.24s/it, est. speed input: 47.86 toks/s, output: 760.05 toks/s]Processed prompts:  87%|████████▋ | 435/500 [40:06<04:40,  4.32s/it, est. speed input: 47.82 toks/s, output: 758.50 toks/s]Processed prompts:  87%|████████▋ | 436/500 [40:12<05:02,  4.73s/it, est. speed input: 47.83 toks/s, output: 758.42 toks/s]Processed prompts:  87%|████████▋ | 437/500 [40:17<05:16,  5.02s/it, est. speed input: 47.84 toks/s, output: 757.56 toks/s]Processed prompts:  88%|████████▊ | 438/500 [40:19<03:57,  3.83s/it, est. speed input: 47.93 toks/s, output: 757.91 toks/s]Processed prompts:  88%|████████▊ | 439/500 [40:30<06:07,  6.03s/it, est. speed input: 47.82 toks/s, output: 757.59 toks/s]Processed prompts:  88%|████████▊ | 440/500 [40:37<06:25,  6.42s/it, est. speed input: 47.80 toks/s, output: 756.06 toks/s]Processed prompts:  88%|████████▊ | 441/500 [40:50<08:20,  8.48s/it, est. speed input: 47.64 toks/s, output: 752.78 toks/s]Processed prompts:  88%|████████▊ | 442/500 [41:12<11:55, 12.34s/it, est. speed input: 47.33 toks/s, output: 747.50 toks/s]Processed prompts:  89%|████████▊ | 443/500 [41:12<08:19,  8.77s/it, est. speed input: 47.42 toks/s, output: 751.67 toks/s]Processed prompts:  89%|████████▉ | 444/500 [41:16<06:42,  7.18s/it, est. speed input: 47.46 toks/s, output: 751.28 toks/s]Processed prompts:  89%|████████▉ | 445/500 [41:18<05:22,  5.86s/it, est. speed input: 47.51 toks/s, output: 751.49 toks/s]Processed prompts:  89%|████████▉ | 446/500 [41:25<05:32,  6.15s/it, est. speed input: 47.49 toks/s, output: 750.21 toks/s]Processed prompts:  89%|████████▉ | 447/500 [41:28<04:27,  5.05s/it, est. speed input: 47.55 toks/s, output: 750.42 toks/s]Processed prompts:  90%|████████▉ | 448/500 [41:31<04:01,  4.65s/it, est. speed input: 47.58 toks/s, output: 753.84 toks/s]Processed prompts:  90%|████████▉ | 449/500 [41:45<06:15,  7.37s/it, est. speed input: 47.42 toks/s, output: 751.72 toks/s]WARNING 04-06 04:26:00 scheduler.py:1555] Sequence group 492 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  90%|█████████ | 450/500 [42:00<07:59,  9.58s/it, est. speed input: 47.24 toks/s, output: 748.57 toks/s]Processed prompts:  90%|█████████ | 451/500 [42:02<05:55,  7.26s/it, est. speed input: 47.30 toks/s, output: 749.05 toks/s]Processed prompts:  90%|█████████ | 452/500 [42:05<04:46,  5.96s/it, est. speed input: 47.34 toks/s, output: 749.45 toks/s]Processed prompts:  91%|█████████ | 453/500 [42:33<09:56, 12.70s/it, est. speed input: 46.91 toks/s, output: 742.45 toks/s]Processed prompts:  91%|█████████ | 454/500 [42:43<09:02, 11.78s/it, est. speed input: 46.84 toks/s, output: 740.91 toks/s]Processed prompts:  91%|█████████ | 455/500 [42:54<08:48, 11.74s/it, est. speed input: 46.72 toks/s, output: 739.65 toks/s]Processed prompts:  91%|█████████ | 456/500 [43:06<08:37, 11.75s/it, est. speed input: 46.61 toks/s, output: 740.10 toks/s]Processed prompts:  91%|█████████▏| 457/500 [43:09<06:31,  9.11s/it, est. speed input: 46.67 toks/s, output: 740.81 toks/s]Processed prompts:  92%|█████████▏| 458/500 [43:10<04:35,  6.56s/it, est. speed input: 46.76 toks/s, output: 742.07 toks/s]Processed prompts:  92%|█████████▏| 459/500 [43:10<03:14,  4.75s/it, est. speed input: 46.86 toks/s, output: 743.34 toks/s]Processed prompts:  92%|█████████▏| 460/500 [43:11<02:17,  3.43s/it, est. speed input: 46.96 toks/s, output: 744.38 toks/s]Processed prompts:  92%|█████████▏| 461/500 [43:14<02:11,  3.38s/it, est. speed input: 47.00 toks/s, output: 744.88 toks/s]Processed prompts:  92%|█████████▏| 462/500 [43:23<03:14,  5.11s/it, est. speed input: 46.93 toks/s, output: 743.86 toks/s]Processed prompts:  93%|█████████▎| 463/500 [43:31<03:39,  5.92s/it, est. speed input: 46.89 toks/s, output: 743.59 toks/s]Processed prompts:  93%|█████████▎| 464/500 [43:35<03:19,  5.55s/it, est. speed input: 46.92 toks/s, output: 742.85 toks/s]Processed prompts:  93%|█████████▎| 465/500 [44:03<07:09, 12.28s/it, est. speed input: 46.54 toks/s, output: 736.94 toks/s]Processed prompts:  93%|█████████▎| 466/500 [44:05<05:10,  9.12s/it, est. speed input: 46.61 toks/s, output: 738.27 toks/s]Processed prompts:  93%|█████████▎| 467/500 [44:12<04:38,  8.45s/it, est. speed input: 46.58 toks/s, output: 738.21 toks/s]Processed prompts:  94%|█████████▎| 468/500 [44:16<03:52,  7.25s/it, est. speed input: 46.60 toks/s, output: 739.03 toks/s]Processed prompts:  94%|█████████▍| 469/500 [44:20<03:10,  6.14s/it, est. speed input: 46.63 toks/s, output: 739.86 toks/s]Processed prompts:  94%|█████████▍| 470/500 [44:22<02:28,  4.95s/it, est. speed input: 46.68 toks/s, output: 741.15 toks/s]Processed prompts:  94%|█████████▍| 471/500 [44:34<03:20,  6.91s/it, est. speed input: 46.59 toks/s, output: 740.09 toks/s]Processed prompts:  94%|█████████▍| 472/500 [44:44<03:40,  7.87s/it, est. speed input: 46.51 toks/s, output: 739.15 toks/s]Processed prompts:  95%|█████████▍| 473/500 [44:44<02:33,  5.67s/it, est. speed input: 46.60 toks/s, output: 741.08 toks/s]Processed prompts:  95%|█████████▍| 474/500 [44:48<02:13,  5.13s/it, est. speed input: 46.62 toks/s, output: 741.26 toks/s]Processed prompts:  95%|█████████▌| 475/500 [44:52<02:01,  4.86s/it, est. speed input: 46.64 toks/s, output: 742.21 toks/s]Processed prompts:  95%|█████████▌| 476/500 [44:54<01:30,  3.76s/it, est. speed input: 46.72 toks/s, output: 743.39 toks/s]Processed prompts:  95%|█████████▌| 477/500 [44:57<01:25,  3.72s/it, est. speed input: 46.75 toks/s, output: 744.58 toks/s]Processed prompts:  96%|█████████▌| 478/500 [45:06<01:55,  5.27s/it, est. speed input: 46.70 toks/s, output: 742.94 toks/s]Processed prompts:  96%|█████████▌| 479/500 [45:08<01:28,  4.19s/it, est. speed input: 46.76 toks/s, output: 743.04 toks/s]Processed prompts:  96%|█████████▌| 480/500 [45:14<01:37,  4.88s/it, est. speed input: 46.75 toks/s, output: 743.50 toks/s]Processed prompts:  96%|█████████▌| 481/500 [45:20<01:35,  5.04s/it, est. speed input: 46.75 toks/s, output: 744.40 toks/s]Processed prompts:  96%|█████████▋| 482/500 [45:21<01:08,  3.81s/it, est. speed input: 46.82 toks/s, output: 745.72 toks/s]Processed prompts:  97%|█████████▋| 483/500 [45:22<00:50,  2.98s/it, est. speed input: 46.90 toks/s, output: 747.69 toks/s]Processed prompts:  97%|█████████▋| 484/500 [45:33<01:25,  5.34s/it, est. speed input: 46.81 toks/s, output: 747.03 toks/s]Processed prompts:  97%|█████████▋| 485/500 [45:39<01:25,  5.69s/it, est. speed input: 46.81 toks/s, output: 747.62 toks/s]Processed prompts:  97%|█████████▋| 486/500 [46:07<02:53, 12.37s/it, est. speed input: 46.43 toks/s, output: 741.12 toks/s]Processed prompts:  97%|█████████▋| 487/500 [46:51<04:42, 21.76s/it, est. speed input: 45.82 toks/s, output: 731.38 toks/s]Processed prompts:  98%|█████████▊| 488/500 [47:03<03:45, 18.82s/it, est. speed input: 45.74 toks/s, output: 729.99 toks/s]Processed prompts:  98%|█████████▊| 489/500 [47:05<02:33, 13.94s/it, est. speed input: 45.79 toks/s, output: 732.35 toks/s]Processed prompts:  98%|█████████▊| 490/500 [47:08<01:44, 10.49s/it, est. speed input: 45.84 toks/s, output: 734.67 toks/s]Processed prompts:  98%|█████████▊| 491/500 [47:33<02:15, 15.01s/it, est. speed input: 45.52 toks/s, output: 730.22 toks/s]Processed prompts:  98%|█████████▊| 492/500 [47:41<01:42, 12.85s/it, est. speed input: 45.48 toks/s, output: 729.73 toks/s]Processed prompts:  99%|█████████▊| 493/500 [51:00<08:01, 68.82s/it, est. speed input: 42.60 toks/s, output: 692.89 toks/s]Processed prompts:  99%|█████████▉| 494/500 [52:38<07:43, 77.32s/it, est. speed input: 41.37 toks/s, output: 681.95 toks/s]Processed prompts:  99%|█████████▉| 495/500 [53:36<05:57, 71.55s/it, est. speed input: 40.72 toks/s, output: 679.82 toks/s]Processed prompts:  99%|█████████▉| 496/500 [57:58<08:35, 128.78s/it, est. speed input: 37.74 toks/s, output: 637.97 toks/s]Processed prompts:  99%|█████████▉| 497/500 [59:17<05:41, 113.74s/it, est. speed input: 36.97 toks/s, output: 633.08 toks/s]Processed prompts: 100%|█████████▉| 498/500 [59:51<02:59, 89.95s/it, est. speed input: 36.70 toks/s, output: 636.13 toks/s] Processed prompts: 100%|█████████▉| 499/500 [1:00:06<01:07, 67.41s/it, est. speed input: 36.61 toks/s, output: 642.61 toks/s]Processed prompts: 100%|██████████| 500/500 [1:05:38<00:00, 146.79s/it, est. speed input: 33.59 toks/s, output: 596.76 toks/s]Processed prompts: 100%|██████████| 500/500 [1:05:38<00:00,  7.88s/it, est. speed input: 33.59 toks/s, output: 596.76 toks/s] 
INFO 04-06 04:49:46 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2189754)[0;0m INFO 04-06 04:49:46 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2189753)[0;0m INFO 04-06 04:49:46 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2189755)[0;0m INFO 04-06 04:49:46 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W406 04:49:58.065031509 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-06 04:50:13 config.py:510] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.
INFO 04-06 04:50:13 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-06 04:50:13 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-06 04:50:13 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-06 04:50:13 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-06 04:50:14 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-06 04:50:14 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:15 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:15 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:15 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:15 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:15 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:15 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-06 04:50:15 selector.py:120] Using Flash Attention backend.
INFO 04-06 04:50:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:17 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-06 04:50:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2195758)[0;0m WARNING 04-06 04:50:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2195759)[0;0m WARNING 04-06 04:50:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2195760)[0;0m WARNING 04-06 04:50:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-06 04:50:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-06 04:50:17 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_13b23e25'), local_subscribe_port=35791, remote_subscribe_port=None)
INFO 04-06 04:50:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.58it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.64it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.13it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.97it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.89it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.85it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.83it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.80it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.80it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.83it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.81it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.96it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.92it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.93it/s]

[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:25 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-06 04:50:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:28 worker.py:241] Memory profiling takes 2.61 seconds
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:28 worker.py:241] Memory profiling takes 2.62 seconds
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:28 worker.py:241] Memory profiling takes 2.64 seconds
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-06 04:50:28 worker.py:241] Memory profiling takes 2.85 seconds
INFO 04-06 04:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-06 04:50:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-06 04:50:28 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-06 04:50:28 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:50:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:50:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-06 04:50:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:50:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:40,  1.24s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:28,  1.15s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:28,  1.16s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:24,  1.14s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:22,  1.13s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:22,  1.14s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:08<02:21,  1.14s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:09<02:19,  1.14s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:10<02:18,  1.14s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:11<02:18,  1.14s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:12<02:17,  1.15s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:13<02:17,  1.15s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:14<02:14,  1.14s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:15<02:12,  1.13s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:17<02:11,  1.13s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:18<02:11,  1.14s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:19<02:07,  1.12s/it]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:20<02:06,  1.12s/it]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:21<02:05,  1.12s/it]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:22<02:01,  1.10s/it]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:23<02:00,  1.10s/it]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:24<01:57,  1.08s/it]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:25<01:57,  1.09s/it]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:26<01:56,  1.09s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:28<01:53,  1.07s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:29<01:53,  1.08s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:30<01:52,  1.08s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:31<01:49,  1.06s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:32<01:47,  1.05s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:33<01:47,  1.06s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:34<01:47,  1.07s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:35<01:46,  1.08s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:36<01:44,  1.07s/it]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:37<01:41,  1.05s/it]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:38<01:41,  1.05s/it]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:39<01:39,  1.05s/it]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:40<01:36,  1.02s/it]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:41<01:35,  1.03s/it]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:42<01:35,  1.03s/it]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:43<01:31,  1.01s/it]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:44<01:30,  1.01s/it]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:45<01:28,  1.01it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:46<01:29,  1.01s/it]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:47<01:26,  1.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:48<01:26,  1.00s/it]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:49<01:24,  1.01it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:50<01:23,  1.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:51<01:23,  1.00s/it]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:52<01:20,  1.02it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:53<01:19,  1.02it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:54<01:19,  1.01it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:55<01:18,  1.00it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:56<01:16,  1.02it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:57<01:15,  1.02it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:58<01:13,  1.03it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:59<01:13,  1.02it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [01:00<01:12,  1.02it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [01:01<01:11,  1.02it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [01:02<01:10,  1.02it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [01:03<01:09,  1.03it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:04<01:07,  1.04it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:05<01:05,  1.05it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:06<01:04,  1.05it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:07<01:02,  1.07it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:07<01:01,  1.08it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:08<00:59,  1.09it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:09<00:59,  1.08it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:10<00:56,  1.11it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:11<00:55,  1.11it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:12<00:53,  1.13it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:13<00:52,  1.14it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:14<00:52,  1.13it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:15<00:51,  1.12it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:15<00:49,  1.15it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:16<00:49,  1.13it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:17<00:48,  1.14it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:18<00:47,  1.13it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:19<00:47,  1.11it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:20<00:46,  1.12it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:21<00:45,  1.13it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:22<00:44,  1.13it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:22<00:43,  1.14it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:23<00:41,  1.15it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:24<00:40,  1.17it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:25<00:38,  1.18it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:26<00:37,  1.21it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:27<00:36,  1.19it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:27<00:36,  1.18it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:28<00:35,  1.18it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:29<00:35,  1.17it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:30<00:34,  1.16it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:31<00:32,  1.20it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:32<00:31,  1.22it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:33<00:30,  1.20it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:33<00:29,  1.21it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:34<00:28,  1.22it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:35<00:28,  1.20it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:36<00:27,  1.21it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:37<00:25,  1.26it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:37<00:24,  1.29it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:38<00:23,  1.28it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:39<00:22,  1.31it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:40<00:21,  1.30it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:40<00:20,  1.30it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:41<00:20,  1.30it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:42<00:19,  1.29it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:43<00:18,  1.33it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:43<00:17,  1.32it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:44<00:16,  1.34it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:45<00:15,  1.33it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:46<00:15,  1.32it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:46<00:14,  1.32it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:47<00:13,  1.32it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:48<00:12,  1.34it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:49<00:11,  1.37it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:49<00:10,  1.39it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:50<00:10,  1.39it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:51<00:09,  1.38it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:51<00:08,  1.37it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:52<00:08,  1.35it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:53<00:07,  1.32it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:54<00:06,  1.32it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:54<00:05,  1.37it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:55<00:04,  1.40it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:56<00:04,  1.43it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:56<00:03,  1.44it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:57<00:02,  1.43it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:58<00:02,  1.46it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:59<00:01,  1.43it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:59<00:00,  1.40it/s][1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 04:52:43 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 04:52:43 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 04:52:43 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.24it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.08it/s]
INFO 04-06 04:52:43 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
INFO 04-06 04:52:43 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 138.10 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: flow
Generating answers for task: flow
Processed prompts:   0%|          | 0/405 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-06 04:53:55 scheduler.py:1555] Sequence group 404 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
Processed prompts:   0%|          | 1/405 [01:40<11:18:10, 100.72s/it, est. speed input: 2.13 toks/s, output: 3.41 toks/s]WARNING 04-06 04:54:30 scheduler.py:1555] Sequence group 354 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
Processed prompts:   0%|          | 2/405 [01:54<5:33:33, 49.66s/it, est. speed input: 3.74 toks/s, output: 6.64 toks/s]  Processed prompts:   1%|          | 3/405 [01:56<3:06:43, 27.87s/it, est. speed input: 5.52 toks/s, output: 10.27 toks/s]WARNING 04-06 04:54:45 scheduler.py:1555] Sequence group 304 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   1%|          | 4/405 [02:00<2:01:59, 18.25s/it, est. speed input: 7.14 toks/s, output: 13.48 toks/s]Processed prompts:   1%|          | 5/405 [02:08<1:39:05, 14.86s/it, est. speed input: 8.31 toks/s, output: 16.57 toks/s]Processed prompts:   1%|▏         | 6/405 [02:11<1:10:24, 10.59s/it, est. speed input: 9.79 toks/s, output: 20.32 toks/s]Processed prompts:   2%|▏         | 7/405 [02:11<47:55,  7.23s/it, est. speed input: 11.40 toks/s, output: 23.99 toks/s] Processed prompts:   2%|▏         | 8/405 [02:12<33:51,  5.12s/it, est. speed input: 12.96 toks/s, output: 27.88 toks/s]Processed prompts:   2%|▏         | 9/405 [02:19<39:13,  5.94s/it, est. speed input: 13.82 toks/s, output: 30.50 toks/s]Processed prompts:   3%|▎         | 11/405 [02:20<21:02,  3.21s/it, est. speed input: 16.86 toks/s, output: 38.24 toks/s]Processed prompts:   3%|▎         | 12/405 [02:22<18:54,  2.89s/it, est. speed input: 18.14 toks/s, output: 41.93 toks/s]WARNING 04-06 04:55:09 scheduler.py:1555] Sequence group 253 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:   3%|▎         | 13/405 [02:27<22:34,  3.46s/it, est. speed input: 19.03 toks/s, output: 44.59 toks/s]Processed prompts:   3%|▎         | 14/405 [02:28<18:59,  2.91s/it, est. speed input: 20.28 toks/s, output: 48.28 toks/s]Processed prompts:   4%|▎         | 15/405 [02:31<19:43,  3.03s/it, est. speed input: 21.29 toks/s, output: 51.61 toks/s]Processed prompts:   4%|▍         | 16/405 [02:33<16:00,  2.47s/it, est. speed input: 22.54 toks/s, output: 55.47 toks/s]Processed prompts:   4%|▍         | 17/405 [02:33<12:33,  1.94s/it, est. speed input: 23.84 toks/s, output: 59.44 toks/s]Processed prompts:   4%|▍         | 18/405 [02:38<18:26,  2.86s/it, est. speed input: 24.47 toks/s, output: 62.08 toks/s]Processed prompts:   5%|▍         | 19/405 [02:41<17:59,  2.80s/it, est. speed input: 25.44 toks/s, output: 65.71 toks/s]Processed prompts:   5%|▍         | 20/405 [02:42<13:49,  2.15s/it, est. speed input: 26.76 toks/s, output: 70.10 toks/s]Processed prompts:   5%|▌         | 21/405 [02:42<10:23,  1.62s/it, est. speed input: 28.10 toks/s, output: 74.57 toks/s]Processed prompts:   5%|▌         | 22/405 [02:43<09:11,  1.44s/it, est. speed input: 29.24 toks/s, output: 78.75 toks/s]Processed prompts:   6%|▌         | 23/405 [02:46<12:49,  2.02s/it, est. speed input: 29.99 toks/s, output: 81.90 toks/s]Processed prompts:   6%|▌         | 24/405 [02:49<14:30,  2.28s/it, est. speed input: 30.74 toks/s, output: 85.29 toks/s]Processed prompts:   6%|▌         | 25/405 [02:51<13:49,  2.18s/it, est. speed input: 31.63 toks/s, output: 89.15 toks/s]Processed prompts:   6%|▋         | 26/405 [02:51<10:06,  1.60s/it, est. speed input: 32.84 toks/s, output: 93.68 toks/s]Processed prompts:   7%|▋         | 27/405 [02:53<09:46,  1.55s/it, est. speed input: 33.84 toks/s, output: 97.74 toks/s]Processed prompts:   7%|▋         | 28/405 [02:55<10:38,  1.69s/it, est. speed input: 34.71 toks/s, output: 101.46 toks/s]Processed prompts:   7%|▋         | 29/405 [02:56<09:13,  1.47s/it, est. speed input: 35.77 toks/s, output: 105.82 toks/s]WARNING 04-06 04:55:48 scheduler.py:1555] Sequence group 196 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:   7%|▋         | 30/405 [03:10<32:23,  5.18s/it, est. speed input: 34.33 toks/s, output: 103.34 toks/s]Processed prompts:   8%|▊         | 31/405 [03:11<25:02,  4.02s/it, est. speed input: 35.29 toks/s, output: 107.72 toks/s]Processed prompts:   8%|▊         | 32/405 [03:19<32:14,  5.19s/it, est. speed input: 35.01 toks/s, output: 108.82 toks/s]Processed prompts:   8%|▊         | 33/405 [03:19<23:30,  3.79s/it, est. speed input: 36.06 toks/s, output: 113.88 toks/s]Processed prompts:   8%|▊         | 34/405 [03:24<25:19,  4.09s/it, est. speed input: 36.37 toks/s, output: 116.66 toks/s]Processed prompts:   9%|▊         | 35/405 [03:25<18:27,  2.99s/it, est. speed input: 37.37 toks/s, output: 121.92 toks/s]Processed prompts:   9%|▉         | 36/405 [03:33<28:45,  4.68s/it, est. speed input: 36.93 toks/s, output: 122.67 toks/s]Processed prompts:   9%|▉         | 37/405 [03:37<27:53,  4.55s/it, est. speed input: 37.22 toks/s, output: 125.98 toks/s]Processed prompts:   9%|▉         | 38/405 [03:39<22:23,  3.66s/it, est. speed input: 37.99 toks/s, output: 130.81 toks/s]Processed prompts:  10%|▉         | 39/405 [03:45<27:00,  4.43s/it, est. speed input: 37.96 toks/s, output: 133.02 toks/s]Processed prompts:  10%|▉         | 40/405 [03:56<38:35,  6.34s/it, est. speed input: 37.16 toks/s, output: 133.01 toks/s]Processed prompts:  10%|█         | 41/405 [03:58<30:10,  4.97s/it, est. speed input: 37.81 toks/s, output: 138.11 toks/s]Processed prompts:  10%|█         | 42/405 [03:58<21:34,  3.57s/it, est. speed input: 38.69 toks/s, output: 144.03 toks/s]Processed prompts:  11%|█         | 43/405 [03:59<15:43,  2.61s/it, est. speed input: 39.56 toks/s, output: 149.92 toks/s]Processed prompts:  11%|█         | 44/405 [04:04<20:00,  3.32s/it, est. speed input: 39.65 toks/s, output: 153.02 toks/s]Processed prompts:  11%|█         | 45/405 [04:06<17:53,  2.98s/it, est. speed input: 40.23 toks/s, output: 157.91 toks/s]Processed prompts:  11%|█▏        | 46/405 [04:11<22:20,  3.73s/it, est. speed input: 40.26 toks/s, output: 160.79 toks/s]Processed prompts:  12%|█▏        | 47/405 [04:16<23:44,  3.98s/it, est. speed input: 40.43 toks/s, output: 164.35 toks/s]Processed prompts:  12%|█▏        | 48/405 [04:18<21:02,  3.54s/it, est. speed input: 40.90 toks/s, output: 169.20 toks/s]Processed prompts:  12%|█▏        | 49/405 [04:20<18:08,  3.06s/it, est. speed input: 41.53 toks/s, output: 174.45 toks/s]Processed prompts:  12%|█▏        | 50/405 [04:22<16:24,  2.77s/it, est. speed input: 42.04 toks/s, output: 179.59 toks/s]Processed prompts:  13%|█▎        | 51/405 [04:24<15:02,  2.55s/it, est. speed input: 42.55 toks/s, output: 184.80 toks/s]Processed prompts:  13%|█▎        | 52/405 [04:30<21:19,  3.63s/it, est. speed input: 42.41 toks/s, output: 187.29 toks/s]Processed prompts:  13%|█▎        | 53/405 [04:31<15:58,  2.72s/it, est. speed input: 43.13 toks/s, output: 193.55 toks/s]Processed prompts:  13%|█▎        | 54/405 [04:33<15:17,  2.61s/it, est. speed input: 43.59 toks/s, output: 198.65 toks/s]Processed prompts:  14%|█▎        | 55/405 [04:35<14:09,  2.43s/it, est. speed input: 44.08 toks/s, output: 204.01 toks/s]Processed prompts:  14%|█▍        | 56/405 [04:38<13:48,  2.38s/it, est. speed input: 44.52 toks/s, output: 209.20 toks/s]Processed prompts:  14%|█▍        | 57/405 [04:40<13:24,  2.31s/it, est. speed input: 44.96 toks/s, output: 214.42 toks/s]Processed prompts:  14%|█▍        | 58/405 [04:46<19:16,  3.33s/it, est. speed input: 44.86 toks/s, output: 217.08 toks/s]Processed prompts:  15%|█▍        | 59/405 [04:46<14:48,  2.57s/it, est. speed input: 45.53 toks/s, output: 223.46 toks/s]WARNING 04-06 04:57:37 scheduler.py:1555] Sequence group 145 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:  15%|█▍        | 60/405 [05:00<34:38,  6.03s/it, est. speed input: 44.18 toks/s, output: 220.18 toks/s]Processed prompts:  15%|█▌        | 61/405 [05:09<38:22,  6.69s/it, est. speed input: 43.77 toks/s, output: 221.60 toks/s]Processed prompts:  15%|█▌        | 62/405 [05:17<41:42,  7.30s/it, est. speed input: 43.31 toks/s, output: 222.93 toks/s]Processed prompts:  16%|█▌        | 63/405 [05:21<35:45,  6.27s/it, est. speed input: 43.49 toks/s, output: 227.68 toks/s]Processed prompts:  16%|█▌        | 64/405 [05:24<29:22,  5.17s/it, est. speed input: 43.83 toks/s, output: 233.33 toks/s]Processed prompts:  16%|█▌        | 65/405 [05:57<1:16:21, 13.48s/it, est. speed input: 40.43 toks/s, output: 219.82 toks/s]Processed prompts:  16%|█▋        | 66/405 [06:00<59:31, 10.54s/it, est. speed input: 40.64 toks/s, output: 225.55 toks/s]  Processed prompts:  17%|█▋        | 67/405 [06:09<56:36, 10.05s/it, est. speed input: 40.50 toks/s, output: 228.21 toks/s]Processed prompts:  17%|█▋        | 68/405 [06:12<44:38,  7.95s/it, est. speed input: 40.85 toks/s, output: 234.47 toks/s]Processed prompts:  17%|█▋        | 69/405 [06:13<32:59,  5.89s/it, est. speed input: 41.36 toks/s, output: 241.96 toks/s]Processed prompts:  17%|█▋        | 70/405 [06:18<30:09,  5.40s/it, est. speed input: 41.56 toks/s, output: 247.45 toks/s]Processed prompts:  18%|█▊        | 71/405 [06:28<38:39,  6.95s/it, est. speed input: 41.02 toks/s, output: 249.07 toks/s]Processed prompts:  18%|█▊        | 72/405 [06:28<27:14,  4.91s/it, est. speed input: 41.59 toks/s, output: 257.31 toks/s]Processed prompts:  18%|█▊        | 73/405 [06:34<28:15,  5.11s/it, est. speed input: 41.60 toks/s, output: 262.08 toks/s]Processed prompts:  18%|█▊        | 74/405 [06:36<22:37,  4.10s/it, est. speed input: 41.99 toks/s, output: 269.32 toks/s]Processed prompts:  19%|█▊        | 75/405 [06:41<24:57,  4.54s/it, est. speed input: 41.98 toks/s, output: 274.08 toks/s]Processed prompts:  19%|█▉        | 76/405 [06:44<21:39,  3.95s/it, est. speed input: 42.26 toks/s, output: 280.84 toks/s]Processed prompts:  19%|█▉        | 77/405 [06:57<35:49,  6.55s/it, est. speed input: 41.57 toks/s, output: 280.96 toks/s]Processed prompts:  19%|█▉        | 78/405 [06:57<26:27,  4.85s/it, est. speed input: 42.12 toks/s, output: 288.99 toks/s]Processed prompts:  20%|█▉        | 79/405 [07:02<26:18,  4.84s/it, est. speed input: 42.21 toks/s, output: 294.39 toks/s]Processed prompts:  20%|█▉        | 80/405 [07:09<29:45,  5.49s/it, est. speed input: 42.05 toks/s, output: 298.30 toks/s]Processed prompts:  20%|██        | 81/405 [07:10<22:37,  4.19s/it, est. speed input: 42.51 toks/s, output: 306.28 toks/s]Processed prompts:  20%|██        | 82/405 [07:33<53:02,  9.85s/it, est. speed input: 40.84 toks/s, output: 299.69 toks/s]Processed prompts:  20%|██        | 83/405 [07:50<1:03:22, 11.81s/it, est. speed input: 39.96 toks/s, output: 298.39 toks/s]Processed prompts:  21%|██        | 84/405 [08:05<1:08:38, 12.83s/it, est. speed input: 39.23 toks/s, output: 298.32 toks/s]Processed prompts:  21%|██        | 85/405 [08:26<1:21:14, 15.23s/it, est. speed input: 38.08 toks/s, output: 295.52 toks/s]Processed prompts:  21%|██        | 86/405 [08:49<1:34:08, 17.71s/it, est. speed input: 36.83 toks/s, output: 292.11 toks/s]Processed prompts:  21%|██▏       | 87/405 [08:50<1:06:43, 12.59s/it, est. speed input: 37.23 toks/s, output: 301.43 toks/s]Processed prompts:  22%|██▏       | 88/405 [08:51<48:21,  9.15s/it, est. speed input: 37.58 toks/s, output: 310.47 toks/s]  Processed prompts:  22%|██▏       | 89/405 [09:21<1:20:18, 15.25s/it, est. speed input: 36.17 toks/s, output: 304.10 toks/s]Processed prompts:  22%|██▏       | 90/405 [09:40<1:26:33, 16.49s/it, est. speed input: 35.44 toks/s, output: 304.05 toks/s]Processed prompts:  22%|██▏       | 91/405 [09:47<1:10:50, 13.54s/it, est. speed input: 35.51 toks/s, output: 310.78 toks/s]Processed prompts:  23%|██▎       | 92/405 [09:49<53:35, 10.27s/it, est. speed input: 35.77 toks/s, output: 319.39 toks/s]  Processed prompts:  23%|██▎       | 93/405 [10:02<56:50, 10.93s/it, est. speed input: 35.41 toks/s, output: 323.07 toks/s]Processed prompts:  23%|██▎       | 94/405 [10:10<53:12, 10.27s/it, est. speed input: 35.34 toks/s, output: 328.82 toks/s]Processed prompts:  23%|██▎       | 95/405 [10:36<1:16:03, 14.72s/it, est. speed input: 34.39 toks/s, output: 326.40 toks/s]Processed prompts:  24%|██▎       | 96/405 [11:00<1:30:15, 17.53s/it, est. speed input: 33.53 toks/s, output: 325.24 toks/s]WARNING 04-06 05:04:20 scheduler.py:1555] Sequence group 93 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  24%|██▍       | 97/405 [11:39<2:03:11, 24.00s/it, est. speed input: 32.00 toks/s, output: 318.09 toks/s]Processed prompts:  24%|██▍       | 98/405 [11:40<1:27:15, 17.05s/it, est. speed input: 32.48 toks/s, output: 328.63 toks/s]Processed prompts:  24%|██▍       | 99/405 [11:41<1:02:56, 12.34s/it, est. speed input: 32.85 toks/s, output: 338.55 toks/s]Processed prompts:  25%|██▍       | 100/405 [11:44<48:21,  9.51s/it, est. speed input: 33.39 toks/s, output: 346.98 toks/s] Processed prompts:  25%|██▍       | 101/405 [11:57<53:34, 10.57s/it, est. speed input: 33.13 toks/s, output: 351.82 toks/s]Processed prompts:  25%|██▌       | 102/405 [12:20<1:11:56, 14.25s/it, est. speed input: 32.43 toks/s, output: 352.29 toks/s]Processed prompts:  25%|██▌       | 103/405 [12:21<51:49, 10.30s/it, est. speed input: 32.91 toks/s, output: 363.09 toks/s]  Processed prompts:  26%|██▌       | 104/405 [12:41<1:06:04, 13.17s/it, est. speed input: 32.82 toks/s, output: 365.04 toks/s]Processed prompts:  26%|██▌       | 105/405 [12:54<1:06:03, 13.21s/it, est. speed input: 32.59 toks/s, output: 370.28 toks/s]Processed prompts:  26%|██▌       | 106/405 [13:29<1:37:43, 19.61s/it, est. speed input: 31.65 toks/s, output: 366.19 toks/s]Processed prompts:  26%|██▋       | 107/405 [13:34<1:16:36, 15.42s/it, est. speed input: 31.77 toks/s, output: 375.39 toks/s]Processed prompts:  27%|██▋       | 108/405 [13:50<1:16:42, 15.50s/it, est. speed input: 31.64 toks/s, output: 380.13 toks/s]Processed prompts:  27%|██▋       | 109/405 [13:51<54:50, 11.12s/it, est. speed input: 32.19 toks/s, output: 391.56 toks/s]  Processed prompts:  27%|██▋       | 110/405 [14:10<1:06:31, 13.53s/it, est. speed input: 31.75 toks/s, output: 392.38 toks/s]Processed prompts:  27%|██▋       | 111/405 [14:11<48:18,  9.86s/it, est. speed input: 32.07 toks/s, output: 403.72 toks/s]  Processed prompts:  28%|██▊       | 112/405 [14:38<1:13:15, 15.00s/it, est. speed input: 31.44 toks/s, output: 403.36 toks/s]Processed prompts:  28%|██▊       | 113/405 [14:43<58:20, 11.99s/it, est. speed input: 31.92 toks/s, output: 406.85 toks/s]  Processed prompts:  28%|██▊       | 114/405 [15:08<1:16:28, 15.77s/it, est. speed input: 31.50 toks/s, output: 408.02 toks/s]Processed prompts:  28%|██▊       | 115/405 [15:31<1:26:40, 17.93s/it, est. speed input: 31.09 toks/s, output: 410.21 toks/s]Processed prompts:  29%|██▊       | 116/405 [15:50<1:27:55, 18.26s/it, est. speed input: 30.84 toks/s, output: 414.35 toks/s]Processed prompts:  29%|██▉       | 117/405 [16:06<1:24:22, 17.58s/it, est. speed input: 30.91 toks/s, output: 419.89 toks/s]Processed prompts:  29%|██▉       | 118/405 [16:14<1:10:48, 14.80s/it, est. speed input: 31.42 toks/s, output: 428.73 toks/s]Processed prompts:  29%|██▉       | 119/405 [16:17<52:52, 11.09s/it, est. speed input: 31.91 toks/s, output: 440.11 toks/s]  Processed prompts:  30%|██▉       | 120/405 [16:18<38:33,  8.12s/it, est. speed input: 32.13 toks/s, output: 452.03 toks/s]Processed prompts:  30%|██▉       | 121/405 [16:27<40:23,  8.53s/it, est. speed input: 32.10 toks/s, output: 457.01 toks/s]Processed prompts:  30%|███       | 122/405 [16:40<46:46,  9.92s/it, est. speed input: 32.48 toks/s, output: 459.54 toks/s]Processed prompts:  30%|███       | 123/405 [16:49<44:58,  9.57s/it, est. speed input: 32.48 toks/s, output: 468.07 toks/s]Processed prompts:  31%|███       | 124/405 [16:52<35:46,  7.64s/it, est. speed input: 32.64 toks/s, output: 479.15 toks/s]Processed prompts:  31%|███       | 125/405 [17:03<39:52,  8.55s/it, est. speed input: 32.59 toks/s, output: 482.01 toks/s]Processed prompts:  31%|███       | 126/405 [17:22<54:30, 11.72s/it, est. speed input: 32.34 toks/s, output: 480.27 toks/s]Processed prompts:  31%|███▏      | 127/405 [18:05<1:37:07, 20.96s/it, est. speed input: 31.59 toks/s, output: 465.33 toks/s]Processed prompts:  32%|███▏      | 128/405 [18:09<1:13:32, 15.93s/it, est. speed input: 31.75 toks/s, output: 476.24 toks/s]Processed prompts:  32%|███▏      | 129/405 [18:46<1:42:40, 22.32s/it, est. speed input: 31.10 toks/s, output: 467.69 toks/s]Processed prompts:  32%|███▏      | 130/405 [18:58<1:28:17, 19.26s/it, est. speed input: 31.12 toks/s, output: 475.55 toks/s]Processed prompts:  32%|███▏      | 131/405 [19:44<2:05:07, 27.40s/it, est. speed input: 30.41 toks/s, output: 469.88 toks/s]Processed prompts:  33%|███▎      | 132/405 [19:51<1:36:38, 21.24s/it, est. speed input: 30.76 toks/s, output: 480.13 toks/s]Processed prompts:  33%|███▎      | 133/405 [20:04<1:24:24, 18.62s/it, est. speed input: 31.04 toks/s, output: 488.14 toks/s]Processed prompts:  33%|███▎      | 134/405 [20:32<1:37:13, 21.53s/it, est. speed input: 30.74 toks/s, output: 482.12 toks/s]Processed prompts:  33%|███▎      | 135/405 [20:35<1:11:56, 15.99s/it, est. speed input: 31.12 toks/s, output: 485.89 toks/s]Processed prompts:  34%|███▎      | 136/405 [20:51<1:11:55, 16.04s/it, est. speed input: 30.94 toks/s, output: 488.40 toks/s]Processed prompts:  34%|███▍      | 137/405 [20:55<55:37, 12.45s/it, est. speed input: 32.33 toks/s, output: 488.31 toks/s]  Processed prompts:  34%|███▍      | 138/405 [21:28<1:22:50, 18.62s/it, est. speed input: 32.11 toks/s, output: 488.98 toks/s]Processed prompts:  34%|███▍      | 139/405 [22:08<1:50:55, 25.02s/it, est. speed input: 32.35 toks/s, output: 479.90 toks/s]WARNING 04-06 05:15:21 scheduler.py:1555] Sequence group 152 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  35%|███▍      | 140/405 [22:37<1:54:47, 25.99s/it, est. speed input: 31.86 toks/s, output: 478.18 toks/s]Processed prompts:  35%|███▍      | 141/405 [23:04<1:56:28, 26.47s/it, est. speed input: 31.80 toks/s, output: 474.91 toks/s]Processed prompts:  35%|███▌      | 142/405 [23:05<1:21:44, 18.65s/it, est. speed input: 32.31 toks/s, output: 488.13 toks/s]Processed prompts:  35%|███▌      | 143/405 [24:27<2:45:23, 37.88s/it, est. speed input: 31.27 toks/s, output: 467.66 toks/s]Processed prompts:  36%|███▌      | 144/405 [24:42<2:14:38, 30.95s/it, est. speed input: 31.31 toks/s, output: 470.86 toks/s]Processed prompts:  36%|███▌      | 145/405 [24:59<1:55:50, 26.73s/it, est. speed input: 31.77 toks/s, output: 472.48 toks/s]Processed prompts:  36%|███▌      | 146/405 [25:10<1:35:21, 22.09s/it, est. speed input: 31.87 toks/s, output: 476.16 toks/s]Processed prompts:  36%|███▋      | 147/405 [25:40<1:44:13, 24.24s/it, est. speed input: 31.85 toks/s, output: 474.57 toks/s]Processed prompts:  37%|███▋      | 148/405 [25:58<1:35:47, 22.37s/it, est. speed input: 31.63 toks/s, output: 476.79 toks/s]Processed prompts:  37%|███▋      | 149/405 [30:16<6:37:26, 93.15s/it, est. speed input: 27.82 toks/s, output: 417.01 toks/s]Processed prompts:  37%|███▋      | 150/405 [31:47<6:32:56, 92.46s/it, est. speed input: 27.50 toks/s, output: 406.24 toks/s]Processed prompts:  37%|███▋      | 151/405 [33:11<6:21:35, 90.14s/it, est. speed input: 27.26 toks/s, output: 397.04 toks/s]Processed prompts:  38%|███▊      | 152/405 [42:44<16:30:01, 234.79s/it, est. speed input: 21.27 toks/s, output: 321.20 toks/s]Processed prompts:  38%|███▊      | 153/405 [44:33<13:47:43, 197.08s/it, est. speed input: 20.51 toks/s, output: 320.36 toks/s]Processed prompts:  38%|███▊      | 154/405 [45:23<10:40:02, 153.00s/it, est. speed input: 20.24 toks/s, output: 326.49 toks/s]Processed prompts:  38%|███▊      | 155/405 [45:47<7:56:21, 114.33s/it, est. speed input: 20.14 toks/s, output: 335.55 toks/s] Processed prompts:  39%|███▊      | 156/405 [46:00<5:47:39, 83.77s/it, est. speed input: 20.14 toks/s, output: 345.91 toks/s] WARNING 04-06 05:39:10 scheduler.py:1555] Sequence group 157 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  39%|███▉      | 157/405 [46:38<4:50:19, 70.24s/it, est. speed input: 20.10 toks/s, output: 352.84 toks/s]Processed prompts:  39%|███▉      | 158/405 [47:12<4:04:38, 59.43s/it, est. speed input: 20.22 toks/s, output: 360.14 toks/s]Processed prompts:  39%|███▉      | 159/405 [50:47<7:14:01, 105.86s/it, est. speed input: 19.16 toks/s, output: 345.58 toks/s]Processed prompts:  40%|███▉      | 160/405 [53:34<8:27:18, 124.24s/it, est. speed input: 18.64 toks/s, output: 337.81 toks/s]Processed prompts:  40%|███▉      | 161/405 [58:27<11:51:56, 175.07s/it, est. speed input: 17.53 toks/s, output: 318.87 toks/s]WARNING 04-06 05:52:04 scheduler.py:1555] Sequence group 162 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  40%|████      | 162/405 [1:01:21<11:47:27, 174.68s/it, est. speed input: 17.29 toks/s, output: 312.72 toks/s]Processed prompts:  40%|████      | 163/405 [1:04:17<11:45:40, 174.96s/it, est. speed input: 16.97 toks/s, output: 306.98 toks/s]Processed prompts:  40%|████      | 164/405 [1:06:09<10:27:26, 156.21s/it, est. speed input: 16.95 toks/s, output: 306.53 toks/s]Processed prompts:  41%|████      | 165/405 [1:08:30<10:06:09, 151.54s/it, est. speed input: 16.80 toks/s, output: 304.02 toks/s]Processed prompts:  41%|████      | 166/405 [1:10:38<9:35:14, 144.41s/it, est. speed input: 16.87 toks/s, output: 302.58 toks/s] Processed prompts:  41%|████      | 167/405 [1:13:43<10:21:36, 156.71s/it, est. speed input: 16.67 toks/s, output: 296.95 toks/s]Processed prompts:  41%|████▏     | 168/405 [1:14:12<7:47:31, 118.36s/it, est. speed input: 17.13 toks/s, output: 302.39 toks/s] Processed prompts:  42%|████▏     | 169/405 [1:16:33<8:11:45, 125.02s/it, est. speed input: 17.04 toks/s, output: 300.27 toks/s]WARNING 04-06 06:09:28 scheduler.py:1555] Sequence group 188 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  42%|████▏     | 170/405 [1:17:22<6:40:35, 102.28s/it, est. speed input: 16.91 toks/s, output: 304.14 toks/s]Processed prompts:  42%|████▏     | 171/405 [1:25:02<13:37:39, 209.66s/it, est. speed input: 15.44 toks/s, output: 283.13 toks/s]Processed prompts:  42%|████▏     | 172/405 [1:27:16<12:06:01, 186.96s/it, est. speed input: 15.09 toks/s, output: 282.15 toks/s]Processed prompts:  43%|████▎     | 173/405 [1:28:57<10:22:40, 161.04s/it, est. speed input: 14.87 toks/s, output: 282.97 toks/s]Processed prompts:  43%|████▎     | 174/405 [1:29:37<8:01:17, 125.01s/it, est. speed input: 14.80 toks/s, output: 283.26 toks/s] Processed prompts:  43%|████▎     | 175/405 [1:33:40<10:14:52, 160.40s/it, est. speed input: 14.21 toks/s, output: 276.84 toks/s]Processed prompts:  43%|████▎     | 176/405 [1:35:21<9:03:38, 142.44s/it, est. speed input: 14.00 toks/s, output: 277.71 toks/s] Processed prompts:  44%|████▎     | 177/405 [1:37:36<8:52:14, 140.06s/it, est. speed input: 13.75 toks/s, output: 276.92 toks/s]Processed prompts:  44%|████▍     | 178/405 [1:38:29<7:12:00, 114.19s/it, est. speed input: 13.67 toks/s, output: 279.95 toks/s]Processed prompts:  44%|████▍     | 179/405 [1:40:06<6:50:30, 108.98s/it, est. speed input: 13.50 toks/s, output: 280.89 toks/s]Processed prompts:  44%|████▍     | 180/405 [1:40:50<5:35:12, 89.39s/it, est. speed input: 13.47 toks/s, output: 281.81 toks/s] Processed prompts:  45%|████▍     | 181/405 [1:41:11<4:17:19, 68.93s/it, est. speed input: 13.46 toks/s, output: 286.23 toks/s]WARNING 04-06 06:34:20 scheduler.py:1555] Sequence group 204 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  45%|████▍     | 182/405 [1:42:33<4:31:07, 72.95s/it, est. speed input: 13.39 toks/s, output: 287.72 toks/s]Processed prompts:  45%|████▌     | 183/405 [1:44:31<5:20:00, 86.49s/it, est. speed input: 13.21 toks/s, output: 287.53 toks/s]WARNING 04-06 06:41:37 scheduler.py:1555] Sequence group 190 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  45%|████▌     | 184/405 [1:52:43<12:45:56, 207.95s/it, est. speed input: 12.33 toks/s, output: 271.49 toks/s]Processed prompts:  46%|████▌     | 185/405 [1:52:48<8:59:32, 147.15s/it, est. speed input: 12.41 toks/s, output: 276.12 toks/s] Processed prompts:  46%|████▌     | 186/405 [2:02:07<16:28:09, 270.73s/it, est. speed input: 11.55 toks/s, output: 259.52 toks/s]Processed prompts:  46%|████▌     | 187/405 [2:03:55<13:26:09, 221.88s/it, est. speed input: 11.41 toks/s, output: 260.16 toks/s]Processed prompts:  46%|████▋     | 188/405 [2:05:13<10:45:55, 178.60s/it, est. speed input: 11.33 toks/s, output: 261.84 toks/s]Processed prompts:  47%|████▋     | 189/405 [2:06:16<8:38:22, 143.99s/it, est. speed input: 11.28 toks/s, output: 263.98 toks/s] Processed prompts:  47%|████▋     | 190/405 [2:07:18<7:08:21, 119.54s/it, est. speed input: 11.22 toks/s, output: 266.11 toks/s]Processed prompts:  47%|████▋     | 191/405 [2:07:53<5:35:58, 94.20s/it, est. speed input: 11.21 toks/s, output: 269.16 toks/s] Processed prompts:  47%|████▋     | 192/405 [2:08:48<4:52:24, 82.37s/it, est. speed input: 11.16 toks/s, output: 271.49 toks/s]Processed prompts:  48%|████▊     | 193/405 [2:09:33<4:11:00, 71.04s/it, est. speed input: 11.14 toks/s, output: 274.15 toks/s]WARNING 04-06 07:03:06 scheduler.py:1555] Sequence group 217 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  48%|████▊     | 194/405 [2:10:44<4:10:22, 71.20s/it, est. speed input: 11.08 toks/s, output: 273.99 toks/s]Processed prompts:  48%|████▊     | 195/405 [2:15:17<7:40:55, 131.69s/it, est. speed input: 10.79 toks/s, output: 268.81 toks/s]Processed prompts:  48%|████▊     | 196/405 [2:17:56<8:07:20, 139.91s/it, est. speed input: 10.62 toks/s, output: 267.61 toks/s]Processed prompts:  49%|████▊     | 197/405 [2:19:59<7:47:23, 134.82s/it, est. speed input: 10.51 toks/s, output: 267.59 toks/s]Processed prompts:  49%|████▉     | 198/405 [2:21:10<6:39:04, 115.68s/it, est. speed input: 10.49 toks/s, output: 269.22 toks/s]Processed prompts:  49%|████▉     | 199/405 [2:24:23<7:56:09, 138.69s/it, est. speed input: 10.29 toks/s, output: 267.02 toks/s]Processed prompts:  49%|████▉     | 200/405 [2:28:02<9:16:03, 162.75s/it, est. speed input: 10.09 toks/s, output: 264.13 toks/s]WARNING 04-06 07:25:12 scheduler.py:1555] Sequence group 205 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  50%|████▉     | 201/405 [2:33:38<12:10:40, 214.91s/it, est. speed input: 9.75 toks/s, output: 258.04 toks/s]Processed prompts:  50%|████▉     | 202/405 [2:35:15<10:07:10, 179.46s/it, est. speed input: 9.69 toks/s, output: 258.88 toks/s]Processed prompts:  50%|█████     | 203/405 [2:36:32<8:21:16, 148.90s/it, est. speed input: 9.63 toks/s, output: 260.23 toks/s] Processed prompts:  50%|█████     | 204/405 [2:37:04<6:21:06, 113.76s/it, est. speed input: 9.64 toks/s, output: 262.83 toks/s]Processed prompts:  51%|█████     | 205/405 [2:37:48<5:09:22, 92.81s/it, est. speed input: 9.64 toks/s, output: 265.07 toks/s] Processed prompts:  51%|█████     | 206/405 [2:38:30<4:16:45, 77.42s/it, est. speed input: 9.63 toks/s, output: 267.36 toks/s]WARNING 04-06 07:32:08 scheduler.py:1555] Sequence group 238 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  51%|█████     | 207/405 [2:40:27<4:55:14, 89.47s/it, est. speed input: 9.54 toks/s, output: 267.49 toks/s]Processed prompts:  51%|█████▏    | 208/405 [2:43:05<6:00:35, 109.82s/it, est. speed input: 9.43 toks/s, output: 266.54 toks/s]Processed prompts:  52%|█████▏    | 209/405 [2:50:58<11:55:17, 218.97s/it, est. speed input: 9.02 toks/s, output: 257.43 toks/s]Processed prompts:  52%|█████▏    | 210/405 [2:54:10<11:24:52, 210.73s/it, est. speed input: 8.90 toks/s, output: 255.85 toks/s]Processed prompts:  52%|█████▏    | 211/405 [2:57:02<10:43:50, 199.12s/it, est. speed input: 8.79 toks/s, output: 254.79 toks/s]Processed prompts:  52%|█████▏    | 212/405 [2:57:50<8:15:10, 153.94s/it, est. speed input: 8.77 toks/s, output: 256.70 toks/s] WARNING 04-06 07:52:32 scheduler.py:1555] Sequence group 215 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  53%|█████▎    | 213/405 [3:04:11<11:50:07, 221.91s/it, est. speed input: 8.50 toks/s, output: 250.83 toks/s]Processed prompts:  53%|█████▎    | 214/405 [3:05:16<9:17:04, 175.00s/it, est. speed input: 8.48 toks/s, output: 252.30 toks/s] Processed prompts:  53%|█████▎    | 215/405 [3:06:05<7:13:41, 136.95s/it, est. speed input: 8.47 toks/s, output: 254.14 toks/s]Processed prompts:  53%|█████▎    | 216/405 [3:07:11<6:04:45, 115.80s/it, est. speed input: 8.46 toks/s, output: 255.56 toks/s]Processed prompts:  54%|█████▎    | 217/405 [3:07:29<4:30:58, 86.48s/it, est. speed input: 8.46 toks/s, output: 258.06 toks/s] Processed prompts:  54%|█████▍    | 218/405 [3:07:48<3:26:33, 66.28s/it, est. speed input: 8.47 toks/s, output: 260.53 toks/s]Processed prompts:  54%|█████▍    | 219/405 [3:08:01<2:36:00, 50.32s/it, est. speed input: 8.50 toks/s, output: 260.32 toks/s]Processed prompts:  54%|█████▍    | 220/405 [3:13:42<7:04:01, 137.52s/it, est. speed input: 8.27 toks/s, output: 255.51 toks/s]Processed prompts:  55%|█████▍    | 221/405 [3:14:24<5:33:23, 108.71s/it, est. speed input: 8.27 toks/s, output: 257.41 toks/s]Processed prompts:  55%|█████▍    | 222/405 [3:16:14<5:32:35, 109.05s/it, est. speed input: 8.23 toks/s, output: 257.79 toks/s]Processed prompts:  55%|█████▌    | 223/405 [3:21:41<8:49:31, 174.57s/it, est. speed input: 8.04 toks/s, output: 253.52 toks/s]WARNING 04-06 08:16:21 scheduler.py:1555] Sequence group 228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  55%|█████▌    | 224/405 [3:24:04<8:18:19, 165.19s/it, est. speed input: 7.97 toks/s, output: 253.23 toks/s]Processed prompts:  56%|█████▌    | 225/405 [3:28:45<9:59:16, 199.76s/it, est. speed input: 7.82 toks/s, output: 250.18 toks/s]Processed prompts:  56%|█████▌    | 226/405 [3:29:30<7:37:26, 153.33s/it, est. speed input: 7.82 toks/s, output: 251.89 toks/s]Processed prompts:  56%|█████▌    | 227/405 [3:31:09<6:46:48, 137.12s/it, est. speed input: 7.78 toks/s, output: 252.50 toks/s]Processed prompts:  56%|█████▋    | 228/405 [3:32:16<5:41:57, 115.92s/it, est. speed input: 7.76 toks/s, output: 253.76 toks/s]Processed prompts:  57%|█████▋    | 229/405 [3:33:07<4:43:18, 96.58s/it, est. speed input: 7.74 toks/s, output: 255.30 toks/s] Processed prompts:  57%|█████▋    | 230/405 [3:34:08<4:10:17, 85.81s/it, est. speed input: 7.75 toks/s, output: 256.64 toks/s]WARNING 04-06 08:28:05 scheduler.py:1555] Sequence group 265 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  57%|█████▋    | 231/405 [3:36:31<4:58:50, 103.05s/it, est. speed input: 7.69 toks/s, output: 256.33 toks/s]Processed prompts:  57%|█████▋    | 232/405 [3:43:27<9:27:40, 196.88s/it, est. speed input: 7.47 toks/s, output: 250.83 toks/s]Processed prompts:  58%|█████▊    | 233/405 [3:45:17<8:09:57, 170.92s/it, est. speed input: 7.43 toks/s, output: 251.20 toks/s]Processed prompts:  58%|█████▊    | 234/405 [3:45:22<5:44:59, 121.05s/it, est. speed input: 7.45 toks/s, output: 251.95 toks/s]Processed prompts:  58%|█████▊    | 235/405 [3:52:57<10:27:06, 221.33s/it, est. speed input: 7.23 toks/s, output: 246.09 toks/s]Processed prompts:  58%|█████▊    | 236/405 [3:53:23<7:37:50, 162.55s/it, est. speed input: 7.24 toks/s, output: 247.98 toks/s] Processed prompts:  59%|█████▊    | 237/405 [3:57:41<8:55:42, 191.33s/it, est. speed input: 7.16 toks/s, output: 245.79 toks/s]Processed prompts:  59%|█████▉    | 238/405 [3:57:49<6:19:23, 136.31s/it, est. speed input: 7.19 toks/s, output: 247.16 toks/s]Processed prompts:  59%|█████▉    | 239/405 [3:59:09<5:30:16, 119.38s/it, est. speed input: 7.19 toks/s, output: 248.07 toks/s]Processed prompts:  59%|█████▉    | 240/405 [4:00:20<4:48:13, 104.81s/it, est. speed input: 7.17 toks/s, output: 249.13 toks/s]WARNING 04-06 08:53:18 scheduler.py:1555] Sequence group 253 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  60%|█████▉    | 241/405 [4:01:31<4:19:09, 94.82s/it, est. speed input: 7.16 toks/s, output: 250.16 toks/s] Processed prompts:  60%|█████▉    | 242/405 [4:02:06<3:28:55, 76.91s/it, est. speed input: 7.17 toks/s, output: 251.81 toks/s]Processed prompts:  60%|██████    | 243/405 [4:02:28<2:43:09, 60.43s/it, est. speed input: 7.20 toks/s, output: 253.68 toks/s]Processed prompts:  60%|██████    | 244/405 [4:04:01<3:08:00, 70.06s/it, est. speed input: 7.17 toks/s, output: 254.32 toks/s]Processed prompts:  60%|██████    | 245/405 [4:04:46<2:47:00, 62.63s/it, est. speed input: 7.20 toks/s, output: 254.21 toks/s]Processed prompts:  61%|██████    | 246/405 [4:12:11<7:49:53, 177.32s/it, est. speed input: 7.01 toks/s, output: 248.90 toks/s]Processed prompts:  61%|██████    | 247/405 [4:13:45<6:41:16, 152.38s/it, est. speed input: 6.98 toks/s, output: 248.50 toks/s]Processed prompts:  61%|██████    | 248/405 [4:14:23<5:08:28, 117.89s/it, est. speed input: 6.98 toks/s, output: 250.04 toks/s]Processed prompts:  61%|██████▏   | 249/405 [4:16:36<5:18:34, 122.53s/it, est. speed input: 6.94 toks/s, output: 249.40 toks/s]Processed prompts:  62%|██████▏   | 250/405 [4:18:51<5:26:36, 126.43s/it, est. speed input: 6.90 toks/s, output: 249.34 toks/s]WARNING 04-06 09:13:18 scheduler.py:1555] Sequence group 261 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  62%|██████▏   | 251/405 [4:23:07<7:04:09, 165.25s/it, est. speed input: 6.81 toks/s, output: 247.37 toks/s]Processed prompts:  62%|██████▏   | 252/405 [4:24:33<6:00:11, 141.25s/it, est. speed input: 6.79 toks/s, output: 248.11 toks/s]Processed prompts:  62%|██████▏   | 253/405 [4:26:33<5:42:24, 135.16s/it, est. speed input: 6.75 toks/s, output: 248.28 toks/s]Processed prompts:  63%|██████▎   | 254/405 [4:27:58<5:02:07, 120.05s/it, est. speed input: 6.75 toks/s, output: 249.01 toks/s]Processed prompts:  63%|██████▎   | 255/405 [4:29:28<4:37:03, 110.82s/it, est. speed input: 6.73 toks/s, output: 249.66 toks/s]Processed prompts:  63%|██████▎   | 256/405 [4:29:56<3:33:28, 85.96s/it, est. speed input: 6.73 toks/s, output: 251.25 toks/s] Processed prompts:  63%|██████▎   | 257/405 [4:31:53<3:55:21, 95.42s/it, est. speed input: 6.72 toks/s, output: 251.45 toks/s]Processed prompts:  64%|██████▎   | 258/405 [4:36:57<6:26:47, 157.87s/it, est. speed input: 6.61 toks/s, output: 248.83 toks/s]Processed prompts:  64%|██████▍   | 259/405 [4:39:25<6:17:34, 155.17s/it, est. speed input: 6.57 toks/s, output: 248.57 toks/s]Processed prompts:  64%|██████▍   | 260/405 [4:44:43<8:12:43, 203.88s/it, est. speed input: 6.46 toks/s, output: 245.87 toks/s]Processed prompts:  64%|██████▍   | 261/405 [4:46:32<7:01:09, 175.48s/it, est. speed input: 6.44 toks/s, output: 246.22 toks/s]Processed prompts:  65%|██████▍   | 262/405 [4:51:00<8:04:02, 203.10s/it, est. speed input: 6.36 toks/s, output: 244.32 toks/s]Processed prompts:  65%|██████▍   | 263/405 [4:52:34<6:43:05, 170.32s/it, est. speed input: 6.34 toks/s, output: 244.88 toks/s]WARNING 04-06 09:46:22 scheduler.py:1555] Sequence group 275 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  65%|██████▌   | 264/405 [4:54:03<5:43:14, 146.06s/it, est. speed input: 6.33 toks/s, output: 245.50 toks/s]Processed prompts:  65%|██████▌   | 265/405 [4:54:42<4:26:07, 114.05s/it, est. speed input: 6.33 toks/s, output: 246.80 toks/s]Processed prompts:  66%|██████▌   | 266/405 [4:56:22<4:14:10, 109.72s/it, est. speed input: 6.31 toks/s, output: 247.26 toks/s]Processed prompts:  66%|██████▌   | 267/405 [4:56:30<3:01:56, 79.10s/it, est. speed input: 6.34 toks/s, output: 248.35 toks/s] Processed prompts:  66%|██████▌   | 268/405 [4:57:36<2:51:47, 75.24s/it, est. speed input: 6.35 toks/s, output: 249.26 toks/s]WARNING 04-06 09:51:09 scheduler.py:1555] Sequence group 298 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  66%|██████▋   | 269/405 [4:58:42<2:44:08, 72.41s/it, est. speed input: 6.37 toks/s, output: 250.18 toks/s]Processed prompts:  67%|██████▋   | 270/405 [4:59:25<2:23:17, 63.68s/it, est. speed input: 6.36 toks/s, output: 249.73 toks/s]Processed prompts:  67%|██████▋   | 271/405 [5:02:14<3:32:46, 95.27s/it, est. speed input: 6.32 toks/s, output: 249.21 toks/s]WARNING 04-06 09:58:05 scheduler.py:1555] Sequence group 283 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  67%|██████▋   | 272/405 [5:06:16<5:08:34, 139.21s/it, est. speed input: 6.25 toks/s, output: 247.71 toks/s]Processed prompts:  67%|██████▋   | 273/405 [5:06:30<3:43:38, 101.66s/it, est. speed input: 6.26 toks/s, output: 249.31 toks/s]Processed prompts:  68%|██████▊   | 274/405 [5:08:25<3:51:00, 105.80s/it, est. speed input: 6.23 toks/s, output: 249.52 toks/s]Processed prompts:  68%|██████▊   | 275/405 [5:12:51<5:33:00, 153.70s/it, est. speed input: 6.18 toks/s, output: 246.86 toks/s]Processed prompts:  68%|██████▊   | 276/405 [5:15:16<5:24:57, 151.15s/it, est. speed input: 6.15 toks/s, output: 246.70 toks/s]Processed prompts:  68%|██████▊   | 277/405 [5:16:12<4:21:24, 122.53s/it, est. speed input: 6.16 toks/s, output: 247.70 toks/s]Processed prompts:  69%|██████▊   | 278/405 [5:21:38<6:28:26, 183.52s/it, est. speed input: 6.09 toks/s, output: 245.22 toks/s]Processed prompts:  69%|██████▉   | 279/405 [5:24:29<6:17:49, 179.92s/it, est. speed input: 6.07 toks/s, output: 244.74 toks/s]Processed prompts:  69%|██████▉   | 280/405 [5:28:41<6:59:37, 201.42s/it, est. speed input: 6.01 toks/s, output: 243.28 toks/s]Processed prompts:  69%|██████▉   | 281/405 [5:28:41<4:51:33, 141.08s/it, est. speed input: 6.03 toks/s, output: 244.94 toks/s]Processed prompts:  70%|██████▉   | 282/405 [5:28:44<3:24:38, 99.82s/it, est. speed input: 6.04 toks/s, output: 246.56 toks/s] Processed prompts:  70%|██████▉   | 283/405 [5:28:47<2:23:23, 70.52s/it, est. speed input: 6.06 toks/s, output: 248.19 toks/s]Processed prompts:  70%|███████   | 284/405 [5:28:53<1:43:17, 51.22s/it, est. speed input: 6.07 toks/s, output: 248.13 toks/s]Processed prompts:  70%|███████   | 285/405 [5:29:00<1:15:54, 37.95s/it, est. speed input: 6.08 toks/s, output: 248.17 toks/s]Processed prompts:  71%|███████   | 286/405 [5:29:12<1:00:13, 30.37s/it, est. speed input: 6.11 toks/s, output: 249.67 toks/s]WARNING 04-06 10:22:19 scheduler.py:1555] Sequence group 365 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  71%|███████   | 287/405 [5:30:23<1:23:32, 42.48s/it, est. speed input: 6.10 toks/s, output: 249.75 toks/s]Processed prompts:  71%|███████   | 288/405 [5:30:29<1:01:19, 31.45s/it, est. speed input: 6.12 toks/s, output: 251.33 toks/s]Processed prompts:  71%|███████▏  | 289/405 [5:30:39<48:11, 24.93s/it, est. speed input: 6.16 toks/s, output: 251.23 toks/s]  WARNING 04-06 10:23:43 scheduler.py:1555] Sequence group 362 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
WARNING 04-06 10:27:22 scheduler.py:1555] Sequence group 311 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301
Processed prompts:  72%|███████▏  | 290/405 [5:41:02<6:31:47, 204.41s/it, est. speed input: 5.99 toks/s, output: 245.18 toks/s]Processed prompts:  72%|███████▏  | 291/405 [5:42:04<5:07:02, 161.60s/it, est. speed input: 5.98 toks/s, output: 245.09 toks/s]Processed prompts:  72%|███████▏  | 292/405 [5:43:49<4:32:46, 144.84s/it, est. speed input: 5.97 toks/s, output: 245.42 toks/s]Processed prompts:  72%|███████▏  | 293/405 [5:44:13<3:22:35, 108.53s/it, est. speed input: 5.98 toks/s, output: 246.72 toks/s]Processed prompts:  73%|███████▎  | 294/405 [5:55:05<8:22:14, 271.48s/it, est. speed input: 5.83 toks/s, output: 240.72 toks/s]Processed prompts:  73%|███████▎  | 295/405 [5:55:34<6:04:20, 198.73s/it, est. speed input: 5.83 toks/s, output: 241.13 toks/s]Processed prompts:  73%|███████▎  | 296/405 [5:56:17<4:36:24, 152.15s/it, est. speed input: 5.83 toks/s, output: 242.17 toks/s]Processed prompts:  73%|███████▎  | 297/405 [5:57:23<3:47:08, 126.19s/it, est. speed input: 5.83 toks/s, output: 242.96 toks/s]Processed prompts:  74%|███████▎  | 298/405 [5:58:26<3:11:09, 107.19s/it, est. speed input: 5.85 toks/s, output: 243.77 toks/s]Processed prompts:  74%|███████▍  | 299/405 [5:58:56<2:28:26, 84.02s/it, est. speed input: 5.86 toks/s, output: 244.96 toks/s] Processed prompts:  74%|███████▍  | 300/405 [5:59:08<1:49:17, 62.45s/it, est. speed input: 5.86 toks/s, output: 246.34 toks/s]Processed prompts:  74%|███████▍  | 301/405 [5:59:23<1:23:29, 48.17s/it, est. speed input: 5.87 toks/s, output: 247.69 toks/s]Processed prompts:  75%|███████▍  | 302/405 [5:59:25<59:05, 34.43s/it, est. speed input: 5.89 toks/s, output: 248.08 toks/s]  Processed prompts:  75%|███████▍  | 303/405 [6:00:05<1:01:21, 36.09s/it, est. speed input: 5.90 toks/s, output: 247.96 toks/s]Processed prompts:  75%|███████▌  | 304/405 [6:00:55<1:07:40, 40.20s/it, est. speed input: 5.90 toks/s, output: 248.90 toks/s]WARNING 04-06 10:56:27 scheduler.py:1555] Sequence group 319 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351
Processed prompts:  75%|███████▌  | 305/405 [6:05:31<3:04:53, 110.93s/it, est. speed input: 5.83 toks/s, output: 247.26 toks/s]Processed prompts:  76%|███████▌  | 306/405 [6:12:53<5:46:55, 210.26s/it, est. speed input: 5.73 toks/s, output: 243.84 toks/s]Processed prompts:  76%|███████▌  | 307/405 [6:13:14<4:10:47, 153.55s/it, est. speed input: 5.74 toks/s, output: 245.08 toks/s]Processed prompts:  76%|███████▌  | 308/405 [6:19:42<6:02:00, 223.92s/it, est. speed input: 5.65 toks/s, output: 242.34 toks/s]Processed prompts:  76%|███████▋  | 309/405 [6:21:30<5:02:42, 189.20s/it, est. speed input: 5.63 toks/s, output: 242.63 toks/s]Processed prompts:  77%|███████▋  | 310/405 [6:23:27<4:24:58, 167.35s/it, est. speed input: 5.62 toks/s, output: 242.82 toks/s]Processed prompts:  77%|███████▋  | 311/405 [6:24:23<3:30:12, 134.18s/it, est. speed input: 5.61 toks/s, output: 243.65 toks/s]Processed prompts:  77%|███████▋  | 312/405 [6:25:02<2:43:34, 105.54s/it, est. speed input: 5.61 toks/s, output: 243.65 toks/s]Processed prompts:  77%|███████▋  | 313/405 [6:25:06<1:55:11, 75.12s/it, est. speed input: 5.62 toks/s, output: 245.03 toks/s] Processed prompts:  78%|███████▊  | 314/405 [6:25:25<1:28:11, 58.15s/it, est. speed input: 5.63 toks/s, output: 246.25 toks/s]Processed prompts:  78%|███████▊  | 315/405 [6:25:57<1:15:42, 50.47s/it, est. speed input: 5.64 toks/s, output: 247.32 toks/s]Processed prompts:  78%|███████▊  | 316/405 [6:26:40<1:11:10, 47.98s/it, est. speed input: 5.64 toks/s, output: 248.28 toks/s]WARNING 04-06 11:20:37 scheduler.py:1555] Sequence group 341 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401
Processed prompts:  78%|███████▊  | 317/405 [6:28:19<1:32:53, 63.33s/it, est. speed input: 5.64 toks/s, output: 247.69 toks/s]Processed prompts:  79%|███████▊  | 318/405 [6:29:01<1:22:44, 57.07s/it, est. speed input: 5.64 toks/s, output: 247.62 toks/s]Processed prompts:  79%|███████▉  | 319/405 [6:29:50<1:18:06, 54.49s/it, est. speed input: 5.65 toks/s, output: 247.77 toks/s]Processed prompts:  79%|███████▉  | 320/405 [6:33:04<2:16:31, 96.37s/it, est. speed input: 5.61 toks/s, output: 247.12 toks/s]Processed prompts:  79%|███████▉  | 321/405 [6:36:48<3:08:26, 134.60s/it, est. speed input: 5.57 toks/s, output: 246.18 toks/s]Processed prompts:  80%|███████▉  | 322/405 [6:38:55<3:03:17, 132.50s/it, est. speed input: 5.56 toks/s, output: 246.23 toks/s]Processed prompts:  80%|███████▉  | 323/405 [6:39:16<2:15:18, 99.01s/it, est. speed input: 5.58 toks/s, output: 246.81 toks/s] Processed prompts:  80%|████████  | 324/405 [6:44:45<3:46:54, 168.08s/it, est. speed input: 5.52 toks/s, output: 244.81 toks/s]Processed prompts:  80%|████████  | 325/405 [6:50:31<4:55:08, 221.35s/it, est. speed input: 5.45 toks/s, output: 242.70 toks/s]Processed prompts:  80%|████████  | 326/405 [6:51:04<3:37:04, 164.86s/it, est. speed input: 5.45 toks/s, output: 243.71 toks/s]Processed prompts:  81%|████████  | 327/405 [6:51:36<2:42:22, 124.90s/it, est. speed input: 5.46 toks/s, output: 244.72 toks/s]Processed prompts:  81%|████████  | 328/405 [6:51:43<1:55:08, 89.72s/it, est. speed input: 5.47 toks/s, output: 245.31 toks/s] Processed prompts:  81%|████████  | 329/405 [6:51:44<1:19:46, 62.98s/it, est. speed input: 5.48 toks/s, output: 246.42 toks/s]Processed prompts:  81%|████████▏ | 330/405 [6:53:40<1:38:50, 79.07s/it, est. speed input: 5.46 toks/s, output: 246.59 toks/s]WARNING 04-06 11:46:43 scheduler.py:1555] Sequence group 350 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451
Processed prompts:  82%|████████▏ | 331/405 [6:54:21<1:23:09, 67.42s/it, est. speed input: 5.48 toks/s, output: 247.51 toks/s]Processed prompts:  82%|████████▏ | 332/405 [6:54:30<1:00:46, 49.95s/it, est. speed input: 5.49 toks/s, output: 248.16 toks/s]Processed prompts:  82%|████████▏ | 333/405 [6:54:48<48:25, 40.35s/it, est. speed input: 5.49 toks/s, output: 249.30 toks/s]  Processed prompts:  82%|████████▏ | 334/405 [6:55:15<42:58, 36.31s/it, est. speed input: 5.49 toks/s, output: 250.34 toks/s]WARNING 04-06 11:50:10 scheduler.py:1555] Sequence group 370 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501
Processed prompts:  83%|████████▎ | 335/405 [7:07:51<4:54:12, 252.18s/it, est. speed input: 5.34 toks/s, output: 244.25 toks/s]Processed prompts:  83%|████████▎ | 336/405 [7:12:04<4:50:19, 252.46s/it, est. speed input: 5.32 toks/s, output: 243.13 toks/s]Processed prompts:  83%|████████▎ | 337/405 [7:16:30<4:50:47, 256.58s/it, est. speed input: 5.27 toks/s, output: 241.29 toks/s]Processed prompts:  83%|████████▎ | 338/405 [7:17:44<3:45:14, 201.70s/it, est. speed input: 5.27 toks/s, output: 241.86 toks/s]Processed prompts:  84%|████████▎ | 339/405 [7:18:34<2:51:52, 156.24s/it, est. speed input: 5.26 toks/s, output: 242.64 toks/s]Processed prompts:  84%|████████▍ | 340/405 [7:19:23<2:14:34, 124.22s/it, est. speed input: 5.28 toks/s, output: 243.43 toks/s]Processed prompts:  84%|████████▍ | 341/405 [7:19:28<1:34:11, 88.31s/it, est. speed input: 5.29 toks/s, output: 243.76 toks/s] Processed prompts:  84%|████████▍ | 342/405 [7:20:04<1:16:14, 72.61s/it, est. speed input: 5.29 toks/s, output: 244.67 toks/s]Processed prompts:  85%|████████▍ | 343/405 [7:20:57<1:08:54, 66.68s/it, est. speed input: 5.29 toks/s, output: 245.42 toks/s]Processed prompts:  85%|████████▍ | 344/405 [7:21:23<55:38, 54.74s/it, est. speed input: 5.29 toks/s, output: 246.41 toks/s]  Processed prompts:  85%|████████▌ | 345/405 [7:21:51<46:35, 46.59s/it, est. speed input: 5.29 toks/s, output: 247.39 toks/s]Processed prompts:  85%|████████▌ | 346/405 [7:24:01<1:10:23, 71.58s/it, est. speed input: 5.28 toks/s, output: 247.41 toks/s]WARNING 04-06 12:17:35 scheduler.py:1555] Sequence group 364 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551
Processed prompts:  86%|████████▌ | 347/405 [7:25:28<1:13:38, 76.17s/it, est. speed input: 5.28 toks/s, output: 246.95 toks/s]Processed prompts:  86%|████████▌ | 348/405 [7:28:49<1:47:54, 113.59s/it, est. speed input: 5.25 toks/s, output: 245.61 toks/s]Processed prompts:  86%|████████▌ | 349/405 [7:31:51<2:05:16, 134.23s/it, est. speed input: 5.22 toks/s, output: 245.16 toks/s]Processed prompts:  86%|████████▋ | 350/405 [7:32:51<1:42:38, 111.97s/it, est. speed input: 5.22 toks/s, output: 245.22 toks/s]Processed prompts:  87%|████████▋ | 351/405 [7:33:32<1:21:40, 90.74s/it, est. speed input: 5.23 toks/s, output: 245.64 toks/s] Processed prompts:  87%|████████▋ | 352/405 [7:34:18<1:08:20, 77.36s/it, est. speed input: 5.23 toks/s, output: 246.43 toks/s]Processed prompts:  87%|████████▋ | 353/405 [7:39:52<2:13:40, 154.23s/it, est. speed input: 5.18 toks/s, output: 244.64 toks/s]Processed prompts:  87%|████████▋ | 354/405 [7:40:55<1:47:46, 126.80s/it, est. speed input: 5.17 toks/s, output: 245.27 toks/s]Processed prompts:  88%|████████▊ | 355/405 [7:42:54<1:43:50, 124.60s/it, est. speed input: 5.16 toks/s, output: 245.39 toks/s]Processed prompts:  88%|████████▊ | 356/405 [7:44:59<1:41:47, 124.64s/it, est. speed input: 5.15 toks/s, output: 245.47 toks/s]Processed prompts:  88%|████████▊ | 357/405 [7:45:06<1:11:24, 89.26s/it, est. speed input: 5.18 toks/s, output: 245.60 toks/s] Processed prompts:  88%|████████▊ | 358/405 [7:45:40<56:53, 72.63s/it, est. speed input: 5.18 toks/s, output: 246.47 toks/s]  Processed prompts:  89%|████████▊ | 359/405 [7:45:51<41:41, 54.38s/it, est. speed input: 5.20 toks/s, output: 246.76 toks/s]Processed prompts:  89%|████████▉ | 360/405 [7:46:43<40:07, 53.49s/it, est. speed input: 5.20 toks/s, output: 247.47 toks/s]Processed prompts:  89%|████████▉ | 361/405 [7:47:55<43:25, 59.22s/it, est. speed input: 5.19 toks/s, output: 248.00 toks/s]WARNING 04-06 12:41:56 scheduler.py:1555] Sequence group 382 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601
Processed prompts:  89%|████████▉ | 362/405 [7:54:29<1:54:21, 159.57s/it, est. speed input: 5.13 toks/s, output: 245.72 toks/s]Processed prompts:  90%|████████▉ | 363/405 [7:55:24<1:29:44, 128.20s/it, est. speed input: 5.14 toks/s, output: 246.40 toks/s]Processed prompts:  90%|████████▉ | 364/405 [7:55:30<1:02:35, 91.61s/it, est. speed input: 5.17 toks/s, output: 246.72 toks/s] Processed prompts:  90%|█████████ | 365/405 [7:56:18<52:15, 78.38s/it, est. speed input: 5.17 toks/s, output: 247.45 toks/s]  Processed prompts:  90%|█████████ | 366/405 [8:00:08<1:20:36, 124.02s/it, est. speed input: 5.13 toks/s, output: 246.61 toks/s]Processed prompts:  91%|█████████ | 367/405 [8:05:16<1:53:24, 179.06s/it, est. speed input: 5.09 toks/s, output: 245.13 toks/s]Processed prompts:  91%|█████████ | 368/405 [8:06:18<1:28:52, 144.11s/it, est. speed input: 5.10 toks/s, output: 245.01 toks/s]Processed prompts:  91%|█████████ | 369/405 [8:10:12<1:42:34, 170.96s/it, est. speed input: 5.08 toks/s, output: 244.18 toks/s]Processed prompts:  91%|█████████▏| 370/405 [8:13:02<1:39:33, 170.66s/it, est. speed input: 5.07 toks/s, output: 243.88 toks/s]Processed prompts:  92%|█████████▏| 371/405 [8:13:47<1:15:16, 132.84s/it, est. speed input: 5.11 toks/s, output: 244.62 toks/s]Processed prompts:  92%|█████████▏| 372/405 [8:14:07<54:28, 99.05s/it, est. speed input: 5.13 toks/s, output: 245.56 toks/s]   Processed prompts:  92%|█████████▏| 373/405 [8:14:29<40:36, 76.13s/it, est. speed input: 5.18 toks/s, output: 245.58 toks/s]Processed prompts:  92%|█████████▏| 374/405 [8:14:48<30:26, 58.93s/it, est. speed input: 5.20 toks/s, output: 246.53 toks/s]Processed prompts:  93%|█████████▎| 375/405 [8:15:28<26:33, 53.11s/it, est. speed input: 5.23 toks/s, output: 247.30 toks/s]Processed prompts:  93%|█████████▎| 376/405 [8:16:16<25:01, 51.77s/it, est. speed input: 5.24 toks/s, output: 248.00 toks/s]WARNING 04-06 13:11:42 scheduler.py:1555] Sequence group 396 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651
Processed prompts:  93%|█████████▎| 377/405 [8:19:51<46:59, 100.68s/it, est. speed input: 5.21 toks/s, output: 247.32 toks/s]Processed prompts:  93%|█████████▎| 378/405 [8:25:58<1:21:16, 180.59s/it, est. speed input: 5.18 toks/s, output: 245.41 toks/s]Processed prompts:  94%|█████████▎| 379/405 [8:26:03<55:22, 127.80s/it, est. speed input: 5.23 toks/s, output: 245.74 toks/s]  Processed prompts:  94%|█████████▍| 380/405 [8:28:03<52:17, 125.50s/it, est. speed input: 5.25 toks/s, output: 245.85 toks/s]Processed prompts:  94%|█████████▍| 381/405 [8:28:08<35:41, 89.23s/it, est. speed input: 5.29 toks/s, output: 246.19 toks/s] Processed prompts:  94%|█████████▍| 382/405 [8:29:04<30:27, 79.47s/it, est. speed input: 5.35 toks/s, output: 246.08 toks/s]Processed prompts:  95%|█████████▍| 383/405 [8:34:39<57:12, 156.00s/it, est. speed input: 5.32 toks/s, output: 244.48 toks/s]Processed prompts:  95%|█████████▍| 384/405 [8:39:25<1:08:15, 195.03s/it, est. speed input: 5.31 toks/s, output: 243.29 toks/s]Processed prompts:  95%|█████████▌| 385/405 [8:41:43<59:15, 177.78s/it, est. speed input: 5.31 toks/s, output: 243.26 toks/s]  Processed prompts:  95%|█████████▌| 386/405 [8:41:47<39:49, 125.74s/it, est. speed input: 5.35 toks/s, output: 243.92 toks/s]Processed prompts:  96%|█████████▌| 387/405 [8:41:52<26:53, 89.66s/it, est. speed input: 5.40 toks/s, output: 244.64 toks/s] Processed prompts:  96%|█████████▌| 388/405 [8:42:45<22:17, 78.69s/it, est. speed input: 5.43 toks/s, output: 245.27 toks/s]Processed prompts:  96%|█████████▌| 389/405 [8:43:35<18:37, 69.84s/it, est. speed input: 5.48 toks/s, output: 245.93 toks/s]Processed prompts:  96%|█████████▋| 390/405 [8:43:56<13:50, 55.38s/it, est. speed input: 5.53 toks/s, output: 246.81 toks/s]Processed prompts:  97%|█████████▋| 391/405 [8:44:14<10:17, 44.12s/it, est. speed input: 5.57 toks/s, output: 247.71 toks/s]Processed prompts:  97%|█████████▋| 392/405 [8:44:34<07:57, 36.75s/it, est. speed input: 5.60 toks/s, output: 248.60 toks/s]Processed prompts:  97%|█████████▋| 393/405 [8:48:43<20:05, 100.47s/it, est. speed input: 5.65 toks/s, output: 247.06 toks/s]Processed prompts:  97%|█████████▋| 394/405 [8:55:54<36:36, 199.65s/it, est. speed input: 5.62 toks/s, output: 244.77 toks/s]Processed prompts:  98%|█████████▊| 395/405 [8:56:53<26:16, 157.62s/it, est. speed input: 5.69 toks/s, output: 244.80 toks/s]Processed prompts:  98%|█████████▊| 396/405 [8:57:23<17:52, 119.17s/it, est. speed input: 5.77 toks/s, output: 245.00 toks/s]Processed prompts:  98%|█████████▊| 397/405 [9:01:45<21:37, 162.21s/it, est. speed input: 5.77 toks/s, output: 244.03 toks/s]Processed prompts:  98%|█████████▊| 398/405 [9:04:27<18:54, 162.03s/it, est. speed input: 5.82 toks/s, output: 243.82 toks/s]Processed prompts:  99%|█████████▊| 399/405 [9:07:19<16:29, 164.86s/it, est. speed input: 5.85 toks/s, output: 243.55 toks/s]Processed prompts:  99%|█████████▉| 400/405 [9:08:03<10:44, 128.86s/it, est. speed input: 5.89 toks/s, output: 244.21 toks/s]Processed prompts:  99%|█████████▉| 401/405 [9:09:06<07:16, 109.09s/it, est. speed input: 5.93 toks/s, output: 244.74 toks/s]Processed prompts:  99%|█████████▉| 402/405 [9:09:35<04:14, 84.85s/it, est. speed input: 5.99 toks/s, output: 245.52 toks/s] Processed prompts: 100%|█████████▉| 403/405 [9:09:50<02:08, 64.07s/it, est. speed input: 6.07 toks/s, output: 246.40 toks/s]Processed prompts: 100%|█████████▉| 404/405 [9:10:01<00:48, 48.16s/it, est. speed input: 6.13 toks/s, output: 247.31 toks/s]Processed prompts: 100%|██████████| 405/405 [9:11:58<00:00, 68.87s/it, est. speed input: 6.16 toks/s, output: 247.42 toks/s]Processed prompts: 100%|██████████| 405/405 [9:11:58<00:00, 81.78s/it, est. speed input: 6.16 toks/s, output: 247.42 toks/s]
INFO 04-06 14:04:44 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2195758)[0;0m INFO 04-06 14:04:44 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2195760)[0;0m INFO 04-06 14:04:44 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2195759)[0;0m INFO 04-06 14:04:44 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W406 14:04:58.891828642 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-06 14:05:14 config.py:510] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 04-06 14:05:14 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-06 14:05:14 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-06 14:05:14 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-06 14:05:14 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-06 14:05:14 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-06 14:05:14 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-06 14:05:16 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:16 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:16 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:16 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:16 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:16 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:16 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-06 14:05:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:17 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-06 14:05:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:17 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:17 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2371574)[0;0m WARNING 04-06 14:05:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2371573)[0;0m WARNING 04-06 14:05:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-06 14:05:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2371572)[0;0m WARNING 04-06 14:05:17 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-06 14:05:17 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_e0183715'), local_subscribe_port=39121, remote_subscribe_port=None)
INFO 04-06 14:05:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:17 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.52it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.71it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.18it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  2.00it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.92it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.85it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.80it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.76it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.74it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.72it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.72it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.85it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.81it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.78it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.87it/s]

INFO 04-06 14:05:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:25 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:26 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:28 worker.py:241] Memory profiling takes 2.63 seconds
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:28 worker.py:241] Memory profiling takes 2.64 seconds
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:28 worker.py:241] Memory profiling takes 2.65 seconds
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-06 14:05:28 worker.py:241] Memory profiling takes 2.75 seconds
INFO 04-06 14:05:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-06 14:05:28 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-06 14:05:29 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-06 14:05:29 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:05:43 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:05:43 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:05:43 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-06 14:05:43 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:10,  1.00s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:12,  1.03s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:11,  1.03s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:10,  1.02s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:09,  1.03s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:06,  1.02s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:05,  1.01s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:04,  1.01s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<02:02,  1.00s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<02:02,  1.01s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:11<02:01,  1.01s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:12<02:00,  1.01s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:13<01:59,  1.01s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:14<01:58,  1.01s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:15<01:56,  1.00s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:16<01:55,  1.00s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:17<01:52,  1.01it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:18<01:52,  1.01it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:19<01:50,  1.02it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:20<01:47,  1.03it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:20<01:46,  1.04it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:21<01:44,  1.05it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:22<01:43,  1.04it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:23<01:42,  1.05it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:24<01:41,  1.04it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:25<01:41,  1.04it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:26<01:39,  1.04it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:27<01:38,  1.05it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:28<01:36,  1.05it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:29<01:36,  1.05it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:30<01:35,  1.05it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:31<01:33,  1.06it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:32<01:32,  1.07it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:33<01:29,  1.08it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:34<01:28,  1.09it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:35<01:26,  1.10it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:35<01:25,  1.10it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:36<01:24,  1.10it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:37<01:23,  1.10it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:38<01:23,  1.10it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:39<01:20,  1.12it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:40<01:19,  1.12it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:41<01:17,  1.13it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:42<01:17,  1.13it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:43<01:16,  1.12it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:43<01:15,  1.12it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:44<01:14,  1.13it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:45<01:13,  1.13it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:46<01:12,  1.14it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:47<01:10,  1.15it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:48<01:09,  1.15it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:49<01:07,  1.16it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:50<01:06,  1.17it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:50<01:06,  1.16it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:51<01:05,  1.16it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:52<01:05,  1.15it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:53<01:03,  1.16it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:54<01:03,  1.16it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:55<01:01,  1.16it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:56<01:00,  1.18it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:56<00:59,  1.18it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:57<00:58,  1.18it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:58<00:57,  1.18it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:59<00:56,  1.19it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:00<00:54,  1.21it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:00<00:53,  1.22it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:01<00:51,  1.24it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:02<00:50,  1.25it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:03<00:48,  1.27it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:04<00:48,  1.27it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:04<00:47,  1.26it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:05<00:46,  1.26it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:06<00:45,  1.27it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:07<00:44,  1.27it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:08<00:43,  1.29it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:08<00:42,  1.30it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:09<00:41,  1.29it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:10<00:40,  1.30it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:11<00:39,  1.30it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:11<00:39,  1.30it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:12<00:38,  1.31it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:13<00:36,  1.34it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:14<00:35,  1.35it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:14<00:34,  1.36it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:15<00:34,  1.34it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:16<00:33,  1.33it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:17<00:32,  1.36it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:17<00:31,  1.38it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:18<00:30,  1.39it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:19<00:29,  1.41it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:19<00:28,  1.41it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:20<00:27,  1.40it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:21<00:27,  1.41it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:21<00:26,  1.41it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:22<00:25,  1.41it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:23<00:24,  1.43it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:23<00:23,  1.46it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:24<00:22,  1.46it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:25<00:22,  1.45it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:26<00:21,  1.45it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:26<00:20,  1.46it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:27<00:19,  1.48it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:28<00:19,  1.46it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:28<00:18,  1.48it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:29<00:17,  1.48it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:30<00:16,  1.50it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:30<00:15,  1.51it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:31<00:15,  1.51it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:32<00:14,  1.51it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:32<00:13,  1.54it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:33<00:12,  1.54it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:33<00:12,  1.54it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:34<00:11,  1.57it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:35<00:10,  1.57it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:35<00:09,  1.60it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:36<00:09,  1.62it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:37<00:08,  1.62it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:37<00:08,  1.62it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:38<00:07,  1.62it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:38<00:06,  1.64it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:39<00:06,  1.63it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:40<00:05,  1.65it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:40<00:04,  1.64it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:41<00:04,  1.64it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:41<00:03,  1.65it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:42<00:03,  1.67it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:43<00:02,  1.65it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:43<00:01,  1.66it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:44<00:01,  1.67it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:44<00:00,  1.67it/s][1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 14:07:29 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:45<00:00,  1.44it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:45<00:00,  1.24it/s]
INFO 04-06 14:07:29 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 14:07:29 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 14:07:29 model_runner.py:1535] Graph capturing finished in 106 secs, took 8.20 GiB
INFO 04-06 14:07:29 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 123.01 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: hamilton
Generating answers for task: hamilton
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-06 14:08:31 scheduler.py:1555] Sequence group 238 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-06 14:09:01 scheduler.py:1555] Sequence group 190 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-06 14:09:43 scheduler.py:1555] Sequence group 142 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   0%|          | 1/500 [02:44<22:51:23, 164.90s/it, est. speed input: 1.47 toks/s, output: 6.21 toks/s]Processed prompts:   0%|          | 2/500 [02:45<9:28:46, 68.53s/it, est. speed input: 2.89 toks/s, output: 12.48 toks/s] Processed prompts:   1%|          | 3/500 [02:47<5:13:29, 37.85s/it, est. speed input: 4.47 toks/s, output: 18.67 toks/s]Processed prompts:   1%|          | 4/500 [02:55<3:35:32, 26.07s/it, est. speed input: 5.61 toks/s, output: 24.39 toks/s]Processed prompts:   1%|          | 5/500 [02:55<2:18:03, 16.73s/it, est. speed input: 7.20 toks/s, output: 30.96 toks/s]Processed prompts:   1%|          | 6/500 [02:57<1:35:50, 11.64s/it, est. speed input: 8.63 toks/s, output: 37.29 toks/s]Processed prompts:   1%|▏         | 7/500 [02:57<1:05:33,  7.98s/it, est. speed input: 9.98 toks/s, output: 43.99 toks/s]Processed prompts:   2%|▏         | 9/500 [03:02<43:32,  5.32s/it, est. speed input: 12.47 toks/s, output: 56.33 toks/s] Processed prompts:   2%|▏         | 10/500 [03:04<35:56,  4.40s/it, est. speed input: 13.83 toks/s, output: 62.70 toks/s]Processed prompts:   2%|▏         | 11/500 [03:04<26:48,  3.29s/it, est. speed input: 15.13 toks/s, output: 69.51 toks/s]Processed prompts:   2%|▏         | 12/500 [03:06<22:25,  2.76s/it, est. speed input: 16.42 toks/s, output: 75.97 toks/s]Processed prompts:   3%|▎         | 13/500 [03:07<20:33,  2.53s/it, est. speed input: 17.60 toks/s, output: 82.02 toks/s]Processed prompts:   3%|▎         | 14/500 [03:10<21:11,  2.62s/it, est. speed input: 18.74 toks/s, output: 87.76 toks/s]Processed prompts:   3%|▎         | 15/500 [03:11<16:35,  2.05s/it, est. speed input: 19.91 toks/s, output: 94.61 toks/s]Processed prompts:   3%|▎         | 16/500 [03:20<33:08,  4.11s/it, est. speed input: 20.50 toks/s, output: 97.67 toks/s]Processed prompts:   3%|▎         | 17/500 [03:31<49:44,  6.18s/it, est. speed input: 20.63 toks/s, output: 100.06 toks/s]Processed prompts:   4%|▎         | 18/500 [03:34<40:36,  5.05s/it, est. speed input: 21.64 toks/s, output: 106.43 toks/s]Processed prompts:   4%|▍         | 19/500 [03:38<38:19,  4.78s/it, est. speed input: 27.18 toks/s, output: 111.97 toks/s]Processed prompts:   4%|▍         | 20/500 [03:43<39:30,  4.94s/it, est. speed input: 27.67 toks/s, output: 117.01 toks/s]Processed prompts:   4%|▍         | 22/500 [03:47<28:55,  3.63s/it, est. speed input: 29.64 toks/s, output: 130.28 toks/s]Processed prompts:   5%|▍         | 23/500 [03:48<22:41,  2.85s/it, est. speed input: 30.80 toks/s, output: 137.94 toks/s]Processed prompts:   5%|▍         | 24/500 [03:50<22:20,  2.82s/it, est. speed input: 31.73 toks/s, output: 144.27 toks/s]Processed prompts:   5%|▌         | 25/500 [03:51<16:56,  2.14s/it, est. speed input: 41.02 toks/s, output: 151.98 toks/s]Processed prompts:   5%|▌         | 26/500 [03:52<14:45,  1.87s/it, est. speed input: 50.66 toks/s, output: 158.46 toks/s]Processed prompts:   5%|▌         | 27/500 [03:54<15:23,  1.95s/it, est. speed input: 51.43 toks/s, output: 165.04 toks/s]Processed prompts:   6%|▌         | 28/500 [04:00<23:54,  3.04s/it, est. speed input: 51.27 toks/s, output: 169.20 toks/s]Processed prompts:   6%|▌         | 29/500 [04:06<30:10,  3.84s/it, est. speed input: 51.47 toks/s, output: 173.32 toks/s]Processed prompts:   6%|▌         | 30/500 [04:07<24:01,  3.07s/it, est. speed input: 52.42 toks/s, output: 180.63 toks/s]Processed prompts:   6%|▌         | 31/500 [04:19<46:14,  5.92s/it, est. speed input: 51.23 toks/s, output: 180.26 toks/s]Processed prompts:   6%|▋         | 32/500 [04:25<44:41,  5.73s/it, est. speed input: 51.35 toks/s, output: 185.19 toks/s]Processed prompts:   7%|▋         | 33/500 [04:29<40:27,  5.20s/it, est. speed input: 51.90 toks/s, output: 190.98 toks/s]WARNING 04-06 14:12:11 scheduler.py:1555] Sequence group 91 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:   7%|▋         | 34/500 [04:44<1:03:33,  8.18s/it, est. speed input: 50.39 toks/s, output: 189.60 toks/s]Processed prompts:   7%|▋         | 35/500 [04:48<53:25,  6.89s/it, est. speed input: 50.93 toks/s, output: 195.89 toks/s]  Processed prompts:   7%|▋         | 36/500 [04:49<40:12,  5.20s/it, est. speed input: 51.76 toks/s, output: 203.94 toks/s]Processed prompts:   7%|▋         | 37/500 [04:55<42:28,  5.51s/it, est. speed input: 52.21 toks/s, output: 208.59 toks/s]Processed prompts:   8%|▊         | 38/500 [04:58<35:43,  4.64s/it, est. speed input: 52.93 toks/s, output: 215.65 toks/s]Processed prompts:   8%|▊         | 39/500 [04:58<25:55,  3.37s/it, est. speed input: 54.07 toks/s, output: 224.37 toks/s]Processed prompts:   8%|▊         | 40/500 [04:59<20:18,  2.65s/it, est. speed input: 55.07 toks/s, output: 232.69 toks/s]Processed prompts:   8%|▊         | 41/500 [05:01<18:35,  2.43s/it, est. speed input: 55.92 toks/s, output: 240.16 toks/s]Processed prompts:   8%|▊         | 42/500 [05:10<33:45,  4.42s/it, est. speed input: 56.00 toks/s, output: 241.41 toks/s]Processed prompts:   9%|▊         | 43/500 [05:11<25:19,  3.32s/it, est. speed input: 56.95 toks/s, output: 250.00 toks/s]Processed prompts:   9%|▉         | 44/500 [05:13<23:10,  3.05s/it, est. speed input: 57.82 toks/s, output: 255.97 toks/s]Processed prompts:   9%|▉         | 45/500 [05:15<20:30,  2.71s/it, est. speed input: 64.84 toks/s, output: 263.64 toks/s]Processed prompts:   9%|▉         | 46/500 [05:20<25:37,  3.39s/it, est. speed input: 69.62 toks/s, output: 268.74 toks/s]Processed prompts:   9%|▉         | 47/500 [05:27<33:11,  4.40s/it, est. speed input: 72.77 toks/s, output: 272.49 toks/s]Processed prompts:  10%|▉         | 48/500 [05:35<41:21,  5.49s/it, est. speed input: 72.25 toks/s, output: 275.40 toks/s]Processed prompts:  10%|▉         | 49/500 [05:36<30:25,  4.05s/it, est. speed input: 73.32 toks/s, output: 284.30 toks/s]Processed prompts:  10%|█         | 50/500 [05:43<37:50,  5.05s/it, est. speed input: 72.86 toks/s, output: 286.05 toks/s]Processed prompts:  10%|█         | 51/500 [05:51<45:03,  6.02s/it, est. speed input: 78.43 toks/s, output: 288.87 toks/s]Processed prompts:  11%|█         | 53/500 [05:59<36:39,  4.92s/it, est. speed input: 84.50 toks/s, output: 302.09 toks/s]Processed prompts:  11%|█         | 54/500 [06:03<35:19,  4.75s/it, est. speed input: 88.87 toks/s, output: 308.33 toks/s]Processed prompts:  11%|█         | 56/500 [06:03<21:24,  2.89s/it, est. speed input: 90.57 toks/s, output: 327.40 toks/s]Processed prompts:  11%|█▏        | 57/500 [06:04<17:56,  2.43s/it, est. speed input: 92.42 toks/s, output: 335.95 toks/s]Processed prompts:  12%|█▏        | 58/500 [06:21<44:33,  6.05s/it, est. speed input: 91.78 toks/s, output: 330.83 toks/s]Processed prompts:  12%|█▏        | 59/500 [06:27<44:02,  5.99s/it, est. speed input: 97.84 toks/s, output: 335.84 toks/s]Processed prompts:  12%|█▏        | 60/500 [06:30<37:13,  5.08s/it, est. speed input: 98.15 toks/s, output: 343.62 toks/s]Processed prompts:  12%|█▏        | 61/500 [06:33<32:49,  4.49s/it, est. speed input: 98.38 toks/s, output: 351.05 toks/s]Processed prompts:  12%|█▏        | 62/500 [06:44<46:11,  6.33s/it, est. speed input: 102.88 toks/s, output: 351.67 toks/s]Processed prompts:  13%|█▎        | 63/500 [06:47<39:32,  5.43s/it, est. speed input: 103.60 toks/s, output: 355.03 toks/s]Processed prompts:  13%|█▎        | 64/500 [06:52<37:37,  5.18s/it, est. speed input: 103.90 toks/s, output: 361.33 toks/s]Processed prompts:  13%|█▎        | 65/500 [07:00<45:31,  6.28s/it, est. speed input: 102.51 toks/s, output: 364.05 toks/s]Processed prompts:  13%|█▎        | 66/500 [07:07<46:51,  6.48s/it, est. speed input: 101.75 toks/s, output: 368.58 toks/s]Processed prompts:  13%|█▎        | 67/500 [07:19<57:57,  8.03s/it, est. speed input: 100.15 toks/s, output: 365.89 toks/s]Processed prompts:  14%|█▎        | 68/500 [07:32<1:08:54,  9.57s/it, est. speed input: 98.52 toks/s, output: 365.89 toks/s]Processed prompts:  14%|█▍        | 69/500 [07:33<50:45,  7.07s/it, est. speed input: 99.27 toks/s, output: 375.61 toks/s]  Processed prompts:  14%|█▍        | 70/500 [07:36<40:56,  5.71s/it, est. speed input: 102.71 toks/s, output: 384.24 toks/s]Processed prompts:  14%|█▍        | 71/500 [07:41<39:14,  5.49s/it, est. speed input: 106.16 toks/s, output: 388.40 toks/s]Processed prompts:  14%|█▍        | 72/500 [07:42<29:15,  4.10s/it, est. speed input: 107.07 toks/s, output: 398.38 toks/s]Processed prompts:  15%|█▍        | 73/500 [07:42<21:46,  3.06s/it, est. speed input: 107.99 toks/s, output: 408.59 toks/s]Processed prompts:  15%|█▍        | 74/500 [07:49<29:17,  4.13s/it, est. speed input: 109.39 toks/s, output: 413.65 toks/s]Processed prompts:  15%|█▌        | 75/500 [07:55<32:50,  4.64s/it, est. speed input: 113.20 toks/s, output: 419.38 toks/s]Processed prompts:  15%|█▌        | 76/500 [08:04<43:02,  6.09s/it, est. speed input: 114.62 toks/s, output: 422.09 toks/s]Processed prompts:  15%|█▌        | 77/500 [08:08<37:33,  5.33s/it, est. speed input: 116.33 toks/s, output: 429.93 toks/s]Processed prompts:  16%|█▌        | 78/500 [08:11<33:25,  4.75s/it, est. speed input: 116.46 toks/s, output: 437.89 toks/s]Processed prompts:  16%|█▌        | 79/500 [08:16<32:40,  4.66s/it, est. speed input: 121.16 toks/s, output: 444.89 toks/s]Processed prompts:  16%|█▌        | 80/500 [08:31<55:11,  7.89s/it, est. speed input: 121.74 toks/s, output: 442.53 toks/s]Processed prompts:  16%|█▌        | 81/500 [08:37<50:25,  7.22s/it, est. speed input: 122.30 toks/s, output: 448.78 toks/s]Processed prompts:  16%|█▋        | 82/500 [08:38<38:24,  5.51s/it, est. speed input: 125.80 toks/s, output: 453.84 toks/s]Processed prompts:  17%|█▋        | 83/500 [08:40<30:53,  4.44s/it, est. speed input: 126.74 toks/s, output: 463.27 toks/s]Processed prompts:  17%|█▋        | 84/500 [08:41<22:37,  3.26s/it, est. speed input: 130.79 toks/s, output: 466.05 toks/s]Processed prompts:  17%|█▋        | 85/500 [08:56<47:35,  6.88s/it, est. speed input: 131.30 toks/s, output: 463.96 toks/s]Processed prompts:  17%|█▋        | 86/500 [09:12<1:06:31,  9.64s/it, est. speed input: 132.01 toks/s, output: 456.08 toks/s]Processed prompts:  17%|█▋        | 87/500 [09:14<49:02,  7.12s/it, est. speed input: 132.42 toks/s, output: 463.72 toks/s]  Processed prompts:  18%|█▊        | 88/500 [09:21<49:19,  7.18s/it, est. speed input: 135.48 toks/s, output: 468.98 toks/s]Processed prompts:  18%|█▊        | 89/500 [09:22<36:43,  5.36s/it, est. speed input: 140.14 toks/s, output: 471.28 toks/s]Processed prompts:  18%|█▊        | 90/500 [09:25<32:04,  4.69s/it, est. speed input: 139.89 toks/s, output: 473.88 toks/s]Processed prompts:  18%|█▊        | 91/500 [09:26<24:39,  3.62s/it, est. speed input: 141.54 toks/s, output: 484.34 toks/s]Processed prompts:  18%|█▊        | 92/500 [09:28<21:43,  3.19s/it, est. speed input: 141.56 toks/s, output: 487.58 toks/s]Processed prompts:  19%|█▊        | 93/500 [09:47<53:07,  7.83s/it, est. speed input: 138.36 toks/s, output: 473.97 toks/s]Processed prompts:  19%|█▉        | 94/500 [10:00<1:03:42,  9.42s/it, est. speed input: 139.02 toks/s, output: 468.84 toks/s]Processed prompts:  19%|█▉        | 95/500 [10:32<1:48:51, 16.13s/it, est. speed input: 134.83 toks/s, output: 456.98 toks/s]Processed prompts:  19%|█▉        | 96/500 [10:48<1:47:38, 15.99s/it, est. speed input: 132.28 toks/s, output: 457.68 toks/s]WARNING 04-06 14:18:30 scheduler.py:1555] Sequence group 128 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:  19%|█▉        | 97/500 [11:00<1:40:41, 14.99s/it, est. speed input: 134.34 toks/s, output: 454.19 toks/s]Processed prompts:  20%|█▉        | 98/500 [11:00<1:10:37, 10.54s/it, est. speed input: 137.79 toks/s, output: 465.91 toks/s]Processed prompts:  20%|█▉        | 99/500 [11:07<1:01:44,  9.24s/it, est. speed input: 137.34 toks/s, output: 473.46 toks/s]Processed prompts:  20%|██        | 100/500 [11:09<48:21,  7.25s/it, est. speed input: 140.50 toks/s, output: 483.47 toks/s] Processed prompts:  20%|██        | 101/500 [11:11<36:16,  5.45s/it, est. speed input: 140.62 toks/s, output: 487.39 toks/s]Processed prompts:  20%|██        | 102/500 [11:18<41:00,  6.18s/it, est. speed input: 140.11 toks/s, output: 483.59 toks/s]Processed prompts:  21%|██        | 103/500 [11:22<36:45,  5.56s/it, est. speed input: 142.83 toks/s, output: 482.30 toks/s]Processed prompts:  21%|██        | 104/500 [11:25<30:01,  4.55s/it, est. speed input: 143.99 toks/s, output: 486.25 toks/s]Processed prompts:  21%|██        | 105/500 [11:26<24:03,  3.65s/it, est. speed input: 147.76 toks/s, output: 489.87 toks/s]Processed prompts:  21%|██        | 106/500 [11:35<33:40,  5.13s/it, est. speed input: 146.81 toks/s, output: 495.80 toks/s]Processed prompts:  21%|██▏       | 107/500 [11:40<33:40,  5.14s/it, est. speed input: 146.23 toks/s, output: 498.87 toks/s]Processed prompts:  22%|██▏       | 108/500 [11:44<32:12,  4.93s/it, est. speed input: 145.87 toks/s, output: 502.63 toks/s]Processed prompts:  22%|██▏       | 109/500 [11:46<25:41,  3.94s/it, est. speed input: 148.37 toks/s, output: 503.96 toks/s]Processed prompts:  22%|██▏       | 110/500 [11:58<40:24,  6.22s/it, est. speed input: 150.29 toks/s, output: 507.88 toks/s]Processed prompts:  22%|██▏       | 111/500 [12:09<49:56,  7.70s/it, est. speed input: 150.98 toks/s, output: 501.75 toks/s]Processed prompts:  22%|██▏       | 112/500 [12:15<47:01,  7.27s/it, est. speed input: 150.99 toks/s, output: 502.95 toks/s]Processed prompts:  23%|██▎       | 113/500 [12:45<1:31:35, 14.20s/it, est. speed input: 145.45 toks/s, output: 492.52 toks/s]Processed prompts:  23%|██▎       | 114/500 [12:50<1:12:54, 11.33s/it, est. speed input: 147.48 toks/s, output: 501.72 toks/s]Processed prompts:  23%|██▎       | 115/500 [12:52<54:18,  8.46s/it, est. speed input: 147.49 toks/s, output: 507.36 toks/s]  Processed prompts:  23%|██▎       | 116/500 [12:54<42:09,  6.59s/it, est. speed input: 148.62 toks/s, output: 508.37 toks/s]Processed prompts:  23%|██▎       | 117/500 [12:56<33:45,  5.29s/it, est. speed input: 148.60 toks/s, output: 513.62 toks/s]Processed prompts:  24%|██▎       | 118/500 [13:01<32:18,  5.07s/it, est. speed input: 151.09 toks/s, output: 522.78 toks/s]Processed prompts:  24%|██▍       | 119/500 [13:06<33:10,  5.22s/it, est. speed input: 153.03 toks/s, output: 531.27 toks/s]Processed prompts:  24%|██▍       | 120/500 [13:07<24:58,  3.94s/it, est. speed input: 153.26 toks/s, output: 538.46 toks/s]Processed prompts:  24%|██▍       | 121/500 [13:08<18:15,  2.89s/it, est. speed input: 156.64 toks/s, output: 538.92 toks/s]Processed prompts:  24%|██▍       | 122/500 [13:15<26:58,  4.28s/it, est. speed input: 156.42 toks/s, output: 536.43 toks/s]Processed prompts:  25%|██▍       | 123/500 [13:17<21:31,  3.42s/it, est. speed input: 159.23 toks/s, output: 537.85 toks/s]Processed prompts:  25%|██▍       | 124/500 [13:18<17:37,  2.81s/it, est. speed input: 160.06 toks/s, output: 538.11 toks/s]Processed prompts:  25%|██▌       | 125/500 [13:23<22:14,  3.56s/it, est. speed input: 161.81 toks/s, output: 535.58 toks/s]Processed prompts:  25%|██▌       | 126/500 [13:27<22:13,  3.56s/it, est. speed input: 164.37 toks/s, output: 545.40 toks/s]Processed prompts:  25%|██▌       | 127/500 [13:31<22:26,  3.61s/it, est. speed input: 164.04 toks/s, output: 549.08 toks/s]Processed prompts:  26%|██▌       | 128/500 [13:33<19:49,  3.20s/it, est. speed input: 164.08 toks/s, output: 553.89 toks/s]Processed prompts:  26%|██▌       | 129/500 [13:41<28:08,  4.55s/it, est. speed input: 162.86 toks/s, output: 549.92 toks/s]Processed prompts:  26%|██▌       | 130/500 [13:42<21:13,  3.44s/it, est. speed input: 163.38 toks/s, output: 557.38 toks/s]Processed prompts:  26%|██▌       | 131/500 [13:43<18:06,  2.94s/it, est. speed input: 163.48 toks/s, output: 556.97 toks/s]Processed prompts:  26%|██▋       | 132/500 [13:46<17:11,  2.80s/it, est. speed input: 164.27 toks/s, output: 555.75 toks/s]Processed prompts:  27%|██▋       | 133/500 [13:54<27:02,  4.42s/it, est. speed input: 162.98 toks/s, output: 553.58 toks/s]Processed prompts:  27%|██▋       | 134/500 [14:13<53:24,  8.76s/it, est. speed input: 159.89 toks/s, output: 542.84 toks/s]Processed prompts:  27%|██▋       | 135/500 [14:22<53:16,  8.76s/it, est. speed input: 158.61 toks/s, output: 538.82 toks/s]Processed prompts:  27%|██▋       | 136/500 [14:28<48:57,  8.07s/it, est. speed input: 158.29 toks/s, output: 536.54 toks/s]Processed prompts:  27%|██▋       | 137/500 [14:29<35:33,  5.88s/it, est. speed input: 158.81 toks/s, output: 548.29 toks/s]Processed prompts:  28%|██▊       | 138/500 [14:34<33:59,  5.64s/it, est. speed input: 159.66 toks/s, output: 546.69 toks/s]Processed prompts:  28%|██▊       | 139/500 [14:34<24:25,  4.06s/it, est. speed input: 162.47 toks/s, output: 558.62 toks/s]WARNING 04-06 14:22:10 scheduler.py:1555] Sequence group 199 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:  28%|██▊       | 140/500 [14:40<26:55,  4.49s/it, est. speed input: 162.17 toks/s, output: 567.34 toks/s]Processed prompts:  28%|██▊       | 141/500 [14:57<49:52,  8.34s/it, est. speed input: 159.48 toks/s, output: 563.46 toks/s]Processed prompts:  28%|██▊       | 142/500 [15:04<47:25,  7.95s/it, est. speed input: 158.64 toks/s, output: 561.55 toks/s]Processed prompts:  29%|██▊       | 143/500 [15:10<43:55,  7.38s/it, est. speed input: 158.59 toks/s, output: 563.87 toks/s]Processed prompts:  29%|██▉       | 144/500 [15:15<39:59,  6.74s/it, est. speed input: 157.95 toks/s, output: 565.07 toks/s]Processed prompts:  29%|██▉       | 145/500 [15:23<41:52,  7.08s/it, est. speed input: 158.45 toks/s, output: 572.45 toks/s]Processed prompts:  29%|██▉       | 147/500 [15:25<24:13,  4.12s/it, est. speed input: 158.88 toks/s, output: 580.11 toks/s]Processed prompts:  30%|██▉       | 148/500 [15:31<26:50,  4.58s/it, est. speed input: 158.21 toks/s, output: 578.83 toks/s]Processed prompts:  30%|██▉       | 149/500 [15:48<46:13,  7.90s/it, est. speed input: 157.15 toks/s, output: 574.96 toks/s]Processed prompts:  30%|███       | 150/500 [16:25<1:31:57, 15.76s/it, est. speed input: 151.60 toks/s, output: 556.34 toks/s]Processed prompts:  30%|███       | 151/500 [16:33<1:19:10, 13.61s/it, est. speed input: 151.27 toks/s, output: 564.09 toks/s]Processed prompts:  30%|███       | 152/500 [16:34<57:54,  9.98s/it, est. speed input: 151.41 toks/s, output: 566.71 toks/s]  Processed prompts:  31%|███       | 153/500 [16:45<1:00:44, 10.50s/it, est. speed input: 149.94 toks/s, output: 564.77 toks/s]Processed prompts:  31%|███       | 154/500 [16:49<48:24,  8.40s/it, est. speed input: 149.67 toks/s, output: 564.62 toks/s]  Processed prompts:  31%|███       | 155/500 [16:53<41:18,  7.18s/it, est. speed input: 149.31 toks/s, output: 567.57 toks/s]Processed prompts:  31%|███       | 156/500 [16:59<39:35,  6.91s/it, est. speed input: 148.68 toks/s, output: 570.60 toks/s]Processed prompts:  31%|███▏      | 157/500 [17:02<31:56,  5.59s/it, est. speed input: 148.59 toks/s, output: 573.47 toks/s]Processed prompts:  32%|███▏      | 158/500 [17:03<23:35,  4.14s/it, est. speed input: 148.76 toks/s, output: 574.63 toks/s]WARNING 04-06 14:24:39 scheduler.py:1555] Sequence group 203 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  32%|███▏      | 159/500 [17:12<32:34,  5.73s/it, est. speed input: 147.63 toks/s, output: 572.79 toks/s]Processed prompts:  32%|███▏      | 160/500 [17:22<40:16,  7.11s/it, est. speed input: 146.44 toks/s, output: 572.50 toks/s]Processed prompts:  32%|███▏      | 161/500 [17:23<29:28,  5.22s/it, est. speed input: 146.67 toks/s, output: 577.63 toks/s]Processed prompts:  32%|███▏      | 162/500 [17:25<22:59,  4.08s/it, est. speed input: 148.91 toks/s, output: 577.98 toks/s]Processed prompts:  33%|███▎      | 163/500 [17:25<16:16,  2.90s/it, est. speed input: 149.14 toks/s, output: 580.16 toks/s]Processed prompts:  33%|███▎      | 164/500 [17:28<16:34,  2.96s/it, est. speed input: 150.84 toks/s, output: 587.36 toks/s]Processed prompts:  33%|███▎      | 165/500 [17:29<13:34,  2.43s/it, est. speed input: 151.21 toks/s, output: 591.54 toks/s]Processed prompts:  33%|███▎      | 166/500 [17:34<17:18,  3.11s/it, est. speed input: 152.99 toks/s, output: 589.26 toks/s]Processed prompts:  33%|███▎      | 167/500 [17:38<19:12,  3.46s/it, est. speed input: 152.58 toks/s, output: 587.76 toks/s]Processed prompts:  34%|███▎      | 168/500 [17:43<22:14,  4.02s/it, est. speed input: 152.59 toks/s, output: 588.54 toks/s]Processed prompts:  34%|███▍      | 169/500 [17:47<22:20,  4.05s/it, est. speed input: 154.81 toks/s, output: 586.89 toks/s]Processed prompts:  34%|███▍      | 170/500 [17:54<25:49,  4.70s/it, est. speed input: 154.60 toks/s, output: 587.43 toks/s]Processed prompts:  34%|███▍      | 171/500 [17:57<23:49,  4.34s/it, est. speed input: 154.32 toks/s, output: 589.47 toks/s]Processed prompts:  34%|███▍      | 172/500 [18:13<42:49,  7.83s/it, est. speed input: 154.35 toks/s, output: 585.43 toks/s]Processed prompts:  35%|███▍      | 173/500 [18:21<43:33,  7.99s/it, est. speed input: 155.95 toks/s, output: 584.39 toks/s]Processed prompts:  35%|███▍      | 174/500 [18:26<38:07,  7.02s/it, est. speed input: 155.59 toks/s, output: 588.49 toks/s]Processed prompts:  35%|███▌      | 175/500 [18:28<29:13,  5.40s/it, est. speed input: 155.60 toks/s, output: 588.28 toks/s]Processed prompts:  35%|███▌      | 176/500 [18:28<20:38,  3.82s/it, est. speed input: 155.82 toks/s, output: 588.95 toks/s]Processed prompts:  35%|███▌      | 177/500 [18:36<27:14,  5.06s/it, est. speed input: 156.34 toks/s, output: 590.68 toks/s]Processed prompts:  36%|███▌      | 178/500 [18:45<33:51,  6.31s/it, est. speed input: 157.55 toks/s, output: 586.62 toks/s]Processed prompts:  36%|███▌      | 179/500 [18:54<38:18,  7.16s/it, est. speed input: 157.23 toks/s, output: 585.07 toks/s]Processed prompts:  36%|███▌      | 180/500 [18:57<31:21,  5.88s/it, est. speed input: 157.04 toks/s, output: 584.18 toks/s]Processed prompts:  36%|███▌      | 181/500 [19:13<47:41,  8.97s/it, est. speed input: 155.64 toks/s, output: 580.52 toks/s]Processed prompts:  36%|███▋      | 182/500 [19:16<36:56,  6.97s/it, est. speed input: 156.72 toks/s, output: 583.41 toks/s]Processed prompts:  37%|███▋      | 183/500 [19:21<33:37,  6.36s/it, est. speed input: 156.71 toks/s, output: 585.39 toks/s]Processed prompts:  37%|███▋      | 184/500 [19:26<31:30,  5.98s/it, est. speed input: 156.24 toks/s, output: 587.72 toks/s]Processed prompts:  37%|███▋      | 185/500 [19:37<39:56,  7.61s/it, est. speed input: 157.26 toks/s, output: 582.77 toks/s]Processed prompts:  37%|███▋      | 186/500 [19:38<29:04,  5.56s/it, est. speed input: 157.43 toks/s, output: 587.04 toks/s]Processed prompts:  37%|███▋      | 187/500 [19:39<22:45,  4.36s/it, est. speed input: 157.48 toks/s, output: 588.69 toks/s]Processed prompts:  38%|███▊      | 188/500 [19:42<19:52,  3.82s/it, est. speed input: 158.99 toks/s, output: 594.58 toks/s]WARNING 04-06 14:27:24 scheduler.py:1555] Sequence group 241 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  38%|███▊      | 189/500 [19:53<30:19,  5.85s/it, est. speed input: 157.91 toks/s, output: 591.48 toks/s]Processed prompts:  38%|███▊      | 190/500 [19:54<22:42,  4.40s/it, est. speed input: 158.13 toks/s, output: 595.72 toks/s]Processed prompts:  38%|███▊      | 191/500 [20:00<25:25,  4.94s/it, est. speed input: 159.54 toks/s, output: 592.87 toks/s]Processed prompts:  38%|███▊      | 192/500 [20:01<19:53,  3.87s/it, est. speed input: 160.69 toks/s, output: 592.59 toks/s]Processed prompts:  39%|███▊      | 193/500 [20:03<16:43,  3.27s/it, est. speed input: 160.78 toks/s, output: 592.35 toks/s]Processed prompts:  39%|███▉      | 194/500 [20:04<12:50,  2.52s/it, est. speed input: 160.91 toks/s, output: 596.89 toks/s]Processed prompts:  39%|███▉      | 195/500 [20:13<23:36,  4.65s/it, est. speed input: 159.84 toks/s, output: 597.77 toks/s]Processed prompts:  39%|███▉      | 196/500 [20:15<18:18,  3.61s/it, est. speed input: 160.51 toks/s, output: 602.03 toks/s]Processed prompts:  39%|███▉      | 197/500 [20:17<16:02,  3.18s/it, est. speed input: 160.46 toks/s, output: 601.48 toks/s]Processed prompts:  40%|███▉      | 198/500 [20:24<21:42,  4.31s/it, est. speed input: 159.74 toks/s, output: 599.79 toks/s]Processed prompts:  40%|███▉      | 199/500 [20:27<19:55,  3.97s/it, est. speed input: 160.61 toks/s, output: 599.23 toks/s]Processed prompts:  40%|████      | 200/500 [20:29<17:30,  3.50s/it, est. speed input: 160.52 toks/s, output: 603.01 toks/s]Processed prompts:  40%|████      | 201/500 [20:40<27:55,  5.61s/it, est. speed input: 159.33 toks/s, output: 598.98 toks/s]Processed prompts:  40%|████      | 202/500 [20:59<48:14,  9.71s/it, est. speed input: 157.13 toks/s, output: 590.75 toks/s]Processed prompts:  41%|████      | 203/500 [21:02<37:52,  7.65s/it, est. speed input: 157.73 toks/s, output: 592.33 toks/s]Processed prompts:  41%|████      | 204/500 [21:04<29:54,  6.06s/it, est. speed input: 157.75 toks/s, output: 592.02 toks/s]Processed prompts:  41%|████      | 205/500 [21:17<38:54,  7.91s/it, est. speed input: 158.28 toks/s, output: 587.21 toks/s]Processed prompts:  41%|████      | 206/500 [21:19<30:20,  6.19s/it, est. speed input: 158.20 toks/s, output: 590.80 toks/s]Processed prompts:  41%|████▏     | 207/500 [21:19<21:57,  4.50s/it, est. speed input: 159.32 toks/s, output: 595.16 toks/s]Processed prompts:  42%|████▏     | 208/500 [21:32<34:35,  7.11s/it, est. speed input: 157.97 toks/s, output: 591.70 toks/s]Processed prompts:  42%|████▏     | 209/500 [21:36<29:11,  6.02s/it, est. speed input: 157.77 toks/s, output: 597.28 toks/s]Processed prompts:  42%|████▏     | 210/500 [21:40<26:05,  5.40s/it, est. speed input: 158.77 toks/s, output: 596.35 toks/s]Processed prompts:  42%|████▏     | 211/500 [21:47<28:19,  5.88s/it, est. speed input: 160.05 toks/s, output: 593.67 toks/s]Processed prompts:  42%|████▏     | 212/500 [21:47<20:10,  4.20s/it, est. speed input: 160.24 toks/s, output: 596.29 toks/s]Processed prompts:  43%|████▎     | 213/500 [21:50<18:27,  3.86s/it, est. speed input: 161.07 toks/s, output: 597.69 toks/s]Processed prompts:  43%|████▎     | 214/500 [21:52<15:56,  3.34s/it, est. speed input: 161.02 toks/s, output: 599.51 toks/s]Processed prompts:  43%|████▎     | 215/500 [21:58<19:17,  4.06s/it, est. speed input: 161.10 toks/s, output: 598.24 toks/s]Processed prompts:  43%|████▎     | 216/500 [22:01<17:24,  3.68s/it, est. speed input: 162.68 toks/s, output: 599.75 toks/s]Processed prompts:  43%|████▎     | 217/500 [22:06<18:41,  3.96s/it, est. speed input: 163.12 toks/s, output: 610.13 toks/s]Processed prompts:  44%|████▎     | 218/500 [22:13<23:01,  4.90s/it, est. speed input: 162.56 toks/s, output: 608.65 toks/s]Processed prompts:  44%|████▍     | 219/500 [22:22<29:07,  6.22s/it, est. speed input: 161.87 toks/s, output: 606.93 toks/s]Processed prompts:  44%|████▍     | 220/500 [22:24<22:57,  4.92s/it, est. speed input: 162.49 toks/s, output: 606.41 toks/s]Processed prompts:  44%|████▍     | 221/500 [22:25<18:22,  3.95s/it, est. speed input: 162.45 toks/s, output: 608.95 toks/s]Processed prompts:  44%|████▍     | 222/500 [22:31<20:32,  4.43s/it, est. speed input: 162.03 toks/s, output: 606.63 toks/s]Processed prompts:  45%|████▍     | 223/500 [22:45<32:57,  7.14s/it, est. speed input: 160.73 toks/s, output: 603.68 toks/s]Processed prompts:  45%|████▍     | 224/500 [22:45<23:22,  5.08s/it, est. speed input: 161.98 toks/s, output: 605.22 toks/s]Processed prompts:  45%|████▌     | 225/500 [22:47<19:05,  4.17s/it, est. speed input: 161.95 toks/s, output: 607.93 toks/s]Processed prompts:  45%|████▌     | 226/500 [22:51<18:43,  4.10s/it, est. speed input: 161.65 toks/s, output: 609.68 toks/s]Processed prompts:  45%|████▌     | 227/500 [22:58<22:37,  4.97s/it, est. speed input: 162.33 toks/s, output: 607.26 toks/s]Processed prompts:  46%|████▌     | 228/500 [23:00<18:45,  4.14s/it, est. speed input: 162.32 toks/s, output: 607.26 toks/s]Processed prompts:  46%|████▌     | 229/500 [23:04<18:46,  4.16s/it, est. speed input: 162.12 toks/s, output: 607.21 toks/s]Processed prompts:  46%|████▌     | 230/500 [23:05<14:21,  3.19s/it, est. speed input: 163.88 toks/s, output: 612.58 toks/s]Processed prompts:  46%|████▌     | 231/500 [23:11<17:41,  3.94s/it, est. speed input: 164.87 toks/s, output: 611.72 toks/s]Processed prompts:  46%|████▋     | 232/500 [23:13<14:44,  3.30s/it, est. speed input: 164.84 toks/s, output: 611.59 toks/s]Processed prompts:  47%|████▋     | 233/500 [23:17<15:41,  3.53s/it, est. speed input: 164.56 toks/s, output: 611.71 toks/s]Processed prompts:  47%|████▋     | 234/500 [23:17<11:23,  2.57s/it, est. speed input: 166.40 toks/s, output: 611.79 toks/s]WARNING 04-06 14:30:52 scheduler.py:1555] Sequence group 299 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  47%|████▋     | 235/500 [23:22<14:54,  3.38s/it, est. speed input: 166.03 toks/s, output: 615.00 toks/s]Processed prompts:  47%|████▋     | 236/500 [23:33<25:04,  5.70s/it, est. speed input: 164.95 toks/s, output: 610.49 toks/s]Processed prompts:  47%|████▋     | 237/500 [23:35<20:11,  4.61s/it, est. speed input: 166.86 toks/s, output: 610.21 toks/s]Processed prompts:  48%|████▊     | 238/500 [23:43<24:15,  5.55s/it, est. speed input: 166.14 toks/s, output: 607.76 toks/s]Processed prompts:  48%|████▊     | 239/500 [23:49<25:01,  5.75s/it, est. speed input: 165.60 toks/s, output: 606.06 toks/s]Processed prompts:  48%|████▊     | 240/500 [23:50<18:15,  4.21s/it, est. speed input: 165.92 toks/s, output: 608.61 toks/s]Processed prompts:  48%|████▊     | 241/500 [23:50<13:16,  3.08s/it, est. speed input: 166.19 toks/s, output: 610.23 toks/s]Processed prompts:  48%|████▊     | 242/500 [23:51<10:10,  2.37s/it, est. speed input: 166.32 toks/s, output: 615.26 toks/s]Processed prompts:  49%|████▊     | 243/500 [24:03<22:45,  5.31s/it, est. speed input: 165.11 toks/s, output: 611.11 toks/s]Processed prompts:  49%|████▉     | 244/500 [24:08<21:40,  5.08s/it, est. speed input: 166.03 toks/s, output: 611.51 toks/s]Processed prompts:  49%|████▉     | 245/500 [24:08<15:20,  3.61s/it, est. speed input: 166.32 toks/s, output: 612.33 toks/s]Processed prompts:  49%|████▉     | 246/500 [24:14<17:58,  4.25s/it, est. speed input: 166.45 toks/s, output: 616.77 toks/s]Processed prompts:  49%|████▉     | 247/500 [24:17<16:42,  3.96s/it, est. speed input: 166.25 toks/s, output: 616.54 toks/s]Processed prompts:  50%|████▉     | 248/500 [24:19<14:25,  3.44s/it, est. speed input: 167.46 toks/s, output: 617.46 toks/s]Processed prompts:  50%|████▉     | 249/500 [24:26<17:58,  4.30s/it, est. speed input: 166.95 toks/s, output: 616.69 toks/s]Processed prompts:  50%|█████     | 250/500 [24:26<12:55,  3.10s/it, est. speed input: 167.48 toks/s, output: 616.71 toks/s]Processed prompts:  50%|█████     | 251/500 [24:27<09:59,  2.41s/it, est. speed input: 167.58 toks/s, output: 617.59 toks/s]Processed prompts:  50%|█████     | 252/500 [24:31<12:32,  3.03s/it, est. speed input: 167.46 toks/s, output: 621.93 toks/s]Processed prompts:  51%|█████     | 253/500 [24:37<15:35,  3.79s/it, est. speed input: 167.04 toks/s, output: 621.21 toks/s]Processed prompts:  51%|█████     | 254/500 [24:40<15:25,  3.76s/it, est. speed input: 168.63 toks/s, output: 619.80 toks/s]Processed prompts:  51%|█████     | 255/500 [24:47<19:12,  4.71s/it, est. speed input: 168.00 toks/s, output: 618.18 toks/s]Processed prompts:  51%|█████     | 256/500 [24:48<14:32,  3.57s/it, est. speed input: 168.66 toks/s, output: 618.25 toks/s]Processed prompts:  51%|█████▏    | 257/500 [24:59<22:34,  5.57s/it, est. speed input: 168.88 toks/s, output: 614.66 toks/s]Processed prompts:  52%|█████▏    | 258/500 [25:20<41:24, 10.27s/it, est. speed input: 168.20 toks/s, output: 612.44 toks/s]Processed prompts:  52%|█████▏    | 259/500 [25:22<31:06,  7.75s/it, est. speed input: 169.41 toks/s, output: 612.27 toks/s]Processed prompts:  52%|█████▏    | 261/500 [25:22<17:04,  4.29s/it, est. speed input: 171.52 toks/s, output: 613.75 toks/s]Processed prompts:  52%|█████▏    | 262/500 [25:26<16:37,  4.19s/it, est. speed input: 172.69 toks/s, output: 612.66 toks/s]Processed prompts:  53%|█████▎    | 263/500 [25:35<21:06,  5.34s/it, est. speed input: 171.89 toks/s, output: 610.80 toks/s]Processed prompts:  53%|█████▎    | 264/500 [25:39<19:33,  4.97s/it, est. speed input: 171.73 toks/s, output: 609.78 toks/s]Processed prompts:  53%|█████▎    | 266/500 [25:41<12:34,  3.23s/it, est. speed input: 173.23 toks/s, output: 612.37 toks/s]Processed prompts:  53%|█████▎    | 267/500 [25:43<11:54,  3.07s/it, est. speed input: 174.87 toks/s, output: 611.56 toks/s]Processed prompts:  54%|█████▎    | 268/500 [25:43<09:00,  2.33s/it, est. speed input: 175.01 toks/s, output: 613.16 toks/s]Processed prompts:  54%|█████▍    | 269/500 [25:46<09:12,  2.39s/it, est. speed input: 174.85 toks/s, output: 613.50 toks/s]Processed prompts:  54%|█████▍    | 270/500 [25:49<09:58,  2.60s/it, est. speed input: 175.33 toks/s, output: 616.37 toks/s]Processed prompts:  54%|█████▍    | 271/500 [25:54<12:21,  3.24s/it, est. speed input: 174.99 toks/s, output: 617.36 toks/s]Processed prompts:  54%|█████▍    | 272/500 [26:10<26:51,  7.07s/it, est. speed input: 173.30 toks/s, output: 618.04 toks/s]WARNING 04-06 14:33:46 scheduler.py:1555] Sequence group 328 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  55%|█████▍    | 273/500 [26:49<1:01:22, 16.22s/it, est. speed input: 169.32 toks/s, output: 604.97 toks/s]Processed prompts:  55%|█████▍    | 274/500 [27:06<1:02:25, 16.57s/it, est. speed input: 167.76 toks/s, output: 600.32 toks/s]Processed prompts:  55%|█████▌    | 275/500 [27:07<44:12, 11.79s/it, est. speed input: 167.94 toks/s, output: 603.53 toks/s]  Processed prompts:  55%|█████▌    | 276/500 [27:12<36:39,  9.82s/it, est. speed input: 167.56 toks/s, output: 603.53 toks/s]Processed prompts:  55%|█████▌    | 277/500 [27:16<30:31,  8.21s/it, est. speed input: 167.41 toks/s, output: 604.30 toks/s]Processed prompts:  56%|█████▌    | 278/500 [27:20<25:01,  6.76s/it, est. speed input: 167.31 toks/s, output: 604.99 toks/s]Processed prompts:  56%|█████▌    | 279/500 [27:44<44:30, 12.08s/it, est. speed input: 165.04 toks/s, output: 598.68 toks/s]Processed prompts:  56%|█████▌    | 280/500 [27:50<37:02, 10.10s/it, est. speed input: 164.72 toks/s, output: 599.38 toks/s]Processed prompts:  56%|█████▌    | 281/500 [27:54<30:58,  8.49s/it, est. speed input: 164.53 toks/s, output: 599.88 toks/s]Processed prompts:  56%|█████▋    | 282/500 [27:59<26:34,  7.31s/it, est. speed input: 164.25 toks/s, output: 605.34 toks/s]Processed prompts:  57%|█████▋    | 283/500 [28:02<21:33,  5.96s/it, est. speed input: 165.16 toks/s, output: 605.52 toks/s]Processed prompts:  57%|█████▋    | 284/500 [28:27<42:12, 11.73s/it, est. speed input: 162.95 toks/s, output: 598.67 toks/s]Processed prompts:  57%|█████▋    | 285/500 [28:31<33:22,  9.31s/it, est. speed input: 162.76 toks/s, output: 598.57 toks/s]Processed prompts:  57%|█████▋    | 286/500 [28:37<29:59,  8.41s/it, est. speed input: 162.34 toks/s, output: 598.96 toks/s]Processed prompts:  57%|█████▋    | 287/500 [28:38<22:13,  6.26s/it, est. speed input: 162.41 toks/s, output: 601.41 toks/s]Processed prompts:  58%|█████▊    | 288/500 [28:40<17:13,  4.87s/it, est. speed input: 162.48 toks/s, output: 601.68 toks/s]Processed prompts:  58%|█████▊    | 289/500 [29:03<36:26, 10.36s/it, est. speed input: 161.62 toks/s, output: 598.90 toks/s]Processed prompts:  58%|█████▊    | 290/500 [29:07<29:06,  8.32s/it, est. speed input: 161.72 toks/s, output: 600.76 toks/s]Processed prompts:  58%|█████▊    | 291/500 [29:09<23:14,  6.67s/it, est. speed input: 161.67 toks/s, output: 602.52 toks/s]Processed prompts:  58%|█████▊    | 292/500 [29:31<38:13, 11.02s/it, est. speed input: 159.93 toks/s, output: 598.19 toks/s]Processed prompts:  59%|█████▊    | 293/500 [29:35<30:51,  8.94s/it, est. speed input: 159.69 toks/s, output: 597.37 toks/s]Processed prompts:  59%|█████▉    | 294/500 [29:44<31:35,  9.20s/it, est. speed input: 160.28 toks/s, output: 597.45 toks/s]Processed prompts:  59%|█████▉    | 295/500 [29:46<24:00,  7.03s/it, est. speed input: 161.18 toks/s, output: 597.72 toks/s]Processed prompts:  59%|█████▉    | 296/500 [30:01<31:49,  9.36s/it, est. speed input: 161.28 toks/s, output: 596.69 toks/s]Processed prompts:  59%|█████▉    | 297/500 [30:06<27:07,  8.02s/it, est. speed input: 161.11 toks/s, output: 596.33 toks/s]Processed prompts:  60%|█████▉    | 298/500 [30:14<27:20,  8.12s/it, est. speed input: 160.58 toks/s, output: 596.11 toks/s]Processed prompts:  60%|█████▉    | 299/500 [30:21<25:56,  7.74s/it, est. speed input: 160.13 toks/s, output: 597.15 toks/s]Processed prompts:  60%|██████    | 300/500 [30:28<24:45,  7.43s/it, est. speed input: 161.19 toks/s, output: 595.39 toks/s]Processed prompts:  60%|██████    | 301/500 [30:30<18:44,  5.65s/it, est. speed input: 161.65 toks/s, output: 595.19 toks/s]WARNING 04-06 14:38:10 scheduler.py:1555] Sequence group 332 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  60%|██████    | 302/500 [30:41<24:06,  7.30s/it, est. speed input: 162.33 toks/s, output: 595.40 toks/s]Processed prompts:  61%|██████    | 303/500 [30:45<21:21,  6.50s/it, est. speed input: 163.05 toks/s, output: 594.06 toks/s]Processed prompts:  61%|██████    | 304/500 [30:51<19:58,  6.12s/it, est. speed input: 163.41 toks/s, output: 592.65 toks/s]Processed prompts:  61%|██████    | 305/500 [30:53<16:45,  5.16s/it, est. speed input: 163.94 toks/s, output: 595.52 toks/s]Processed prompts:  61%|██████    | 306/500 [30:56<14:15,  4.41s/it, est. speed input: 164.59 toks/s, output: 595.89 toks/s]Processed prompts:  61%|██████▏   | 307/500 [31:24<36:54, 11.47s/it, est. speed input: 162.35 toks/s, output: 591.05 toks/s]Processed prompts:  62%|██████▏   | 308/500 [31:31<31:55,  9.97s/it, est. speed input: 162.46 toks/s, output: 593.07 toks/s]Processed prompts:  62%|██████▏   | 309/500 [31:41<32:18, 10.15s/it, est. speed input: 161.76 toks/s, output: 593.75 toks/s]Processed prompts:  62%|██████▏   | 310/500 [31:44<25:32,  8.07s/it, est. speed input: 161.70 toks/s, output: 596.78 toks/s]Processed prompts:  62%|██████▏   | 311/500 [31:59<31:13,  9.91s/it, est. speed input: 160.68 toks/s, output: 595.56 toks/s]Processed prompts:  62%|██████▏   | 312/500 [32:22<43:59, 14.04s/it, est. speed input: 160.19 toks/s, output: 588.67 toks/s]Processed prompts:  63%|██████▎   | 313/500 [32:24<32:30, 10.43s/it, est. speed input: 161.27 toks/s, output: 588.53 toks/s]Processed prompts:  63%|██████▎   | 314/500 [32:42<39:20, 12.69s/it, est. speed input: 159.96 toks/s, output: 586.59 toks/s]Processed prompts:  63%|██████▎   | 315/500 [32:43<28:11,  9.15s/it, est. speed input: 161.30 toks/s, output: 587.02 toks/s]Processed prompts:  63%|██████▎   | 316/500 [32:48<23:44,  7.74s/it, est. speed input: 161.49 toks/s, output: 586.96 toks/s]Processed prompts:  63%|██████▎   | 317/500 [32:48<16:42,  5.48s/it, est. speed input: 161.61 toks/s, output: 589.26 toks/s]Processed prompts:  64%|██████▎   | 318/500 [33:12<33:29, 11.04s/it, est. speed input: 160.10 toks/s, output: 586.60 toks/s]Processed prompts:  64%|██████▍   | 319/500 [33:21<31:33, 10.46s/it, est. speed input: 159.50 toks/s, output: 585.06 toks/s]Processed prompts:  64%|██████▍   | 320/500 [33:30<29:54,  9.97s/it, est. speed input: 159.12 toks/s, output: 587.94 toks/s]Processed prompts:  64%|██████▍   | 321/500 [33:38<28:00,  9.39s/it, est. speed input: 158.96 toks/s, output: 586.52 toks/s]WARNING 04-06 14:41:22 scheduler.py:1555] Sequence group 355 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  64%|██████▍   | 322/500 [33:51<31:12, 10.52s/it, est. speed input: 158.77 toks/s, output: 583.25 toks/s]Processed prompts:  65%|██████▍   | 323/500 [33:54<24:16,  8.23s/it, est. speed input: 158.70 toks/s, output: 584.09 toks/s]Processed prompts:  65%|██████▍   | 324/500 [34:01<23:13,  7.92s/it, est. speed input: 158.26 toks/s, output: 583.41 toks/s]Processed prompts:  65%|██████▌   | 325/500 [34:09<23:03,  7.91s/it, est. speed input: 157.82 toks/s, output: 582.69 toks/s]Processed prompts:  65%|██████▌   | 326/500 [34:10<16:46,  5.78s/it, est. speed input: 157.92 toks/s, output: 583.82 toks/s]Processed prompts:  65%|██████▌   | 327/500 [34:15<16:17,  5.65s/it, est. speed input: 158.82 toks/s, output: 583.18 toks/s]Processed prompts:  66%|██████▌   | 328/500 [34:15<11:28,  4.00s/it, est. speed input: 158.94 toks/s, output: 585.40 toks/s]Processed prompts:  66%|██████▌   | 329/500 [34:24<15:15,  5.35s/it, est. speed input: 158.39 toks/s, output: 583.26 toks/s]Processed prompts:  66%|██████▌   | 330/500 [34:27<13:23,  4.73s/it, est. speed input: 158.27 toks/s, output: 586.42 toks/s]Processed prompts:  66%|██████▌   | 331/500 [34:50<29:14, 10.38s/it, est. speed input: 157.20 toks/s, output: 585.56 toks/s]Processed prompts:  66%|██████▋   | 332/500 [34:52<21:41,  7.75s/it, est. speed input: 157.27 toks/s, output: 586.53 toks/s]Processed prompts:  67%|██████▋   | 333/500 [35:02<23:46,  8.54s/it, est. speed input: 157.78 toks/s, output: 583.96 toks/s]Processed prompts:  67%|██████▋   | 334/500 [35:16<28:03, 10.14s/it, est. speed input: 156.93 toks/s, output: 581.61 toks/s]Processed prompts:  67%|██████▋   | 335/500 [35:18<21:13,  7.72s/it, est. speed input: 156.96 toks/s, output: 582.22 toks/s]Processed prompts:  67%|██████▋   | 336/500 [35:20<16:23,  6.00s/it, est. speed input: 157.01 toks/s, output: 583.44 toks/s]Processed prompts:  67%|██████▋   | 337/500 [35:38<25:22,  9.34s/it, est. speed input: 156.64 toks/s, output: 580.61 toks/s]Processed prompts:  68%|██████▊   | 338/500 [35:47<25:23,  9.41s/it, est. speed input: 156.05 toks/s, output: 578.58 toks/s]Processed prompts:  68%|██████▊   | 339/500 [36:03<30:21, 11.31s/it, est. speed input: 155.09 toks/s, output: 576.49 toks/s]Processed prompts:  68%|██████▊   | 340/500 [36:08<25:17,  9.49s/it, est. speed input: 154.87 toks/s, output: 576.23 toks/s]Processed prompts:  68%|██████▊   | 341/500 [36:21<27:50, 10.51s/it, est. speed input: 154.06 toks/s, output: 573.61 toks/s]Processed prompts:  68%|██████▊   | 342/500 [36:35<30:12, 11.47s/it, est. speed input: 153.30 toks/s, output: 570.94 toks/s]Processed prompts:  69%|██████▊   | 343/500 [36:38<23:32,  8.99s/it, est. speed input: 153.25 toks/s, output: 572.36 toks/s]Processed prompts:  69%|██████▉   | 344/500 [36:57<31:25, 12.09s/it, est. speed input: 152.03 toks/s, output: 568.77 toks/s]Processed prompts:  69%|██████▉   | 345/500 [37:19<38:53, 15.06s/it, est. speed input: 150.68 toks/s, output: 565.69 toks/s]Processed prompts:  69%|██████▉   | 346/500 [37:34<38:34, 15.03s/it, est. speed input: 149.78 toks/s, output: 563.54 toks/s]Processed prompts:  69%|██████▉   | 347/500 [37:51<39:51, 15.63s/it, est. speed input: 148.80 toks/s, output: 561.11 toks/s]Processed prompts:  70%|██████▉   | 348/500 [37:55<30:28, 12.03s/it, est. speed input: 148.66 toks/s, output: 562.95 toks/s]Processed prompts:  70%|██████▉   | 349/500 [37:58<23:13,  9.23s/it, est. speed input: 148.83 toks/s, output: 563.22 toks/s]Processed prompts:  70%|███████   | 350/500 [38:16<29:56, 11.98s/it, est. speed input: 147.86 toks/s, output: 561.55 toks/s]Processed prompts:  70%|███████   | 351/500 [38:33<33:22, 13.44s/it, est. speed input: 147.26 toks/s, output: 561.86 toks/s]Processed prompts:  70%|███████   | 352/500 [38:34<24:16,  9.84s/it, est. speed input: 147.31 toks/s, output: 562.53 toks/s]Processed prompts:  71%|███████   | 353/500 [38:44<23:57,  9.78s/it, est. speed input: 146.80 toks/s, output: 560.71 toks/s]Processed prompts:  71%|███████   | 354/500 [38:46<18:07,  7.45s/it, est. speed input: 146.79 toks/s, output: 561.70 toks/s]Processed prompts:  71%|███████   | 355/500 [38:49<14:38,  6.06s/it, est. speed input: 147.79 toks/s, output: 561.22 toks/s]Processed prompts:  71%|███████   | 356/500 [38:52<12:30,  5.21s/it, est. speed input: 147.73 toks/s, output: 560.49 toks/s]Processed prompts:  71%|███████▏  | 357/500 [38:54<10:29,  4.40s/it, est. speed input: 148.46 toks/s, output: 565.85 toks/s]Processed prompts:  72%|███████▏  | 358/500 [39:03<13:24,  5.66s/it, est. speed input: 148.03 toks/s, output: 563.84 toks/s]Processed prompts:  72%|███████▏  | 359/500 [39:05<10:44,  4.57s/it, est. speed input: 148.28 toks/s, output: 569.33 toks/s]WARNING 04-06 14:46:45 scheduler.py:1555] Sequence group 413 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  72%|███████▏  | 360/500 [39:18<16:32,  7.09s/it, est. speed input: 147.57 toks/s, output: 566.37 toks/s]Processed prompts:  72%|███████▏  | 361/500 [39:24<15:38,  6.75s/it, est. speed input: 147.33 toks/s, output: 565.10 toks/s]Processed prompts:  72%|███████▏  | 362/500 [39:47<26:30, 11.53s/it, est. speed input: 146.05 toks/s, output: 562.20 toks/s]Processed prompts:  73%|███████▎  | 363/500 [39:52<22:08,  9.70s/it, est. speed input: 145.82 toks/s, output: 561.22 toks/s]Processed prompts:  73%|███████▎  | 364/500 [39:57<18:51,  8.32s/it, est. speed input: 145.60 toks/s, output: 560.35 toks/s]Processed prompts:  73%|███████▎  | 365/500 [40:16<25:53, 11.51s/it, est. speed input: 144.56 toks/s, output: 556.39 toks/s]Processed prompts:  73%|███████▎  | 366/500 [40:51<41:07, 18.41s/it, est. speed input: 142.84 toks/s, output: 549.73 toks/s]Processed prompts:  73%|███████▎  | 367/500 [41:03<36:32, 16.49s/it, est. speed input: 142.24 toks/s, output: 548.28 toks/s]Processed prompts:  74%|███████▎  | 368/500 [41:20<36:53, 16.77s/it, est. speed input: 141.33 toks/s, output: 547.37 toks/s]Processed prompts:  74%|███████▍  | 369/500 [41:26<29:45, 13.63s/it, est. speed input: 141.13 toks/s, output: 546.86 toks/s]Processed prompts:  74%|███████▍  | 370/500 [41:44<31:52, 14.71s/it, est. speed input: 140.72 toks/s, output: 546.90 toks/s]Processed prompts:  74%|███████▍  | 371/500 [42:05<36:07, 16.81s/it, est. speed input: 139.64 toks/s, output: 543.25 toks/s]Processed prompts:  74%|███████▍  | 372/500 [42:51<54:38, 25.61s/it, est. speed input: 137.81 toks/s, output: 536.52 toks/s]Processed prompts:  75%|███████▍  | 373/500 [42:54<39:48, 18.81s/it, est. speed input: 137.97 toks/s, output: 548.63 toks/s]Processed prompts:  75%|███████▍  | 374/500 [42:57<29:02, 13.83s/it, est. speed input: 137.98 toks/s, output: 548.30 toks/s]Processed prompts:  75%|███████▌  | 375/500 [43:18<33:48, 16.23s/it, est. speed input: 137.53 toks/s, output: 545.32 toks/s]Processed prompts:  75%|███████▌  | 376/500 [43:22<25:47, 12.48s/it, est. speed input: 138.19 toks/s, output: 546.00 toks/s]WARNING 04-06 14:50:59 scheduler.py:1555] Sequence group 413 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  75%|███████▌  | 377/500 [44:09<46:33, 22.71s/it, est. speed input: 135.99 toks/s, output: 536.91 toks/s]Processed prompts:  76%|███████▌  | 378/500 [45:16<1:13:29, 36.14s/it, est. speed input: 133.08 toks/s, output: 525.69 toks/s]Processed prompts:  76%|███████▌  | 379/500 [45:17<51:16, 25.43s/it, est. speed input: 133.21 toks/s, output: 526.67 toks/s]  Processed prompts:  76%|███████▌  | 380/500 [45:47<53:44, 26.87s/it, est. speed input: 132.55 toks/s, output: 532.80 toks/s]Processed prompts:  76%|███████▌  | 381/500 [45:50<39:09, 19.74s/it, est. speed input: 132.48 toks/s, output: 532.70 toks/s]Processed prompts:  76%|███████▋  | 382/500 [45:52<28:19, 14.40s/it, est. speed input: 132.52 toks/s, output: 535.18 toks/s]Processed prompts:  77%|███████▋  | 383/500 [47:51<1:29:18, 45.80s/it, est. speed input: 127.63 toks/s, output: 516.45 toks/s]Processed prompts:  77%|███████▋  | 384/500 [48:30<1:24:25, 43.67s/it, est. speed input: 126.01 toks/s, output: 512.34 toks/s]Processed prompts:  77%|███████▋  | 385/500 [51:15<2:33:38, 80.16s/it, est. speed input: 119.99 toks/s, output: 495.46 toks/s]Processed prompts:  77%|███████▋  | 386/500 [51:46<2:04:04, 65.30s/it, est. speed input: 119.66 toks/s, output: 501.12 toks/s]WARNING 04-06 14:59:27 scheduler.py:1555] Sequence group 411 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  77%|███████▋  | 387/500 [52:05<1:37:05, 51.56s/it, est. speed input: 119.02 toks/s, output: 508.48 toks/s]WARNING 04-06 15:06:39 scheduler.py:1555] Sequence group 396 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  78%|███████▊  | 388/500 [59:16<5:08:48, 165.43s/it, est. speed input: 105.35 toks/s, output: 456.06 toks/s]Processed prompts:  78%|███████▊  | 389/500 [1:03:51<6:06:55, 198.34s/it, est. speed input: 98.53 toks/s, output: 431.87 toks/s]Processed prompts:  78%|███████▊  | 390/500 [1:06:51<5:53:16, 192.69s/it, est. speed input: 94.56 toks/s, output: 420.71 toks/s]Processed prompts:  78%|███████▊  | 391/500 [1:08:05<4:45:21, 157.07s/it, est. speed input: 92.98 toks/s, output: 421.11 toks/s]Processed prompts:  78%|███████▊  | 392/500 [1:13:17<6:06:12, 203.45s/it, est. speed input: 86.88 toks/s, output: 398.62 toks/s]Processed prompts:  79%|███████▊  | 393/500 [1:14:14<4:44:54, 159.76s/it, est. speed input: 86.21 toks/s, output: 400.80 toks/s]Processed prompts:  79%|███████▉  | 394/500 [1:14:33<3:27:24, 117.40s/it, est. speed input: 85.92 toks/s, output: 406.46 toks/s]Processed prompts:  79%|███████▉  | 395/500 [1:14:36<2:25:35, 83.20s/it, est. speed input: 85.92 toks/s, output: 413.47 toks/s] Processed prompts:  79%|███████▉  | 396/500 [1:15:07<1:56:56, 67.47s/it, est. speed input: 85.38 toks/s, output: 410.85 toks/s]Processed prompts:  79%|███████▉  | 397/500 [1:15:35<1:35:40, 55.73s/it, est. speed input: 85.05 toks/s, output: 415.51 toks/s]WARNING 04-06 15:23:38 scheduler.py:1555] Sequence group 433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  80%|███████▉  | 398/500 [1:17:10<1:54:42, 67.47s/it, est. speed input: 83.46 toks/s, output: 414.07 toks/s]Processed prompts:  80%|███████▉  | 399/500 [1:25:44<5:39:03, 201.42s/it, est. speed input: 75.19 toks/s, output: 379.08 toks/s]Processed prompts:  80%|████████  | 400/500 [1:28:13<5:09:30, 185.70s/it, est. speed input: 73.40 toks/s, output: 374.59 toks/s]Processed prompts:  80%|████████  | 401/500 [1:30:39<4:46:45, 173.79s/it, est. speed input: 71.53 toks/s, output: 370.56 toks/s]Processed prompts:  80%|████████  | 402/500 [1:31:12<3:34:43, 131.47s/it, est. speed input: 71.29 toks/s, output: 374.34 toks/s]WARNING 04-06 15:42:20 scheduler.py:1555] Sequence group 412 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  81%|████████  | 403/500 [1:36:51<5:12:58, 193.59s/it, est. speed input: 67.18 toks/s, output: 358.17 toks/s]Processed prompts:  81%|████████  | 404/500 [1:40:49<5:31:14, 207.02s/it, est. speed input: 64.81 toks/s, output: 349.47 toks/s]Processed prompts:  81%|████████  | 405/500 [1:41:06<3:57:43, 150.15s/it, est. speed input: 64.66 toks/s, output: 350.94 toks/s]Processed prompts:  81%|████████  | 406/500 [1:41:50<3:05:09, 118.19s/it, est. speed input: 64.25 toks/s, output: 353.80 toks/s]Processed prompts:  81%|████████▏ | 407/500 [1:42:27<2:25:15, 93.71s/it, est. speed input: 63.91 toks/s, output: 357.02 toks/s] Processed prompts:  82%|████████▏ | 408/500 [1:42:53<1:52:53, 73.63s/it, est. speed input: 63.76 toks/s, output: 360.78 toks/s]Processed prompts:  82%|████████▏ | 409/500 [1:43:33<1:36:12, 63.43s/it, est. speed input: 63.68 toks/s, output: 363.75 toks/s]Processed prompts:  82%|████████▏ | 410/500 [1:44:36<1:34:46, 63.18s/it, est. speed input: 63.08 toks/s, output: 365.35 toks/s]Processed prompts:  82%|████████▏ | 411/500 [1:44:42<1:08:33, 46.22s/it, est. speed input: 63.05 toks/s, output: 364.99 toks/s]WARNING 04-06 15:53:10 scheduler.py:1555] Sequence group 436 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  82%|████████▏ | 412/500 [1:50:56<3:31:46, 144.40s/it, est. speed input: 59.54 toks/s, output: 349.43 toks/s]Processed prompts:  83%|████████▎ | 413/500 [1:51:38<2:45:07, 113.87s/it, est. speed input: 59.20 toks/s, output: 352.10 toks/s]Processed prompts:  83%|████████▎ | 414/500 [1:57:19<4:20:32, 181.77s/it, est. speed input: 56.37 toks/s, output: 339.74 toks/s]Processed prompts:  83%|████████▎ | 415/500 [1:57:45<3:11:43, 135.33s/it, est. speed input: 56.22 toks/s, output: 341.19 toks/s]Processed prompts:  83%|████████▎ | 416/500 [2:04:58<5:14:28, 224.63s/it, est. speed input: 53.02 toks/s, output: 325.86 toks/s]Processed prompts:  83%|████████▎ | 417/500 [2:06:36<4:17:49, 186.38s/it, est. speed input: 52.71 toks/s, output: 326.00 toks/s]Processed prompts:  84%|████████▎ | 418/500 [2:08:14<3:38:38, 159.98s/it, est. speed input: 52.35 toks/s, output: 326.09 toks/s]Processed prompts:  84%|████████▍ | 419/500 [2:09:22<2:58:40, 132.35s/it, est. speed input: 52.18 toks/s, output: 327.46 toks/s]Processed prompts:  84%|████████▍ | 420/500 [2:09:59<2:18:26, 103.83s/it, est. speed input: 51.98 toks/s, output: 330.10 toks/s]Processed prompts:  84%|████████▍ | 421/500 [2:10:16<1:42:33, 77.89s/it, est. speed input: 51.90 toks/s, output: 333.56 toks/s] Processed prompts:  84%|████████▍ | 422/500 [2:10:21<1:12:48, 56.00s/it, est. speed input: 51.90 toks/s, output: 333.39 toks/s]Processed prompts:  85%|████████▍ | 423/500 [2:10:33<54:54, 42.79s/it, est. speed input: 51.87 toks/s, output: 337.07 toks/s]  WARNING 04-06 16:18:27 scheduler.py:1555] Sequence group 473 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  85%|████████▍ | 424/500 [2:11:38<1:02:30, 49.35s/it, est. speed input: 51.48 toks/s, output: 334.52 toks/s]Processed prompts:  85%|████████▌ | 425/500 [2:11:51<48:00, 38.41s/it, est. speed input: 51.44 toks/s, output: 334.20 toks/s]  Processed prompts:  85%|████████▌ | 426/500 [2:12:01<36:50, 29.87s/it, est. speed input: 51.40 toks/s, output: 334.04 toks/s]Processed prompts:  85%|████████▌ | 427/500 [2:12:53<44:20, 36.45s/it, est. speed input: 51.10 toks/s, output: 335.98 toks/s]WARNING 04-06 16:25:52 scheduler.py:1555] Sequence group 434 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  86%|████████▌ | 428/500 [2:22:04<3:49:00, 190.84s/it, est. speed input: 47.83 toks/s, output: 318.10 toks/s]Processed prompts:  86%|████████▌ | 429/500 [2:23:11<3:01:49, 153.65s/it, est. speed input: 47.49 toks/s, output: 319.44 toks/s]Processed prompts:  86%|████████▌ | 430/500 [2:26:32<3:16:00, 168.00s/it, est. speed input: 46.44 toks/s, output: 315.85 toks/s]Processed prompts:  86%|████████▌ | 431/500 [2:27:15<2:29:55, 130.37s/it, est. speed input: 46.26 toks/s, output: 318.04 toks/s]Processed prompts:  86%|████████▋ | 432/500 [2:32:02<3:21:05, 177.43s/it, est. speed input: 45.03 toks/s, output: 311.61 toks/s]Processed prompts:  87%|████████▋ | 433/500 [2:34:31<3:08:45, 169.04s/it, est. speed input: 44.49 toks/s, output: 310.13 toks/s]Processed prompts:  87%|████████▋ | 434/500 [2:37:23<3:06:40, 169.71s/it, est. speed input: 43.71 toks/s, output: 307.97 toks/s]Processed prompts:  87%|████████▋ | 435/500 [2:37:36<2:13:01, 122.80s/it, est. speed input: 43.89 toks/s, output: 311.00 toks/s]Processed prompts:  87%|████████▋ | 436/500 [2:38:34<1:50:13, 103.34s/it, est. speed input: 43.65 toks/s, output: 312.55 toks/s]Processed prompts:  87%|████████▋ | 437/500 [2:39:27<1:32:45, 88.35s/it, est. speed input: 43.43 toks/s, output: 314.23 toks/s] Processed prompts:  88%|████████▊ | 438/500 [2:43:14<2:14:20, 130.00s/it, est. speed input: 42.45 toks/s, output: 310.29 toks/s]Processed prompts:  88%|████████▊ | 439/500 [2:45:05<2:06:13, 124.16s/it, est. speed input: 42.01 toks/s, output: 310.14 toks/s]WARNING 04-06 16:53:36 scheduler.py:1555] Sequence group 452 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  88%|████████▊ | 440/500 [2:48:19<2:25:05, 145.09s/it, est. speed input: 41.23 toks/s, output: 307.42 toks/s]Processed prompts:  88%|████████▊ | 441/500 [2:51:42<2:39:51, 162.57s/it, est. speed input: 40.65 toks/s, output: 304.54 toks/s]Processed prompts:  88%|████████▊ | 442/500 [2:54:25<2:37:14, 162.67s/it, est. speed input: 40.07 toks/s, output: 302.93 toks/s]Processed prompts:  89%|████████▊ | 443/500 [3:00:38<3:34:23, 225.68s/it, est. speed input: 38.91 toks/s, output: 295.53 toks/s]Processed prompts:  89%|████████▉ | 444/500 [3:00:55<2:32:18, 163.18s/it, est. speed input: 38.88 toks/s, output: 298.08 toks/s]Processed prompts:  89%|████████▉ | 445/500 [3:03:54<2:33:53, 167.89s/it, est. speed input: 38.34 toks/s, output: 296.22 toks/s]Processed prompts:  89%|████████▉ | 446/500 [3:04:21<1:53:00, 125.57s/it, est. speed input: 38.27 toks/s, output: 298.46 toks/s]Processed prompts:  89%|████████▉ | 447/500 [3:04:45<1:23:55, 95.01s/it, est. speed input: 38.22 toks/s, output: 300.78 toks/s] Processed prompts:  90%|████████▉ | 448/500 [3:05:16<1:05:49, 75.95s/it, est. speed input: 38.14 toks/s, output: 302.88 toks/s]WARNING 04-06 17:14:04 scheduler.py:1555] Sequence group 482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  90%|████████▉ | 449/500 [3:06:57<1:10:47, 83.29s/it, est. speed input: 37.83 toks/s, output: 303.09 toks/s]Processed prompts:  90%|█████████ | 450/500 [3:07:51<1:02:13, 74.68s/it, est. speed input: 37.67 toks/s, output: 301.94 toks/s]Processed prompts:  90%|█████████ | 451/500 [3:08:44<55:39, 68.15s/it, est. speed input: 37.51 toks/s, output: 300.84 toks/s]  Processed prompts:  90%|█████████ | 452/500 [3:08:50<39:31, 49.41s/it, est. speed input: 37.52 toks/s, output: 300.99 toks/s]Processed prompts:  91%|█████████ | 453/500 [3:16:52<2:20:32, 179.41s/it, est. speed input: 36.01 toks/s, output: 291.47 toks/s]Processed prompts:  91%|█████████ | 454/500 [3:17:46<1:48:29, 141.50s/it, est. speed input: 36.06 toks/s, output: 292.92 toks/s]Processed prompts:  91%|█████████ | 455/500 [3:18:53<1:29:27, 119.28s/it, est. speed input: 35.88 toks/s, output: 294.02 toks/s]Processed prompts:  91%|█████████ | 456/500 [3:18:58<1:02:20, 85.01s/it, est. speed input: 36.04 toks/s, output: 294.59 toks/s] Processed prompts:  91%|█████████▏| 457/500 [3:19:54<54:43, 76.37s/it, est. speed input: 35.99 toks/s, output: 295.94 toks/s]  WARNING 04-06 17:29:47 scheduler.py:1555] Sequence group 467 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  92%|█████████▏| 458/500 [3:22:32<1:10:29, 100.70s/it, est. speed input: 35.70 toks/s, output: 294.80 toks/s]Processed prompts:  92%|█████████▏| 459/500 [3:28:53<2:06:18, 184.84s/it, est. speed input: 34.64 toks/s, output: 287.49 toks/s]Processed prompts:  92%|█████████▏| 460/500 [3:33:40<2:23:40, 215.51s/it, est. speed input: 34.06 toks/s, output: 283.61 toks/s]Processed prompts:  92%|█████████▏| 461/500 [3:34:56<1:52:54, 173.69s/it, est. speed input: 34.03 toks/s, output: 284.47 toks/s]Processed prompts:  92%|█████████▏| 462/500 [3:35:16<1:20:47, 127.55s/it, est. speed input: 34.00 toks/s, output: 286.57 toks/s]Processed prompts:  93%|█████████▎| 463/500 [3:35:32<57:59, 94.04s/it, est. speed input: 33.98 toks/s, output: 288.75 toks/s]   Processed prompts:  93%|█████████▎| 464/500 [3:36:23<48:40, 81.13s/it, est. speed input: 33.98 toks/s, output: 290.14 toks/s]Processed prompts:  93%|█████████▎| 465/500 [3:37:57<49:41, 85.19s/it, est. speed input: 33.75 toks/s, output: 290.55 toks/s]Processed prompts:  93%|█████████▎| 466/500 [3:39:54<53:37, 94.64s/it, est. speed input: 33.47 toks/s, output: 290.46 toks/s]Processed prompts:  93%|█████████▎| 467/500 [3:43:19<1:10:17, 127.79s/it, est. speed input: 33.16 toks/s, output: 288.46 toks/s]WARNING 04-06 17:53:55 scheduler.py:1555] Sequence group 478 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  94%|█████████▎| 468/500 [3:51:25<2:05:24, 235.13s/it, est. speed input: 32.17 toks/s, output: 280.73 toks/s]Processed prompts:  94%|█████████▍| 469/500 [3:52:35<1:35:58, 185.75s/it, est. speed input: 32.03 toks/s, output: 281.66 toks/s]Processed prompts:  94%|█████████▍| 470/500 [3:54:22<1:20:56, 161.87s/it, est. speed input: 31.81 toks/s, output: 281.87 toks/s]Processed prompts:  94%|█████████▍| 471/500 [3:56:21<1:12:01, 149.03s/it, est. speed input: 31.56 toks/s, output: 281.81 toks/s]Processed prompts:  94%|█████████▍| 472/500 [3:58:11<1:04:09, 137.49s/it, est. speed input: 31.40 toks/s, output: 281.67 toks/s]Processed prompts:  95%|█████████▍| 473/500 [4:00:35<1:02:39, 139.25s/it, est. speed input: 31.26 toks/s, output: 281.15 toks/s]Processed prompts:  95%|█████████▍| 474/500 [4:03:02<1:01:22, 141.62s/it, est. speed input: 30.97 toks/s, output: 280.56 toks/s]Processed prompts:  95%|█████████▌| 475/500 [4:03:58<48:23, 116.14s/it, est. speed input: 30.87 toks/s, output: 279.51 toks/s]  Processed prompts:  95%|█████████▌| 476/500 [4:04:03<33:01, 82.55s/it, est. speed input: 30.94 toks/s, output: 281.67 toks/s] Processed prompts:  95%|█████████▌| 477/500 [4:05:00<28:48, 75.16s/it, est. speed input: 30.86 toks/s, output: 282.79 toks/s]Processed prompts:  96%|█████████▌| 478/500 [4:05:13<20:37, 56.23s/it, est. speed input: 30.99 toks/s, output: 282.78 toks/s]Processed prompts:  96%|█████████▌| 479/500 [4:08:30<34:31, 98.66s/it, est. speed input: 30.60 toks/s, output: 281.23 toks/s]Processed prompts:  96%|█████████▌| 480/500 [4:13:37<53:41, 161.08s/it, est. speed input: 30.00 toks/s, output: 277.71 toks/s]Processed prompts:  96%|█████████▌| 481/500 [4:13:54<37:19, 117.86s/it, est. speed input: 30.02 toks/s, output: 279.55 toks/s]Processed prompts:  96%|█████████▋| 482/500 [4:18:03<47:07, 157.09s/it, est. speed input: 29.70 toks/s, output: 276.01 toks/s]WARNING 04-06 18:27:39 scheduler.py:1555] Sequence group 493 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
Processed prompts:  97%|█████████▋| 483/500 [4:20:54<45:41, 161.28s/it, est. speed input: 29.40 toks/s, output: 275.09 toks/s]Processed prompts:  97%|█████████▋| 484/500 [4:21:23<32:27, 121.70s/it, est. speed input: 29.47 toks/s, output: 276.66 toks/s]Processed prompts:  97%|█████████▋| 485/500 [4:25:36<40:18, 161.23s/it, est. speed input: 29.19 toks/s, output: 274.32 toks/s]Processed prompts:  97%|█████████▋| 486/500 [4:27:06<32:36, 139.75s/it, est. speed input: 29.21 toks/s, output: 274.83 toks/s]Processed prompts:  97%|█████████▋| 487/500 [4:31:39<38:54, 179.57s/it, est. speed input: 28.86 toks/s, output: 272.25 toks/s]Processed prompts:  98%|█████████▊| 488/500 [4:34:32<35:34, 177.84s/it, est. speed input: 28.58 toks/s, output: 271.36 toks/s]Processed prompts:  98%|█████████▊| 489/500 [4:35:06<24:40, 134.60s/it, est. speed input: 28.54 toks/s, output: 272.79 toks/s]Processed prompts:  98%|█████████▊| 490/500 [4:35:29<16:50, 101.05s/it, est. speed input: 28.63 toks/s, output: 274.40 toks/s]Processed prompts:  98%|█████████▊| 491/500 [4:36:11<12:29, 83.32s/it, est. speed input: 28.58 toks/s, output: 275.68 toks/s] Processed prompts:  98%|█████████▊| 492/500 [4:38:07<12:25, 93.25s/it, est. speed input: 28.44 toks/s, output: 275.72 toks/s]Processed prompts:  99%|█████████▊| 493/500 [4:40:16<12:07, 103.89s/it, est. speed input: 28.24 toks/s, output: 275.56 toks/s]Processed prompts:  99%|█████████▉| 494/500 [4:42:20<11:00, 110.10s/it, est. speed input: 28.05 toks/s, output: 275.47 toks/s]Processed prompts:  99%|█████████▉| 495/500 [4:47:14<13:46, 165.25s/it, est. speed input: 27.60 toks/s, output: 272.67 toks/s]Processed prompts:  99%|█████████▉| 496/500 [4:48:03<08:40, 130.23s/it, est. speed input: 27.54 toks/s, output: 273.80 toks/s]Processed prompts:  99%|█████████▉| 497/500 [4:48:10<04:40, 93.39s/it, est. speed input: 27.59 toks/s, output: 275.58 toks/s] Processed prompts: 100%|█████████▉| 498/500 [4:52:05<04:31, 135.85s/it, est. speed input: 27.24 toks/s, output: 273.76 toks/s]Processed prompts: 100%|█████████▉| 499/500 [4:52:20<01:39, 99.49s/it, est. speed input: 27.31 toks/s, output: 275.40 toks/s] Processed prompts: 100%|██████████| 500/500 [4:56:11<00:00, 139.05s/it, est. speed input: 27.07 toks/s, output: 273.65 toks/s]Processed prompts: 100%|██████████| 500/500 [4:56:11<00:00, 35.54s/it, est. speed input: 27.07 toks/s, output: 273.65 toks/s] 
INFO 04-06 19:03:43 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2371574)[0;0m INFO 04-06 19:03:43 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2371572)[0;0m INFO 04-06 19:03:43 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2371573)[0;0m INFO 04-06 19:03:43 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W406 19:03:55.266583033 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-06 19:04:12 config.py:510] This model supports multiple tasks: {'embed', 'reward', 'generate', 'classify', 'score'}. Defaulting to 'generate'.
INFO 04-06 19:04:12 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-06 19:04:12 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-06 19:04:12 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-06 19:04:12 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-06 19:04:13 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-06 19:04:13 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:14 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:14 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-06 19:04:14 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:14 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:14 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:14 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:14 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-06 19:04:15 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:15 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-06 19:04:15 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:15 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:15 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:15 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:15 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:15 pynccl.py:69] vLLM is using nccl==2.21.5
WARNING 04-06 19:04:15 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2409679)[0;0m WARNING 04-06 19:04:15 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2409677)[0;0m WARNING 04-06 19:04:15 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2409678)[0;0m WARNING 04-06 19:04:15 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-06 19:04:15 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_af4e17cd'), local_subscribe_port=50819, remote_subscribe_port=None)
INFO 04-06 19:04:15 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:15 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:15 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:15 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.37it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.68it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.13it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.98it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.91it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:02<00:04,  1.88it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.86it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.85it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.84it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.83it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.96it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.92it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.94it/s]

INFO 04-06 19:04:23 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:23 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:24 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:24 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:26 worker.py:241] Memory profiling takes 2.64 seconds
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:26 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:26 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:26 worker.py:241] Memory profiling takes 2.65 seconds
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:26 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:26 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:26 worker.py:241] Memory profiling takes 2.73 seconds
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:26 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:26 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
INFO 04-06 19:04:26 worker.py:241] Memory profiling takes 2.76 seconds
INFO 04-06 19:04:26 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-06 19:04:26 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-06 19:04:27 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-06 19:04:27 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:04:41 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:04:41 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:04:41 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-06 19:04:41 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<02:09,  1.00it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:10,  1.01s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:07,  1.00it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:08,  1.01s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:05,  1.00it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:05<02:04,  1.00it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:03,  1.00it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:07<02:02,  1.01it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:08<02:00,  1.01it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:09<01:59,  1.01it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:10<01:57,  1.02it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:11<01:57,  1.01it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:12<01:56,  1.01it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:13<01:57,  1.00s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:14<01:55,  1.00it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:15<01:53,  1.01it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:16<01:51,  1.03it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:17<01:48,  1.04it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:18<01:49,  1.03it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:19<01:45,  1.05it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:20<01:44,  1.05it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:21<01:41,  1.07it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:22<01:41,  1.07it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:23<01:39,  1.08it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:24<01:38,  1.08it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:25<01:38,  1.07it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:26<01:36,  1.07it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:27<01:35,  1.08it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:27<01:33,  1.09it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:28<01:33,  1.08it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:29<01:31,  1.09it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:30<01:30,  1.09it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:31<01:28,  1.11it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:32<01:27,  1.11it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:33<01:24,  1.13it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:34<01:24,  1.12it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:35<01:21,  1.15it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:35<01:20,  1.16it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:36<01:20,  1.15it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:37<01:18,  1.16it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:38<01:17,  1.17it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:39<01:17,  1.15it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:40<01:14,  1.18it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:41<01:14,  1.18it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:41<01:13,  1.17it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:42<01:12,  1.17it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:43<01:12,  1.17it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:44<01:09,  1.19it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:45<01:08,  1.19it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:46<01:07,  1.20it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:46<01:07,  1.18it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:47<01:06,  1.19it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:48<01:05,  1.18it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:49<01:03,  1.21it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:50<01:02,  1.22it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:51<01:01,  1.22it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:51<01:00,  1.22it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:52<01:00,  1.21it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:53<00:58,  1.24it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:54<00:57,  1.23it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:55<00:57,  1.22it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:55<00:55,  1.23it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:56<00:55,  1.24it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:57<00:53,  1.25it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:58<00:52,  1.27it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:59<00:49,  1.30it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:59<00:49,  1.30it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:00<00:47,  1.32it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:01<00:46,  1.34it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:01<00:45,  1.34it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:02<00:44,  1.34it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:03<00:44,  1.33it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:04<00:44,  1.31it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:04<00:42,  1.34it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:05<00:41,  1.35it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:06<00:40,  1.36it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:07<00:39,  1.37it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:07<00:38,  1.36it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:08<00:38,  1.35it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:09<00:37,  1.37it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:10<00:35,  1.40it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:10<00:34,  1.41it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:11<00:33,  1.43it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:12<00:32,  1.43it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:12<00:32,  1.44it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:13<00:31,  1.43it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:14<00:29,  1.47it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:14<00:29,  1.46it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:15<00:28,  1.47it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:16<00:28,  1.43it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:16<00:27,  1.47it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:17<00:26,  1.48it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:18<00:25,  1.48it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:18<00:24,  1.50it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:19<00:24,  1.49it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:20<00:23,  1.47it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:20<00:22,  1.51it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:21<00:21,  1.52it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:22<00:20,  1.53it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:22<00:20,  1.55it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:23<00:19,  1.55it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:24<00:18,  1.56it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:24<00:18,  1.54it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:25<00:16,  1.60it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:25<00:16,  1.57it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:26<00:15,  1.62it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:27<00:14,  1.62it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:27<00:14,  1.61it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:28<00:13,  1.61it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:29<00:12,  1.62it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:29<00:12,  1.61it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:30<00:11,  1.63it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:30<00:10,  1.66it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:31<00:10,  1.65it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:31<00:09,  1.70it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:32<00:08,  1.71it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:33<00:08,  1.71it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:33<00:07,  1.66it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:34<00:07,  1.71it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:34<00:06,  1.69it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:35<00:05,  1.72it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:36<00:05,  1.69it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:36<00:04,  1.71it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:37<00:04,  1.74it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:37<00:03,  1.72it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:38<00:02,  1.75it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:38<00:02,  1.76it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:39<00:01,  1.81it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:40<00:01,  1.79it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:40<00:00,  1.80it/s][1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-06 19:06:22 model_runner.py:1535] Graph capturing finished in 102 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:41<00:00,  1.53it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:41<00:00,  1.29it/s]
INFO 04-06 19:06:22 model_runner.py:1535] Graph capturing finished in 101 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-06 19:06:22 model_runner.py:1535] Graph capturing finished in 101 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-06 19:06:22 model_runner.py:1535] Graph capturing finished in 101 secs, took 8.20 GiB
INFO 04-06 19:06:22 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 118.68 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: substructure
Generating answers for task: substructure
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-06 19:07:36 scheduler.py:1555] Sequence group 499 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-06 19:07:46 scheduler.py:1555] Sequence group 449 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-06 19:07:59 scheduler.py:1555] Sequence group 399 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
WARNING 04-06 19:08:12 scheduler.py:1555] Sequence group 349 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
WARNING 04-06 19:08:29 scheduler.py:1555] Sequence group 299 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:   0%|          | 1/500 [02:15<18:44:27, 135.21s/it, est. speed input: 1.96 toks/s, output: 3.87 toks/s]WARNING 04-06 19:08:53 scheduler.py:1555] Sequence group 249 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:   0%|          | 2/500 [02:31<9:02:48, 65.40s/it, est. speed input: 3.62 toks/s, output: 7.69 toks/s]  Processed prompts:   1%|          | 3/500 [02:41<5:30:51, 39.94s/it, est. speed input: 5.11 toks/s, output: 11.75 toks/s]WARNING 04-06 19:09:24 scheduler.py:1555] Sequence group 198 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:   1%|          | 4/500 [03:01<4:24:17, 31.97s/it, est. speed input: 6.32 toks/s, output: 15.40 toks/s]Processed prompts:   1%|          | 5/500 [03:04<2:57:32, 21.52s/it, est. speed input: 7.84 toks/s, output: 20.10 toks/s]Processed prompts:   1%|          | 6/500 [03:07<2:06:13, 15.33s/it, est. speed input: 9.28 toks/s, output: 24.68 toks/s]Processed prompts:   1%|▏         | 7/500 [03:09<1:30:19, 10.99s/it, est. speed input: 10.60 toks/s, output: 29.37 toks/s]Processed prompts:   2%|▏         | 8/500 [03:45<2:34:35, 18.85s/it, est. speed input: 10.10 toks/s, output: 30.45 toks/s]Processed prompts:   2%|▏         | 9/500 [03:45<1:47:52, 13.18s/it, est. speed input: 11.35 toks/s, output: 36.12 toks/s]WARNING 04-06 19:10:12 scheduler.py:1555] Sequence group 146 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:   2%|▏         | 10/500 [04:02<1:56:48, 14.30s/it, est. speed input: 11.82 toks/s, output: 39.63 toks/s]Processed prompts:   2%|▏         | 11/500 [04:09<1:38:58, 12.14s/it, est. speed input: 12.57 toks/s, output: 44.57 toks/s]Processed prompts:   2%|▏         | 12/500 [04:34<2:10:02, 15.99s/it, est. speed input: 12.60 toks/s, output: 47.16 toks/s]Processed prompts:   3%|▎         | 13/500 [04:35<1:32:35, 11.41s/it, est. speed input: 13.58 toks/s, output: 53.65 toks/s]Processed prompts:   3%|▎         | 14/500 [04:37<1:09:45,  8.61s/it, est. speed input: 14.50 toks/s, output: 59.90 toks/s]Processed prompts:   3%|▎         | 15/500 [04:54<1:28:29, 10.95s/it, est. speed input: 14.69 toks/s, output: 63.54 toks/s]Processed prompts:   3%|▎         | 16/500 [04:55<1:04:48,  8.03s/it, est. speed input: 15.58 toks/s, output: 70.24 toks/s]Processed prompts:   4%|▎         | 18/500 [04:56<36:28,  4.54s/it, est. speed input: 17.53 toks/s, output: 83.82 toks/s]  Processed prompts:   4%|▍         | 19/500 [05:05<46:19,  5.78s/it, est. speed input: 17.88 toks/s, output: 88.33 toks/s]Processed prompts:   4%|▍         | 20/500 [05:07<37:50,  4.73s/it, est. speed input: 18.72 toks/s, output: 94.97 toks/s]WARNING 04-06 19:11:56 scheduler.py:1555] Sequence group 94 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:   4%|▍         | 21/500 [05:36<1:29:40, 11.23s/it, est. speed input: 18.10 toks/s, output: 94.48 toks/s]Processed prompts:   4%|▍         | 22/500 [05:42<1:17:47,  9.77s/it, est. speed input: 18.56 toks/s, output: 100.49 toks/s]Processed prompts:   5%|▍         | 23/500 [05:46<1:05:56,  8.29s/it, est. speed input: 19.50 toks/s, output: 106.88 toks/s]Processed prompts:   5%|▍         | 24/500 [05:52<1:00:36,  7.64s/it, est. speed input: 19.96 toks/s, output: 112.88 toks/s]Processed prompts:   5%|▌         | 25/500 [05:55<48:17,  6.10s/it, est. speed input: 20.60 toks/s, output: 119.97 toks/s]  Processed prompts:   5%|▌         | 26/500 [06:05<56:48,  7.19s/it, est. speed input: 20.87 toks/s, output: 124.76 toks/s]Processed prompts:   5%|▌         | 27/500 [06:09<49:22,  6.26s/it, est. speed input: 21.49 toks/s, output: 131.42 toks/s]Processed prompts:   6%|▌         | 28/500 [06:10<37:43,  4.79s/it, est. speed input: 22.15 toks/s, output: 139.03 toks/s]Processed prompts:   6%|▌         | 29/500 [06:11<27:47,  3.54s/it, est. speed input: 22.98 toks/s, output: 146.88 toks/s]Processed prompts:   6%|▌         | 30/500 [06:17<34:38,  4.42s/it, est. speed input: 23.31 toks/s, output: 152.50 toks/s]Processed prompts:   6%|▌         | 31/500 [06:25<42:26,  5.43s/it, est. speed input: 23.67 toks/s, output: 157.66 toks/s]Processed prompts:   6%|▋         | 32/500 [06:25<30:13,  3.87s/it, est. speed input: 24.44 toks/s, output: 165.82 toks/s]Processed prompts:   7%|▋         | 33/500 [06:44<1:04:16,  8.26s/it, est. speed input: 24.61 toks/s, output: 166.68 toks/s]Processed prompts:   7%|▋         | 34/500 [06:48<56:18,  7.25s/it, est. speed input: 25.09 toks/s, output: 173.18 toks/s]  Processed prompts:   7%|▋         | 35/500 [06:52<46:32,  6.01s/it, est. speed input: 25.77 toks/s, output: 180.41 toks/s]Processed prompts:   7%|▋         | 36/500 [07:06<1:05:20,  8.45s/it, est. speed input: 25.56 toks/s, output: 183.09 toks/s]Processed prompts:   7%|▋         | 37/500 [07:12<1:01:07,  7.92s/it, est. speed input: 25.80 toks/s, output: 189.01 toks/s]Processed prompts:   8%|▊         | 38/500 [07:22<1:05:35,  8.52s/it, est. speed input: 25.92 toks/s, output: 193.62 toks/s]Processed prompts:   8%|▊         | 39/500 [07:36<1:18:09, 10.17s/it, est. speed input: 26.01 toks/s, output: 196.65 toks/s]Processed prompts:   8%|▊         | 40/500 [07:38<58:50,  7.67s/it, est. speed input: 26.52 toks/s, output: 204.85 toks/s]  Processed prompts:   8%|▊         | 41/500 [07:46<59:11,  7.74s/it, est. speed input: 26.77 toks/s, output: 210.36 toks/s]Processed prompts:   8%|▊         | 42/500 [07:51<51:46,  6.78s/it, est. speed input: 27.16 toks/s, output: 217.43 toks/s]Processed prompts:   9%|▊         | 43/500 [08:07<1:12:34,  9.53s/it, est. speed input: 26.84 toks/s, output: 219.59 toks/s]Processed prompts:   9%|▉         | 44/500 [09:22<3:42:09, 29.23s/it, est. speed input: 24.80 toks/s, output: 200.20 toks/s]Processed prompts:   9%|▉         | 45/500 [10:00<4:02:30, 31.98s/it, est. speed input: 23.65 toks/s, output: 197.71 toks/s]Processed prompts:   9%|▉         | 46/500 [10:43<4:26:51, 35.27s/it, est. speed input: 22.86 toks/s, output: 195.16 toks/s]Processed prompts:   9%|▉         | 47/500 [10:45<3:11:12, 25.33s/it, est. speed input: 23.35 toks/s, output: 205.11 toks/s]Processed prompts:  10%|▉         | 48/500 [10:48<2:20:31, 18.65s/it, est. speed input: 23.80 toks/s, output: 214.38 toks/s]Processed prompts:  10%|▉         | 49/500 [11:03<2:11:41, 17.52s/it, est. speed input: 23.70 toks/s, output: 220.36 toks/s]Processed prompts:  10%|█         | 50/500 [11:10<1:48:19, 14.44s/it, est. speed input: 23.85 toks/s, output: 227.88 toks/s]Processed prompts:  10%|█         | 51/500 [11:49<2:42:10, 21.67s/it, est. speed input: 22.94 toks/s, output: 226.62 toks/s]Processed prompts:  10%|█         | 52/500 [11:51<1:57:48, 15.78s/it, est. speed input: 24.49 toks/s, output: 237.02 toks/s]Processed prompts:  11%|█         | 53/500 [12:02<1:46:23, 14.28s/it, est. speed input: 24.53 toks/s, output: 244.69 toks/s]Processed prompts:  11%|█         | 54/500 [12:04<1:18:59, 10.63s/it, est. speed input: 24.87 toks/s, output: 255.21 toks/s]Processed prompts:  11%|█         | 56/500 [12:10<53:15,  7.20s/it, est. speed input: 25.61 toks/s, output: 271.73 toks/s]  Processed prompts:  11%|█▏        | 57/500 [12:41<1:36:59, 13.14s/it, est. speed input: 24.94 toks/s, output: 272.08 toks/s]Processed prompts:  12%|█▏        | 58/500 [12:45<1:17:26, 10.51s/it, est. speed input: 25.79 toks/s, output: 282.45 toks/s]Processed prompts:  12%|█▏        | 59/500 [12:46<58:48,  8.00s/it, est. speed input: 26.16 toks/s, output: 293.46 toks/s]  Processed prompts:  12%|█▏        | 60/500 [12:50<49:57,  6.81s/it, est. speed input: 26.54 toks/s, output: 303.53 toks/s]Processed prompts:  12%|█▏        | 61/500 [13:24<1:46:33, 14.56s/it, est. speed input: 25.93 toks/s, output: 299.84 toks/s]Processed prompts:  12%|█▏        | 62/500 [14:06<2:46:14, 22.77s/it, est. speed input: 24.95 toks/s, output: 296.57 toks/s]Processed prompts:  13%|█▎        | 63/500 [14:21<2:28:59, 20.46s/it, est. speed input: 24.88 toks/s, output: 303.46 toks/s]Processed prompts:  13%|█▎        | 64/500 [15:17<3:45:07, 30.98s/it, est. speed input: 23.74 toks/s, output: 297.18 toks/s]Processed prompts:  13%|█▎        | 65/500 [16:02<4:13:14, 34.93s/it, est. speed input: 22.98 toks/s, output: 295.97 toks/s]Processed prompts:  13%|█▎        | 66/500 [16:21<3:37:48, 30.11s/it, est. speed input: 22.88 toks/s, output: 302.88 toks/s]Processed prompts:  13%|█▎        | 67/500 [16:25<2:42:38, 22.54s/it, est. speed input: 23.06 toks/s, output: 314.02 toks/s]Processed prompts:  14%|█▎        | 68/500 [16:29<2:01:48, 16.92s/it, est. speed input: 24.56 toks/s, output: 325.43 toks/s]Processed prompts:  14%|█▍        | 69/500 [16:46<2:01:10, 16.87s/it, est. speed input: 24.64 toks/s, output: 325.74 toks/s]Processed prompts:  14%|█▍        | 70/500 [16:54<1:43:17, 14.41s/it, est. speed input: 24.76 toks/s, output: 332.45 toks/s]Processed prompts:  14%|█▍        | 71/500 [16:58<1:20:41, 11.29s/it, est. speed input: 25.80 toks/s, output: 336.15 toks/s]Processed prompts:  14%|█▍        | 72/500 [17:02<1:04:53,  9.10s/it, est. speed input: 26.03 toks/s, output: 347.56 toks/s]Processed prompts:  15%|█▍        | 73/500 [17:09<59:26,  8.35s/it, est. speed input: 26.24 toks/s, output: 358.07 toks/s]  Processed prompts:  15%|█▍        | 74/500 [17:11<46:52,  6.60s/it, est. speed input: 26.56 toks/s, output: 369.94 toks/s]Processed prompts:  15%|█▌        | 75/500 [17:33<1:18:02, 11.02s/it, est. speed input: 27.13 toks/s, output: 375.27 toks/s]Processed prompts:  15%|█▌        | 76/500 [17:34<57:18,  8.11s/it, est. speed input: 27.38 toks/s, output: 379.58 toks/s]  Processed prompts:  15%|█▌        | 77/500 [17:35<41:28,  5.88s/it, est. speed input: 28.13 toks/s, output: 392.15 toks/s]WARNING 04-06 19:24:05 scheduler.py:1555] Sequence group 107 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  16%|█▌        | 78/500 [17:45<50:04,  7.12s/it, est. speed input: 28.21 toks/s, output: 401.30 toks/s]Processed prompts:  16%|█▌        | 79/500 [17:46<36:57,  5.27s/it, est. speed input: 28.93 toks/s, output: 413.77 toks/s]Processed prompts:  16%|█▌        | 80/500 [18:06<1:08:53,  9.84s/it, est. speed input: 28.86 toks/s, output: 408.31 toks/s]Processed prompts:  16%|█▌        | 81/500 [18:11<57:32,  8.24s/it, est. speed input: 29.02 toks/s, output: 419.49 toks/s]  Processed prompts:  16%|█▋        | 82/500 [18:49<2:00:35, 17.31s/it, est. speed input: 28.97 toks/s, output: 408.71 toks/s]Processed prompts:  17%|█▋        | 83/500 [19:14<2:16:45, 19.68s/it, est. speed input: 28.89 toks/s, output: 412.77 toks/s]Processed prompts:  17%|█▋        | 84/500 [19:16<1:38:49, 14.25s/it, est. speed input: 29.17 toks/s, output: 415.48 toks/s]Processed prompts:  17%|█▋        | 85/500 [19:38<1:54:38, 16.58s/it, est. speed input: 28.94 toks/s, output: 411.32 toks/s]Processed prompts:  17%|█▋        | 86/500 [19:40<1:24:06, 12.19s/it, est. speed input: 29.19 toks/s, output: 423.66 toks/s]Processed prompts:  17%|█▋        | 87/500 [19:48<1:16:14, 11.08s/it, est. speed input: 29.23 toks/s, output: 424.20 toks/s]Processed prompts:  18%|█▊        | 88/500 [20:05<1:28:17, 12.86s/it, est. speed input: 29.68 toks/s, output: 421.23 toks/s]Processed prompts:  18%|█▊        | 89/500 [20:13<1:16:35, 11.18s/it, est. speed input: 29.90 toks/s, output: 423.53 toks/s]Processed prompts:  18%|█▊        | 90/500 [20:14<56:03,  8.20s/it, est. speed input: 30.20 toks/s, output: 436.17 toks/s]  Processed prompts:  18%|█▊        | 91/500 [20:32<1:15:41, 11.10s/it, est. speed input: 30.04 toks/s, output: 431.60 toks/s]Processed prompts:  18%|█▊        | 92/500 [20:47<1:23:26, 12.27s/it, est. speed input: 29.91 toks/s, output: 435.97 toks/s]Processed prompts:  19%|█▊        | 93/500 [21:02<1:29:02, 13.13s/it, est. speed input: 29.84 toks/s, output: 436.43 toks/s]Processed prompts:  19%|█▉        | 94/500 [21:08<1:13:22, 10.84s/it, est. speed input: 29.99 toks/s, output: 436.09 toks/s]Processed prompts:  19%|█▉        | 95/500 [21:09<54:24,  8.06s/it, est. speed input: 30.36 toks/s, output: 437.23 toks/s]  Processed prompts:  19%|█▉        | 96/500 [22:18<2:57:12, 26.32s/it, est. speed input: 29.32 toks/s, output: 422.45 toks/s]Processed prompts:  19%|█▉        | 97/500 [22:26<2:20:44, 20.95s/it, est. speed input: 29.38 toks/s, output: 424.83 toks/s]Processed prompts:  20%|█▉        | 98/500 [23:23<3:31:08, 31.51s/it, est. speed input: 28.81 toks/s, output: 421.22 toks/s]Processed prompts:  20%|█▉        | 99/500 [23:29<2:39:54, 23.93s/it, est. speed input: 29.50 toks/s, output: 432.77 toks/s]Processed prompts:  20%|██        | 100/500 [24:26<3:46:39, 34.00s/it, est. speed input: 28.94 toks/s, output: 422.23 toks/s]WARNING 04-06 19:30:59 scheduler.py:1555] Sequence group 115 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  20%|██        | 101/500 [25:27<4:39:45, 42.07s/it, est. speed input: 28.08 toks/s, output: 413.97 toks/s]Processed prompts:  20%|██        | 102/500 [27:39<7:38:23, 69.10s/it, est. speed input: 26.01 toks/s, output: 388.02 toks/s]Processed prompts:  21%|██        | 103/500 [27:52<5:44:41, 52.09s/it, est. speed input: 25.98 toks/s, output: 392.30 toks/s]Processed prompts:  21%|██        | 104/500 [27:54<4:04:22, 37.03s/it, est. speed input: 26.56 toks/s, output: 398.37 toks/s]Processed prompts:  21%|██        | 105/500 [28:30<4:01:29, 36.68s/it, est. speed input: 26.16 toks/s, output: 398.00 toks/s]Processed prompts:  21%|██        | 106/500 [28:59<3:46:00, 34.42s/it, est. speed input: 26.06 toks/s, output: 398.92 toks/s]Processed prompts:  21%|██▏       | 107/500 [29:31<3:42:03, 33.90s/it, est. speed input: 25.75 toks/s, output: 398.13 toks/s]Processed prompts:  22%|██▏       | 108/500 [29:44<2:59:28, 27.47s/it, est. speed input: 25.80 toks/s, output: 403.39 toks/s]Processed prompts:  22%|██▏       | 109/500 [29:56<2:29:14, 22.90s/it, est. speed input: 25.79 toks/s, output: 408.44 toks/s]Processed prompts:  22%|██▏       | 110/500 [39:30<20:23:32, 188.24s/it, est. speed input: 19.86 toks/s, output: 323.36 toks/s]Processed prompts:  22%|██▏       | 111/500 [40:43<16:36:41, 153.73s/it, est. speed input: 19.43 toks/s, output: 321.93 toks/s]Processed prompts:  22%|██▏       | 112/500 [42:39<15:19:51, 142.25s/it, est. speed input: 18.66 toks/s, output: 320.21 toks/s]Processed prompts:  23%|██▎       | 113/500 [45:35<16:23:10, 152.43s/it, est. speed input: 17.67 toks/s, output: 311.57 toks/s]Processed prompts:  23%|██▎       | 114/500 [45:56<12:07:37, 113.10s/it, est. speed input: 17.63 toks/s, output: 321.04 toks/s]Processed prompts:  23%|██▎       | 115/500 [46:26<9:25:42, 88.16s/it, est. speed input: 17.55 toks/s, output: 329.35 toks/s]  Processed prompts:  23%|██▎       | 116/500 [46:27<6:36:24, 61.94s/it, est. speed input: 17.70 toks/s, output: 330.29 toks/s]Processed prompts:  23%|██▎       | 117/500 [46:31<4:43:55, 44.48s/it, est. speed input: 17.98 toks/s, output: 341.59 toks/s]Processed prompts:  24%|██▎       | 118/500 [46:39<3:34:46, 33.73s/it, est. speed input: 18.01 toks/s, output: 341.00 toks/s]Processed prompts:  24%|██▍       | 119/500 [46:46<2:41:46, 25.48s/it, est. speed input: 18.11 toks/s, output: 340.75 toks/s]Processed prompts:  24%|██▍       | 120/500 [46:47<1:56:17, 18.36s/it, est. speed input: 18.20 toks/s, output: 341.06 toks/s]Processed prompts:  24%|██▍       | 121/500 [46:55<1:34:52, 15.02s/it, est. speed input: 18.25 toks/s, output: 340.75 toks/s]Processed prompts:  24%|██▍       | 122/500 [46:58<1:11:44, 11.39s/it, est. speed input: 18.35 toks/s, output: 340.96 toks/s]Processed prompts:  25%|██▍       | 123/500 [47:17<1:27:23, 13.91s/it, est. speed input: 18.31 toks/s, output: 339.39 toks/s]Processed prompts:  25%|██▍       | 124/500 [47:20<1:06:44, 10.65s/it, est. speed input: 18.43 toks/s, output: 339.96 toks/s]Processed prompts:  25%|██▌       | 125/500 [47:28<1:00:55,  9.75s/it, est. speed input: 18.53 toks/s, output: 350.55 toks/s]Processed prompts:  25%|██▌       | 126/500 [47:35<56:12,  9.02s/it, est. speed input: 18.65 toks/s, output: 350.10 toks/s]  Processed prompts:  25%|██▌       | 127/500 [47:40<47:35,  7.66s/it, est. speed input: 18.73 toks/s, output: 361.00 toks/s]Processed prompts:  26%|██▌       | 128/500 [47:47<46:25,  7.49s/it, est. speed input: 18.80 toks/s, output: 360.59 toks/s]Processed prompts:  26%|██▌       | 129/500 [47:52<42:06,  6.81s/it, est. speed input: 18.93 toks/s, output: 360.42 toks/s]WARNING 04-06 19:54:33 scheduler.py:1555] Sequence group 182 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  26%|██▌       | 130/500 [48:23<1:25:59, 13.94s/it, est. speed input: 18.83 toks/s, output: 357.24 toks/s]Processed prompts:  26%|██▌       | 131/500 [49:01<2:10:06, 21.15s/it, est. speed input: 18.70 toks/s, output: 353.40 toks/s]Processed prompts:  26%|██▋       | 132/500 [49:05<1:38:41, 16.09s/it, est. speed input: 18.76 toks/s, output: 353.70 toks/s]Processed prompts:  27%|██▋       | 133/500 [49:14<1:25:59, 14.06s/it, est. speed input: 19.01 toks/s, output: 353.84 toks/s]Processed prompts:  27%|██▋       | 134/500 [49:15<1:01:54, 10.15s/it, est. speed input: 19.10 toks/s, output: 355.00 toks/s]Processed prompts:  27%|██▋       | 135/500 [49:21<53:30,  8.80s/it, est. speed input: 19.17 toks/s, output: 355.17 toks/s]  Processed prompts:  27%|██▋       | 136/500 [51:33<4:37:48, 45.79s/it, est. speed input: 18.44 toks/s, output: 341.87 toks/s]Processed prompts:  27%|██▋       | 137/500 [51:51<3:47:12, 37.56s/it, est. speed input: 18.45 toks/s, output: 347.41 toks/s]Processed prompts:  28%|██▊       | 138/500 [53:05<4:52:31, 48.49s/it, est. speed input: 18.11 toks/s, output: 349.62 toks/s]Processed prompts:  28%|██▊       | 139/500 [53:10<3:31:58, 35.23s/it, est. speed input: 18.19 toks/s, output: 351.45 toks/s]Processed prompts:  28%|██▊       | 140/500 [53:11<2:29:25, 24.90s/it, est. speed input: 18.28 toks/s, output: 352.48 toks/s]Processed prompts:  28%|██▊       | 141/500 [55:37<6:07:07, 61.36s/it, est. speed input: 17.56 toks/s, output: 339.93 toks/s]Processed prompts:  28%|██▊       | 142/500 [56:46<6:20:21, 63.75s/it, est. speed input: 17.29 toks/s, output: 336.22 toks/s]Processed prompts:  29%|██▊       | 143/500 [1:00:07<10:24:37, 104.98s/it, est. speed input: 16.41 toks/s, output: 326.55 toks/s]WARNING 04-06 20:09:41 scheduler.py:1555] Sequence group 136 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
Processed prompts:  29%|██▉       | 144/500 [1:05:41<17:09:50, 173.57s/it, est. speed input: 15.09 toks/s, output: 307.22 toks/s]Processed prompts:  29%|██▉       | 145/500 [1:08:38<17:13:48, 174.73s/it, est. speed input: 14.52 toks/s, output: 301.94 toks/s]Processed prompts:  29%|██▉       | 146/500 [1:09:56<14:18:19, 145.48s/it, est. speed input: 14.33 toks/s, output: 302.70 toks/s]Processed prompts:  29%|██▉       | 147/500 [1:12:43<14:54:03, 151.96s/it, est. speed input: 13.86 toks/s, output: 298.61 toks/s]Processed prompts:  30%|██▉       | 148/500 [1:14:21<13:16:03, 135.69s/it, est. speed input: 13.74 toks/s, output: 299.42 toks/s]Processed prompts:  30%|██▉       | 149/500 [1:15:31<11:19:32, 116.16s/it, est. speed input: 13.59 toks/s, output: 301.98 toks/s]Processed prompts:  30%|███       | 150/500 [1:17:51<11:58:38, 123.20s/it, est. speed input: 13.36 toks/s, output: 299.97 toks/s]Processed prompts:  30%|███       | 151/500 [1:17:52<8:23:06, 86.50s/it, est. speed input: 13.42 toks/s, output: 306.93 toks/s]  Processed prompts:  30%|███       | 152/500 [1:17:57<6:00:51, 62.22s/it, est. speed input: 13.47 toks/s, output: 313.57 toks/s]Processed prompts:  31%|███       | 153/500 [1:18:05<4:25:11, 45.86s/it, est. speed input: 13.50 toks/s, output: 313.35 toks/s]Processed prompts:  31%|███       | 154/500 [1:18:07<3:09:41, 32.89s/it, est. speed input: 13.58 toks/s, output: 313.47 toks/s]Processed prompts:  31%|███       | 155/500 [1:18:15<2:25:28, 25.30s/it, est. speed input: 13.62 toks/s, output: 313.30 toks/s]Processed prompts:  31%|███       | 156/500 [1:19:16<3:25:50, 35.90s/it, est. speed input: 13.53 toks/s, output: 316.19 toks/s]Processed prompts:  31%|███▏      | 157/500 [1:25:37<13:17:31, 139.51s/it, est. speed input: 12.59 toks/s, output: 299.10 toks/s]Processed prompts:  32%|███▏      | 158/500 [1:27:09<11:53:18, 125.14s/it, est. speed input: 12.44 toks/s, output: 300.13 toks/s]WARNING 04-06 20:34:10 scheduler.py:1555] Sequence group 162 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
Processed prompts:  32%|███▏      | 159/500 [1:31:32<15:47:27, 166.71s/it, est. speed input: 11.89 toks/s, output: 291.69 toks/s]Processed prompts:  32%|███▏      | 160/500 [1:31:52<11:35:02, 122.65s/it, est. speed input: 11.91 toks/s, output: 294.20 toks/s]Processed prompts:  32%|███▏      | 161/500 [1:34:30<12:32:10, 133.13s/it, est. speed input: 11.69 toks/s, output: 291.80 toks/s]Processed prompts:  32%|███▏      | 162/500 [1:37:54<14:29:58, 154.43s/it, est. speed input: 11.34 toks/s, output: 287.24 toks/s]Processed prompts:  33%|███▎      | 163/500 [1:40:13<14:01:02, 149.74s/it, est. speed input: 11.13 toks/s, output: 286.06 toks/s]Processed prompts:  33%|███▎      | 164/500 [1:42:06<12:58:13, 138.97s/it, est. speed input: 10.99 toks/s, output: 286.09 toks/s]Processed prompts:  33%|███▎      | 165/500 [1:43:49<11:54:46, 128.02s/it, est. speed input: 10.87 toks/s, output: 286.65 toks/s]Processed prompts:  33%|███▎      | 166/500 [1:45:22<10:53:28, 117.39s/it, est. speed input: 10.76 toks/s, output: 287.63 toks/s]Processed prompts:  33%|███▎      | 167/500 [1:45:56<8:32:50, 92.40s/it, est. speed input: 10.80 toks/s, output: 291.24 toks/s]  Processed prompts:  34%|███▎      | 168/500 [1:47:00<7:44:04, 83.87s/it, est. speed input: 10.75 toks/s, output: 293.45 toks/s]WARNING 04-06 20:55:11 scheduler.py:1555] Sequence group 180 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
Processed prompts:  34%|███▍      | 169/500 [1:52:08<13:54:31, 151.27s/it, est. speed input: 10.31 toks/s, output: 284.86 toks/s]Processed prompts:  34%|███▍      | 170/500 [1:56:02<16:07:37, 175.93s/it, est. speed input: 10.03 toks/s, output: 280.01 toks/s]Processed prompts:  34%|███▍      | 171/500 [2:02:21<21:38:36, 236.83s/it, est. speed input: 9.55 toks/s, output: 270.02 toks/s] Processed prompts:  34%|███▍      | 172/500 [2:02:35<15:30:39, 170.24s/it, est. speed input: 9.61 toks/s, output: 273.93 toks/s]Processed prompts:  35%|███▍      | 173/500 [2:07:17<18:29:09, 203.51s/it, est. speed input: 9.30 toks/s, output: 268.14 toks/s]Processed prompts:  35%|███▍      | 174/500 [2:08:19<14:36:19, 161.29s/it, est. speed input: 9.26 toks/s, output: 270.21 toks/s]Processed prompts:  35%|███▌      | 175/500 [2:09:22<11:54:13, 131.86s/it, est. speed input: 9.24 toks/s, output: 272.23 toks/s]Processed prompts:  35%|███▌      | 176/500 [2:10:14<9:42:39, 107.90s/it, est. speed input: 9.21 toks/s, output: 274.61 toks/s] Processed prompts:  35%|███▌      | 177/500 [2:11:09<8:14:18, 91.82s/it, est. speed input: 9.23 toks/s, output: 276.88 toks/s] Processed prompts:  36%|███▌      | 178/500 [2:11:12<5:50:20, 65.28s/it, est. speed input: 9.26 toks/s, output: 276.87 toks/s]Processed prompts:  36%|███▌      | 179/500 [2:11:27<4:28:42, 50.23s/it, est. speed input: 9.28 toks/s, output: 276.55 toks/s]Processed prompts:  36%|███▌      | 180/500 [2:11:54<3:51:03, 43.32s/it, est. speed input: 9.28 toks/s, output: 279.74 toks/s]WARNING 04-06 21:18:45 scheduler.py:1555] Sequence group 216 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
Processed prompts:  36%|███▌      | 181/500 [2:14:17<6:28:52, 73.14s/it, est. speed input: 9.15 toks/s, output: 278.85 toks/s]Processed prompts:  36%|███▋      | 182/500 [2:16:21<7:48:42, 88.43s/it, est. speed input: 9.06 toks/s, output: 278.62 toks/s]Processed prompts:  37%|███▋      | 183/500 [2:21:34<13:43:11, 155.81s/it, est. speed input: 8.77 toks/s, output: 272.21 toks/s]Processed prompts:  37%|███▋      | 184/500 [2:22:54<11:39:59, 132.91s/it, est. speed input: 8.72 toks/s, output: 273.51 toks/s]Processed prompts:  37%|███▋      | 185/500 [2:26:32<13:52:30, 158.57s/it, est. speed input: 8.54 toks/s, output: 270.44 toks/s]WARNING 04-06 21:34:07 scheduler.py:1555] Sequence group 191 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
Processed prompts:  37%|███▋      | 186/500 [2:30:13<15:27:17, 177.19s/it, est. speed input: 8.42 toks/s, output: 267.46 toks/s]Processed prompts:  37%|███▋      | 187/500 [2:34:43<17:50:18, 205.17s/it, est. speed input: 8.22 toks/s, output: 263.20 toks/s]Processed prompts:  38%|███▊      | 188/500 [2:36:13<14:46:46, 170.53s/it, est. speed input: 8.18 toks/s, output: 264.17 toks/s]Processed prompts:  38%|███▊      | 189/500 [2:37:25<12:09:57, 140.83s/it, est. speed input: 8.15 toks/s, output: 265.64 toks/s]Processed prompts:  38%|███▊      | 190/500 [2:39:18<11:25:35, 132.70s/it, est. speed input: 8.20 toks/s, output: 265.91 toks/s]Processed prompts:  38%|███▊      | 191/500 [2:39:47<8:42:01, 101.36s/it, est. speed input: 8.20 toks/s, output: 268.55 toks/s] Processed prompts:  38%|███▊      | 192/500 [2:39:53<6:14:56, 73.04s/it, est. speed input: 8.23 toks/s, output: 268.50 toks/s] Processed prompts:  39%|███▊      | 193/500 [2:40:33<5:22:22, 63.01s/it, est. speed input: 8.23 toks/s, output: 270.80 toks/s]Processed prompts:  39%|███▉      | 194/500 [2:40:51<4:12:31, 49.51s/it, est. speed input: 8.25 toks/s, output: 270.38 toks/s]Processed prompts:  39%|███▉      | 195/500 [2:41:09<3:22:49, 39.90s/it, est. speed input: 8.26 toks/s, output: 273.28 toks/s]WARNING 04-06 21:48:22 scheduler.py:1555] Sequence group 233 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851
Processed prompts:  39%|███▉      | 196/500 [2:42:31<4:26:28, 52.60s/it, est. speed input: 8.26 toks/s, output: 274.34 toks/s]Processed prompts:  39%|███▉      | 197/500 [2:52:58<18:55:40, 224.89s/it, est. speed input: 7.78 toks/s, output: 260.93 toks/s]Processed prompts:  40%|███▉      | 198/500 [2:53:49<14:29:37, 172.77s/it, est. speed input: 7.77 toks/s, output: 262.79 toks/s]Processed prompts:  40%|███▉      | 199/500 [2:53:57<10:19:02, 123.40s/it, est. speed input: 7.80 toks/s, output: 265.72 toks/s]WARNING 04-06 22:01:14 scheduler.py:1555] Sequence group 209 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901
Processed prompts:  40%|████      | 200/500 [3:01:25<18:23:57, 220.79s/it, est. speed input: 7.50 toks/s, output: 257.80 toks/s]Processed prompts:  40%|████      | 201/500 [3:03:55<16:34:22, 199.54s/it, est. speed input: 7.43 toks/s, output: 257.26 toks/s]Processed prompts:  40%|████      | 202/500 [3:05:34<14:01:22, 169.40s/it, est. speed input: 7.41 toks/s, output: 257.91 toks/s]Processed prompts:  41%|████      | 203/500 [3:07:02<11:57:11, 144.89s/it, est. speed input: 7.38 toks/s, output: 258.82 toks/s]Processed prompts:  41%|████      | 204/500 [3:07:49<9:29:26, 115.43s/it, est. speed input: 7.37 toks/s, output: 260.66 toks/s] Processed prompts:  41%|████      | 205/500 [3:08:24<7:30:16, 91.58s/it, est. speed input: 7.37 toks/s, output: 262.73 toks/s] Processed prompts:  41%|████      | 206/500 [3:09:14<6:26:34, 78.89s/it, est. speed input: 7.38 toks/s, output: 264.47 toks/s]Processed prompts:  41%|████▏     | 207/500 [3:11:36<7:57:24, 97.76s/it, est. speed input: 7.34 toks/s, output: 264.06 toks/s]Processed prompts:  42%|████▏     | 208/500 [3:17:16<13:50:20, 170.62s/it, est. speed input: 7.16 toks/s, output: 259.23 toks/s]Processed prompts:  42%|████▏     | 209/500 [3:19:50<13:23:08, 165.59s/it, est. speed input: 7.09 toks/s, output: 258.63 toks/s]Processed prompts:  42%|████▏     | 210/500 [3:20:54<10:53:40, 135.24s/it, est. speed input: 7.08 toks/s, output: 259.97 toks/s]Processed prompts:  42%|████▏     | 211/500 [3:23:28<11:17:45, 140.71s/it, est. speed input: 7.04 toks/s, output: 259.39 toks/s]Processed prompts:  42%|████▏     | 212/500 [3:28:51<15:38:24, 195.50s/it, est. speed input: 6.90 toks/s, output: 255.31 toks/s]WARNING 04-06 22:36:14 scheduler.py:1555] Sequence group 218 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951
Processed prompts:  43%|████▎     | 213/500 [3:30:09<12:46:43, 160.29s/it, est. speed input: 6.88 toks/s, output: 256.33 toks/s]Processed prompts:  43%|████▎     | 214/500 [3:32:21<12:03:43, 151.83s/it, est. speed input: 6.83 toks/s, output: 256.24 toks/s]Processed prompts:  43%|████▎     | 215/500 [3:33:19<9:46:05, 123.39s/it, est. speed input: 6.83 toks/s, output: 257.66 toks/s] Processed prompts:  43%|████▎     | 216/500 [3:33:49<7:32:36, 95.62s/it, est. speed input: 6.83 toks/s, output: 259.59 toks/s] Processed prompts:  43%|████▎     | 217/500 [3:34:17<5:54:53, 75.24s/it, est. speed input: 6.84 toks/s, output: 261.58 toks/s]Processed prompts:  44%|████▎     | 218/500 [3:34:41<4:41:31, 59.90s/it, est. speed input: 6.85 toks/s, output: 261.16 toks/s]WARNING 04-06 22:42:45 scheduler.py:1555] Sequence group 239 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001
Processed prompts:  44%|████▍     | 219/500 [3:36:26<5:44:18, 73.52s/it, est. speed input: 6.82 toks/s, output: 261.57 toks/s]Processed prompts:  44%|████▍     | 220/500 [3:39:26<8:11:44, 105.37s/it, est. speed input: 6.75 toks/s, output: 260.48 toks/s]Processed prompts:  44%|████▍     | 221/500 [3:44:50<13:14:25, 170.84s/it, est. speed input: 6.62 toks/s, output: 256.66 toks/s]Processed prompts:  44%|████▍     | 222/500 [3:51:25<18:24:08, 238.31s/it, est. speed input: 6.46 toks/s, output: 251.71 toks/s]Processed prompts:  45%|████▍     | 223/500 [3:52:35<14:26:08, 187.61s/it, est. speed input: 6.45 toks/s, output: 252.81 toks/s]Processed prompts:  45%|████▍     | 224/500 [3:52:59<10:37:53, 138.67s/it, est. speed input: 6.51 toks/s, output: 254.71 toks/s]Processed prompts:  45%|████▌     | 225/500 [3:58:33<15:03:26, 197.11s/it, est. speed input: 6.38 toks/s, output: 251.06 toks/s]Processed prompts:  45%|████▌     | 226/500 [3:59:49<12:14:24, 160.82s/it, est. speed input: 6.37 toks/s, output: 252.01 toks/s]Processed prompts:  45%|████▌     | 227/500 [4:01:24<10:42:34, 141.23s/it, est. speed input: 6.35 toks/s, output: 252.61 toks/s]Processed prompts:  46%|████▌     | 228/500 [4:02:09<8:28:27, 112.16s/it, est. speed input: 6.35 toks/s, output: 254.10 toks/s] Processed prompts:  46%|████▌     | 229/500 [4:02:47<6:46:48, 90.07s/it, est. speed input: 6.36 toks/s, output: 255.67 toks/s] Processed prompts:  46%|████▌     | 230/500 [4:03:18<5:25:40, 72.37s/it, est. speed input: 6.36 toks/s, output: 257.38 toks/s]WARNING 04-06 23:09:59 scheduler.py:1555] Sequence group 264 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051
Processed prompts:  46%|████▌     | 231/500 [4:05:50<7:10:36, 96.04s/it, est. speed input: 6.32 toks/s, output: 256.96 toks/s]Processed prompts:  46%|████▋     | 232/500 [4:08:53<9:05:58, 122.23s/it, est. speed input: 6.26 toks/s, output: 256.00 toks/s]Processed prompts:  47%|████▋     | 233/500 [4:14:21<13:39:14, 184.10s/it, est. speed input: 6.14 toks/s, output: 252.63 toks/s]Processed prompts:  47%|████▋     | 234/500 [4:17:56<14:16:25, 193.18s/it, est. speed input: 6.08 toks/s, output: 251.25 toks/s]Processed prompts:  47%|████▋     | 235/500 [4:19:06<11:30:17, 156.29s/it, est. speed input: 6.08 toks/s, output: 252.23 toks/s]Processed prompts:  47%|████▋     | 236/500 [4:24:11<14:43:43, 200.85s/it, est. speed input: 5.98 toks/s, output: 249.44 toks/s]Processed prompts:  47%|████▋     | 237/500 [4:25:31<12:01:31, 164.61s/it, est. speed input: 5.97 toks/s, output: 250.25 toks/s]Processed prompts:  48%|████▊     | 238/500 [4:26:54<10:11:50, 140.12s/it, est. speed input: 6.00 toks/s, output: 251.00 toks/s]WARNING 04-06 23:34:10 scheduler.py:1555] Sequence group 247 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101
Processed prompts:  48%|████▊     | 239/500 [4:28:10<8:45:49, 120.88s/it, est. speed input: 6.04 toks/s, output: 251.85 toks/s] Processed prompts:  48%|████▊     | 240/500 [4:28:48<6:56:52, 96.20s/it, est. speed input: 6.04 toks/s, output: 253.28 toks/s] Processed prompts:  48%|████▊     | 241/500 [4:29:35<5:50:27, 81.19s/it, est. speed input: 6.04 toks/s, output: 254.58 toks/s]Processed prompts:  48%|████▊     | 242/500 [4:30:43<5:33:14, 77.50s/it, est. speed input: 6.04 toks/s, output: 255.52 toks/s]WARNING 04-06 23:37:27 scheduler.py:1555] Sequence group 283 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151
Processed prompts:  49%|████▊     | 243/500 [4:37:01<11:57:10, 167.43s/it, est. speed input: 5.93 toks/s, output: 251.69 toks/s]Processed prompts:  49%|████▉     | 244/500 [4:40:11<12:23:38, 174.29s/it, est. speed input: 5.88 toks/s, output: 250.79 toks/s]Processed prompts:  49%|████▉     | 245/500 [4:40:27<8:58:32, 126.71s/it, est. speed input: 5.90 toks/s, output: 252.19 toks/s] Processed prompts:  49%|████▉     | 246/500 [4:42:06<8:21:07, 118.37s/it, est. speed input: 5.88 toks/s, output: 252.65 toks/s]Processed prompts:  49%|████▉     | 247/500 [4:51:05<17:11:41, 244.67s/it, est. speed input: 5.72 toks/s, output: 246.72 toks/s]WARNING 04-06 23:58:19 scheduler.py:1555] Sequence group 254 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201
Processed prompts:  50%|████▉     | 248/500 [4:52:30<13:45:58, 196.66s/it, est. speed input: 5.71 toks/s, output: 247.40 toks/s]Processed prompts:  50%|████▉     | 249/500 [4:54:34<12:12:18, 175.05s/it, est. speed input: 5.70 toks/s, output: 247.51 toks/s]Processed prompts:  50%|█████     | 250/500 [4:56:06<10:25:21, 150.09s/it, est. speed input: 5.68 toks/s, output: 248.08 toks/s]Processed prompts:  50%|█████     | 251/500 [4:57:07<8:32:22, 123.47s/it, est. speed input: 5.68 toks/s, output: 249.06 toks/s] Processed prompts:  50%|█████     | 252/500 [4:57:44<6:42:49, 97.46s/it, est. speed input: 5.68 toks/s, output: 250.38 toks/s] Processed prompts:  51%|█████     | 253/500 [4:58:25<5:30:45, 80.35s/it, est. speed input: 5.73 toks/s, output: 251.65 toks/s]Processed prompts:  51%|█████     | 254/500 [4:58:45<4:15:34, 62.34s/it, est. speed input: 5.75 toks/s, output: 253.19 toks/s]WARNING 04-07 00:07:33 scheduler.py:1555] Sequence group 274 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251
Processed prompts:  51%|█████     | 255/500 [5:06:02<11:54:03, 174.87s/it, est. speed input: 5.64 toks/s, output: 248.94 toks/s]Processed prompts:  51%|█████     | 256/500 [5:07:39<10:15:50, 151.44s/it, est. speed input: 5.64 toks/s, output: 249.41 toks/s]Processed prompts:  51%|█████▏    | 257/500 [5:11:56<12:21:11, 183.01s/it, est. speed input: 5.58 toks/s, output: 247.74 toks/s]Processed prompts:  52%|█████▏    | 258/500 [5:12:08<8:51:33, 131.79s/it, est. speed input: 5.60 toks/s, output: 249.33 toks/s] Processed prompts:  52%|█████▏    | 259/500 [5:16:23<11:17:43, 168.73s/it, est. speed input: 5.55 toks/s, output: 247.71 toks/s]Processed prompts:  52%|█████▏    | 260/500 [5:21:11<13:38:22, 204.59s/it, est. speed input: 5.48 toks/s, output: 245.70 toks/s]Processed prompts:  52%|█████▏    | 261/500 [5:23:05<11:45:56, 177.22s/it, est. speed input: 5.46 toks/s, output: 245.96 toks/s]Processed prompts:  52%|█████▏    | 262/500 [5:23:53<9:09:45, 138.59s/it, est. speed input: 5.47 toks/s, output: 247.03 toks/s] Processed prompts:  53%|█████▎    | 263/500 [5:24:38<7:16:12, 110.43s/it, est. speed input: 5.47 toks/s, output: 248.14 toks/s]Processed prompts:  53%|█████▎    | 264/500 [5:25:03<5:33:58, 84.91s/it, est. speed input: 5.47 toks/s, output: 249.50 toks/s] Processed prompts:  53%|█████▎    | 265/500 [5:26:00<4:59:28, 76.46s/it, est. speed input: 5.47 toks/s, output: 250.45 toks/s]WARNING 04-07 00:32:42 scheduler.py:1555] Sequence group 301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301
Processed prompts:  53%|█████▎    | 266/500 [5:27:39<5:24:07, 83.11s/it, est. speed input: 5.46 toks/s, output: 250.86 toks/s]Processed prompts:  53%|█████▎    | 267/500 [5:32:53<9:52:31, 152.58s/it, est. speed input: 5.39 toks/s, output: 248.55 toks/s]Processed prompts:  54%|█████▎    | 268/500 [5:32:57<6:57:28, 107.97s/it, est. speed input: 5.40 toks/s, output: 249.23 toks/s]Processed prompts:  54%|█████▍    | 269/500 [5:37:05<9:37:38, 150.04s/it, est. speed input: 5.35 toks/s, output: 247.80 toks/s]Processed prompts:  54%|█████▍    | 270/500 [5:41:39<11:57:00, 187.05s/it, est. speed input: 5.30 toks/s, output: 246.09 toks/s]Processed prompts:  54%|█████▍    | 271/500 [5:42:23<9:10:41, 144.28s/it, est. speed input: 5.30 toks/s, output: 247.15 toks/s] WARNING 04-07 00:51:43 scheduler.py:1555] Sequence group 282 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351
Processed prompts:  54%|█████▍    | 272/500 [5:47:58<12:45:04, 201.34s/it, est. speed input: 5.28 toks/s, output: 244.76 toks/s]Processed prompts:  55%|█████▍    | 273/500 [5:51:21<12:43:36, 201.84s/it, est. speed input: 5.24 toks/s, output: 243.96 toks/s]Processed prompts:  55%|█████▍    | 274/500 [5:51:56<9:31:34, 151.75s/it, est. speed input: 5.26 toks/s, output: 245.11 toks/s] Processed prompts:  55%|█████▌    | 275/500 [5:53:01<7:51:50, 125.82s/it, est. speed input: 5.28 toks/s, output: 245.90 toks/s]Processed prompts:  55%|█████▌    | 276/500 [5:53:23<5:54:03, 94.84s/it, est. speed input: 5.31 toks/s, output: 247.18 toks/s] Processed prompts:  55%|█████▌    | 277/500 [5:53:44<4:29:27, 72.50s/it, est. speed input: 5.32 toks/s, output: 248.49 toks/s]Processed prompts:  56%|█████▌    | 278/500 [5:54:04<3:30:00, 56.76s/it, est. speed input: 5.33 toks/s, output: 249.80 toks/s]WARNING 04-07 01:01:11 scheduler.py:1555] Sequence group 333 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401
Processed prompts:  56%|█████▌    | 279/500 [5:57:56<6:42:31, 109.28s/it, est. speed input: 5.28 toks/s, output: 247.58 toks/s]Processed prompts:  56%|█████▌    | 280/500 [6:00:56<7:58:53, 130.60s/it, est. speed input: 5.27 toks/s, output: 247.03 toks/s]Processed prompts:  56%|█████▌    | 281/500 [6:03:25<8:17:09, 136.21s/it, est. speed input: 5.25 toks/s, output: 246.85 toks/s]WARNING 04-07 01:11:00 scheduler.py:1555] Sequence group 293 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451
Processed prompts:  56%|█████▋    | 282/500 [6:04:39<7:06:57, 117.51s/it, est. speed input: 5.28 toks/s, output: 246.64 toks/s]Processed prompts:  57%|█████▋    | 283/500 [6:06:17<6:43:29, 111.56s/it, est. speed input: 5.27 toks/s, output: 247.04 toks/s]Processed prompts:  57%|█████▋    | 284/500 [6:07:36<6:06:45, 101.88s/it, est. speed input: 5.26 toks/s, output: 247.11 toks/s]Processed prompts:  57%|█████▋    | 285/500 [6:09:58<6:47:43, 113.79s/it, est. speed input: 5.24 toks/s, output: 247.01 toks/s]Processed prompts:  57%|█████▋    | 286/500 [6:12:07<7:01:53, 118.29s/it, est. speed input: 5.22 toks/s, output: 247.06 toks/s]Processed prompts:  57%|█████▋    | 287/500 [6:20:13<13:32:18, 228.82s/it, est. speed input: 5.13 toks/s, output: 243.22 toks/s]Processed prompts:  58%|█████▊    | 288/500 [6:20:42<9:56:21, 168.78s/it, est. speed input: 5.13 toks/s, output: 244.35 toks/s] Processed prompts:  58%|█████▊    | 289/500 [6:21:26<7:42:09, 131.42s/it, est. speed input: 5.14 toks/s, output: 245.31 toks/s]Processed prompts:  58%|█████▊    | 290/500 [6:22:19<6:17:39, 107.90s/it, est. speed input: 5.16 toks/s, output: 246.17 toks/s]Processed prompts:  58%|█████▊    | 291/500 [6:22:49<4:54:06, 84.43s/it, est. speed input: 5.16 toks/s, output: 247.28 toks/s] Processed prompts:  58%|█████▊    | 292/500 [6:23:47<4:25:24, 76.56s/it, est. speed input: 5.16 toks/s, output: 248.08 toks/s]WARNING 04-07 01:30:47 scheduler.py:1555] Sequence group 321 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501
Processed prompts:  59%|█████▊    | 293/500 [6:25:13<4:34:07, 79.46s/it, est. speed input: 5.15 toks/s, output: 247.74 toks/s]Processed prompts:  59%|█████▉    | 294/500 [6:25:47<3:45:10, 65.59s/it, est. speed input: 5.16 toks/s, output: 248.80 toks/s]Processed prompts:  59%|█████▉    | 295/500 [6:32:23<9:23:02, 164.79s/it, est. speed input: 5.11 toks/s, output: 246.01 toks/s]Processed prompts:  59%|█████▉    | 296/500 [6:35:03<9:15:31, 163.39s/it, est. speed input: 5.09 toks/s, output: 245.73 toks/s]Processed prompts:  59%|█████▉    | 297/500 [6:38:23<9:50:17, 174.47s/it, est. speed input: 5.06 toks/s, output: 245.04 toks/s]Processed prompts:  60%|█████▉    | 298/500 [6:43:19<11:49:47, 210.83s/it, est. speed input: 5.01 toks/s, output: 243.40 toks/s]Processed prompts:  60%|█████▉    | 299/500 [6:44:55<9:51:14, 176.49s/it, est. speed input: 5.06 toks/s, output: 243.78 toks/s] Processed prompts:  60%|██████    | 300/500 [6:49:02<10:58:31, 197.56s/it, est. speed input: 5.02 toks/s, output: 242.67 toks/s]Processed prompts:  60%|██████    | 301/500 [6:50:07<8:43:01, 157.69s/it, est. speed input: 5.02 toks/s, output: 243.36 toks/s] Processed prompts:  60%|██████    | 302/500 [6:50:38<6:35:32, 119.86s/it, est. speed input: 5.02 toks/s, output: 244.38 toks/s]WARNING 04-07 01:57:22 scheduler.py:1555] Sequence group 314 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551
Processed prompts:  61%|██████    | 303/500 [6:51:55<5:51:24, 107.03s/it, est. speed input: 5.02 toks/s, output: 244.94 toks/s]Processed prompts:  61%|██████    | 304/500 [6:52:06<4:14:49, 78.01s/it, est. speed input: 5.03 toks/s, output: 246.16 toks/s] Processed prompts:  61%|██████    | 305/500 [6:52:16<3:07:34, 57.71s/it, est. speed input: 5.04 toks/s, output: 247.39 toks/s]WARNING 04-07 02:00:36 scheduler.py:1555] Sequence group 329 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601
Processed prompts:  61%|██████    | 306/500 [6:54:34<4:24:43, 81.87s/it, est. speed input: 5.02 toks/s, output: 246.48 toks/s]Processed prompts:  61%|██████▏   | 307/500 [6:57:39<6:02:40, 112.75s/it, est. speed input: 5.00 toks/s, output: 245.97 toks/s]Processed prompts:  62%|██████▏   | 308/500 [7:01:54<8:17:39, 155.52s/it, est. speed input: 4.96 toks/s, output: 244.79 toks/s]Processed prompts:  62%|██████▏   | 309/500 [7:04:14<7:59:49, 150.73s/it, est. speed input: 4.94 toks/s, output: 244.73 toks/s]Processed prompts:  62%|██████▏   | 310/500 [7:04:30<5:49:41, 110.43s/it, est. speed input: 4.97 toks/s, output: 245.86 toks/s]Processed prompts:  62%|██████▏   | 311/500 [7:14:09<13:10:39, 251.00s/it, est. speed input: 4.87 toks/s, output: 241.65 toks/s]Processed prompts:  62%|██████▏   | 312/500 [7:15:48<10:43:11, 205.27s/it, est. speed input: 4.87 toks/s, output: 242.00 toks/s]Processed prompts:  63%|██████▎   | 313/500 [7:16:23<8:00:18, 154.11s/it, est. speed input: 4.90 toks/s, output: 242.93 toks/s] Processed prompts:  63%|██████▎   | 314/500 [7:17:22<6:29:23, 125.61s/it, est. speed input: 4.90 toks/s, output: 243.63 toks/s]Processed prompts:  63%|██████▎   | 315/500 [7:18:18<5:23:36, 104.95s/it, est. speed input: 4.90 toks/s, output: 244.35 toks/s]Processed prompts:  63%|██████▎   | 316/500 [7:19:14<4:36:35, 90.19s/it, est. speed input: 4.90 toks/s, output: 245.07 toks/s] Processed prompts:  63%|██████▎   | 317/500 [7:19:56<3:50:59, 75.73s/it, est. speed input: 4.90 toks/s, output: 245.93 toks/s]WARNING 04-07 02:26:28 scheduler.py:1555] Sequence group 358 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651
Processed prompts:  64%|██████▎   | 318/500 [7:21:19<3:55:45, 77.72s/it, est. speed input: 4.90 toks/s, output: 246.40 toks/s]Processed prompts:  64%|██████▍   | 319/500 [7:29:19<9:59:11, 198.63s/it, est. speed input: 4.83 toks/s, output: 243.22 toks/s]Processed prompts:  64%|██████▍   | 320/500 [7:29:44<7:19:42, 146.57s/it, est. speed input: 4.83 toks/s, output: 244.21 toks/s]WARNING 04-07 02:37:53 scheduler.py:1555] Sequence group 331 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701
Processed prompts:  64%|██████▍   | 321/500 [7:33:46<8:42:32, 175.16s/it, est. speed input: 4.80 toks/s, output: 243.24 toks/s]Processed prompts:  64%|██████▍   | 322/500 [7:35:48<7:51:54, 159.07s/it, est. speed input: 4.79 toks/s, output: 243.36 toks/s]Processed prompts:  65%|██████▍   | 323/500 [7:41:09<10:12:55, 207.77s/it, est. speed input: 4.75 toks/s, output: 241.72 toks/s]Processed prompts:  65%|██████▍   | 324/500 [7:42:43<8:29:04, 173.55s/it, est. speed input: 4.74 toks/s, output: 242.08 toks/s] Processed prompts:  65%|██████▌   | 325/500 [7:43:56<6:58:21, 143.44s/it, est. speed input: 4.74 toks/s, output: 242.62 toks/s]Processed prompts:  65%|██████▌   | 326/500 [7:45:11<5:56:36, 122.97s/it, est. speed input: 4.74 toks/s, output: 243.14 toks/s]Processed prompts:  65%|██████▌   | 327/500 [7:46:13<5:01:06, 104.43s/it, est. speed input: 4.74 toks/s, output: 243.78 toks/s]Processed prompts:  66%|██████▌   | 328/500 [7:47:04<4:13:32, 88.44s/it, est. speed input: 4.74 toks/s, output: 244.51 toks/s] Processed prompts:  66%|██████▌   | 329/500 [7:48:19<4:00:59, 84.56s/it, est. speed input: 4.74 toks/s, output: 245.02 toks/s]Processed prompts:  66%|██████▌   | 330/500 [7:50:09<4:21:04, 92.14s/it, est. speed input: 4.73 toks/s, output: 244.31 toks/s]WARNING 04-07 02:56:47 scheduler.py:1555] Sequence group 347 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751
Processed prompts:  66%|██████▌   | 331/500 [7:52:38<5:07:55, 109.32s/it, est. speed input: 4.73 toks/s, output: 244.18 toks/s]Processed prompts:  66%|██████▋   | 332/500 [7:55:17<5:47:34, 124.14s/it, est. speed input: 4.72 toks/s, output: 243.97 toks/s]Processed prompts:  67%|██████▋   | 333/500 [8:02:09<9:45:52, 210.49s/it, est. speed input: 4.69 toks/s, output: 241.63 toks/s]Processed prompts:  67%|██████▋   | 334/500 [8:02:38<7:11:16, 155.88s/it, est. speed input: 4.70 toks/s, output: 242.52 toks/s]Processed prompts:  67%|██████▋   | 335/500 [8:03:27<5:41:11, 124.07s/it, est. speed input: 4.70 toks/s, output: 243.23 toks/s]Processed prompts:  67%|██████▋   | 336/500 [8:09:40<9:02:32, 198.49s/it, est. speed input: 4.65 toks/s, output: 241.27 toks/s]Processed prompts:  67%|██████▋   | 337/500 [8:10:46<7:11:32, 158.85s/it, est. speed input: 4.65 toks/s, output: 241.84 toks/s]Processed prompts:  68%|██████▊   | 338/500 [8:11:58<5:58:49, 132.90s/it, est. speed input: 4.65 toks/s, output: 242.35 toks/s]Processed prompts:  68%|██████▊   | 339/500 [8:12:24<4:30:15, 100.72s/it, est. speed input: 4.65 toks/s, output: 243.25 toks/s]WARNING 04-07 03:19:25 scheduler.py:1555] Sequence group 365 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801
Processed prompts:  68%|██████▊   | 340/500 [8:13:11<3:45:38, 84.62s/it, est. speed input: 4.66 toks/s, output: 243.97 toks/s] Processed prompts:  68%|██████▊   | 341/500 [8:13:15<2:40:32, 60.58s/it, est. speed input: 4.67 toks/s, output: 244.42 toks/s]WARNING 04-07 03:20:51 scheduler.py:1555] Sequence group 380 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851
Processed prompts:  68%|██████▊   | 342/500 [8:14:32<2:52:22, 65.46s/it, est. speed input: 4.67 toks/s, output: 243.83 toks/s]Processed prompts:  69%|██████▊   | 343/500 [8:15:08<2:27:55, 56.53s/it, est. speed input: 4.67 toks/s, output: 244.64 toks/s]Processed prompts:  69%|██████▉   | 344/500 [8:18:48<4:34:27, 105.56s/it, est. speed input: 4.65 toks/s, output: 243.94 toks/s]WARNING 04-07 03:29:52 scheduler.py:1555] Sequence group 355 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901
Processed prompts:  69%|██████▉   | 345/500 [8:23:34<6:52:52, 159.82s/it, est. speed input: 4.61 toks/s, output: 242.71 toks/s]Processed prompts:  69%|██████▉   | 346/500 [8:23:39<4:50:43, 113.27s/it, est. speed input: 4.62 toks/s, output: 243.03 toks/s]Processed prompts:  69%|██████▉   | 347/500 [8:24:18<3:51:48, 90.90s/it, est. speed input: 4.62 toks/s, output: 243.80 toks/s] Processed prompts:  70%|██████▉   | 348/500 [8:29:12<6:24:38, 151.83s/it, est. speed input: 4.59 toks/s, output: 242.52 toks/s]Processed prompts:  70%|██████▉   | 349/500 [8:37:37<10:49:17, 258.00s/it, est. speed input: 4.53 toks/s, output: 239.63 toks/s]Processed prompts:  70%|███████   | 350/500 [8:38:16<8:00:44, 192.30s/it, est. speed input: 4.53 toks/s, output: 239.84 toks/s] Processed prompts:  70%|███████   | 351/500 [8:39:56<6:48:10, 164.36s/it, est. speed input: 4.52 toks/s, output: 240.13 toks/s]Processed prompts:  70%|███████   | 352/500 [8:41:05<5:35:09, 135.88s/it, est. speed input: 4.52 toks/s, output: 240.64 toks/s]Processed prompts:  71%|███████   | 353/500 [8:41:56<4:30:26, 110.38s/it, est. speed input: 4.55 toks/s, output: 241.30 toks/s]Processed prompts:  71%|███████   | 354/500 [8:42:19<3:24:33, 84.06s/it, est. speed input: 4.56 toks/s, output: 242.17 toks/s] Processed prompts:  71%|███████   | 355/500 [8:42:39<2:36:50, 64.90s/it, est. speed input: 4.56 toks/s, output: 243.06 toks/s]Processed prompts:  71%|███████   | 356/500 [8:43:06<2:08:37, 53.59s/it, est. speed input: 4.57 toks/s, output: 243.89 toks/s]Processed prompts:  71%|███████▏  | 357/500 [8:44:05<2:11:46, 55.29s/it, est. speed input: 4.57 toks/s, output: 244.47 toks/s]WARNING 04-07 03:50:45 scheduler.py:1555] Sequence group 400 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951
Processed prompts:  72%|███████▏  | 358/500 [8:50:09<5:49:52, 147.83s/it, est. speed input: 4.53 toks/s, output: 242.71 toks/s]Processed prompts:  72%|███████▏  | 359/500 [8:54:42<7:15:32, 185.33s/it, est. speed input: 4.50 toks/s, output: 241.67 toks/s]Processed prompts:  72%|███████▏  | 360/500 [8:54:46<5:05:23, 130.88s/it, est. speed input: 4.51 toks/s, output: 242.66 toks/s]Processed prompts:  72%|███████▏  | 361/500 [9:04:32<10:19:55, 267.60s/it, est. speed input: 4.46 toks/s, output: 239.30 toks/s]Processed prompts:  72%|███████▏  | 362/500 [9:05:56<8:08:55, 212.58s/it, est. speed input: 4.46 toks/s, output: 239.69 toks/s] Processed prompts:  73%|███████▎  | 363/500 [9:07:17<6:34:46, 172.90s/it, est. speed input: 4.48 toks/s, output: 240.10 toks/s]Processed prompts:  73%|███████▎  | 364/500 [9:08:27<5:22:00, 142.07s/it, est. speed input: 4.48 toks/s, output: 240.58 toks/s]WARNING 04-07 04:15:31 scheduler.py:1555] Sequence group 372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001
Processed prompts:  73%|███████▎  | 365/500 [9:09:39<4:32:12, 120.98s/it, est. speed input: 4.48 toks/s, output: 241.05 toks/s]Processed prompts:  73%|███████▎  | 366/500 [9:10:10<3:30:19, 94.17s/it, est. speed input: 4.48 toks/s, output: 241.82 toks/s] Processed prompts:  73%|███████▎  | 367/500 [9:10:48<2:51:32, 77.38s/it, est. speed input: 4.49 toks/s, output: 242.53 toks/s]Processed prompts:  74%|███████▎  | 368/500 [9:11:21<2:20:51, 64.03s/it, est. speed input: 4.50 toks/s, output: 243.28 toks/s]Processed prompts:  74%|███████▍  | 369/500 [9:16:05<4:43:25, 129.82s/it, est. speed input: 4.47 toks/s, output: 242.19 toks/s]Processed prompts:  74%|███████▍  | 370/500 [9:18:15<4:41:20, 129.85s/it, est. speed input: 4.46 toks/s, output: 241.69 toks/s]Processed prompts:  74%|███████▍  | 371/500 [9:20:56<4:59:51, 139.47s/it, est. speed input: 4.45 toks/s, output: 241.50 toks/s]Processed prompts:  74%|███████▍  | 372/500 [9:22:23<4:23:48, 123.66s/it, est. speed input: 4.45 toks/s, output: 241.85 toks/s]WARNING 04-07 04:30:26 scheduler.py:1555] Sequence group 384 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2051
Processed prompts:  75%|███████▍  | 373/500 [9:25:10<4:49:00, 136.54s/it, est. speed input: 4.43 toks/s, output: 241.63 toks/s]Processed prompts:  75%|███████▍  | 374/500 [9:30:01<6:23:58, 182.85s/it, est. speed input: 4.40 toks/s, output: 240.53 toks/s]Processed prompts:  75%|███████▌  | 375/500 [9:33:05<6:21:50, 183.28s/it, est. speed input: 4.39 toks/s, output: 240.19 toks/s]Processed prompts:  75%|███████▌  | 376/500 [9:34:58<5:35:25, 162.30s/it, est. speed input: 4.38 toks/s, output: 240.35 toks/s]Processed prompts:  75%|███████▌  | 377/500 [9:35:43<4:20:20, 127.00s/it, est. speed input: 4.39 toks/s, output: 240.99 toks/s]Processed prompts:  76%|███████▌  | 378/500 [9:37:15<3:56:50, 116.48s/it, est. speed input: 4.38 toks/s, output: 241.30 toks/s]Processed prompts:  76%|███████▌  | 379/500 [9:37:40<2:59:43, 89.12s/it, est. speed input: 4.39 toks/s, output: 242.07 toks/s] Processed prompts:  76%|███████▌  | 380/500 [9:38:14<2:24:48, 72.40s/it, est. speed input: 4.39 toks/s, output: 242.78 toks/s]WARNING 04-07 04:44:58 scheduler.py:1555] Sequence group 441 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2101
Processed prompts:  76%|███████▌  | 381/500 [9:43:51<5:01:15, 151.89s/it, est. speed input: 4.36 toks/s, output: 241.38 toks/s]WARNING 04-07 04:50:31 scheduler.py:1555] Sequence group 396 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2151
Processed prompts:  76%|███████▋  | 382/500 [9:44:31<3:52:54, 118.43s/it, est. speed input: 4.36 toks/s, output: 242.03 toks/s]Processed prompts:  77%|███████▋  | 383/500 [9:51:44<6:54:37, 212.62s/it, est. speed input: 4.32 toks/s, output: 240.01 toks/s]Processed prompts:  77%|███████▋  | 384/500 [9:52:39<5:19:30, 165.27s/it, est. speed input: 4.33 toks/s, output: 240.56 toks/s]Processed prompts:  77%|███████▋  | 385/500 [9:54:26<4:43:16, 147.80s/it, est. speed input: 4.32 toks/s, output: 240.76 toks/s]Processed prompts:  77%|███████▋  | 386/500 [9:55:14<3:44:25, 118.12s/it, est. speed input: 4.34 toks/s, output: 241.35 toks/s]Processed prompts:  77%|███████▋  | 387/500 [10:02:28<6:40:46, 212.80s/it, est. speed input: 4.30 toks/s, output: 239.36 toks/s]Processed prompts:  78%|███████▊  | 388/500 [10:03:57<5:28:01, 175.72s/it, est. speed input: 4.30 toks/s, output: 239.67 toks/s]Processed prompts:  78%|███████▊  | 389/500 [10:04:51<4:17:29, 139.18s/it, est. speed input: 4.30 toks/s, output: 240.22 toks/s]Processed prompts:  78%|███████▊  | 390/500 [10:05:40<3:25:27, 112.07s/it, est. speed input: 4.30 toks/s, output: 240.80 toks/s]Processed prompts:  78%|███████▊  | 391/500 [10:06:22<2:45:36, 91.16s/it, est. speed input: 4.31 toks/s, output: 241.42 toks/s] Processed prompts:  78%|███████▊  | 392/500 [10:07:56<2:45:33, 91.97s/it, est. speed input: 4.30 toks/s, output: 241.69 toks/s]WARNING 04-07 05:14:39 scheduler.py:1555] Sequence group 418 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2201
Processed prompts:  79%|███████▊  | 393/500 [10:10:04<3:03:15, 102.76s/it, est. speed input: 4.31 toks/s, output: 241.74 toks/s]Processed prompts:  79%|███████▉  | 394/500 [10:13:00<3:40:14, 124.67s/it, est. speed input: 4.29 toks/s, output: 241.48 toks/s]Processed prompts:  79%|███████▉  | 395/500 [10:19:49<6:07:19, 209.90s/it, est. speed input: 4.25 toks/s, output: 239.71 toks/s]Processed prompts:  79%|███████▉  | 396/500 [10:19:53<4:17:00, 148.27s/it, est. speed input: 4.26 toks/s, output: 240.08 toks/s]Processed prompts:  79%|███████▉  | 397/500 [10:20:20<3:12:01, 111.86s/it, est. speed input: 4.27 toks/s, output: 240.79 toks/s]Processed prompts:  80%|███████▉  | 398/500 [10:20:25<2:15:26, 79.67s/it, est. speed input: 4.27 toks/s, output: 241.09 toks/s] Processed prompts:  80%|███████▉  | 399/500 [10:21:21<2:02:29, 72.77s/it, est. speed input: 4.29 toks/s, output: 240.99 toks/s]Processed prompts:  80%|████████  | 400/500 [10:24:51<3:09:39, 113.80s/it, est. speed input: 4.27 toks/s, output: 240.52 toks/s]Processed prompts:  80%|████████  | 401/500 [10:26:26<2:58:33, 108.21s/it, est. speed input: 4.27 toks/s, output: 240.78 toks/s]Processed prompts:  80%|████████  | 402/500 [10:30:24<4:00:15, 147.10s/it, est. speed input: 4.26 toks/s, output: 240.14 toks/s]Processed prompts:  81%|████████  | 403/500 [10:31:31<3:19:07, 123.17s/it, est. speed input: 4.26 toks/s, output: 240.57 toks/s]WARNING 04-07 05:38:57 scheduler.py:1555] Sequence group 407 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2251
Processed prompts:  81%|████████  | 404/500 [10:32:45<2:53:24, 108.39s/it, est. speed input: 4.26 toks/s, output: 240.97 toks/s]Processed prompts:  81%|████████  | 405/500 [10:32:56<2:05:26, 79.22s/it, est. speed input: 4.27 toks/s, output: 240.92 toks/s] Processed prompts:  81%|████████  | 406/500 [10:34:13<2:02:57, 78.49s/it, est. speed input: 4.27 toks/s, output: 241.29 toks/s]WARNING 04-07 05:41:34 scheduler.py:1555] Sequence group 438 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2301
Processed prompts:  81%|████████▏ | 407/500 [10:35:14<1:53:30, 73.23s/it, est. speed input: 4.27 toks/s, output: 241.76 toks/s]Processed prompts:  82%|████████▏ | 408/500 [10:36:12<1:45:00, 68.49s/it, est. speed input: 4.27 toks/s, output: 242.26 toks/s]Processed prompts:  82%|████████▏ | 409/500 [10:39:57<2:55:20, 115.61s/it, est. speed input: 4.26 toks/s, output: 241.69 toks/s]Processed prompts:  82%|████████▏ | 410/500 [10:39:57<2:01:31, 81.01s/it, est. speed input: 4.26 toks/s, output: 241.82 toks/s] WARNING 04-07 05:47:16 scheduler.py:1555] Sequence group 432 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2351
Processed prompts:  82%|████████▏ | 411/500 [10:41:03<1:53:32, 76.54s/it, est. speed input: 4.26 toks/s, output: 241.56 toks/s]Processed prompts:  82%|████████▏ | 412/500 [10:48:44<4:41:09, 191.70s/it, est. speed input: 4.22 toks/s, output: 239.55 toks/s]Processed prompts:  83%|████████▎ | 413/500 [10:52:34<4:54:35, 203.17s/it, est. speed input: 4.20 toks/s, output: 238.98 toks/s]Processed prompts:  83%|████████▎ | 414/500 [10:55:46<4:46:32, 199.91s/it, est. speed input: 4.21 toks/s, output: 238.64 toks/s]Processed prompts:  83%|████████▎ | 415/500 [10:55:55<3:22:02, 142.62s/it, est. speed input: 4.21 toks/s, output: 239.03 toks/s]Processed prompts:  83%|████████▎ | 416/500 [10:58:14<3:18:01, 141.45s/it, est. speed input: 4.22 toks/s, output: 239.02 toks/s]Processed prompts:  83%|████████▎ | 417/500 [10:59:33<2:50:00, 122.90s/it, est. speed input: 4.22 toks/s, output: 239.37 toks/s]Processed prompts:  84%|████████▎ | 418/500 [11:01:01<2:33:26, 112.27s/it, est. speed input: 4.22 toks/s, output: 239.67 toks/s]Processed prompts:  84%|████████▍ | 419/500 [11:02:32<2:23:09, 106.04s/it, est. speed input: 4.22 toks/s, output: 239.94 toks/s]Processed prompts:  84%|████████▍ | 420/500 [11:03:04<1:51:41, 83.77s/it, est. speed input: 4.23 toks/s, output: 240.57 toks/s] Processed prompts:  84%|████████▍ | 421/500 [11:03:35<1:29:33, 68.02s/it, est. speed input: 4.23 toks/s, output: 241.21 toks/s]Processed prompts:  84%|████████▍ | 422/500 [11:04:19<1:19:02, 60.81s/it, est. speed input: 4.26 toks/s, output: 241.76 toks/s]WARNING 04-07 06:13:59 scheduler.py:1555] Sequence group 439 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2401
Processed prompts:  85%|████████▍ | 423/500 [11:10:42<3:21:57, 157.37s/it, est. speed input: 4.23 toks/s, output: 240.28 toks/s]Processed prompts:  85%|████████▍ | 424/500 [11:17:14<4:48:18, 227.61s/it, est. speed input: 4.20 toks/s, output: 238.77 toks/s]Processed prompts:  85%|████████▌ | 425/500 [11:19:12<4:03:34, 194.86s/it, est. speed input: 4.20 toks/s, output: 238.88 toks/s]Processed prompts:  85%|████████▌ | 426/500 [11:21:37<3:41:47, 179.84s/it, est. speed input: 4.19 toks/s, output: 238.84 toks/s]Processed prompts:  85%|████████▌ | 427/500 [11:22:48<2:59:06, 147.22s/it, est. speed input: 4.19 toks/s, output: 239.22 toks/s]Processed prompts:  86%|████████▌ | 428/500 [11:24:26<2:39:05, 132.57s/it, est. speed input: 4.19 toks/s, output: 239.45 toks/s]Processed prompts:  86%|████████▌ | 429/500 [11:25:49<2:19:18, 117.73s/it, est. speed input: 4.19 toks/s, output: 239.76 toks/s]Processed prompts:  86%|████████▌ | 430/500 [11:27:19<2:07:21, 109.16s/it, est. speed input: 4.19 toks/s, output: 240.03 toks/s]Processed prompts:  86%|████████▌ | 431/500 [11:28:29<1:52:17, 97.65s/it, est. speed input: 4.19 toks/s, output: 240.42 toks/s] Processed prompts:  86%|████████▋ | 432/500 [11:35:15<3:35:18, 189.98s/it, est. speed input: 4.17 toks/s, output: 238.87 toks/s]Processed prompts:  87%|████████▋ | 433/500 [11:36:46<2:59:05, 160.38s/it, est. speed input: 4.17 toks/s, output: 239.13 toks/s]Processed prompts:  87%|████████▋ | 434/500 [11:38:58<2:47:03, 151.87s/it, est. speed input: 4.16 toks/s, output: 239.16 toks/s]WARNING 04-07 06:50:00 scheduler.py:1555] Sequence group 445 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2451
Processed prompts:  87%|████████▋ | 435/500 [11:43:40<3:26:42, 190.81s/it, est. speed input: 4.14 toks/s, output: 237.80 toks/s]Processed prompts:  87%|████████▋ | 436/500 [11:45:05<2:49:47, 159.18s/it, est. speed input: 4.14 toks/s, output: 238.09 toks/s]Processed prompts:  87%|████████▋ | 437/500 [11:46:34<2:24:52, 137.98s/it, est. speed input: 4.14 toks/s, output: 238.37 toks/s]Processed prompts:  88%|████████▊ | 438/500 [11:48:31<2:16:08, 131.75s/it, est. speed input: 4.14 toks/s, output: 238.48 toks/s]Processed prompts:  88%|████████▊ | 439/500 [11:49:45<1:56:16, 114.37s/it, est. speed input: 4.14 toks/s, output: 238.84 toks/s]Processed prompts:  88%|████████▊ | 440/500 [11:50:37<1:35:37, 95.62s/it, est. speed input: 4.14 toks/s, output: 239.32 toks/s] Processed prompts:  88%|████████▊ | 441/500 [11:52:08<1:32:53, 94.47s/it, est. speed input: 4.14 toks/s, output: 239.57 toks/s]Processed prompts:  88%|████████▊ | 442/500 [11:52:31<1:10:33, 72.99s/it, est. speed input: 4.15 toks/s, output: 240.21 toks/s]Processed prompts:  89%|████████▊ | 443/500 [11:53:32<1:05:54, 69.37s/it, est. speed input: 4.15 toks/s, output: 239.89 toks/s]Processed prompts:  89%|████████▉ | 444/500 [11:53:50<50:16, 53.86s/it, est. speed input: 4.16 toks/s, output: 240.55 toks/s]  Processed prompts:  89%|████████▉ | 445/500 [11:53:50<34:43, 37.89s/it, est. speed input: 4.17 toks/s, output: 240.56 toks/s]WARNING 04-07 07:00:27 scheduler.py:1555] Sequence group 497 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2501
Processed prompts:  89%|████████▉ | 446/500 [11:55:18<47:22, 52.64s/it, est. speed input: 4.17 toks/s, output: 240.12 toks/s]Processed prompts:  89%|████████▉ | 447/500 [11:58:11<1:18:35, 88.98s/it, est. speed input: 4.16 toks/s, output: 239.91 toks/s]Processed prompts:  90%|████████▉ | 448/500 [12:00:32<1:30:33, 104.48s/it, est. speed input: 4.15 toks/s, output: 239.89 toks/s]WARNING 04-07 07:08:24 scheduler.py:1555] Sequence group 460 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2551
Processed prompts:  90%|████████▉ | 449/500 [12:04:22<2:00:45, 142.06s/it, est. speed input: 4.14 toks/s, output: 239.38 toks/s]Processed prompts:  90%|█████████ | 450/500 [12:05:37<1:41:42, 122.04s/it, est. speed input: 4.14 toks/s, output: 239.72 toks/s]Processed prompts:  90%|█████████ | 451/500 [12:13:44<3:09:10, 231.63s/it, est. speed input: 4.10 toks/s, output: 237.81 toks/s]Processed prompts:  90%|█████████ | 452/500 [12:13:52<2:11:30, 164.39s/it, est. speed input: 4.11 toks/s, output: 238.27 toks/s]Processed prompts:  91%|█████████ | 453/500 [12:15:08<1:48:03, 137.94s/it, est. speed input: 4.11 toks/s, output: 238.60 toks/s]Processed prompts:  91%|█████████ | 454/500 [12:16:43<1:35:57, 125.17s/it, est. speed input: 4.11 toks/s, output: 238.52 toks/s]Processed prompts:  91%|█████████ | 455/500 [12:17:03<1:10:12, 93.61s/it, est. speed input: 4.12 toks/s, output: 239.15 toks/s] Processed prompts:  91%|█████████ | 456/500 [12:18:16<1:04:07, 87.43s/it, est. speed input: 4.12 toks/s, output: 239.50 toks/s]Processed prompts:  91%|█████████▏| 457/500 [12:22:03<1:32:36, 129.22s/it, est. speed input: 4.10 toks/s, output: 239.02 toks/s]Processed prompts:  92%|█████████▏| 458/500 [12:22:27<1:08:14, 97.50s/it, est. speed input: 4.11 toks/s, output: 239.63 toks/s] Processed prompts:  92%|█████████▏| 459/500 [12:22:54<52:10, 76.34s/it, est. speed input: 4.11 toks/s, output: 240.22 toks/s]  Processed prompts:  92%|█████████▏| 460/500 [12:23:18<40:27, 60.68s/it, est. speed input: 4.12 toks/s, output: 240.82 toks/s]WARNING 04-07 07:31:40 scheduler.py:1555] Sequence group 486 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2601
Processed prompts:  92%|█████████▏| 461/500 [12:31:35<2:04:32, 191.60s/it, est. speed input: 4.08 toks/s, output: 238.89 toks/s]Processed prompts:  92%|█████████▏| 462/500 [12:36:22<2:19:33, 220.36s/it, est. speed input: 4.06 toks/s, output: 238.10 toks/s]Processed prompts:  93%|█████████▎| 463/500 [12:36:30<1:36:30, 156.49s/it, est. speed input: 4.08 toks/s, output: 238.78 toks/s]Processed prompts:  93%|█████████▎| 464/500 [12:38:34<1:28:01, 146.70s/it, est. speed input: 4.08 toks/s, output: 238.85 toks/s]Processed prompts:  93%|█████████▎| 465/500 [12:40:21<1:18:41, 134.89s/it, est. speed input: 4.07 toks/s, output: 238.69 toks/s]Processed prompts:  93%|█████████▎| 466/500 [12:44:31<1:36:03, 169.53s/it, est. speed input: 4.07 toks/s, output: 238.10 toks/s]Processed prompts:  93%|█████████▎| 467/500 [12:45:42<1:16:59, 139.98s/it, est. speed input: 4.07 toks/s, output: 238.45 toks/s]Processed prompts:  94%|█████████▎| 468/500 [12:49:39<1:30:11, 169.10s/it, est. speed input: 4.08 toks/s, output: 237.93 toks/s]Processed prompts:  94%|█████████▍| 469/500 [12:50:32<1:09:16, 134.08s/it, est. speed input: 4.08 toks/s, output: 238.37 toks/s]Processed prompts:  94%|█████████▍| 470/500 [12:50:39<48:02, 96.07s/it, est. speed input: 4.09 toks/s, output: 238.69 toks/s]   Processed prompts:  94%|█████████▍| 471/500 [12:51:36<40:42, 84.23s/it, est. speed input: 4.10 toks/s, output: 239.10 toks/s]Processed prompts:  94%|█████████▍| 472/500 [12:52:09<32:06, 68.80s/it, est. speed input: 4.11 toks/s, output: 239.64 toks/s]WARNING 04-07 07:59:01 scheduler.py:1555] Sequence group 497 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2651
Processed prompts:  95%|█████████▍| 473/500 [12:53:03<29:00, 64.45s/it, est. speed input: 4.11 toks/s, output: 240.07 toks/s]Processed prompts:  95%|█████████▍| 474/500 [12:55:51<41:21, 95.44s/it, est. speed input: 4.11 toks/s, output: 239.91 toks/s]Processed prompts:  95%|█████████▌| 475/500 [12:57:11<37:56, 91.04s/it, est. speed input: 4.11 toks/s, output: 240.19 toks/s]Processed prompts:  95%|█████████▌| 476/500 [12:59:48<44:14, 110.61s/it, est. speed input: 4.10 toks/s, output: 240.09 toks/s]Processed prompts:  95%|█████████▌| 477/500 [13:00:28<34:18, 89.50s/it, est. speed input: 4.10 toks/s, output: 240.08 toks/s] Processed prompts:  96%|█████████▌| 478/500 [13:08:43<1:17:26, 211.20s/it, est. speed input: 4.06 toks/s, output: 238.26 toks/s]Processed prompts:  96%|█████████▌| 479/500 [13:08:59<53:24, 152.60s/it, est. speed input: 4.07 toks/s, output: 238.87 toks/s]  Processed prompts:  96%|█████████▌| 480/500 [13:14:39<1:09:38, 208.91s/it, est. speed input: 4.05 toks/s, output: 237.85 toks/s]Processed prompts:  96%|█████████▌| 481/500 [13:19:11<1:12:09, 227.87s/it, est. speed input: 4.03 toks/s, output: 237.19 toks/s]Processed prompts:  96%|█████████▋| 482/500 [13:19:37<50:11, 167.29s/it, est. speed input: 4.03 toks/s, output: 237.74 toks/s]  Processed prompts:  97%|█████████▋| 483/500 [13:20:18<36:38, 129.34s/it, est. speed input: 4.04 toks/s, output: 238.22 toks/s]Processed prompts:  97%|█████████▋| 484/500 [13:20:58<27:17, 102.37s/it, est. speed input: 4.04 toks/s, output: 238.71 toks/s]Processed prompts:  97%|█████████▋| 485/500 [13:21:12<18:58, 75.88s/it, est. speed input: 4.05 toks/s, output: 239.32 toks/s] Processed prompts:  97%|█████████▋| 486/500 [13:21:22<13:07, 56.27s/it, est. speed input: 4.05 toks/s, output: 239.95 toks/s]WARNING 04-07 08:31:33 scheduler.py:1555] Sequence group 499 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2701
Processed prompts:  97%|█████████▋| 487/500 [13:26:40<29:10, 134.69s/it, est. speed input: 4.03 toks/s, output: 239.05 toks/s]Processed prompts:  98%|█████████▊| 488/500 [13:29:20<28:29, 142.43s/it, est. speed input: 4.03 toks/s, output: 238.94 toks/s]Processed prompts:  98%|█████████▊| 489/500 [13:30:56<23:32, 128.43s/it, est. speed input: 4.02 toks/s, output: 239.14 toks/s]Processed prompts:  98%|█████████▊| 490/500 [13:31:22<16:16, 97.68s/it, est. speed input: 4.03 toks/s, output: 239.69 toks/s] Processed prompts:  98%|█████████▊| 491/500 [13:35:25<21:12, 141.34s/it, est. speed input: 4.01 toks/s, output: 239.16 toks/s]Processed prompts:  98%|█████████▊| 492/500 [13:38:55<21:34, 161.85s/it, est. speed input: 4.00 toks/s, output: 238.81 toks/s]Processed prompts:  99%|█████████▊| 493/500 [13:40:40<16:53, 144.81s/it, est. speed input: 4.00 toks/s, output: 238.97 toks/s]Processed prompts:  99%|█████████▉| 494/500 [13:44:12<16:30, 165.05s/it, est. speed input: 3.99 toks/s, output: 238.60 toks/s]Processed prompts:  99%|█████████▉| 495/500 [13:45:39<11:48, 141.62s/it, est. speed input: 3.99 toks/s, output: 238.85 toks/s]Processed prompts:  99%|█████████▉| 496/500 [13:46:30<07:37, 114.31s/it, est. speed input: 3.99 toks/s, output: 239.26 toks/s]Processed prompts:  99%|█████████▉| 497/500 [13:46:59<04:26, 88.77s/it, est. speed input: 4.00 toks/s, output: 239.78 toks/s] Processed prompts: 100%|█████████▉| 498/500 [13:47:54<02:37, 78.63s/it, est. speed input: 4.00 toks/s, output: 240.18 toks/s]Processed prompts: 100%|█████████▉| 499/500 [13:49:08<01:17, 77.19s/it, est. speed input: 4.00 toks/s, output: 240.48 toks/s]Processed prompts: 100%|██████████| 500/500 [13:50:24<00:00, 77.05s/it, est. speed input: 4.00 toks/s, output: 240.77 toks/s]Processed prompts: 100%|██████████| 500/500 [13:50:24<00:00, 99.65s/it, est. speed input: 4.00 toks/s, output: 240.77 toks/s]
INFO 04-07 08:56:50 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2409679)[0;0m INFO 04-07 08:56:50 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2409677)[0;0m INFO 04-07 08:56:50 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2409678)[0;0m INFO 04-07 08:56:50 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 08:57:03.914007713 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 08:57:19 config.py:510] This model supports multiple tasks: {'classify', 'generate', 'embed', 'reward', 'score'}. Defaulting to 'generate'.
INFO 04-07 08:57:19 config.py:1310] Defaulting to use mp for distributed inference
WARNING 04-07 08:57:19 arg_utils.py:1103] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 04-07 08:57:19 config.py:1458] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 04-07 08:57:19 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', speculative_config=None, tokenizer='/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 08:57:19 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 08:57:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 08:57:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 08:57:22 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:22 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:22 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:22 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 08:57:22 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:22 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:22 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:22 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2602739)[0;0m WARNING 04-07 08:57:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2602740)[0;0m WARNING 04-07 08:57:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 08:57:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2602741)[0;0m WARNING 04-07 08:57:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 08:57:22 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_2fc82ba8'), local_subscribe_port=54635, remote_subscribe_port=None)
INFO 04-07 08:57:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/QwQ-32B/Qwen/QwQ-32B...
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:00<00:01,  7.04it/s]
Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:00<00:04,  2.57it/s]
Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:01<00:05,  2.02it/s]
Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:01<00:05,  1.86it/s]
Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:02<00:04,  1.81it/s]
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:03<00:04,  1.79it/s]
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:03<00:03,  1.78it/s]
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:04<00:03,  1.78it/s]
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:04<00:02,  1.78it/s]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:05<00:02,  1.79it/s]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:05<00:01,  1.81it/s]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:06<00:01,  1.93it/s]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:06<00:00,  1.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.87it/s]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:07<00:00,  1.89it/s]

[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:30 model_runner.py:1099] Loading model weights took 15.4136 GB
INFO 04-07 08:57:30 model_runner.py:1099] Loading model weights took 15.4136 GB
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:33 worker.py:241] Memory profiling takes 2.69 seconds
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:33 worker.py:241] Memory profiling takes 2.72 seconds
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.51GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.54GiB.
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:33 worker.py:241] Memory profiling takes 2.76 seconds
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.43GiB; PyTorch activation peak memory takes 0.19GiB; the rest of the memory reserved for KV Cache is 19.62GiB.
INFO 04-07 08:57:33 worker.py:241] Memory profiling takes 2.89 seconds
INFO 04-07 08:57:33 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.75) = 35.65GiB
INFO 04-07 08:57:33 worker.py:241] model weights take 15.41GiB; non_torch_memory takes 0.55GiB; PyTorch activation peak memory takes 5.54GiB; the rest of the memory reserved for KV Cache is 14.15GiB.
INFO 04-07 08:57:33 distributed_gpu_executor.py:57] # GPU blocks: 14491, # CPU blocks: 16384
INFO 04-07 08:57:33 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 1.77x
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:57:48 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:57:48 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:57:48 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 08:57:48 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<02:31,  1.17s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:27,  1.15s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:23,  1.12s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:20,  1.11s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:19,  1.11s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:20,  1.12s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:18,  1.12s/it]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<02:17,  1.12s/it]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:10<02:17,  1.12s/it]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:11<02:16,  1.13s/it]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:12<02:14,  1.12s/it]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:13<02:14,  1.13s/it]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:14<02:12,  1.12s/it]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:15<02:11,  1.13s/it]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:16<02:08,  1.11s/it]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:17<02:06,  1.10s/it]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:18<02:05,  1.10s/it]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:20<02:04,  1.10s/it]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:21<02:01,  1.08s/it]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:22<02:00,  1.08s/it]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:23<01:59,  1.08s/it]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:24<01:57,  1.08s/it]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:25<01:57,  1.08s/it]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:26<01:56,  1.09s/it]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:27<01:54,  1.08s/it]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:28<01:51,  1.06s/it]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:29<01:49,  1.05s/it]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:30<01:49,  1.06s/it]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:31<01:49,  1.07s/it]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:32<01:48,  1.07s/it]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:34<01:47,  1.08s/it]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:35<01:46,  1.08s/it]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:36<01:43,  1.06s/it]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:37<01:40,  1.04s/it]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:38<01:40,  1.04s/it]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:39<01:36,  1.02s/it]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:40<01:34,  1.01s/it]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:41<01:33,  1.00s/it]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:42<01:32,  1.01s/it]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:43<01:32,  1.01s/it]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:44<01:31,  1.01s/it]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:45<01:30,  1.01s/it]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:46<01:28,  1.01s/it]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:47<01:26,  1.00it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:48<01:26,  1.00s/it]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:49<01:25,  1.00s/it]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:50<01:24,  1.01s/it]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:51<01:23,  1.00s/it]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:52<01:21,  1.01it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:53<01:19,  1.01it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:54<01:18,  1.02it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:55<01:17,  1.02it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:56<01:16,  1.01it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:56<01:15,  1.02it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:57<01:13,  1.03it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:58<01:12,  1.03it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:59<01:12,  1.03it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [01:00<01:10,  1.03it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [01:01<01:09,  1.03it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [01:02<01:07,  1.05it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [01:03<01:07,  1.04it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [01:04<01:06,  1.04it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [01:05<01:05,  1.04it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [01:06<01:04,  1.04it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [01:07<01:01,  1.06it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [01:08<01:00,  1.08it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [01:09<00:59,  1.08it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [01:10<00:58,  1.08it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [01:11<00:56,  1.09it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [01:12<00:55,  1.10it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [01:12<00:54,  1.10it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [01:13<00:53,  1.10it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [01:14<00:52,  1.11it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:15<00:50,  1.12it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:16<00:50,  1.12it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:17<00:49,  1.12it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:18<00:47,  1.13it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:19<00:46,  1.14it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:20<00:45,  1.13it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:20<00:44,  1.14it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:21<00:43,  1.14it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:22<00:42,  1.15it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:23<00:41,  1.16it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:24<00:40,  1.16it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:25<00:39,  1.17it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:25<00:37,  1.19it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:26<00:37,  1.18it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:27<00:36,  1.19it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:28<00:35,  1.19it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:29<00:34,  1.19it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:30<00:33,  1.19it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:30<00:32,  1.20it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:31<00:31,  1.20it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:32<00:30,  1.21it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:33<00:29,  1.22it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:34<00:28,  1.22it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:35<00:27,  1.23it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:35<00:26,  1.23it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:36<00:26,  1.23it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:37<00:25,  1.24it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:38<00:24,  1.25it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:39<00:22,  1.27it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:39<00:21,  1.27it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:40<00:21,  1.27it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:41<00:20,  1.27it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:42<00:19,  1.27it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:42<00:18,  1.28it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:43<00:17,  1.29it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:44<00:17,  1.28it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:45<00:16,  1.30it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:45<00:15,  1.30it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:46<00:14,  1.30it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:47<00:13,  1.30it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:48<00:13,  1.31it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:49<00:12,  1.33it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:49<00:11,  1.33it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:50<00:10,  1.34it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:51<00:09,  1.34it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:51<00:08,  1.36it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:52<00:08,  1.37it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:53<00:07,  1.36it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:54<00:06,  1.34it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:54<00:05,  1.35it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:55<00:05,  1.36it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:56<00:04,  1.38it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:57<00:03,  1.38it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:57<00:02,  1.39it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:58<00:02,  1.41it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:59<00:01,  1.42it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:59<00:00,  1.42it/s][1;36m(VllmWorkerProcess pid=2602739)[0;0m INFO 04-07 08:59:49 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2602740)[0;0m INFO 04-07 08:59:49 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
[1;36m(VllmWorkerProcess pid=2602741)[0;0m INFO 04-07 08:59:49 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.25it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [02:00<00:00,  1.08it/s]
INFO 04-07 08:59:49 model_runner.py:1535] Graph capturing finished in 121 secs, took 8.20 GiB
INFO 04-07 08:59:49 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 138.52 seconds
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTest.py:118: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Processing task: cycle
Generating answers for task: cycle
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:00:52 scheduler.py:1555] Sequence group 301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
WARNING 04-07 09:01:10 scheduler.py:1555] Sequence group 251 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
WARNING 04-07 09:01:38 scheduler.py:1555] Sequence group 201 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
Processed prompts:   0%|          | 1/500 [02:10<18:06:54, 130.69s/it, est. speed input: 1.16 toks/s, output: 4.73 toks/s]WARNING 04-07 09:02:25 scheduler.py:1555] Sequence group 151 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
Processed prompts:   0%|          | 2/500 [03:04<11:49:28, 85.48s/it, est. speed input: 4.50 toks/s, output: 9.60 toks/s] Processed prompts:   1%|          | 3/500 [03:07<6:36:21, 47.85s/it, est. speed input: 5.36 toks/s, output: 15.78 toks/s]Processed prompts:   1%|          | 4/500 [03:26<5:00:50, 36.39s/it, est. speed input: 5.66 toks/s, output: 21.01 toks/s]Processed prompts:   1%|          | 5/500 [03:31<3:26:02, 24.98s/it, est. speed input: 6.42 toks/s, output: 27.38 toks/s]Processed prompts:   1%|          | 6/500 [03:35<2:28:08, 17.99s/it, est. speed input: 7.69 toks/s, output: 33.76 toks/s]Processed prompts:   1%|▏         | 7/500 [03:36<1:41:22, 12.34s/it, est. speed input: 8.45 toks/s, output: 40.61 toks/s]Processed prompts:   2%|▏         | 8/500 [03:36<1:10:04,  8.55s/it, est. speed input: 9.24 toks/s, output: 47.46 toks/s]Processed prompts:   2%|▏         | 9/500 [03:41<1:00:19,  7.37s/it, est. speed input: 9.86 toks/s, output: 53.44 toks/s]Processed prompts:   2%|▏         | 10/500 [03:43<46:11,  5.66s/it, est. speed input: 12.79 toks/s, output: 60.09 toks/s]Processed prompts:   2%|▏         | 11/500 [03:43<32:24,  3.98s/it, est. speed input: 23.84 toks/s, output: 67.08 toks/s]Processed prompts:   2%|▏         | 12/500 [03:48<34:47,  4.28s/it, est. speed input: 24.17 toks/s, output: 72.82 toks/s]Processed prompts:   3%|▎         | 13/500 [03:50<29:37,  3.65s/it, est. speed input: 24.93 toks/s, output: 79.37 toks/s]Processed prompts:   3%|▎         | 14/500 [03:51<21:52,  2.70s/it, est. speed input: 27.95 toks/s, output: 86.37 toks/s]Processed prompts:   3%|▎         | 15/500 [03:51<15:58,  1.98s/it, est. speed input: 28.72 toks/s, output: 93.46 toks/s]Processed prompts:   3%|▎         | 16/500 [03:55<20:09,  2.50s/it, est. speed input: 30.52 toks/s, output: 99.16 toks/s]Processed prompts:   3%|▎         | 17/500 [04:00<25:51,  3.21s/it, est. speed input: 31.89 toks/s, output: 104.54 toks/s]Processed prompts:   4%|▎         | 18/500 [04:00<19:27,  2.42s/it, est. speed input: 40.15 toks/s, output: 111.66 toks/s]WARNING 04-07 09:03:54 scheduler.py:1555] Sequence group 106 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
Processed prompts:   4%|▍         | 19/500 [04:03<21:04,  2.63s/it, est. speed input: 40.38 toks/s, output: 117.70 toks/s]Processed prompts:   4%|▍         | 20/500 [04:09<28:16,  3.53s/it, est. speed input: 42.06 toks/s, output: 122.58 toks/s]Processed prompts:   4%|▍         | 21/500 [04:10<21:56,  2.75s/it, est. speed input: 44.00 toks/s, output: 129.76 toks/s]Processed prompts:   4%|▍         | 22/500 [04:15<27:12,  3.42s/it, est. speed input: 43.92 toks/s, output: 134.93 toks/s]Processed prompts:   5%|▍         | 23/500 [04:21<32:56,  4.14s/it, est. speed input: 43.97 toks/s, output: 139.72 toks/s]Processed prompts:   5%|▍         | 24/500 [04:21<24:56,  3.14s/it, est. speed input: 49.54 toks/s, output: 147.11 toks/s]Processed prompts:   5%|▌         | 25/500 [04:39<58:32,  7.39s/it, est. speed input: 47.66 toks/s, output: 146.08 toks/s]Processed prompts:   5%|▌         | 26/500 [04:41<46:04,  5.83s/it, est. speed input: 48.17 toks/s, output: 153.09 toks/s]Processed prompts:   5%|▌         | 27/500 [04:44<38:42,  4.91s/it, est. speed input: 48.71 toks/s, output: 159.78 toks/s]Processed prompts:   6%|▌         | 28/500 [04:46<32:23,  4.12s/it, est. speed input: 50.37 toks/s, output: 166.66 toks/s]Processed prompts:   6%|▌         | 29/500 [04:53<39:23,  5.02s/it, est. speed input: 51.96 toks/s, output: 170.89 toks/s]Processed prompts:   6%|▌         | 30/500 [04:54<30:08,  3.85s/it, est. speed input: 52.95 toks/s, output: 178.56 toks/s]Processed prompts:   6%|▌         | 31/500 [05:00<33:52,  4.33s/it, est. speed input: 52.63 toks/s, output: 183.66 toks/s]Processed prompts:   6%|▋         | 32/500 [05:05<36:08,  4.63s/it, est. speed input: 52.96 toks/s, output: 188.94 toks/s]Processed prompts:   7%|▋         | 33/500 [05:06<26:44,  3.43s/it, est. speed input: 53.83 toks/s, output: 197.03 toks/s]Processed prompts:   7%|▋         | 34/500 [05:06<19:24,  2.50s/it, est. speed input: 54.56 toks/s, output: 205.31 toks/s]Processed prompts:   7%|▋         | 35/500 [05:11<24:43,  3.19s/it, est. speed input: 54.34 toks/s, output: 210.67 toks/s]Processed prompts:   7%|▋         | 36/500 [05:14<24:04,  3.11s/it, est. speed input: 59.69 toks/s, output: 216.78 toks/s]Processed prompts:   7%|▋         | 37/500 [05:15<20:15,  2.62s/it, est. speed input: 60.13 toks/s, output: 224.35 toks/s]Processed prompts:   8%|▊         | 38/500 [05:17<19:09,  2.49s/it, est. speed input: 60.94 toks/s, output: 231.38 toks/s]Processed prompts:   8%|▊         | 39/500 [05:18<14:38,  1.90s/it, est. speed input: 61.67 toks/s, output: 239.53 toks/s]Processed prompts:   8%|▊         | 40/500 [05:23<22:29,  2.93s/it, est. speed input: 62.45 toks/s, output: 244.28 toks/s]Processed prompts:   8%|▊         | 41/500 [05:24<16:25,  2.15s/it, est. speed input: 68.15 toks/s, output: 252.72 toks/s]Processed prompts:   8%|▊         | 42/500 [05:24<11:42,  1.53s/it, est. speed input: 68.84 toks/s, output: 261.33 toks/s]Processed prompts:   9%|▊         | 43/500 [05:28<17:32,  2.30s/it, est. speed input: 72.16 toks/s, output: 266.76 toks/s]Processed prompts:   9%|▉         | 44/500 [05:31<19:02,  2.51s/it, est. speed input: 72.20 toks/s, output: 273.07 toks/s]Processed prompts:   9%|▉         | 45/500 [05:33<17:43,  2.34s/it, est. speed input: 73.30 toks/s, output: 280.21 toks/s]Processed prompts:   9%|▉         | 46/500 [05:36<20:33,  2.72s/it, est. speed input: 73.16 toks/s, output: 286.03 toks/s]Processed prompts:   9%|▉         | 47/500 [05:37<14:55,  1.98s/it, est. speed input: 77.08 toks/s, output: 292.96 toks/s]Processed prompts:  10%|▉         | 48/500 [05:42<23:20,  3.10s/it, est. speed input: 81.74 toks/s, output: 296.96 toks/s]Processed prompts:  10%|▉         | 49/500 [05:43<19:01,  2.53s/it, est. speed input: 82.70 toks/s, output: 301.92 toks/s]Processed prompts:  10%|█         | 51/500 [05:45<12:18,  1.64s/it, est. speed input: 83.91 toks/s, output: 318.65 toks/s]Processed prompts:  10%|█         | 52/500 [05:51<20:40,  2.77s/it, est. speed input: 84.24 toks/s, output: 322.00 toks/s]Processed prompts:  11%|█         | 53/500 [05:55<22:30,  3.02s/it, est. speed input: 84.79 toks/s, output: 325.73 toks/s]Processed prompts:  11%|█         | 54/500 [05:57<21:23,  2.88s/it, est. speed input: 85.53 toks/s, output: 332.56 toks/s]Processed prompts:  11%|█         | 55/500 [05:58<16:27,  2.22s/it, est. speed input: 88.68 toks/s, output: 336.87 toks/s]Processed prompts:  11%|█         | 56/500 [05:59<14:15,  1.93s/it, est. speed input: 89.65 toks/s, output: 344.84 toks/s]Processed prompts:  11%|█▏        | 57/500 [05:59<10:26,  1.42s/it, est. speed input: 95.01 toks/s, output: 351.70 toks/s]Processed prompts:  12%|█▏        | 58/500 [06:03<16:46,  2.28s/it, est. speed input: 95.19 toks/s, output: 356.56 toks/s]Processed prompts:  12%|█▏        | 59/500 [06:04<13:42,  1.86s/it, est. speed input: 95.51 toks/s, output: 359.81 toks/s]Processed prompts:  12%|█▏        | 60/500 [06:05<11:17,  1.54s/it, est. speed input: 102.27 toks/s, output: 368.15 toks/s]Processed prompts:  12%|█▏        | 61/500 [06:07<11:56,  1.63s/it, est. speed input: 102.79 toks/s, output: 375.46 toks/s]Processed prompts:  12%|█▏        | 62/500 [06:08<11:23,  1.56s/it, est. speed input: 103.77 toks/s, output: 378.68 toks/s]Processed prompts:  13%|█▎        | 63/500 [06:11<13:05,  1.80s/it, est. speed input: 104.05 toks/s, output: 385.49 toks/s]Processed prompts:  13%|█▎        | 64/500 [06:12<12:16,  1.69s/it, est. speed input: 104.81 toks/s, output: 393.23 toks/s]Processed prompts:  13%|█▎        | 65/500 [06:14<12:43,  1.76s/it, est. speed input: 106.12 toks/s, output: 394.90 toks/s]Processed prompts:  13%|█▎        | 66/500 [06:15<10:54,  1.51s/it, est. speed input: 107.89 toks/s, output: 401.81 toks/s]Processed prompts:  13%|█▎        | 67/500 [06:15<08:08,  1.13s/it, est. speed input: 109.77 toks/s, output: 407.70 toks/s]Processed prompts:  14%|█▎        | 68/500 [06:16<06:53,  1.05it/s, est. speed input: 111.37 toks/s, output: 416.33 toks/s]Processed prompts:  14%|█▍        | 69/500 [06:18<10:07,  1.41s/it, est. speed input: 111.12 toks/s, output: 422.88 toks/s]Processed prompts:  14%|█▍        | 70/500 [06:24<19:54,  2.78s/it, est. speed input: 113.24 toks/s, output: 420.56 toks/s]Processed prompts:  14%|█▍        | 71/500 [06:25<14:54,  2.08s/it, est. speed input: 115.13 toks/s, output: 423.64 toks/s]Processed prompts:  14%|█▍        | 72/500 [06:25<11:29,  1.61s/it, est. speed input: 115.67 toks/s, output: 426.39 toks/s]Processed prompts:  15%|█▍        | 73/500 [06:27<12:45,  1.79s/it, est. speed input: 119.85 toks/s, output: 427.73 toks/s]Processed prompts:  15%|█▍        | 74/500 [06:33<21:22,  3.01s/it, est. speed input: 121.98 toks/s, output: 425.52 toks/s]Processed prompts:  15%|█▌        | 76/500 [06:37<17:39,  2.50s/it, est. speed input: 127.20 toks/s, output: 427.55 toks/s]Processed prompts:  15%|█▌        | 77/500 [06:40<18:47,  2.67s/it, est. speed input: 127.10 toks/s, output: 433.61 toks/s]Processed prompts:  16%|█▌        | 78/500 [06:42<17:34,  2.50s/it, est. speed input: 127.64 toks/s, output: 440.92 toks/s]Processed prompts:  16%|█▌        | 79/500 [06:44<16:33,  2.36s/it, est. speed input: 127.96 toks/s, output: 448.18 toks/s]Processed prompts:  16%|█▌        | 80/500 [06:46<15:33,  2.22s/it, est. speed input: 129.28 toks/s, output: 453.42 toks/s]Processed prompts:  16%|█▌        | 81/500 [06:46<11:31,  1.65s/it, est. speed input: 129.64 toks/s, output: 458.70 toks/s]Processed prompts:  16%|█▋        | 82/500 [06:47<10:13,  1.47s/it, est. speed input: 132.33 toks/s, output: 460.99 toks/s]Processed prompts:  17%|█▋        | 83/500 [06:48<09:19,  1.34s/it, est. speed input: 135.54 toks/s, output: 464.63 toks/s]Processed prompts:  17%|█▋        | 84/500 [06:53<17:03,  2.46s/it, est. speed input: 134.28 toks/s, output: 462.98 toks/s]Processed prompts:  17%|█▋        | 85/500 [06:58<20:59,  3.03s/it, est. speed input: 133.47 toks/s, output: 462.98 toks/s]Processed prompts:  17%|█▋        | 86/500 [06:59<17:41,  2.56s/it, est. speed input: 135.15 toks/s, output: 470.94 toks/s]Processed prompts:  17%|█▋        | 87/500 [07:07<28:11,  4.10s/it, est. speed input: 134.34 toks/s, output: 472.11 toks/s]Processed prompts:  18%|█▊        | 88/500 [07:07<20:25,  2.97s/it, est. speed input: 136.08 toks/s, output: 481.41 toks/s]Processed prompts:  18%|█▊        | 89/500 [07:11<22:37,  3.30s/it, est. speed input: 135.78 toks/s, output: 486.52 toks/s]Processed prompts:  18%|█▊        | 90/500 [07:14<20:51,  3.05s/it, est. speed input: 135.65 toks/s, output: 493.45 toks/s]Processed prompts:  18%|█▊        | 91/500 [07:26<38:32,  5.65s/it, est. speed input: 133.04 toks/s, output: 490.27 toks/s]Processed prompts:  18%|█▊        | 92/500 [07:28<32:25,  4.77s/it, est. speed input: 133.57 toks/s, output: 497.10 toks/s]Processed prompts:  19%|█▊        | 93/500 [07:33<31:45,  4.68s/it, est. speed input: 132.90 toks/s, output: 502.00 toks/s]Processed prompts:  19%|█▉        | 94/500 [07:35<27:50,  4.11s/it, est. speed input: 134.36 toks/s, output: 508.78 toks/s]Processed prompts:  19%|█▉        | 95/500 [07:37<22:00,  3.26s/it, est. speed input: 135.46 toks/s, output: 517.18 toks/s]Processed prompts:  19%|█▉        | 96/500 [07:38<18:39,  2.77s/it, est. speed input: 135.86 toks/s, output: 525.20 toks/s]Processed prompts:  19%|█▉        | 97/500 [07:42<20:44,  3.09s/it, est. speed input: 139.09 toks/s, output: 524.60 toks/s]Processed prompts:  20%|█▉        | 98/500 [07:43<16:01,  2.39s/it, est. speed input: 140.75 toks/s, output: 527.10 toks/s]Processed prompts:  20%|█▉        | 99/500 [07:44<13:29,  2.02s/it, est. speed input: 141.67 toks/s, output: 535.68 toks/s]Processed prompts:  20%|██        | 100/500 [07:44<09:45,  1.46s/it, est. speed input: 142.00 toks/s, output: 539.25 toks/s]Processed prompts:  20%|██        | 101/500 [07:46<10:32,  1.59s/it, est. speed input: 145.45 toks/s, output: 547.00 toks/s]Processed prompts:  20%|██        | 102/500 [07:50<14:03,  2.12s/it, est. speed input: 145.81 toks/s, output: 546.76 toks/s]Processed prompts:  21%|██        | 103/500 [07:51<11:49,  1.79s/it, est. speed input: 148.26 toks/s, output: 555.46 toks/s]Processed prompts:  21%|██        | 104/500 [07:51<10:08,  1.54s/it, est. speed input: 148.68 toks/s, output: 555.95 toks/s]Processed prompts:  21%|██        | 105/500 [07:54<12:00,  1.82s/it, est. speed input: 149.62 toks/s, output: 562.93 toks/s]Processed prompts:  21%|██        | 106/500 [07:55<09:28,  1.44s/it, est. speed input: 151.27 toks/s, output: 566.08 toks/s]Processed prompts:  21%|██▏       | 107/500 [07:56<10:09,  1.55s/it, est. speed input: 155.31 toks/s, output: 573.87 toks/s]Processed prompts:  22%|██▏       | 108/500 [08:00<14:48,  2.27s/it, est. speed input: 155.54 toks/s, output: 571.92 toks/s]Processed prompts:  22%|██▏       | 109/500 [08:07<24:04,  3.69s/it, est. speed input: 154.00 toks/s, output: 568.84 toks/s]Processed prompts:  22%|██▏       | 110/500 [08:10<21:41,  3.34s/it, est. speed input: 157.96 toks/s, output: 575.92 toks/s]Processed prompts:  22%|██▏       | 111/500 [08:16<26:56,  4.16s/it, est. speed input: 157.09 toks/s, output: 578.90 toks/s]Processed prompts:  22%|██▏       | 112/500 [08:18<22:39,  3.51s/it, est. speed input: 156.84 toks/s, output: 580.82 toks/s]Processed prompts:  23%|██▎       | 113/500 [08:23<25:52,  4.01s/it, est. speed input: 156.03 toks/s, output: 578.40 toks/s]Processed prompts:  23%|██▎       | 114/500 [08:25<20:56,  3.25s/it, est. speed input: 158.12 toks/s, output: 578.84 toks/s]Processed prompts:  23%|██▎       | 115/500 [08:26<16:36,  2.59s/it, est. speed input: 158.15 toks/s, output: 584.03 toks/s]Processed prompts:  23%|██▎       | 116/500 [08:26<12:21,  1.93s/it, est. speed input: 159.03 toks/s, output: 593.64 toks/s]Processed prompts:  23%|██▎       | 117/500 [08:28<11:46,  1.85s/it, est. speed input: 159.71 toks/s, output: 593.54 toks/s]Processed prompts:  24%|██▎       | 118/500 [08:33<17:40,  2.78s/it, est. speed input: 160.61 toks/s, output: 589.97 toks/s]Processed prompts:  24%|██▍       | 119/500 [08:34<14:42,  2.32s/it, est. speed input: 160.60 toks/s, output: 589.97 toks/s]Processed prompts:  24%|██▍       | 120/500 [08:35<12:29,  1.97s/it, est. speed input: 161.78 toks/s, output: 598.77 toks/s]Processed prompts:  24%|██▍       | 121/500 [08:38<14:41,  2.33s/it, est. speed input: 161.68 toks/s, output: 600.12 toks/s]Processed prompts:  24%|██▍       | 122/500 [08:41<16:18,  2.59s/it, est. speed input: 163.22 toks/s, output: 599.20 toks/s]Processed prompts:  25%|██▍       | 123/500 [08:45<19:10,  3.05s/it, est. speed input: 163.24 toks/s, output: 597.91 toks/s]Processed prompts:  25%|██▍       | 124/500 [08:51<23:46,  3.79s/it, est. speed input: 162.63 toks/s, output: 599.47 toks/s]Processed prompts:  25%|██▌       | 125/500 [09:00<33:09,  5.31s/it, est. speed input: 162.83 toks/s, output: 599.91 toks/s]Processed prompts:  25%|██▌       | 126/500 [09:04<31:35,  5.07s/it, est. speed input: 164.54 toks/s, output: 596.79 toks/s]Processed prompts:  25%|██▌       | 127/500 [09:06<25:04,  4.03s/it, est. speed input: 164.41 toks/s, output: 596.96 toks/s]Processed prompts:  26%|██▌       | 128/500 [09:07<19:13,  3.10s/it, est. speed input: 166.13 toks/s, output: 606.19 toks/s]Processed prompts:  26%|██▌       | 129/500 [09:07<13:54,  2.25s/it, est. speed input: 167.19 toks/s, output: 609.43 toks/s]Processed prompts:  26%|██▌       | 130/500 [09:09<13:07,  2.13s/it, est. speed input: 168.14 toks/s, output: 610.84 toks/s]Processed prompts:  26%|██▌       | 131/500 [09:13<16:20,  2.66s/it, est. speed input: 168.00 toks/s, output: 611.79 toks/s]Processed prompts:  26%|██▋       | 132/500 [09:17<19:05,  3.11s/it, est. speed input: 167.64 toks/s, output: 609.62 toks/s]Processed prompts:  27%|██▋       | 133/500 [09:17<14:02,  2.30s/it, est. speed input: 168.18 toks/s, output: 612.93 toks/s]Processed prompts:  27%|██▋       | 134/500 [09:20<14:23,  2.36s/it, est. speed input: 168.23 toks/s, output: 612.36 toks/s]Processed prompts:  27%|██▋       | 135/500 [09:22<14:18,  2.35s/it, est. speed input: 168.56 toks/s, output: 614.39 toks/s]Processed prompts:  27%|██▋       | 137/500 [09:34<24:08,  3.99s/it, est. speed input: 169.43 toks/s, output: 608.63 toks/s]Processed prompts:  28%|██▊       | 138/500 [09:36<20:54,  3.47s/it, est. speed input: 172.54 toks/s, output: 608.83 toks/s]Processed prompts:  28%|██▊       | 139/500 [09:40<22:02,  3.66s/it, est. speed input: 173.17 toks/s, output: 608.51 toks/s]Processed prompts:  28%|██▊       | 140/500 [09:45<24:37,  4.10s/it, est. speed input: 173.36 toks/s, output: 607.04 toks/s]Processed prompts:  28%|██▊       | 141/500 [09:46<19:13,  3.21s/it, est. speed input: 174.95 toks/s, output: 607.76 toks/s]Processed prompts:  28%|██▊       | 142/500 [09:48<17:10,  2.88s/it, est. speed input: 175.32 toks/s, output: 609.81 toks/s]Processed prompts:  29%|██▊       | 143/500 [09:56<25:12,  4.24s/it, est. speed input: 175.68 toks/s, output: 612.54 toks/s]Processed prompts:  29%|██▉       | 144/500 [09:58<21:07,  3.56s/it, est. speed input: 176.02 toks/s, output: 617.31 toks/s]Processed prompts:  29%|██▉       | 145/500 [09:59<16:42,  2.82s/it, est. speed input: 176.71 toks/s, output: 621.02 toks/s]Processed prompts:  29%|██▉       | 146/500 [10:01<15:04,  2.55s/it, est. speed input: 176.48 toks/s, output: 625.64 toks/s]Processed prompts:  29%|██▉       | 147/500 [10:11<28:10,  4.79s/it, est. speed input: 174.56 toks/s, output: 625.82 toks/s]Processed prompts:  30%|██▉       | 148/500 [10:12<21:02,  3.59s/it, est. speed input: 176.09 toks/s, output: 635.53 toks/s]Processed prompts:  30%|██▉       | 149/500 [10:14<17:48,  3.05s/it, est. speed input: 176.08 toks/s, output: 635.75 toks/s]Processed prompts:  30%|███       | 150/500 [10:21<25:17,  4.34s/it, est. speed input: 177.65 toks/s, output: 633.56 toks/s]WARNING 04-07 09:10:17 scheduler.py:1555] Sequence group 208 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
Processed prompts:  30%|███       | 151/500 [10:26<26:27,  4.55s/it, est. speed input: 176.50 toks/s, output: 632.87 toks/s]Processed prompts:  30%|███       | 152/500 [10:26<19:16,  3.32s/it, est. speed input: 176.99 toks/s, output: 642.94 toks/s]Processed prompts:  31%|███       | 153/500 [10:32<23:57,  4.14s/it, est. speed input: 176.12 toks/s, output: 638.03 toks/s]Processed prompts:  31%|███       | 154/500 [10:38<26:54,  4.66s/it, est. speed input: 176.74 toks/s, output: 638.22 toks/s]Processed prompts:  31%|███       | 155/500 [10:41<22:35,  3.93s/it, est. speed input: 176.44 toks/s, output: 640.89 toks/s]Processed prompts:  31%|███       | 156/500 [10:43<20:07,  3.51s/it, est. speed input: 176.08 toks/s, output: 642.55 toks/s]Processed prompts:  31%|███▏      | 157/500 [10:47<20:13,  3.54s/it, est. speed input: 175.80 toks/s, output: 640.44 toks/s]Processed prompts:  32%|███▏      | 158/500 [10:48<17:11,  3.01s/it, est. speed input: 176.17 toks/s, output: 643.01 toks/s]Processed prompts:  32%|███▏      | 159/500 [10:50<15:10,  2.67s/it, est. speed input: 176.93 toks/s, output: 642.43 toks/s]Processed prompts:  32%|███▏      | 160/500 [10:54<17:26,  3.08s/it, est. speed input: 176.70 toks/s, output: 645.62 toks/s]Processed prompts:  32%|███▏      | 161/500 [10:56<15:07,  2.68s/it, est. speed input: 177.96 toks/s, output: 654.55 toks/s]Processed prompts:  32%|███▏      | 162/500 [10:59<15:09,  2.69s/it, est. speed input: 179.73 toks/s, output: 655.57 toks/s]Processed prompts:  33%|███▎      | 163/500 [11:00<12:50,  2.29s/it, est. speed input: 179.63 toks/s, output: 662.08 toks/s]Processed prompts:  33%|███▎      | 164/500 [11:01<10:36,  1.90s/it, est. speed input: 182.59 toks/s, output: 671.73 toks/s]Processed prompts:  33%|███▎      | 165/500 [11:09<21:12,  3.80s/it, est. speed input: 183.10 toks/s, output: 674.12 toks/s]Processed prompts:  33%|███▎      | 166/500 [11:11<18:08,  3.26s/it, est. speed input: 184.64 toks/s, output: 682.76 toks/s]Processed prompts:  33%|███▎      | 167/500 [11:13<14:58,  2.70s/it, est. speed input: 184.65 toks/s, output: 682.62 toks/s]Processed prompts:  34%|███▎      | 168/500 [11:25<31:19,  5.66s/it, est. speed input: 182.50 toks/s, output: 680.74 toks/s]Processed prompts:  34%|███▍      | 169/500 [11:30<29:38,  5.37s/it, est. speed input: 181.57 toks/s, output: 676.83 toks/s]Processed prompts:  34%|███▍      | 170/500 [11:36<31:00,  5.64s/it, est. speed input: 180.58 toks/s, output: 678.42 toks/s]Processed prompts:  34%|███▍      | 171/500 [11:37<22:26,  4.09s/it, est. speed input: 182.80 toks/s, output: 683.05 toks/s]Processed prompts:  34%|███▍      | 172/500 [11:38<17:00,  3.11s/it, est. speed input: 183.34 toks/s, output: 685.24 toks/s]Processed prompts:  35%|███▍      | 173/500 [11:38<12:02,  2.21s/it, est. speed input: 186.03 toks/s, output: 687.76 toks/s]Processed prompts:  35%|███▍      | 174/500 [11:40<12:48,  2.36s/it, est. speed input: 187.43 toks/s, output: 686.97 toks/s]Processed prompts:  35%|███▌      | 175/500 [11:42<10:44,  1.98s/it, est. speed input: 187.39 toks/s, output: 688.16 toks/s]Processed prompts:  35%|███▌      | 176/500 [11:42<08:03,  1.49s/it, est. speed input: 187.88 toks/s, output: 691.07 toks/s]Processed prompts:  35%|███▌      | 177/500 [11:43<08:12,  1.52s/it, est. speed input: 189.05 toks/s, output: 700.16 toks/s]Processed prompts:  36%|███▌      | 178/500 [11:55<23:34,  4.39s/it, est. speed input: 188.74 toks/s, output: 690.39 toks/s]Processed prompts:  36%|███▌      | 179/500 [11:58<21:53,  4.09s/it, est. speed input: 188.54 toks/s, output: 688.33 toks/s]WARNING 04-07 09:12:07 scheduler.py:1555] Sequence group 248 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
Processed prompts:  36%|███▌      | 180/500 [12:19<48:11,  9.03s/it, est. speed input: 185.60 toks/s, output: 671.20 toks/s]Processed prompts:  36%|███▌      | 181/500 [12:19<34:54,  6.57s/it, est. speed input: 187.07 toks/s, output: 676.13 toks/s]Processed prompts:  36%|███▋      | 182/500 [12:26<35:10,  6.64s/it, est. speed input: 186.13 toks/s, output: 671.58 toks/s]Processed prompts:  37%|███▋      | 183/500 [12:30<30:34,  5.79s/it, est. speed input: 185.91 toks/s, output: 670.45 toks/s]Processed prompts:  37%|███▋      | 184/500 [12:33<26:20,  5.00s/it, est. speed input: 187.53 toks/s, output: 669.43 toks/s]Processed prompts:  37%|███▋      | 185/500 [12:38<26:21,  5.02s/it, est. speed input: 186.98 toks/s, output: 672.33 toks/s]Processed prompts:  37%|███▋      | 186/500 [12:39<19:38,  3.75s/it, est. speed input: 188.11 toks/s, output: 675.66 toks/s]Processed prompts:  37%|███▋      | 187/500 [12:42<18:02,  3.46s/it, est. speed input: 187.73 toks/s, output: 675.05 toks/s]Processed prompts:  38%|███▊      | 188/500 [12:43<14:36,  2.81s/it, est. speed input: 188.44 toks/s, output: 674.99 toks/s]Processed prompts:  38%|███▊      | 189/500 [12:43<10:41,  2.06s/it, est. speed input: 188.69 toks/s, output: 680.18 toks/s]Processed prompts:  38%|███▊      | 191/500 [12:46<08:45,  1.70s/it, est. speed input: 189.10 toks/s, output: 685.02 toks/s]Processed prompts:  38%|███▊      | 192/500 [12:48<09:24,  1.83s/it, est. speed input: 191.55 toks/s, output: 687.05 toks/s]Processed prompts:  39%|███▊      | 193/500 [12:52<12:01,  2.35s/it, est. speed input: 190.95 toks/s, output: 686.09 toks/s]Processed prompts:  39%|███▉      | 194/500 [12:57<16:05,  3.16s/it, est. speed input: 190.84 toks/s, output: 682.20 toks/s]Processed prompts:  39%|███▉      | 195/500 [13:02<18:20,  3.61s/it, est. speed input: 190.43 toks/s, output: 680.07 toks/s]Processed prompts:  39%|███▉      | 196/500 [13:03<14:59,  2.96s/it, est. speed input: 191.10 toks/s, output: 680.59 toks/s]Processed prompts:  39%|███▉      | 197/500 [13:08<17:10,  3.40s/it, est. speed input: 190.31 toks/s, output: 684.52 toks/s]Processed prompts:  40%|███▉      | 198/500 [13:09<14:24,  2.86s/it, est. speed input: 191.17 toks/s, output: 686.39 toks/s]Processed prompts:  40%|███▉      | 199/500 [13:10<10:35,  2.11s/it, est. speed input: 192.44 toks/s, output: 686.80 toks/s]Processed prompts:  40%|████      | 200/500 [13:14<13:15,  2.65s/it, est. speed input: 193.41 toks/s, output: 694.17 toks/s]Processed prompts:  40%|████      | 201/500 [13:18<15:43,  3.16s/it, est. speed input: 194.33 toks/s, output: 691.56 toks/s]Processed prompts:  40%|████      | 202/500 [13:18<11:30,  2.32s/it, est. speed input: 195.18 toks/s, output: 694.18 toks/s]Processed prompts:  41%|████      | 203/500 [13:20<10:37,  2.15s/it, est. speed input: 196.22 toks/s, output: 697.05 toks/s]Processed prompts:  41%|████      | 204/500 [13:23<11:53,  2.41s/it, est. speed input: 198.16 toks/s, output: 697.91 toks/s]Processed prompts:  41%|████      | 205/500 [13:30<17:47,  3.62s/it, est. speed input: 197.81 toks/s, output: 692.87 toks/s]Processed prompts:  41%|████      | 206/500 [13:34<18:37,  3.80s/it, est. speed input: 197.23 toks/s, output: 692.87 toks/s]Processed prompts:  41%|████▏     | 207/500 [13:35<15:01,  3.08s/it, est. speed input: 198.23 toks/s, output: 702.47 toks/s]Processed prompts:  42%|████▏     | 208/500 [13:39<15:32,  3.19s/it, est. speed input: 199.67 toks/s, output: 710.31 toks/s]Processed prompts:  42%|████▏     | 209/500 [13:41<14:01,  2.89s/it, est. speed input: 199.41 toks/s, output: 711.06 toks/s]Processed prompts:  42%|████▏     | 210/500 [13:51<24:01,  4.97s/it, est. speed input: 199.71 toks/s, output: 703.32 toks/s]Processed prompts:  42%|████▏     | 211/500 [14:00<29:46,  6.18s/it, est. speed input: 198.42 toks/s, output: 696.71 toks/s]Processed prompts:  42%|████▏     | 212/500 [14:04<27:28,  5.72s/it, est. speed input: 198.70 toks/s, output: 698.80 toks/s]Processed prompts:  43%|████▎     | 213/500 [14:06<21:31,  4.50s/it, est. speed input: 200.04 toks/s, output: 701.00 toks/s]Processed prompts:  43%|████▎     | 214/500 [14:07<15:58,  3.35s/it, est. speed input: 201.00 toks/s, output: 701.19 toks/s]Processed prompts:  43%|████▎     | 215/500 [14:09<14:18,  3.01s/it, est. speed input: 201.99 toks/s, output: 700.97 toks/s]Processed prompts:  43%|████▎     | 216/500 [14:10<11:27,  2.42s/it, est. speed input: 202.47 toks/s, output: 702.80 toks/s]WARNING 04-07 09:14:05 scheduler.py:1555] Sequence group 297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
Processed prompts:  43%|████▎     | 217/500 [14:22<25:23,  5.38s/it, est. speed input: 202.27 toks/s, output: 693.62 toks/s]Processed prompts:  44%|████▎     | 218/500 [14:22<17:51,  3.80s/it, est. speed input: 203.52 toks/s, output: 699.76 toks/s]Processed prompts:  44%|████▍     | 219/500 [14:27<19:25,  4.15s/it, est. speed input: 202.71 toks/s, output: 698.16 toks/s]Processed prompts:  44%|████▍     | 220/500 [14:28<15:16,  3.27s/it, est. speed input: 203.36 toks/s, output: 699.37 toks/s]Processed prompts:  44%|████▍     | 221/500 [14:32<15:58,  3.44s/it, est. speed input: 203.67 toks/s, output: 700.37 toks/s]Processed prompts:  44%|████▍     | 222/500 [14:34<13:05,  2.83s/it, est. speed input: 204.83 toks/s, output: 705.55 toks/s]Processed prompts:  45%|████▍     | 223/500 [14:35<11:36,  2.51s/it, est. speed input: 205.79 toks/s, output: 707.14 toks/s]Processed prompts:  45%|████▍     | 224/500 [14:39<12:32,  2.73s/it, est. speed input: 206.79 toks/s, output: 705.43 toks/s]Processed prompts:  45%|████▌     | 225/500 [14:39<09:21,  2.04s/it, est. speed input: 207.11 toks/s, output: 709.39 toks/s]Processed prompts:  45%|████▌     | 226/500 [14:44<12:55,  2.83s/it, est. speed input: 206.41 toks/s, output: 710.59 toks/s]Processed prompts:  45%|████▌     | 227/500 [14:51<19:16,  4.24s/it, est. speed input: 206.31 toks/s, output: 705.51 toks/s]Processed prompts:  46%|████▌     | 228/500 [14:55<18:55,  4.18s/it, est. speed input: 205.77 toks/s, output: 705.59 toks/s]Processed prompts:  46%|████▌     | 229/500 [15:01<21:18,  4.72s/it, est. speed input: 204.97 toks/s, output: 707.31 toks/s]Processed prompts:  46%|████▌     | 230/500 [15:05<19:30,  4.34s/it, est. speed input: 204.43 toks/s, output: 707.91 toks/s]Processed prompts:  46%|████▌     | 231/500 [15:05<14:08,  3.15s/it, est. speed input: 204.65 toks/s, output: 712.68 toks/s]Processed prompts:  46%|████▋     | 232/500 [15:09<14:48,  3.32s/it, est. speed input: 204.17 toks/s, output: 710.70 toks/s]Processed prompts:  47%|████▋     | 233/500 [15:09<10:33,  2.37s/it, est. speed input: 204.77 toks/s, output: 716.81 toks/s]Processed prompts:  47%|████▋     | 234/500 [15:11<09:36,  2.17s/it, est. speed input: 204.88 toks/s, output: 718.74 toks/s]Processed prompts:  47%|████▋     | 235/500 [15:12<08:05,  1.83s/it, est. speed input: 204.94 toks/s, output: 720.08 toks/s]Processed prompts:  47%|████▋     | 236/500 [15:20<16:24,  3.73s/it, est. speed input: 203.96 toks/s, output: 716.78 toks/s]Processed prompts:  48%|████▊     | 238/500 [15:23<11:58,  2.74s/it, est. speed input: 203.73 toks/s, output: 719.06 toks/s]Processed prompts:  48%|████▊     | 239/500 [15:23<09:11,  2.11s/it, est. speed input: 205.29 toks/s, output: 722.35 toks/s]Processed prompts:  48%|████▊     | 240/500 [15:31<14:55,  3.45s/it, est. speed input: 204.55 toks/s, output: 720.16 toks/s]Processed prompts:  48%|████▊     | 241/500 [15:34<15:26,  3.58s/it, est. speed input: 205.05 toks/s, output: 720.68 toks/s]WARNING 04-07 09:15:29 scheduler.py:1555] Sequence group 328 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
Processed prompts:  48%|████▊     | 242/500 [15:42<20:11,  4.70s/it, est. speed input: 204.57 toks/s, output: 718.32 toks/s]Processed prompts:  49%|████▊     | 243/500 [15:44<16:25,  3.84s/it, est. speed input: 204.77 toks/s, output: 720.92 toks/s]Processed prompts:  49%|████▉     | 244/500 [15:45<13:25,  3.15s/it, est. speed input: 204.67 toks/s, output: 721.09 toks/s]Processed prompts:  49%|████▉     | 245/500 [15:50<15:31,  3.65s/it, est. speed input: 203.79 toks/s, output: 717.94 toks/s]Processed prompts:  49%|████▉     | 246/500 [15:56<18:40,  4.41s/it, est. speed input: 202.92 toks/s, output: 716.99 toks/s]Processed prompts:  49%|████▉     | 247/500 [16:01<18:50,  4.47s/it, est. speed input: 203.15 toks/s, output: 715.17 toks/s]Processed prompts:  50%|████▉     | 248/500 [16:09<22:55,  5.46s/it, est. speed input: 203.01 toks/s, output: 710.77 toks/s]Processed prompts:  50%|████▉     | 249/500 [16:09<17:01,  4.07s/it, est. speed input: 204.63 toks/s, output: 713.71 toks/s]Processed prompts:  50%|█████     | 250/500 [16:11<14:19,  3.44s/it, est. speed input: 204.40 toks/s, output: 714.19 toks/s]Processed prompts:  50%|█████     | 251/500 [16:12<10:59,  2.65s/it, est. speed input: 204.50 toks/s, output: 715.69 toks/s]Processed prompts:  50%|█████     | 252/500 [16:14<09:49,  2.38s/it, est. speed input: 205.03 toks/s, output: 719.00 toks/s]Processed prompts:  51%|█████     | 253/500 [16:14<07:24,  1.80s/it, est. speed input: 206.18 toks/s, output: 719.12 toks/s]Processed prompts:  51%|█████     | 254/500 [16:15<05:28,  1.34s/it, est. speed input: 206.37 toks/s, output: 720.25 toks/s]Processed prompts:  51%|█████     | 255/500 [16:15<04:15,  1.04s/it, est. speed input: 206.90 toks/s, output: 721.93 toks/s]Processed prompts:  51%|█████▏    | 257/500 [16:24<10:41,  2.64s/it, est. speed input: 206.08 toks/s, output: 719.10 toks/s]Processed prompts:  52%|█████▏    | 258/500 [16:31<14:30,  3.60s/it, est. speed input: 206.59 toks/s, output: 714.84 toks/s]Processed prompts:  52%|█████▏    | 259/500 [16:31<11:36,  2.89s/it, est. speed input: 207.88 toks/s, output: 715.24 toks/s]Processed prompts:  52%|█████▏    | 260/500 [16:32<09:25,  2.36s/it, est. speed input: 208.09 toks/s, output: 718.43 toks/s]Processed prompts:  52%|█████▏    | 261/500 [16:33<07:01,  1.76s/it, est. speed input: 209.68 toks/s, output: 722.87 toks/s]Processed prompts:  52%|█████▏    | 262/500 [16:38<11:01,  2.78s/it, est. speed input: 209.95 toks/s, output: 722.91 toks/s]Processed prompts:  53%|█████▎    | 263/500 [16:38<08:10,  2.07s/it, est. speed input: 212.38 toks/s, output: 733.40 toks/s]Processed prompts:  53%|█████▎    | 264/500 [16:48<17:06,  4.35s/it, est. speed input: 210.51 toks/s, output: 728.90 toks/s]Processed prompts:  53%|█████▎    | 265/500 [16:50<13:41,  3.49s/it, est. speed input: 211.23 toks/s, output: 728.95 toks/s]Processed prompts:  53%|█████▎    | 266/500 [16:52<11:50,  3.03s/it, est. speed input: 211.07 toks/s, output: 729.71 toks/s]Processed prompts:  53%|█████▎    | 267/500 [16:52<09:04,  2.34s/it, est. speed input: 211.54 toks/s, output: 732.90 toks/s]Processed prompts:  54%|█████▎    | 268/500 [16:58<13:09,  3.40s/it, est. speed input: 212.59 toks/s, output: 730.01 toks/s]Processed prompts:  54%|█████▍    | 270/500 [16:58<07:12,  1.88s/it, est. speed input: 213.09 toks/s, output: 733.20 toks/s]WARNING 04-07 09:16:56 scheduler.py:1555] Sequence group 361 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
Processed prompts:  54%|█████▍    | 271/500 [17:07<13:07,  3.44s/it, est. speed input: 211.60 toks/s, output: 729.31 toks/s]Processed prompts:  54%|█████▍    | 272/500 [17:07<10:01,  2.64s/it, est. speed input: 213.39 toks/s, output: 729.46 toks/s]Processed prompts:  55%|█████▍    | 273/500 [17:10<10:54,  2.88s/it, est. speed input: 212.84 toks/s, output: 728.29 toks/s]Processed prompts:  55%|█████▍    | 274/500 [17:15<12:48,  3.40s/it, est. speed input: 212.22 toks/s, output: 728.32 toks/s]Processed prompts:  55%|█████▌    | 275/500 [17:23<17:55,  4.78s/it, est. speed input: 211.21 toks/s, output: 724.85 toks/s]Processed prompts:  55%|█████▌    | 276/500 [17:24<12:52,  3.45s/it, est. speed input: 211.37 toks/s, output: 727.64 toks/s]Processed prompts:  55%|█████▌    | 277/500 [17:31<16:46,  4.51s/it, est. speed input: 210.60 toks/s, output: 724.50 toks/s]Processed prompts:  56%|█████▌    | 279/500 [17:32<10:18,  2.80s/it, est. speed input: 211.05 toks/s, output: 726.05 toks/s]Processed prompts:  56%|█████▌    | 280/500 [17:33<08:23,  2.29s/it, est. speed input: 212.58 toks/s, output: 726.03 toks/s]Processed prompts:  56%|█████▌    | 281/500 [17:35<08:00,  2.19s/it, est. speed input: 212.78 toks/s, output: 726.61 toks/s]Processed prompts:  56%|█████▋    | 282/500 [17:37<08:05,  2.23s/it, est. speed input: 213.30 toks/s, output: 731.89 toks/s]Processed prompts:  57%|█████▋    | 283/500 [17:37<06:05,  1.68s/it, est. speed input: 213.44 toks/s, output: 732.59 toks/s]Processed prompts:  57%|█████▋    | 284/500 [17:40<06:57,  1.93s/it, est. speed input: 214.82 toks/s, output: 731.00 toks/s]Processed prompts:  57%|█████▋    | 285/500 [17:42<07:06,  1.98s/it, est. speed input: 214.80 toks/s, output: 732.92 toks/s]Processed prompts:  57%|█████▋    | 286/500 [17:43<05:56,  1.67s/it, est. speed input: 215.79 toks/s, output: 735.02 toks/s]Processed prompts:  57%|█████▋    | 287/500 [17:50<11:38,  3.28s/it, est. speed input: 215.05 toks/s, output: 734.54 toks/s]Processed prompts:  58%|█████▊    | 288/500 [17:57<14:58,  4.24s/it, est. speed input: 214.34 toks/s, output: 732.07 toks/s]Processed prompts:  58%|█████▊    | 289/500 [17:59<12:30,  3.56s/it, est. speed input: 214.41 toks/s, output: 735.77 toks/s]Processed prompts:  58%|█████▊    | 290/500 [17:59<09:42,  2.78s/it, est. speed input: 215.21 toks/s, output: 737.45 toks/s]Processed prompts:  58%|█████▊    | 291/500 [18:03<10:27,  3.00s/it, est. speed input: 214.73 toks/s, output: 736.78 toks/s]Processed prompts:  58%|█████▊    | 292/500 [18:04<08:34,  2.47s/it, est. speed input: 215.91 toks/s, output: 740.43 toks/s]Processed prompts:  59%|█████▊    | 293/500 [18:16<18:05,  5.24s/it, est. speed input: 213.82 toks/s, output: 732.95 toks/s]Processed prompts:  59%|█████▉    | 294/500 [18:17<13:22,  3.90s/it, est. speed input: 213.95 toks/s, output: 734.95 toks/s]Processed prompts:  59%|█████▉    | 295/500 [18:17<09:27,  2.77s/it, est. speed input: 214.46 toks/s, output: 736.54 toks/s]Processed prompts:  59%|█████▉    | 296/500 [18:19<08:40,  2.55s/it, est. speed input: 214.25 toks/s, output: 735.90 toks/s]Processed prompts:  59%|█████▉    | 297/500 [18:20<06:54,  2.04s/it, est. speed input: 214.68 toks/s, output: 737.04 toks/s]Processed prompts:  60%|█████▉    | 298/500 [18:25<10:13,  3.04s/it, est. speed input: 215.03 toks/s, output: 734.32 toks/s]Processed prompts:  60%|█████▉    | 299/500 [18:31<13:21,  3.99s/it, est. speed input: 214.38 toks/s, output: 733.08 toks/s]Processed prompts:  60%|██████    | 300/500 [18:36<14:06,  4.23s/it, est. speed input: 214.72 toks/s, output: 731.01 toks/s]Processed prompts:  60%|██████    | 301/500 [18:43<16:25,  4.95s/it, est. speed input: 214.28 toks/s, output: 729.83 toks/s]Processed prompts:  60%|██████    | 302/500 [18:44<12:41,  3.85s/it, est. speed input: 214.48 toks/s, output: 730.24 toks/s]Processed prompts:  61%|██████    | 303/500 [18:48<12:52,  3.92s/it, est. speed input: 214.27 toks/s, output: 732.25 toks/s]Processed prompts:  61%|██████    | 304/500 [18:54<14:51,  4.55s/it, est. speed input: 213.89 toks/s, output: 731.41 toks/s]Processed prompts:  61%|██████    | 305/500 [18:55<10:49,  3.33s/it, est. speed input: 214.55 toks/s, output: 731.50 toks/s]Processed prompts:  61%|██████    | 306/500 [18:55<07:55,  2.45s/it, est. speed input: 214.63 toks/s, output: 734.00 toks/s]Processed prompts:  61%|██████▏   | 307/500 [18:56<06:53,  2.14s/it, est. speed input: 214.89 toks/s, output: 734.08 toks/s]Processed prompts:  62%|██████▏   | 308/500 [18:57<04:54,  1.53s/it, est. speed input: 215.09 toks/s, output: 734.66 toks/s]WARNING 04-07 09:18:53 scheduler.py:1555] Sequence group 383 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
Processed prompts:  62%|██████▏   | 309/500 [19:03<09:33,  3.00s/it, est. speed input: 214.50 toks/s, output: 731.16 toks/s]Processed prompts:  62%|██████▏   | 310/500 [19:11<14:35,  4.61s/it, est. speed input: 213.53 toks/s, output: 730.50 toks/s]Processed prompts:  62%|██████▏   | 311/500 [19:15<13:15,  4.21s/it, est. speed input: 213.16 toks/s, output: 729.63 toks/s]Processed prompts:  62%|██████▏   | 312/500 [19:16<10:41,  3.41s/it, est. speed input: 214.26 toks/s, output: 729.43 toks/s]Processed prompts:  63%|██████▎   | 313/500 [19:18<09:07,  2.93s/it, est. speed input: 214.40 toks/s, output: 729.42 toks/s]Processed prompts:  63%|██████▎   | 314/500 [19:32<19:31,  6.30s/it, est. speed input: 212.09 toks/s, output: 723.28 toks/s]Processed prompts:  63%|██████▎   | 315/500 [19:33<14:02,  4.55s/it, est. speed input: 213.77 toks/s, output: 733.65 toks/s]Processed prompts:  63%|██████▎   | 316/500 [19:36<12:57,  4.23s/it, est. speed input: 213.92 toks/s, output: 735.31 toks/s]Processed prompts:  63%|██████▎   | 317/500 [19:37<10:16,  3.37s/it, est. speed input: 213.84 toks/s, output: 736.09 toks/s]Processed prompts:  64%|██████▎   | 318/500 [19:39<08:18,  2.74s/it, est. speed input: 214.04 toks/s, output: 739.58 toks/s]Processed prompts:  64%|██████▍   | 319/500 [19:46<12:46,  4.24s/it, est. speed input: 213.42 toks/s, output: 736.60 toks/s]Processed prompts:  64%|██████▍   | 320/500 [19:49<11:01,  3.67s/it, est. speed input: 213.49 toks/s, output: 736.79 toks/s]Processed prompts:  64%|██████▍   | 321/500 [19:49<08:09,  2.74s/it, est. speed input: 213.98 toks/s, output: 738.98 toks/s]Processed prompts:  64%|██████▍   | 322/500 [19:50<06:29,  2.19s/it, est. speed input: 214.29 toks/s, output: 740.38 toks/s]Processed prompts:  65%|██████▍   | 323/500 [19:52<06:08,  2.08s/it, est. speed input: 215.46 toks/s, output: 741.69 toks/s]Processed prompts:  65%|██████▍   | 324/500 [19:55<06:41,  2.28s/it, est. speed input: 215.22 toks/s, output: 742.55 toks/s]Processed prompts:  65%|██████▌   | 325/500 [19:58<07:05,  2.43s/it, est. speed input: 215.13 toks/s, output: 742.92 toks/s]Processed prompts:  65%|██████▌   | 326/500 [20:03<09:21,  3.23s/it, est. speed input: 214.38 toks/s, output: 743.62 toks/s]Processed prompts:  65%|██████▌   | 327/500 [20:08<11:28,  3.98s/it, est. speed input: 213.52 toks/s, output: 742.20 toks/s]Processed prompts:  66%|██████▌   | 328/500 [20:11<10:35,  3.70s/it, est. speed input: 213.35 toks/s, output: 743.29 toks/s]Processed prompts:  66%|██████▌   | 329/500 [20:19<13:44,  4.82s/it, est. speed input: 213.15 toks/s, output: 740.05 toks/s]Processed prompts:  66%|██████▌   | 330/500 [20:20<10:26,  3.68s/it, est. speed input: 213.14 toks/s, output: 741.28 toks/s]Processed prompts:  66%|██████▌   | 331/500 [20:32<17:35,  6.24s/it, est. speed input: 211.58 toks/s, output: 736.61 toks/s]Processed prompts:  66%|██████▋   | 332/500 [20:36<15:30,  5.54s/it, est. speed input: 211.11 toks/s, output: 737.87 toks/s]Processed prompts:  67%|██████▋   | 333/500 [20:37<11:53,  4.27s/it, est. speed input: 211.39 toks/s, output: 737.60 toks/s]Processed prompts:  67%|██████▋   | 334/500 [20:42<12:23,  4.48s/it, est. speed input: 210.87 toks/s, output: 737.82 toks/s]Processed prompts:  67%|██████▋   | 335/500 [20:44<10:07,  3.68s/it, est. speed input: 210.89 toks/s, output: 738.11 toks/s]Processed prompts:  67%|██████▋   | 336/500 [20:45<07:29,  2.74s/it, est. speed input: 211.49 toks/s, output: 739.83 toks/s]Processed prompts:  67%|██████▋   | 337/500 [20:56<14:48,  5.45s/it, est. speed input: 209.71 toks/s, output: 735.01 toks/s]Processed prompts:  68%|██████▊   | 338/500 [20:59<12:23,  4.59s/it, est. speed input: 209.72 toks/s, output: 737.42 toks/s]Processed prompts:  68%|██████▊   | 339/500 [21:05<13:16,  4.95s/it, est. speed input: 209.01 toks/s, output: 736.26 toks/s]Processed prompts:  68%|██████▊   | 340/500 [21:10<13:05,  4.91s/it, est. speed input: 209.67 toks/s, output: 736.71 toks/s]Processed prompts:  68%|██████▊   | 341/500 [21:20<17:02,  6.43s/it, est. speed input: 208.26 toks/s, output: 733.25 toks/s]Processed prompts:  68%|██████▊   | 342/500 [21:23<14:41,  5.58s/it, est. speed input: 207.99 toks/s, output: 735.00 toks/s]Processed prompts:  69%|██████▊   | 343/500 [21:24<10:26,  3.99s/it, est. speed input: 208.35 toks/s, output: 740.22 toks/s]Processed prompts:  69%|██████▉   | 344/500 [21:27<09:57,  3.83s/it, est. speed input: 208.45 toks/s, output: 740.59 toks/s]Processed prompts:  69%|██████▉   | 345/500 [21:28<07:30,  2.91s/it, est. speed input: 208.86 toks/s, output: 742.60 toks/s]Processed prompts:  69%|██████▉   | 346/500 [21:36<11:40,  4.55s/it, est. speed input: 207.79 toks/s, output: 740.81 toks/s]Processed prompts:  69%|██████▉   | 347/500 [21:37<09:04,  3.56s/it, est. speed input: 207.95 toks/s, output: 745.42 toks/s]Processed prompts:  70%|██████▉   | 348/500 [21:39<07:24,  2.93s/it, est. speed input: 208.80 toks/s, output: 745.48 toks/s]Processed prompts:  70%|██████▉   | 349/500 [21:41<06:28,  2.57s/it, est. speed input: 208.98 toks/s, output: 747.95 toks/s]Processed prompts:  70%|███████   | 350/500 [21:42<05:53,  2.35s/it, est. speed input: 209.02 toks/s, output: 748.96 toks/s]Processed prompts:  70%|███████   | 351/500 [21:47<07:20,  2.96s/it, est. speed input: 208.59 toks/s, output: 748.42 toks/s]Processed prompts:  70%|███████   | 352/500 [21:48<05:58,  2.42s/it, est. speed input: 208.84 toks/s, output: 751.68 toks/s]WARNING 04-07 09:21:45 scheduler.py:1555] Sequence group 436 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
Processed prompts:  71%|███████   | 353/500 [21:55<09:23,  3.83s/it, est. speed input: 208.88 toks/s, output: 747.68 toks/s]Processed prompts:  71%|███████   | 354/500 [22:14<20:20,  8.36s/it, est. speed input: 208.06 toks/s, output: 739.67 toks/s]Processed prompts:  71%|███████   | 355/500 [22:15<14:41,  6.08s/it, est. speed input: 208.98 toks/s, output: 742.48 toks/s]Processed prompts:  71%|███████   | 356/500 [22:18<12:20,  5.14s/it, est. speed input: 209.04 toks/s, output: 742.07 toks/s]Processed prompts:  71%|███████▏  | 357/500 [22:19<09:11,  3.86s/it, est. speed input: 209.03 toks/s, output: 742.74 toks/s]Processed prompts:  72%|███████▏  | 358/500 [22:20<07:18,  3.09s/it, est. speed input: 209.18 toks/s, output: 746.55 toks/s]Processed prompts:  72%|███████▏  | 359/500 [22:21<05:57,  2.53s/it, est. speed input: 209.23 toks/s, output: 748.83 toks/s]Processed prompts:  72%|███████▏  | 360/500 [22:26<07:40,  3.29s/it, est. speed input: 208.93 toks/s, output: 748.30 toks/s]Processed prompts:  72%|███████▏  | 361/500 [22:30<07:58,  3.44s/it, est. speed input: 208.84 toks/s, output: 748.93 toks/s]Processed prompts:  73%|███████▎  | 363/500 [22:35<06:50,  3.00s/it, est. speed input: 208.52 toks/s, output: 751.30 toks/s]/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:26:09 config.py:510] This model supports multiple tasks: {'generate', 'embed', 'score', 'classify', 'reward'}. Defaulting to 'generate'.
INFO 04-07 09:26:09 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:26:09 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:26:09 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:26:09 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:10 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:10 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:10 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:10 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:10 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:10 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:26:10 selector.py:120] Using Flash Attention backend.
INFO 04-07 09:26:12 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:12 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:12 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:12 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-07 09:26:12 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:12 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:12 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:12 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2612039)[0;0m WARNING 04-07 09:26:12 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2612040)[0;0m WARNING 04-07 09:26:12 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 09:26:12 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2612041)[0;0m WARNING 04-07 09:26:12 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:26:12 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_87155f0e'), local_subscribe_port=33529, remote_subscribe_port=None)
INFO 04-07 09:26:12 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:12 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:12 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:12 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.48it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.59it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.45it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.53it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.52it/s]

[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:14 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:14 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:14 model_runner.py:1099] Loading model weights took 3.5546 GB
INFO 04-07 09:26:14 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:18 worker.py:241] Memory profiling takes 4.10 seconds
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:18 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:18 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:18 worker.py:241] Memory profiling takes 4.11 seconds
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:18 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:18 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:18 worker.py:241] Memory profiling takes 4.15 seconds
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:18 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:18 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
INFO 04-07 09:26:19 worker.py:241] Memory profiling takes 4.35 seconds
INFO 04-07 09:26:19 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:26:19 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:26:19 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:26:19 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:26:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:26:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:26:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 09:26:42 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:44,  1.25it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:43,  1.25it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:39,  1.28it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:03<01:39,  1.27it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:37,  1.29it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:36,  1.29it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:35,  1.31it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:06<01:34,  1.31it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:06<01:32,  1.31it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:31,  1.32it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:08<01:32,  1.30it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:09<01:32,  1.29it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:10<01:31,  1.29it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:10<01:31,  1.28it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:11<01:29,  1.30it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:12<01:30,  1.28it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:13<01:29,  1.27it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:14<01:29,  1.27it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:14<01:27,  1.28it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:15<01:27,  1.27it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:16<01:26,  1.27it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:17<01:25,  1.28it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:17<01:23,  1.30it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:18<01:23,  1.29it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:19<01:22,  1.29it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:20<01:19,  1.33it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:20<01:18,  1.32it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:21<01:18,  1.32it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:22<01:16,  1.33it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:23<01:17,  1.31it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:23<01:16,  1.31it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:24<01:15,  1.31it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:25<01:13,  1.32it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:26<01:12,  1.33it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:26<01:11,  1.35it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:27<01:11,  1.33it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:28<01:09,  1.35it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:29<01:08,  1.35it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:29<01:07,  1.37it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:30<01:06,  1.37it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:31<01:06,  1.36it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:32<01:04,  1.37it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:32<01:04,  1.36it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:33<01:03,  1.37it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:34<01:02,  1.37it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:34<01:01,  1.38it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:35<01:01,  1.36it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:36<01:01,  1.35it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:37<01:00,  1.36it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:37<00:59,  1.35it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:38<00:59,  1.34it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:39<00:58,  1.34it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:40<00:58,  1.34it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:40<00:57,  1.33it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:41<00:56,  1.35it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:42<00:55,  1.36it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:43<00:54,  1.36it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:43<00:52,  1.39it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:44<00:52,  1.37it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:45<00:52,  1.36it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:45<00:50,  1.38it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:46<00:49,  1.40it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:47<00:48,  1.39it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:48<00:48,  1.39it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:48<00:45,  1.46it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:49<00:45,  1.44it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:50<00:44,  1.44it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:50<00:42,  1.48it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:51<00:42,  1.46it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:52<00:42,  1.44it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:52<00:41,  1.44it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:53<00:41,  1.41it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:54<00:40,  1.41it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:55<00:40,  1.42it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:55<00:38,  1.44it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:56<00:37,  1.46it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:56<00:35,  1.53it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:57<00:36,  1.45it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:58<00:36,  1.44it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:59<00:35,  1.43it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:59<00:35,  1.42it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:00<00:34,  1.42it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:01<00:33,  1.42it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:01<00:32,  1.45it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:02<00:31,  1.46it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:03<00:30,  1.49it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:03<00:29,  1.47it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:04<00:29,  1.47it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:05<00:28,  1.47it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:05<00:27,  1.47it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:06<00:27,  1.47it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:07<00:26,  1.47it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:07<00:25,  1.48it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:08<00:24,  1.51it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:09<00:24,  1.47it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:10<00:23,  1.47it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:10<00:23,  1.46it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:11<00:22,  1.48it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:12<00:21,  1.48it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:12<00:21,  1.47it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:13<00:20,  1.47it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:14<00:19,  1.49it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:14<00:18,  1.49it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:15<00:18,  1.49it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:16<00:17,  1.52it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:16<00:16,  1.52it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:17<00:15,  1.50it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:18<00:15,  1.51it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:18<00:14,  1.49it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:19<00:13,  1.52it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:20<00:13,  1.51it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:20<00:12,  1.49it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:21<00:11,  1.51it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:22<00:11,  1.50it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:22<00:10,  1.51it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:23<00:09,  1.50it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:24<00:09,  1.51it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:24<00:08,  1.51it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:25<00:07,  1.51it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:25<00:07,  1.53it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:26<00:06,  1.55it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:27<00:05,  1.55it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:27<00:05,  1.51it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:28<00:04,  1.50it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:29<00:03,  1.50it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:29<00:03,  1.53it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:30<00:02,  1.52it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:31<00:01,  1.51it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:31<00:01,  1.53it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:32<00:00,  1.54it/s][1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:28:16 model_runner.py:1535] Graph capturing finished in 93 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:28:16 model_runner.py:1535] Graph capturing finished in 93 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:28:16 model_runner.py:1535] Graph capturing finished in 94 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:33<00:00,  1.35it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:33<00:00,  1.40it/s]
INFO 04-07 09:28:16 model_runner.py:1535] Graph capturing finished in 94 secs, took 3.72 GiB
INFO 04-07 09:28:16 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 121.75 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:01, 474.98 examples/s]Generating train split: 500 examples [00:01, 474.02 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: bipartite
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:22 scheduler.py:944] Input prompt (34710 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:24 scheduler.py:944] Input prompt (34653 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:50<6:56:00, 50.02s/it, est. speed input: 693.90 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 2/500 [00:51<2:59:52, 21.67s/it, est. speed input: 1337.85 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:29 scheduler.py:944] Input prompt (35165 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [00:57<1:57:42, 14.21s/it, est. speed input: 1828.14 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:33 scheduler.py:944] Input prompt (34771 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 4/500 [01:01<1:23:58, 10.16s/it, est. speed input: 2278.86 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:39 scheduler.py:944] Input prompt (34174 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:39 scheduler.py:944] Input prompt (35073 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:39 scheduler.py:944] Input prompt (33713 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:39 scheduler.py:944] Input prompt (35008 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 5/500 [01:07<1:11:20,  8.65s/it, est. speed input: 2585.57 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:42 scheduler.py:944] Input prompt (33879 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:44 scheduler.py:944] Input prompt (34260 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 9/500 [01:11<28:31,  3.49s/it, est. speed input: 4381.40 toks/s, output: 0.00 toks/s]  Processed prompts:   2%|▏         | 10/500 [01:12<25:11,  3.09s/it, est. speed input: 4768.28 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:54 scheduler.py:944] Input prompt (33375 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:54 scheduler.py:944] Input prompt (33734 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:56 scheduler.py:944] Input prompt (34106 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:56 scheduler.py:944] Input prompt (33116 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:56 scheduler.py:944] Input prompt (33645 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:29:56 scheduler.py:944] Input prompt (33812 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 11/500 [01:22<37:11,  4.56s/it, est. speed input: 4600.12 toks/s, output: 0.00 toks/s]WARNING 04-07 09:29:58 scheduler.py:944] Input prompt (33296 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 13/500 [01:24<25:47,  3.18s/it, est. speed input: 5302.70 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:00 scheduler.py:944] Input prompt (33599 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 17/500 [01:26<14:05,  1.75s/it, est. speed input: 6749.17 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:01 scheduler.py:944] Input prompt (33973 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:01 scheduler.py:944] Input prompt (33253 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:01 scheduler.py:944] Input prompt (33738 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:01 scheduler.py:944] Input prompt (34588 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:01 scheduler.py:944] Input prompt (33544 tokens) is too long and exceeds limit of 32768
Processed prompts:   4%|▎         | 18/500 [01:27<14:16,  1.78s/it, est. speed input: 6984.17 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33491 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34056 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33254 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33372 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34247 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34575 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33146 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33101 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33952 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33412 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35019 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33276 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33250 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33280 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34231 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34229 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33973 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33283 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34741 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33991 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33381 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33217 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33399 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33395 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33991 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33534 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33816 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33559 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33172 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33512 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33385 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33803 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33952 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33909 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33493 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33321 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33278 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33351 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34680 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33339 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33274 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33133 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33118 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34186 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33622 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35963 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33884 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33940 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33133 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34069 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33729 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33465 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35178 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33470 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33958 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33602 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33481 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33319 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35170 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33680 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33340 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34429 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34931 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34080 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35087 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35129 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33246 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33834 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33262 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34208 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35064 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33995 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (35182 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33509 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33252 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33836 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33880 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33912 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33881 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34476 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33284 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33147 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33680 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33191 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33455 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34527 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33868 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34208 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33154 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34995 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33309 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (33305 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:03 scheduler.py:944] Input prompt (34141 tokens) is too long and exceeds limit of 32768
Processed prompts:   4%|▍         | 19/500 [01:30<15:00,  1.87s/it, est. speed input: 7182.82 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33186 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33434 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33916 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33629 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33286 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33789 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33241 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:06 scheduler.py:944] Input prompt (33713 tokens) is too long and exceeds limit of 32768
Processed prompts:   5%|▍         | 24/500 [01:31<07:25,  1.07it/s, est. speed input: 8941.81 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (35459 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33114 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33240 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (34196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33261 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (35450 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33301 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33484 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33206 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33424 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:07 scheduler.py:944] Input prompt (33336 tokens) is too long and exceeds limit of 32768
Processed prompts:  25%|██▌       | 125/500 [01:32<00:25, 14.42it/s, est. speed input: 45530.55 toks/s, output: 0.00 toks/s]Processed prompts:  27%|██▋       | 134/500 [01:34<00:27, 13.47it/s, est. speed input: 48259.21 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33275 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33286 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33261 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (35001 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33911 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (34394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:12 scheduler.py:944] Input prompt (33785 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (34370 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33162 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33594 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33481 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33761 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33217 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33302 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (34218 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33404 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:14 scheduler.py:944] Input prompt (33798 tokens) is too long and exceeds limit of 32768
Processed prompts:  29%|██▉       | 146/500 [01:40<00:56,  6.28it/s, est. speed input: 48940.56 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33248 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33318 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (35435 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (35156 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33145 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33793 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33325 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33127 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (34353 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:16 scheduler.py:944] Input prompt (33687 tokens) is too long and exceeds limit of 32768
Processed prompts:  31%|███       | 154/500 [01:41<00:53,  6.44it/s, est. speed input: 51103.13 toks/s, output: 0.00 toks/s]Processed prompts:  33%|███▎      | 164/500 [01:43<00:50,  6.67it/s, est. speed input: 53710.12 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33826 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (35248 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33376 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33861 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33496 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33964 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33159 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (35032 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33817 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33443 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33994 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33123 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33970 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33203 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33235 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33363 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33343 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:19 scheduler.py:944] Input prompt (33151 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33900 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33865 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33564 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33283 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33222 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33586 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33191 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33141 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (35210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33479 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33347 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:21 scheduler.py:944] Input prompt (33275 tokens) is too long and exceeds limit of 32768
Processed prompts:  35%|███▌      | 177/500 [01:47<01:04,  5.04it/s, est. speed input: 55656.58 toks/s, output: 0.00 toks/s]Processed prompts:  39%|███▉      | 195/500 [01:49<00:48,  6.27it/s, est. speed input: 60419.90 toks/s, output: 0.00 toks/s]WARNING 04-07 09:30:24 scheduler.py:944] Input prompt (35114 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33965 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (34270 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33527 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33401 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33228 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33177 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33234 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:30:25 scheduler.py:944] Input prompt (33464 tokens) is too long and exceeds limit of 32768
Processed prompts:  41%|████▏     | 207/500 [01:52<00:54,  5.33it/s, est. speed input: 62259.82 toks/s, output: 0.00 toks/s]Processed prompts:  42%|████▏     | 208/500 [01:52<00:54,  5.36it/s, est. speed input: 62479.04 toks/s, output: 0.00 toks/s]Processed prompts:  43%|████▎     | 217/500 [01:52<00:41,  6.82it/s, est. speed input: 64675.15 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [01:52<00:00,  4.43it/s, est. speed input: 79956.42 toks/s, output: 5.03 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:30:28 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2612039)[0;0m INFO 04-07 09:30:28 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2612040)[0;0m INFO 04-07 09:30:28 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2612041)[0;0m INFO 04-07 09:30:28 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:30:49.145563723 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:31:11 config.py:510] This model supports multiple tasks: {'reward', 'classify', 'embed', 'generate', 'score'}. Defaulting to 'generate'.
INFO 04-07 09:31:11 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:31:11 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:31:12 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:31:12 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 09:31:13 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:13 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:13 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:13 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:13 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:13 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:13 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:31:14 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:14 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:14 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 09:31:14 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:14 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:14 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:14 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:14 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2613921)[0;0m WARNING 04-07 09:31:14 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2613919)[0;0m WARNING 04-07 09:31:14 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2613920)[0;0m WARNING 04-07 09:31:14 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 09:31:14 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:31:14 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_b0d150ca'), local_subscribe_port=54201, remote_subscribe_port=None)
INFO 04-07 09:31:14 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:14 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:14 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:14 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.63it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.79it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.60it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.65it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.66it/s]

INFO 04-07 09:31:16 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:16 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:16 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:16 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:20 worker.py:241] Memory profiling takes 4.22 seconds
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:20 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:20 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:20 worker.py:241] Memory profiling takes 4.23 seconds
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:20 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:20 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:21 worker.py:241] Memory profiling takes 4.28 seconds
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:21 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:21 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
INFO 04-07 09:31:21 worker.py:241] Memory profiling takes 4.34 seconds
INFO 04-07 09:31:21 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:31:21 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:31:21 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:31:21 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:31:44 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:31:44 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 09:31:44 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:31:44 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:15,  1.73it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:21,  1.59it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:01<01:17,  1.66it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:02<01:17,  1.64it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:02<01:14,  1.69it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:03<01:14,  1.68it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:04<01:13,  1.69it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:04<01:14,  1.66it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:05<01:12,  1.67it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:05<01:11,  1.70it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:06<01:10,  1.70it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:07<01:09,  1.70it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:07<01:09,  1.71it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:08<01:09,  1.68it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:08<01:08,  1.70it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:09<01:05,  1.75it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:10<01:07,  1.70it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:10<01:07,  1.68it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:11<01:04,  1.72it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:11<01:04,  1.71it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:12<01:05,  1.67it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:13<01:04,  1.70it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:13<01:03,  1.70it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:14<01:01,  1.73it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:14<01:01,  1.73it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:15<01:00,  1.73it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:15<00:59,  1.75it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:16<00:58,  1.75it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:17<00:58,  1.74it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:17<00:57,  1.76it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:18<00:57,  1.75it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:18<00:56,  1.75it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:19<00:56,  1.74it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:19<00:54,  1.79it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:20<00:53,  1.78it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:20<00:53,  1.78it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:21<00:52,  1.80it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:22<00:51,  1.82it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:22<00:51,  1.78it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:23<00:49,  1.83it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:23<00:49,  1.81it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:24<00:49,  1.81it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:24<00:48,  1.80it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:25<00:48,  1.78it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:25<00:47,  1.81it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:26<00:46,  1.84it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:27<00:46,  1.81it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:27<00:46,  1.78it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:28<00:45,  1.79it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:28<00:44,  1.82it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:29<00:44,  1.80it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:29<00:43,  1.80it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:30<00:43,  1.79it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:30<00:42,  1.81it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:31<00:41,  1.83it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:31<00:39,  1.89it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:32<00:40,  1.82it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:33<00:39,  1.87it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:33<00:38,  1.88it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:34<00:37,  1.89it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:34<00:37,  1.86it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:35<00:37,  1.83it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:35<00:36,  1.85it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:36<00:36,  1.84it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:36<00:35,  1.87it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:37<00:35,  1.85it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:37<00:34,  1.85it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:38<00:33,  1.85it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:38<00:33,  1.83it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:39<00:32,  1.85it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:40<00:32,  1.85it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:40<00:31,  1.85it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:41<00:32,  1.81it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:41<00:31,  1.82it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:42<00:29,  1.87it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:42<00:29,  1.85it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:43<00:28,  1.88it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:43<00:28,  1.86it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:44<00:27,  1.90it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:44<00:26,  1.90it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:45<00:26,  1.88it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [00:45<00:25,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [00:46<00:25,  1.92it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [00:46<00:24,  1.90it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [00:47<00:23,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [00:48<00:23,  1.90it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [00:48<00:22,  1.92it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [00:49<00:22,  1.91it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [00:49<00:21,  1.94it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [00:50<00:21,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [00:50<00:21,  1.89it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [00:51<00:20,  1.90it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [00:51<00:19,  1.90it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [00:52<00:18,  1.95it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [00:52<00:18,  1.93it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [00:53<00:18,  1.89it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [00:53<00:17,  1.92it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [00:54<00:16,  1.95it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [00:54<00:15,  2.00it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [00:55<00:15,  1.98it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [00:55<00:15,  2.00it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [00:56<00:14,  2.00it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [00:56<00:14,  1.95it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [00:57<00:13,  2.01it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [00:57<00:12,  2.01it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [00:58<00:12,  1.97it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [00:58<00:12,  1.98it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [00:59<00:11,  2.04it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [00:59<00:10,  2.01it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:00<00:10,  2.04it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:00<00:09,  2.00it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:01<00:09,  2.01it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:01<00:08,  2.02it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:02<00:08,  2.06it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:02<00:07,  2.06it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:03<00:07,  2.05it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:03<00:07,  1.99it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:04<00:06,  2.02it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:04<00:06,  1.97it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:05<00:05,  1.99it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:05<00:05,  1.99it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:06<00:04,  1.98it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:06<00:04,  1.96it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:07<00:03,  1.99it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:07<00:03,  1.98it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:08<00:02,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:08<00:01,  2.02it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:09<00:01,  2.02it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:09<00:00,  2.02it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:10<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:11<00:00,  1.67it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:11<00:00,  1.84it/s]
INFO 04-07 09:32:55 model_runner.py:1535] Graph capturing finished in 71 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:32:55 model_runner.py:1535] Graph capturing finished in 71 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:32:55 model_runner.py:1535] Graph capturing finished in 71 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:32:55 model_runner.py:1535] Graph capturing finished in 71 secs, took 3.72 GiB
INFO 04-07 09:32:55 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 99.13 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:00, 7683.79 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: connectivity
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:33:52 scheduler.py:944] Input prompt (33530 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:53<7:23:44, 53.35s/it, est. speed input: 628.44 toks/s, output: 0.00 toks/s]WARNING 04-07 09:34:14 scheduler.py:944] Input prompt (34066 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 2/500 [01:15<4:49:48, 34.92s/it, est. speed input: 896.94 toks/s, output: 0.00 toks/s]WARNING 04-07 09:34:27 scheduler.py:944] Input prompt (33512 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [01:28<3:28:06, 25.12s/it, est. speed input: 1138.18 toks/s, output: 0.00 toks/s]Processed prompts:   1%|          | 4/500 [01:41<2:46:56, 20.19s/it, est. speed input: 1005.76 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [01:41<00:00,  4.93it/s, est. speed input: 17235.48 toks/s, output: 9.80 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:34:44 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2613919)[0;0m INFO 04-07 09:34:44 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2613920)[0;0m INFO 04-07 09:34:44 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2613921)[0;0m INFO 04-07 09:34:44 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:35:08.367103559 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:35:28 config.py:510] This model supports multiple tasks: {'embed', 'score', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 04-07 09:35:28 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:35:28 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:35:28 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:35:28 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:29 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:29 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:29 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:29 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:29 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:29 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:35:29 selector.py:120] Using Flash Attention backend.
INFO 04-07 09:35:31 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:31 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:31 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:31 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-07 09:35:31 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:31 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:31 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:31 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2617175)[0;0m WARNING 04-07 09:35:31 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2617174)[0;0m WARNING 04-07 09:35:31 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2617173)[0;0m WARNING 04-07 09:35:31 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 09:35:31 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:35:31 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_73816928'), local_subscribe_port=35809, remote_subscribe_port=None)
INFO 04-07 09:35:31 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:31 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:31 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:31 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.49it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.59it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.42it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.47it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.48it/s]

[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:33 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:33 model_runner.py:1099] Loading model weights took 3.5546 GB
INFO 04-07 09:35:33 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:34 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:38 worker.py:241] Memory profiling takes 4.17 seconds
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:38 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:35:38 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:38 worker.py:241] Memory profiling takes 4.18 seconds
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:38 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:35:38 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:38 worker.py:241] Memory profiling takes 4.23 seconds
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:38 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:35:38 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
INFO 04-07 09:35:38 worker.py:241] Memory profiling takes 4.35 seconds
INFO 04-07 09:35:38 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:35:38 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:35:38 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:35:38 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
INFO 04-07 09:36:02 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:36:02 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:36:02 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s][1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:36:02 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:47,  1.21it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:43,  1.24it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:40,  1.27it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:03<01:39,  1.28it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:37,  1.30it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:34,  1.32it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:32,  1.34it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:06<01:32,  1.33it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:06<01:32,  1.31it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:29,  1.34it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:08<01:32,  1.30it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:09<01:33,  1.27it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:10<01:34,  1.25it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:10<01:29,  1.31it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:11<01:26,  1.34it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:12<01:22,  1.39it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:12<01:22,  1.38it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:13<01:22,  1.37it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:14<01:20,  1.40it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:14<01:17,  1.44it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:15<01:14,  1.47it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:16<01:13,  1.49it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:16<01:11,  1.51it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:17<01:11,  1.49it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:18<01:11,  1.49it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:18<01:10,  1.50it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:19<01:12,  1.44it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:20<01:14,  1.39it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:21<01:13,  1.39it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:21<01:14,  1.36it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:22<01:14,  1.34it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:23<01:13,  1.35it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:24<01:12,  1.36it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:24<01:12,  1.35it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:25<01:09,  1.38it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:26<01:08,  1.39it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:27<01:07,  1.39it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:27<01:07,  1.38it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:28<01:06,  1.39it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:29<01:05,  1.38it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:29<01:05,  1.38it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:30<01:03,  1.41it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:31<01:02,  1.40it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:32<01:02,  1.39it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:32<01:01,  1.39it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:33<01:00,  1.41it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:34<00:59,  1.42it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:34<00:59,  1.40it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:35<00:58,  1.40it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:36<00:57,  1.42it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:37<00:56,  1.42it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:37<00:56,  1.41it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:38<00:55,  1.40it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:39<00:54,  1.41it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:39<00:54,  1.41it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:40<00:54,  1.39it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:41<00:52,  1.42it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:41<00:51,  1.42it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:42<00:51,  1.40it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:43<00:50,  1.40it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:44<00:49,  1.41it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:44<00:48,  1.41it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:45<00:47,  1.43it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:46<00:46,  1.43it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:46<00:46,  1.42it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:47<00:44,  1.46it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:48<00:44,  1.45it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:48<00:43,  1.45it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:49<00:42,  1.45it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:50<00:41,  1.45it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:51<00:42,  1.42it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:51<00:41,  1.44it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:52<00:40,  1.44it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:53<00:39,  1.44it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:53<00:39,  1.42it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:54<00:38,  1.43it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:55<00:37,  1.46it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:55<00:35,  1.48it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:56<00:35,  1.47it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:57<00:34,  1.47it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:57<00:33,  1.47it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [00:58<00:33,  1.47it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [00:59<00:32,  1.47it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [00:59<00:31,  1.48it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:00<00:31,  1.48it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:01<00:30,  1.48it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:01<00:29,  1.49it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:02<00:28,  1.49it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:03<00:28,  1.48it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:03<00:26,  1.52it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:04<00:27,  1.48it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:05<00:25,  1.50it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:05<00:25,  1.52it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:06<00:24,  1.49it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:07<00:24,  1.49it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:07<00:23,  1.48it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:08<00:22,  1.52it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:09<00:21,  1.51it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:09<00:20,  1.54it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:10<00:20,  1.52it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:11<00:19,  1.51it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:11<00:19,  1.52it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:12<00:18,  1.53it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:13<00:17,  1.52it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:13<00:17,  1.52it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:14<00:16,  1.51it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:15<00:15,  1.54it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:15<00:15,  1.53it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:16<00:14,  1.52it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:17<00:13,  1.51it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:17<00:13,  1.52it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:18<00:12,  1.55it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:19<00:11,  1.53it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:19<00:11,  1.53it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:20<00:10,  1.53it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:21<00:09,  1.53it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:21<00:09,  1.53it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:22<00:08,  1.51it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:23<00:07,  1.54it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:23<00:07,  1.52it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:24<00:06,  1.51it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:25<00:05,  1.51it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:25<00:05,  1.51it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:26<00:04,  1.52it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:26<00:03,  1.55it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:27<00:03,  1.54it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:28<00:02,  1.56it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:28<00:01,  1.55it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:29<00:01,  1.56it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:30<00:00,  1.54it/s][1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:37:33 model_runner.py:1535] Graph capturing finished in 91 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:37:33 model_runner.py:1535] Graph capturing finished in 91 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:37:33 model_runner.py:1535] Graph capturing finished in 91 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:31<00:00,  1.34it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:31<00:00,  1.44it/s]
INFO 04-07 09:37:33 model_runner.py:1535] Graph capturing finished in 91 secs, took 3.72 GiB
INFO 04-07 09:37:33 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 119.59 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:00, 6217.17 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: cycle
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:38:17 scheduler.py:944] Input prompt (34343 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:39<5:31:28, 39.86s/it, est. speed input: 861.68 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 2/500 [02:03<9:05:39, 65.74s/it, est. speed input: 306.41 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [02:03<00:00,  4.04it/s, est. speed input: 16324.58 toks/s, output: 8.07 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:39:45 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2617173)[0;0m INFO 04-07 09:39:45 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2617175)[0;0m INFO 04-07 09:39:45 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2617174)[0;0m INFO 04-07 09:39:45 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:40:06.719305020 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:40:26 config.py:510] This model supports multiple tasks: {'embed', 'classify', 'score', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 04-07 09:40:26 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:40:26 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:40:26 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:40:26 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 09:40:27 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:40:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:29 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-07 09:40:29 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:29 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:29 pynccl.py:69] vLLM is using nccl==2.21.5
WARNING 04-07 09:40:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2621066)[0;0m WARNING 04-07 09:40:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2621067)[0;0m WARNING 04-07 09:40:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2621068)[0;0m WARNING 04-07 09:40:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:40:29 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_88535266'), local_subscribe_port=53163, remote_subscribe_port=None)
INFO 04-07 09:40:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.54it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.81it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.68it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.74it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.72it/s]

INFO 04-07 09:40:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:35 worker.py:241] Memory profiling takes 4.06 seconds
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:35 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:35 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:35 worker.py:241] Memory profiling takes 4.16 seconds
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:35 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:35 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:35 worker.py:241] Memory profiling takes 4.16 seconds
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:35 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:35 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
INFO 04-07 09:40:35 worker.py:241] Memory profiling takes 4.20 seconds
INFO 04-07 09:40:35 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:40:35 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:40:36 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:40:36 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:40:58 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:40:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 09:40:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:40:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:17,  1.68it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:17,  1.67it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:01<01:18,  1.64it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:02<01:18,  1.62it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:19,  1.58it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:03<01:17,  1.62it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:04<01:15,  1.65it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:04<01:16,  1.61it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:05<01:17,  1.58it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:06<01:15,  1.60it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:06<01:13,  1.63it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:07<01:12,  1.63it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:08<01:12,  1.62it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:08<01:12,  1.60it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:09<01:11,  1.62it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:09<01:10,  1.64it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:10<01:11,  1.59it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:11<01:10,  1.60it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:11<01:09,  1.62it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:12<01:08,  1.63it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:13<01:08,  1.60it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:13<01:08,  1.60it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:14<01:08,  1.58it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:14<01:06,  1.60it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:15<01:05,  1.61it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:16<01:04,  1.63it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:16<01:04,  1.61it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:17<01:04,  1.61it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:17<01:01,  1.67it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:18<01:01,  1.65it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:19<01:00,  1.65it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:19<00:59,  1.67it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:20<00:57,  1.71it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:20<00:57,  1.70it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:21<00:57,  1.67it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:22<00:56,  1.69it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:22<00:55,  1.68it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:23<00:55,  1.68it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:23<00:55,  1.66it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:24<00:54,  1.67it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:25<00:53,  1.67it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:25<00:52,  1.71it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:26<00:51,  1.70it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:26<00:51,  1.70it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:27<00:50,  1.69it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:28<00:50,  1.69it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:28<00:49,  1.70it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:29<00:49,  1.67it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:29<00:48,  1.69it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:30<00:47,  1.71it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:30<00:47,  1.69it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:31<00:45,  1.73it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:32<00:45,  1.71it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:32<00:44,  1.72it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:33<00:44,  1.70it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:33<00:43,  1.74it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:34<00:42,  1.72it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:34<00:42,  1.73it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:35<00:41,  1.72it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:36<00:41,  1.72it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:36<00:40,  1.75it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:37<00:39,  1.76it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:37<00:39,  1.74it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:38<00:39,  1.70it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:39<00:37,  1.75it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:39<00:37,  1.75it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:40<00:36,  1.76it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:40<00:36,  1.74it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:41<00:35,  1.75it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:41<00:34,  1.77it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:42<00:33,  1.81it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:42<00:32,  1.81it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:43<00:33,  1.76it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:44<00:32,  1.78it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:44<00:31,  1.78it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:45<00:30,  1.80it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:45<00:30,  1.76it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:46<00:30,  1.74it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:46<00:29,  1.78it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:47<00:28,  1.80it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:47<00:27,  1.83it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [00:48<00:27,  1.79it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [00:49<00:27,  1.78it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [00:49<00:26,  1.78it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [00:50<00:24,  1.84it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [00:50<00:24,  1.86it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [00:51<00:24,  1.82it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [00:51<00:23,  1.82it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [00:52<00:23,  1.82it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [00:52<00:21,  1.87it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [00:53<00:21,  1.88it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [00:53<00:21,  1.83it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [00:54<00:21,  1.80it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [00:55<00:20,  1.79it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [00:55<00:20,  1.75it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [00:56<00:20,  1.67it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [00:57<00:20,  1.66it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [00:57<00:19,  1.70it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [00:58<00:18,  1.72it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [00:58<00:18,  1.72it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [00:59<00:17,  1.74it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [00:59<00:16,  1.75it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:00<00:15,  1.79it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:00<00:14,  1.82it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:01<00:14,  1.83it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:01<00:13,  1.84it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:02<00:13,  1.82it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:03<00:12,  1.84it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:03<00:11,  1.88it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:04<00:10,  1.91it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:04<00:10,  1.90it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:05<00:10,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:05<00:09,  1.93it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:06<00:08,  1.94it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:06<00:08,  1.95it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:07<00:07,  1.93it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:07<00:07,  1.93it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:08<00:06,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:08<00:06,  1.95it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:09<00:05,  1.97it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:09<00:05,  1.93it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:10<00:04,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:10<00:04,  1.95it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:11<00:03,  1.98it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:11<00:03,  2.00it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:12<00:02,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:12<00:02,  1.98it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:13<00:01,  1.97it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:13<00:01,  1.98it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:14<00:00,  1.98it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:15<00:00,  1.69it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:15<00:00,  1.74it/s]
INFO 04-07 09:42:14 model_runner.py:1535] Graph capturing finished in 75 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:42:14 model_runner.py:1535] Graph capturing finished in 76 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:42:14 model_runner.py:1535] Graph capturing finished in 75 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:42:14 model_runner.py:1535] Graph capturing finished in 75 secs, took 3.72 GiB
INFO 04-07 09:42:14 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 102.85 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 405 examples [00:00, 547.40 examples/s]Generating train split: 405 examples [00:00, 545.98 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: flow
Processed prompts:   0%|          | 0/405 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:12 scheduler.py:944] Input prompt (33272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:14 scheduler.py:944] Input prompt (33303 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/405 [00:44<5:01:53, 44.84s/it, est. speed input: 742.07 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:16 scheduler.py:944] Input prompt (33202 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:16 scheduler.py:944] Input prompt (33178 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:16 scheduler.py:944] Input prompt (33316 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 2/405 [00:46<2:11:45, 19.62s/it, est. speed input: 1422.62 toks/s, output: 0.00 toks/s]Processed prompts:   1%|          | 3/405 [00:48<1:17:33, 11.58s/it, est. speed input: 2044.28 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:20 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|▏         | 6/405 [00:52<31:58,  4.81s/it, est. speed input: 3780.33 toks/s, output: 0.00 toks/s]  WARNING 04-07 09:43:24 scheduler.py:944] Input prompt (33965 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:24 scheduler.py:944] Input prompt (34015 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:24 scheduler.py:944] Input prompt (34499 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:24 scheduler.py:944] Input prompt (34515 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (34797 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (34753 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (34687 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (35374 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (35102 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (35475 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33582 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (34899 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33143 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33498 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33195 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33188 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33313 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33186 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33596 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33350 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33220 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33856 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:26 scheduler.py:944] Input prompt (33541 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 7/405 [00:56<30:10,  4.55s/it, est. speed input: 4131.54 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:27 scheduler.py:944] Input prompt (33626 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 11/405 [00:57<13:34,  2.07s/it, est. speed input: 6451.79 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33525 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33153 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33425 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33554 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33383 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33442 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33250 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33330 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:28 scheduler.py:944] Input prompt (33499 tokens) is too long and exceeds limit of 32768
Processed prompts:   8%|▊         | 33/405 [00:58<02:38,  2.35it/s, est. speed input: 18918.52 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33945 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33156 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33261 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33257 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33287 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33338 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33514 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33165 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33059 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33172 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33378 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33271 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33377 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33514 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33111 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33178 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33231 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33365 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33199 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33151 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33047 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33377 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33237 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33307 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33112 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (34935 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:30 scheduler.py:944] Input prompt (33245 tokens) is too long and exceeds limit of 32768
Processed prompts:   8%|▊         | 34/405 [01:00<03:00,  2.05it/s, est. speed input: 18956.94 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33291 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33291 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33349 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33365 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33644 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33410 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33230 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33504 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:31 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
Processed prompts:  11%|█         | 44/405 [01:02<02:07,  2.83it/s, est. speed input: 23808.28 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:33 scheduler.py:944] Input prompt (33106 tokens) is too long and exceeds limit of 32768
Processed prompts:  19%|█▉        | 77/405 [01:03<00:49,  6.60it/s, est. speed input: 40379.20 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:35 scheduler.py:944] Input prompt (33529 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:35 scheduler.py:944] Input prompt (33391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:35 scheduler.py:944] Input prompt (33368 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:35 scheduler.py:944] Input prompt (33176 tokens) is too long and exceeds limit of 32768
Processed prompts:  22%|██▏       | 88/405 [01:04<00:42,  7.45it/s, est. speed input: 45491.81 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:36 scheduler.py:944] Input prompt (33278 tokens) is too long and exceeds limit of 32768
Processed prompts:  22%|██▏       | 90/405 [01:06<00:56,  5.60it/s, est. speed input: 45279.25 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33371 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33301 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33205 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33605 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33250 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33289 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33159 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33248 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33221 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33577 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33135 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33268 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33241 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33228 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33694 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33526 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33159 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (32924 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33142 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33229 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33469 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33495 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33395 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:37 scheduler.py:944] Input prompt (33250 tokens) is too long and exceeds limit of 32768
Processed prompts:  23%|██▎       | 93/405 [01:08<01:13,  4.22it/s, est. speed input: 45349.12 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:39 scheduler.py:944] Input prompt (33156 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:39 scheduler.py:944] Input prompt (33391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:39 scheduler.py:944] Input prompt (33488 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:39 scheduler.py:944] Input prompt (33266 tokens) is too long and exceeds limit of 32768
Processed prompts:  23%|██▎       | 94/405 [01:09<01:29,  3.49it/s, est. speed input: 45038.38 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33336 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33490 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33314 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (32842 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33183 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33169 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33773 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33410 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33105 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33212 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33218 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:41 scheduler.py:944] Input prompt (33295 tokens) is too long and exceeds limit of 32768
Processed prompts:  29%|██▉       | 119/405 [01:11<00:42,  6.74it/s, est. speed input: 55519.60 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:42 scheduler.py:944] Input prompt (33290 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:42 scheduler.py:944] Input prompt (33144 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:42 scheduler.py:944] Input prompt (33226 tokens) is too long and exceeds limit of 32768
Processed prompts:  30%|███       | 123/405 [01:13<00:55,  5.11it/s, est. speed input: 55773.32 toks/s, output: 0.00 toks/s]Processed prompts:  33%|███▎      | 135/405 [01:16<00:54,  4.93it/s, est. speed input: 59102.27 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33329 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33320 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33370 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33245 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33132 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33531 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33207 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:47 scheduler.py:944] Input prompt (33263 tokens) is too long and exceeds limit of 32768
Processed prompts:  34%|███▍      | 138/405 [01:19<01:17,  3.45it/s, est. speed input: 58168.92 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:50 scheduler.py:944] Input prompt (33196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:50 scheduler.py:944] Input prompt (33226 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:50 scheduler.py:944] Input prompt (33203 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:51 scheduler.py:944] Input prompt (33201 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:51 scheduler.py:944] Input prompt (33717 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:51 scheduler.py:944] Input prompt (33163 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:51 scheduler.py:944] Input prompt (33245 tokens) is too long and exceeds limit of 32768
Processed prompts:  37%|███▋      | 148/405 [01:22<01:13,  3.50it/s, est. speed input: 60258.84 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:53 scheduler.py:944] Input prompt (33179 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:53 scheduler.py:944] Input prompt (33568 tokens) is too long and exceeds limit of 32768
Processed prompts:  37%|███▋      | 151/405 [01:24<01:27,  2.91it/s, est. speed input: 59870.06 toks/s, output: 0.00 toks/s]Processed prompts:  38%|███▊      | 155/405 [01:25<01:24,  2.97it/s, est. speed input: 60572.49 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33236 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33154 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33518 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33137 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33179 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33198 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33105 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:56 scheduler.py:944] Input prompt (33160 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:58 scheduler.py:944] Input prompt (33305 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:58 scheduler.py:944] Input prompt (33126 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:58 scheduler.py:944] Input prompt (33172 tokens) is too long and exceeds limit of 32768
Processed prompts:  39%|███▉      | 157/405 [01:28<02:02,  2.02it/s, est. speed input: 59117.29 toks/s, output: 0.00 toks/s]WARNING 04-07 09:43:59 scheduler.py:944] Input prompt (33469 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:59 scheduler.py:944] Input prompt (33218 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:43:59 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
Processed prompts:  41%|████      | 167/405 [01:30<01:20,  2.94it/s, est. speed input: 61716.52 toks/s, output: 0.00 toks/s]WARNING 04-07 09:44:01 scheduler.py:944] Input prompt (33129 tokens) is too long and exceeds limit of 32768
Processed prompts:  42%|████▏     | 170/405 [01:32<01:34,  2.49it/s, est. speed input: 61375.63 toks/s, output: 0.00 toks/s]WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33320 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33456 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33155 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33188 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33779 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33558 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (34415 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33498 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (34228 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33812 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:03 scheduler.py:944] Input prompt (33411 tokens) is too long and exceeds limit of 32768
Processed prompts:  43%|████▎     | 173/405 [01:34<01:44,  2.23it/s, est. speed input: 61175.84 toks/s, output: 0.00 toks/s]WARNING 04-07 09:44:05 scheduler.py:944] Input prompt (33311 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:05 scheduler.py:944] Input prompt (33890 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:05 scheduler.py:944] Input prompt (33751 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:05 scheduler.py:944] Input prompt (33672 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:05 scheduler.py:944] Input prompt (34310 tokens) is too long and exceeds limit of 32768
Processed prompts:  43%|████▎     | 174/405 [01:36<02:08,  1.80it/s, est. speed input: 60425.96 toks/s, output: 0.00 toks/s]WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (33864 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (34299 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (34866 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (34420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (35372 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:07 scheduler.py:944] Input prompt (34169 tokens) is too long and exceeds limit of 32768
Processed prompts:  46%|████▌     | 186/405 [01:36<00:55,  3.94it/s, est. speed input: 64256.32 toks/s, output: 0.00 toks/s]Processed prompts:  47%|████▋     | 191/405 [01:38<01:02,  3.43it/s, est. speed input: 64676.72 toks/s, output: 0.00 toks/s]WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34494 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (35556 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34298 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (36374 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34634 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34662 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (35070 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (35559 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34885 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:44:13 scheduler.py:944] Input prompt (34618 tokens) is too long and exceeds limit of 32768
Processed prompts:  49%|████▊     | 197/405 [01:45<01:56,  1.79it/s, est. speed input: 62378.21 toks/s, output: 0.00 toks/s]Processed prompts:  51%|█████     | 207/405 [01:47<01:17,  2.57it/s, est. speed input: 64470.05 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 405/405 [01:47<00:00,  3.78it/s, est. speed input: 79118.61 toks/s, output: 3.71 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:44:18 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2621066)[0;0m INFO 04-07 09:44:18 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2621067)[0;0m INFO 04-07 09:44:18 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2621068)[0;0m INFO 04-07 09:44:18 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:44:38.010279045 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:44:58 config.py:510] This model supports multiple tasks: {'embed', 'classify', 'reward', 'score', 'generate'}. Defaulting to 'generate'.
INFO 04-07 09:44:58 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:44:58 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:44:58 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:44:58 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 09:44:59 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:44:59 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:44:59 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:00 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:00 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:00 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:00 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:45:00 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:00 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:00 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 04-07 09:45:00 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:00 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:00 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:00 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:00 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2624541)[0;0m WARNING 04-07 09:45:01 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2624543)[0;0m WARNING 04-07 09:45:01 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2624542)[0;0m WARNING 04-07 09:45:01 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 09:45:01 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:45:01 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_b32040fe'), local_subscribe_port=54151, remote_subscribe_port=None)
INFO 04-07 09:45:01 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:01 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:01 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:01 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.55it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.66it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.52it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.62it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.60it/s]

INFO 04-07 09:45:03 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:03 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:03 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:03 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:07 worker.py:241] Memory profiling takes 4.20 seconds
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:07 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:07 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:07 worker.py:241] Memory profiling takes 4.21 seconds
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:07 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:07 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:07 worker.py:241] Memory profiling takes 4.24 seconds
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:07 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:07 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
INFO 04-07 09:45:07 worker.py:241] Memory profiling takes 4.31 seconds
INFO 04-07 09:45:07 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:45:07 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:45:07 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:45:07 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
INFO 04-07 09:45:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:45:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:45:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:45:31 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:01<03:18,  1.53s/it]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:02<02:40,  1.24s/it]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:03<02:27,  1.15s/it]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:04<02:31,  1.19s/it]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:05<02:15,  1.07s/it]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:06<02:10,  1.04s/it]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:07<02:00,  1.03it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:08<01:54,  1.08it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:09<01:48,  1.12it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:10<01:46,  1.13it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:10<01:41,  1.18it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:11<01:44,  1.14it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:12<01:39,  1.19it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:13<01:34,  1.23it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:14<01:33,  1.23it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:14<01:33,  1.23it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:15<01:32,  1.23it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:16<01:30,  1.25it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:17<01:33,  1.20it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:18<01:32,  1.20it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:19<01:30,  1.22it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:19<01:27,  1.25it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:20<01:25,  1.26it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:21<01:23,  1.29it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:22<01:23,  1.26it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:22<01:25,  1.22it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:23<01:23,  1.25it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:24<01:21,  1.27it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:25<01:20,  1.27it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:26<01:22,  1.22it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:26<01:19,  1.25it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:27<01:19,  1.25it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:28<01:19,  1.24it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:29<01:16,  1.27it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:30<01:13,  1.30it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:30<01:14,  1.27it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:31<01:13,  1.28it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:32<01:10,  1.31it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:33<01:09,  1.33it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:33<01:08,  1.33it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:34<01:07,  1.33it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:35<01:05,  1.35it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:36<01:05,  1.34it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:36<01:08,  1.28it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:37<01:06,  1.30it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:38<01:04,  1.32it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:39<01:02,  1.34it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:39<01:03,  1.30it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:40<01:02,  1.31it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:41<01:00,  1.34it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:42<01:00,  1.32it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:42<01:00,  1.31it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:43<00:58,  1.33it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:44<00:57,  1.34it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:45<00:57,  1.33it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:45<00:56,  1.33it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:46<00:55,  1.34it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:47<00:53,  1.35it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:48<00:53,  1.35it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:48<00:52,  1.36it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:49<00:50,  1.38it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:50<00:49,  1.40it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:51<00:50,  1.35it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:51<00:48,  1.37it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:52<00:46,  1.40it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:53<00:48,  1.35it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:54<00:48,  1.31it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:54<00:46,  1.35it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:55<00:45,  1.36it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:56<00:45,  1.35it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:56<00:45,  1.33it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:57<00:43,  1.36it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:58<00:42,  1.36it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:59<00:44,  1.29it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:59<00:42,  1.33it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:00<00:40,  1.36it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:01<00:39,  1.37it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:02<00:39,  1.33it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:02<00:37,  1.37it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:03<00:36,  1.40it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:04<00:37,  1.34it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:05<00:38,  1.26it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:05<00:36,  1.31it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:06<00:35,  1.33it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:07<00:35,  1.29it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:08<00:33,  1.35it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:08<00:31,  1.40it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:09<00:31,  1.35it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:10<00:31,  1.35it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:11<00:29,  1.40it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:11<00:27,  1.44it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:12<00:28,  1.37it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:13<00:27,  1.40it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:13<00:25,  1.44it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:14<00:24,  1.47it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:15<00:23,  1.49it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:15<00:23,  1.46it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:16<00:22,  1.48it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:17<00:21,  1.50it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:17<00:21,  1.47it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:18<00:20,  1.46it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:19<00:19,  1.46it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:19<00:18,  1.48it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:20<00:18,  1.49it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:21<00:18,  1.41it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:21<00:17,  1.44it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:22<00:16,  1.46it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:23<00:15,  1.46it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:24<00:15,  1.40it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:24<00:14,  1.42it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:25<00:13,  1.47it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:26<00:12,  1.47it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:26<00:12,  1.45it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:27<00:12,  1.41it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:28<00:11,  1.44it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:28<00:10,  1.46it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:29<00:10,  1.37it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:30<00:09,  1.39it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:31<00:08,  1.45it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:31<00:07,  1.45it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:32<00:07,  1.40it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:33<00:06,  1.43it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:33<00:05,  1.47it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:34<00:04,  1.47it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:35<00:04,  1.46it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:35<00:03,  1.48it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:36<00:02,  1.50it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:37<00:02,  1.48it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:37<00:01,  1.49it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:38<00:00,  1.48it/s][1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:47:10 model_runner.py:1535] Graph capturing finished in 99 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:47:10 model_runner.py:1535] Graph capturing finished in 99 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:47:10 model_runner.py:1535] Graph capturing finished in 99 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:39<00:00,  1.32it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:39<00:00,  1.32it/s]
INFO 04-07 09:47:10 model_runner.py:1535] Graph capturing finished in 100 secs, took 3.72 GiB
INFO 04-07 09:47:10 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 127.33 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:00, 1167.98 examples/s]Generating train split: 500 examples [00:00, 1167.15 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: hamilton
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:47:58 scheduler.py:944] Input prompt (33842 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:37<5:15:14, 37.91s/it, est. speed input: 892.80 toks/s, output: 0.00 toks/s]WARNING 04-07 09:48:04 scheduler.py:944] Input prompt (35139 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 2/500 [00:44<2:39:32, 19.22s/it, est. speed input: 1566.03 toks/s, output: 0.00 toks/s]WARNING 04-07 09:48:29 scheduler.py:944] Input prompt (35238 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:48:31 scheduler.py:944] Input prompt (35647 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:48:31 scheduler.py:944] Input prompt (33594 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [01:09<3:00:57, 21.85s/it, est. speed input: 1510.07 toks/s, output: 0.00 toks/s]Processed prompts:   1%|          | 4/500 [01:10<1:55:35, 13.98s/it, est. speed input: 1971.43 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:02 scheduler.py:944] Input prompt (36610 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 6/500 [01:41<2:01:10, 14.72s/it, est. speed input: 2065.87 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:07 scheduler.py:944] Input prompt (35947 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|▏         | 7/500 [01:47<1:40:49, 12.27s/it, est. speed input: 2288.73 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:15 scheduler.py:944] Input prompt (34679 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 8/500 [01:54<1:29:15, 10.89s/it, est. speed input: 2444.11 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:19 scheduler.py:944] Input prompt (34409 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 9/500 [01:58<1:11:39,  8.76s/it, est. speed input: 2663.22 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (34610 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (35171 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33717 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33863 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33632 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (34053 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (34050 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33696 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (35598 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (35062 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33232 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33513 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (34264 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (35084 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33463 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (35663 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:24 scheduler.py:944] Input prompt (33179 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (33170 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (33444 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (35390 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (35328 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (33299 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (33227 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:26 scheduler.py:944] Input prompt (33553 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 10/500 [02:02<1:01:26,  7.52s/it, est. speed input: 2847.13 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33231 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33345 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33681 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35111 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33233 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (34755 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33490 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35606 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33564 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33438 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33200 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33824 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33390 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35491 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33999 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33268 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (34047 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33251 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33405 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35726 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33240 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35276 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (34460 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33231 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35802 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33504 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35169 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33871 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33589 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35069 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (35774 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33519 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:27 scheduler.py:944] Input prompt (33427 tokens) is too long and exceeds limit of 32768
Processed prompts:   6%|▌         | 30/500 [02:04<07:04,  1.11it/s, est. speed input: 8245.18 toks/s, output: 0.00 toks/s]  WARNING 04-07 09:49:29 scheduler.py:944] Input prompt (36022 tokens) is too long and exceeds limit of 32768
Processed prompts:   7%|▋         | 37/500 [02:05<05:08,  1.50it/s, est. speed input: 10066.67 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:30 scheduler.py:944] Input prompt (33545 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:30 scheduler.py:944] Input prompt (33513 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:30 scheduler.py:944] Input prompt (35381 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:30 scheduler.py:944] Input prompt (33476 tokens) is too long and exceeds limit of 32768
Processed prompts:  15%|█▍        | 73/500 [02:07<01:40,  4.27it/s, est. speed input: 19587.65 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:31 scheduler.py:944] Input prompt (33505 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:31 scheduler.py:944] Input prompt (34188 tokens) is too long and exceeds limit of 32768
Processed prompts:  15%|█▌        | 75/500 [02:09<02:01,  3.50it/s, est. speed input: 19739.29 toks/s, output: 0.00 toks/s]WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33436 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33149 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33527 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (36084 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (35169 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (36037 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (34466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (36203 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33303 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (35177 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33290 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33927 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33242 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (34398 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33602 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (34690 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33541 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (33540 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:49:34 scheduler.py:944] Input prompt (35142 tokens) is too long and exceeds limit of 32768
Processed prompts:  16%|█▌        | 78/500 [02:12<02:19,  3.03it/s, est. speed input: 20186.79 toks/s, output: 0.00 toks/s]Processed prompts:  16%|█▌        | 80/500 [02:12<02:10,  3.23it/s, est. speed input: 20668.38 toks/s, output: 0.00 toks/s]Processed prompts:  20%|██        | 102/500 [02:12<00:56,  7.06it/s, est. speed input: 26049.67 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [02:12<00:00,  3.77it/s, est. speed input: 41664.03 toks/s, output: 6.01 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:49:37 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2624542)[0;0m INFO 04-07 09:49:37 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2624543)[0;0m INFO 04-07 09:49:37 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2624541)[0;0m INFO 04-07 09:49:37 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:49:57.578622931 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:50:19 config.py:510] This model supports multiple tasks: {'embed', 'classify', 'score', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 04-07 09:50:19 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:50:19 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:50:19 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:50:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 09:50:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:20 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:21 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:21 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 09:50:21 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 09:50:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:21 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:21 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:21 pynccl.py:69] vLLM is using nccl==2.21.5
WARNING 04-07 09:50:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2627859)[0;0m WARNING 04-07 09:50:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2627860)[0;0m WARNING 04-07 09:50:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2627861)[0;0m WARNING 04-07 09:50:22 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:50:22 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_ae2d816c'), local_subscribe_port=51967, remote_subscribe_port=None)
INFO 04-07 09:50:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:22 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.49it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.70it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.51it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.61it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.60it/s]

INFO 04-07 09:50:24 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:24 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:24 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:24 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:28 worker.py:241] Memory profiling takes 4.08 seconds
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:28 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:28 worker.py:241] Memory profiling takes 4.11 seconds
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:28 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:28 worker.py:241] Memory profiling takes 4.19 seconds
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:28 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
INFO 04-07 09:50:28 worker.py:241] Memory profiling takes 4.41 seconds
INFO 04-07 09:50:28 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:50:28 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 09:50:29 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:50:29 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:50:52 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:50:52 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 09:50:52 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:50:52 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:46,  1.22it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:42,  1.25it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:38,  1.30it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:03<01:36,  1.31it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:36,  1.31it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:35,  1.31it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:33,  1.32it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:06<01:32,  1.32it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:06<01:30,  1.34it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:30,  1.33it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:08<01:31,  1.31it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:09<01:28,  1.34it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:09<01:27,  1.35it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:10<01:28,  1.33it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:11<01:28,  1.32it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:12<01:25,  1.34it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:12<01:25,  1.34it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:13<01:24,  1.33it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:14<01:23,  1.34it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:15<01:24,  1.31it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:15<01:24,  1.30it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:16<01:22,  1.32it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:17<01:21,  1.33it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:18<01:20,  1.33it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:18<01:19,  1.33it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:19<01:19,  1.32it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:20<01:18,  1.32it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:21<01:17,  1.32it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:21<01:17,  1.32it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:22<01:15,  1.34it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:23<01:14,  1.35it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:24<01:12,  1.36it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:24<01:11,  1.38it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:25<01:09,  1.39it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:26<01:09,  1.37it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:26<01:08,  1.38it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:27<01:07,  1.40it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:28<01:07,  1.37it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:29<01:06,  1.38it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:29<01:05,  1.40it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:30<01:04,  1.38it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:31<01:03,  1.39it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:31<01:02,  1.40it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:32<01:03,  1.38it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:33<01:01,  1.40it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:34<01:01,  1.39it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:34<01:01,  1.37it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:35<01:00,  1.37it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:36<00:59,  1.38it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:37<00:58,  1.40it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:37<00:56,  1.42it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:38<00:55,  1.42it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:39<00:56,  1.39it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:39<00:56,  1.37it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:40<00:54,  1.39it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:41<00:53,  1.41it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:42<00:52,  1.41it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:42<00:51,  1.42it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:43<00:50,  1.43it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:44<00:49,  1.44it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:44<00:48,  1.44it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:45<00:48,  1.42it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:46<00:48,  1.39it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:46<00:48,  1.38it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:47<00:47,  1.39it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:48<00:46,  1.39it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:49<00:45,  1.40it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:49<00:45,  1.39it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:50<00:43,  1.42it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:51<00:42,  1.44it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:51<00:42,  1.40it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:52<00:41,  1.44it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:53<00:41,  1.39it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:54<00:41,  1.38it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:54<00:41,  1.36it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:55<00:39,  1.39it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:56<00:38,  1.38it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:57<00:38,  1.38it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:57<00:37,  1.38it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:58<00:36,  1.40it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:59<00:34,  1.43it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [00:59<00:33,  1.45it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:00<00:32,  1.47it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:01<00:32,  1.46it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:01<00:30,  1.49it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:02<00:30,  1.47it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:03<00:29,  1.48it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:03<00:28,  1.50it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:04<00:27,  1.50it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:05<00:27,  1.50it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:05<00:26,  1.51it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:06<00:26,  1.49it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:07<00:25,  1.51it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:07<00:24,  1.52it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:08<00:24,  1.49it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:09<00:23,  1.48it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:09<00:22,  1.51it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:10<00:21,  1.53it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:11<00:21,  1.50it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:11<00:20,  1.48it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:12<00:19,  1.51it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:13<00:19,  1.46it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:13<00:18,  1.49it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:14<00:17,  1.51it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:15<00:16,  1.54it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:15<00:16,  1.53it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:16<00:15,  1.52it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:17<00:15,  1.52it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:17<00:14,  1.53it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:18<00:13,  1.53it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:18<00:12,  1.55it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:19<00:12,  1.54it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:20<00:11,  1.55it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:20<00:11,  1.49it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:21<00:10,  1.53it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:22<00:09,  1.52it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:22<00:09,  1.54it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:23<00:08,  1.53it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:24<00:07,  1.53it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:24<00:07,  1.55it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:25<00:06,  1.51it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:26<00:05,  1.53it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:26<00:05,  1.54it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:27<00:04,  1.55it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:28<00:03,  1.57it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:28<00:03,  1.53it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:29<00:02,  1.54it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:30<00:01,  1.55it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:30<00:01,  1.52it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:31<00:00,  1.53it/s][1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:52:24 model_runner.py:1535] Graph capturing finished in 92 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:52:24 model_runner.py:1535] Graph capturing finished in 92 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:52:24 model_runner.py:1535] Graph capturing finished in 92 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:32<00:00,  1.34it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:32<00:00,  1.42it/s]
INFO 04-07 09:52:24 model_runner.py:1535] Graph capturing finished in 92 secs, took 3.72 GiB
INFO 04-07 09:52:24 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 120.31 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:01, 471.99 examples/s]Generating train split: 500 examples [00:01, 470.76 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: shortest
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:23 scheduler.py:944] Input prompt (34215 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:39<5:31:24, 39.85s/it, est. speed input: 858.62 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:29 scheduler.py:944] Input prompt (33312 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:31 scheduler.py:944] Input prompt (33415 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 2/500 [00:45<2:42:32, 19.58s/it, est. speed input: 1492.42 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:32 scheduler.py:944] Input prompt (34305 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [00:46<1:34:15, 11.38s/it, est. speed input: 2154.05 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:34 scheduler.py:944] Input prompt (35196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:34 scheduler.py:944] Input prompt (33452 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:34 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 4/500 [00:48<1:02:28,  7.56s/it, est. speed input: 2785.09 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:36 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 5/500 [00:50<44:32,  5.40s/it, est. speed input: 3399.65 toks/s, output: 0.00 toks/s]  WARNING 04-07 09:53:37 scheduler.py:944] Input prompt (33375 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:37 scheduler.py:944] Input prompt (33307 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 8/500 [00:52<20:57,  2.55s/it, est. speed input: 5177.76 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:39 scheduler.py:944] Input prompt (33486 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:39 scheduler.py:944] Input prompt (33445 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 9/500 [00:53<19:08,  2.34s/it, est. speed input: 5643.88 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:41 scheduler.py:944] Input prompt (33539 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 11/500 [00:55<14:26,  1.77s/it, est. speed input: 6664.05 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33735 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (34095 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33747 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33395 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (34049 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33271 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33635 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33237 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:43 scheduler.py:944] Input prompt (33397 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 13/500 [00:57<11:55,  1.47s/it, est. speed input: 7614.16 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (33257 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (33867 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (33473 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (33673 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (34190 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:45 scheduler.py:944] Input prompt (33364 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 14/500 [00:59<12:51,  1.59s/it, est. speed input: 7919.33 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34484 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33562 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33239 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33169 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33412 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34005 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34089 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33509 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (35900 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33224 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33505 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33824 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34907 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33440 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34025 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33763 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33530 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33229 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33446 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33792 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33596 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (34033 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33281 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (36306 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33189 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33842 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33578 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33750 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33238 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33298 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33361 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33553 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33242 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33291 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33465 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33114 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:47 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
Processed prompts:   5%|▍         | 23/500 [01:01<04:49,  1.65it/s, est. speed input: 12548.92 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33480 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33599 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33450 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33658 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33292 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33372 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33694 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33645 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33500 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33254 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33306 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33234 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33378 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33718 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34180 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33200 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33664 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33617 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33311 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34265 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33656 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33378 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34030 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (35711 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34310 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33562 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33424 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33750 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33114 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34707 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33416 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (34629 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33599 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33423 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (35061 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33332 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33479 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33665 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33605 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33249 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33835 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:49 scheduler.py:944] Input prompt (33944 tokens) is too long and exceeds limit of 32768
Processed prompts:   6%|▌         | 29/500 [01:03<04:00,  1.96it/s, est. speed input: 15293.34 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33809 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (32888 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (34660 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33289 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33941 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33521 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (34797 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33493 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33596 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:51 scheduler.py:944] Input prompt (33470 tokens) is too long and exceeds limit of 32768
Processed prompts:  14%|█▍        | 70/500 [01:05<00:53,  7.99it/s, est. speed input: 36246.55 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33312 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33565 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33746 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33461 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33870 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33500 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33451 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33221 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33419 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33641 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33382 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33895 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33876 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33612 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33812 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33234 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33453 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33517 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33756 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33504 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33533 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:52 scheduler.py:944] Input prompt (33357 tokens) is too long and exceeds limit of 32768
Processed prompts:  23%|██▎       | 114/500 [01:07<00:32, 11.90it/s, est. speed input: 57098.46 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33862 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33460 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (34164 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33641 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33560 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33406 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33481 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33690 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33732 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33891 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (32913 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (34393 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33844 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (36258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:54 scheduler.py:944] Input prompt (33571 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:55 scheduler.py:944] Input prompt (34477 tokens) is too long and exceeds limit of 32768
Processed prompts:  25%|██▍       | 124/500 [01:08<00:35, 10.52it/s, est. speed input: 60692.74 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33516 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33649 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (34142 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33295 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33845 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33335 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33241 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33375 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33355 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (34195 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:56 scheduler.py:944] Input prompt (33608 tokens) is too long and exceeds limit of 32768
Processed prompts:  29%|██▉       | 147/500 [01:10<00:31, 11.13it/s, est. speed input: 70052.87 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:58 scheduler.py:944] Input prompt (33664 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:58 scheduler.py:944] Input prompt (33527 tokens) is too long and exceeds limit of 32768
Processed prompts:  33%|███▎      | 165/500 [01:11<00:26, 12.61it/s, est. speed input: 77659.80 toks/s, output: 0.00 toks/s]WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33234 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33350 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33727 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33243 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33323 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33600 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:53:59 scheduler.py:944] Input prompt (33146 tokens) is too long and exceeds limit of 32768
Processed prompts:  36%|███▌      | 178/500 [01:14<00:34,  9.46it/s, est. speed input: 80818.39 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:01 scheduler.py:944] Input prompt (33483 tokens) is too long and exceeds limit of 32768
Processed prompts:  36%|███▌      | 180/500 [01:15<00:38,  8.22it/s, est. speed input: 80736.31 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (33698 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (34059 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (33953 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (33690 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (34413 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:02 scheduler.py:944] Input prompt (33449 tokens) is too long and exceeds limit of 32768
Processed prompts:  38%|███▊      | 188/500 [01:17<00:46,  6.73it/s, est. speed input: 82092.58 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:04 scheduler.py:944] Input prompt (33503 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:04 scheduler.py:944] Input prompt (34483 tokens) is too long and exceeds limit of 32768
Processed prompts:  38%|███▊      | 189/500 [01:18<01:03,  4.88it/s, est. speed input: 80722.87 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33763 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33276 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33690 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33539 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33120 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33570 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:06 scheduler.py:944] Input prompt (33313 tokens) is too long and exceeds limit of 32768
Processed prompts:  39%|███▉      | 196/500 [01:20<01:02,  4.87it/s, est. speed input: 82215.65 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:07 scheduler.py:944] Input prompt (33532 tokens) is too long and exceeds limit of 32768
Processed prompts:  40%|███▉      | 198/500 [01:21<01:15,  4.01it/s, est. speed input: 81730.10 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:09 scheduler.py:944] Input prompt (33259 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:09 scheduler.py:944] Input prompt (33771 tokens) is too long and exceeds limit of 32768
Processed prompts:  41%|████      | 206/500 [01:23<01:11,  4.09it/s, est. speed input: 83086.30 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:11 scheduler.py:944] Input prompt (33290 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:11 scheduler.py:944] Input prompt (33258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:11 scheduler.py:944] Input prompt (34614 tokens) is too long and exceeds limit of 32768
Processed prompts:  41%|████▏     | 207/500 [01:25<01:37,  3.02it/s, est. speed input: 81822.42 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33147 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33499 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33145 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33319 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33840 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:12 scheduler.py:944] Input prompt (33614 tokens) is too long and exceeds limit of 32768
Processed prompts:  42%|████▏     | 209/500 [01:26<01:56,  2.49it/s, est. speed input: 81060.76 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:14 scheduler.py:944] Input prompt (33361 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:14 scheduler.py:944] Input prompt (33305 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:14 scheduler.py:944] Input prompt (33158 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:14 scheduler.py:944] Input prompt (34588 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:14 scheduler.py:944] Input prompt (33986 tokens) is too long and exceeds limit of 32768
Processed prompts:  42%|████▏     | 212/500 [01:28<02:14,  2.15it/s, est. speed input: 80362.41 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:16 scheduler.py:944] Input prompt (33234 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:16 scheduler.py:944] Input prompt (33296 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:16 scheduler.py:944] Input prompt (33256 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:16 scheduler.py:944] Input prompt (33547 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:16 scheduler.py:944] Input prompt (33971 tokens) is too long and exceeds limit of 32768
Processed prompts:  44%|████▎     | 218/500 [01:30<01:48,  2.60it/s, est. speed input: 81176.77 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:18 scheduler.py:944] Input prompt (33676 tokens) is too long and exceeds limit of 32768
Processed prompts:  45%|████▍     | 223/500 [01:32<01:45,  2.63it/s, est. speed input: 81370.67 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33249 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (35305 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (34062 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33050 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33485 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33329 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33395 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33507 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:19 scheduler.py:944] Input prompt (33326 tokens) is too long and exceeds limit of 32768
Processed prompts:  46%|████▌     | 228/500 [01:33<01:35,  2.84it/s, est. speed input: 81893.47 toks/s, output: 0.00 toks/s]Processed prompts:  46%|████▌     | 229/500 [01:35<02:01,  2.24it/s, est. speed input: 80959.46 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:24 scheduler.py:944] Input prompt (33584 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:24 scheduler.py:944] Input prompt (33727 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:24 scheduler.py:944] Input prompt (33589 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:24 scheduler.py:944] Input prompt (33341 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:24 scheduler.py:944] Input prompt (33542 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:26 scheduler.py:944] Input prompt (33466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:26 scheduler.py:944] Input prompt (33123 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:26 scheduler.py:944] Input prompt (33792 tokens) is too long and exceeds limit of 32768
Processed prompts:  48%|████▊     | 239/500 [01:40<02:08,  2.03it/s, est. speed input: 80025.11 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:28 scheduler.py:944] Input prompt (34003 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:28 scheduler.py:944] Input prompt (34171 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:28 scheduler.py:944] Input prompt (33878 tokens) is too long and exceeds limit of 32768
Processed prompts:  49%|████▉     | 244/500 [01:42<01:56,  2.20it/s, est. speed input: 80279.97 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:29 scheduler.py:944] Input prompt (33636 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:29 scheduler.py:944] Input prompt (33370 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:29 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
Processed prompts:  49%|████▉     | 247/500 [01:43<01:58,  2.13it/s, est. speed input: 80010.83 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:31 scheduler.py:944] Input prompt (33275 tokens) is too long and exceeds limit of 32768
Processed prompts:  50%|█████     | 250/500 [01:45<02:01,  2.07it/s, est. speed input: 79752.25 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (34156 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (34103 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (33594 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (33530 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:33 scheduler.py:944] Input prompt (34027 tokens) is too long and exceeds limit of 32768
Processed prompts:  51%|█████     | 253/500 [01:47<02:06,  1.95it/s, est. speed input: 79324.03 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:35 scheduler.py:944] Input prompt (33700 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:35 scheduler.py:944] Input prompt (33463 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:35 scheduler.py:944] Input prompt (33224 tokens) is too long and exceeds limit of 32768
Processed prompts:  51%|█████     | 254/500 [01:48<02:32,  1.61it/s, est. speed input: 78494.89 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:36 scheduler.py:944] Input prompt (34528 tokens) is too long and exceeds limit of 32768
Processed prompts:  52%|█████▏    | 260/500 [01:50<01:51,  2.15it/s, est. speed input: 79104.89 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (33372 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (33484 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (33286 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (33438 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (34400 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:38 scheduler.py:944] Input prompt (33249 tokens) is too long and exceeds limit of 32768
Processed prompts:  53%|█████▎    | 263/500 [01:52<02:05,  1.89it/s, est. speed input: 78487.40 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33347 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33328 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33927 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33612 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33564 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33542 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:40 scheduler.py:944] Input prompt (33677 tokens) is too long and exceeds limit of 32768
Processed prompts:  53%|█████▎    | 264/500 [01:54<02:44,  1.44it/s, est. speed input: 77334.14 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (33651 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (34009 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (33481 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (33424 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (33530 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (33456 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:42 scheduler.py:944] Input prompt (34367 tokens) is too long and exceeds limit of 32768
Processed prompts:  54%|█████▍    | 270/500 [01:56<01:56,  1.97it/s, est. speed input: 77866.21 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33551 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33984 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33490 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33301 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (34634 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (34175 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:44 scheduler.py:944] Input prompt (33746 tokens) is too long and exceeds limit of 32768
Processed prompts:  56%|█████▌    | 278/500 [01:58<01:21,  2.71it/s, est. speed input: 79000.79 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:46 scheduler.py:944] Input prompt (34400 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:46 scheduler.py:944] Input prompt (33130 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:46 scheduler.py:944] Input prompt (33264 tokens) is too long and exceeds limit of 32768
Processed prompts:  57%|█████▋    | 285/500 [02:00<01:12,  2.97it/s, est. speed input: 79657.48 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:48 scheduler.py:944] Input prompt (33250 tokens) is too long and exceeds limit of 32768
Processed prompts:  59%|█████▉    | 294/500 [02:01<00:56,  3.67it/s, est. speed input: 81102.56 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:49 scheduler.py:944] Input prompt (33822 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:49 scheduler.py:944] Input prompt (33836 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:49 scheduler.py:944] Input prompt (33325 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:49 scheduler.py:944] Input prompt (33451 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:49 scheduler.py:944] Input prompt (34179 tokens) is too long and exceeds limit of 32768
Processed prompts:  59%|█████▉    | 297/500 [02:02<00:56,  3.60it/s, est. speed input: 81310.97 toks/s, output: 0.00 toks/s]Processed prompts:  60%|█████▉    | 298/500 [02:04<01:15,  2.67it/s, est. speed input: 80520.15 toks/s, output: 0.00 toks/s]WARNING 04-07 09:54:52 scheduler.py:944] Input prompt (33897 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33611 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33222 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33425 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33275 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33617 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (34041 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (33339 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:54:54 scheduler.py:944] Input prompt (34262 tokens) is too long and exceeds limit of 32768
Processed prompts:  61%|██████    | 303/500 [02:07<01:29,  2.20it/s, est. speed input: 79914.32 toks/s, output: 0.00 toks/s]Processed prompts:  61%|██████    | 304/500 [02:07<01:23,  2.35it/s, est. speed input: 80098.98 toks/s, output: 0.00 toks/s]Processed prompts:  63%|██████▎   | 313/500 [02:08<00:41,  4.54it/s, est. speed input: 82037.38 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [02:08<00:00,  3.90it/s, est. speed input: 96600.47 toks/s, output: 2.94 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:54:55 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2627859)[0;0m INFO 04-07 09:54:55 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2627861)[0;0m INFO 04-07 09:54:55 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2627860)[0;0m INFO 04-07 09:54:55 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 09:55:14.665614898 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 09:55:34 config.py:510] This model supports multiple tasks: {'classify', 'score', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 04-07 09:55:34 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 09:55:34 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 09:55:35 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 09:55:35 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 09:55:36 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:36 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:36 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:36 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:36 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:36 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:36 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:37 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 09:55:37 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:37 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:37 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:37 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 09:55:37 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:37 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:37 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2630594)[0;0m WARNING 04-07 09:55:37 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 09:55:37 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2630595)[0;0m WARNING 04-07 09:55:37 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2630596)[0;0m WARNING 04-07 09:55:37 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 09:55:37 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_d4fedccc'), local_subscribe_port=60869, remote_subscribe_port=None)
INFO 04-07 09:55:38 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:38 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:38 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:38 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.56it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.68it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.50it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.56it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.56it/s]

[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:39 model_runner.py:1099] Loading model weights took 3.5546 GB
INFO 04-07 09:55:39 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:40 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:40 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:44 worker.py:241] Memory profiling takes 4.13 seconds
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:44 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:55:44 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:44 worker.py:241] Memory profiling takes 4.21 seconds
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:44 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:55:44 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
INFO 04-07 09:55:44 worker.py:241] Memory profiling takes 4.26 seconds
INFO 04-07 09:55:44 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 09:55:44 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:44 worker.py:241] Memory profiling takes 4.30 seconds
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:44 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:55:44 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
INFO 04-07 09:55:45 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 09:55:45 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:56:08 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:56:08 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 09:56:08 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:56:08 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:17,  1.68it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:37,  1.32it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:42,  1.25it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:03<01:38,  1.28it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:36,  1.30it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:38,  1.28it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:40,  1.23it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:06<01:38,  1.25it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:07<01:35,  1.27it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:39,  1.21it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:08<01:43,  1.16it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:09<01:38,  1.20it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:10<01:41,  1.16it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:11<01:36,  1.21it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:12<01:33,  1.24it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:12<01:34,  1.21it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:13<01:37,  1.17it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:14<01:34,  1.20it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:15<01:37,  1.15it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:16<01:39,  1.12it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:17<01:33,  1.18it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:18<01:35,  1.14it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:19<01:35,  1.13it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:19<01:30,  1.18it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:20<01:29,  1.19it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:21<01:30,  1.16it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:22<01:26,  1.21it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:23<01:26,  1.19it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:24<01:24,  1.20it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:25<01:26,  1.17it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:25<01:21,  1.22it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:26<01:19,  1.24it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:27<01:20,  1.21it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:28<01:18,  1.23it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:28<01:16,  1.25it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:29<01:22,  1.16it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:30<01:18,  1.20it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:31<01:18,  1.19it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:32<01:16,  1.21it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:33<01:19,  1.15it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:34<01:15,  1.19it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:35<01:17,  1.15it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:35<01:17,  1.14it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:36<01:12,  1.19it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:37<01:10,  1.22it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:38<01:08,  1.23it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:38<01:05,  1.28it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:39<01:05,  1.26it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:40<01:06,  1.24it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:41<01:03,  1.27it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:42<01:03,  1.26it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:42<01:03,  1.25it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:43<01:05,  1.19it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:44<01:02,  1.23it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:45<01:01,  1.24it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:46<01:02,  1.20it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:47<01:01,  1.21it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:47<00:58,  1.26it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:48<00:58,  1.24it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:49<01:01,  1.16it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:50<00:58,  1.20it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:51<00:58,  1.17it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:52<00:59,  1.15it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:53<00:56,  1.19it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:53<00:55,  1.18it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:54<00:52,  1.23it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:55<00:51,  1.24it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:56<00:49,  1.27it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:57<00:49,  1.25it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:57<00:47,  1.29it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:58<00:44,  1.35it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:59<00:43,  1.37it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:59<00:44,  1.31it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [01:00<00:43,  1.30it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [01:01<00:41,  1.34it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [01:02<00:40,  1.35it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [01:02<00:41,  1.30it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [01:03<00:41,  1.28it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:04<00:39,  1.33it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:05<00:38,  1.31it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:06<00:39,  1.25it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:06<00:39,  1.25it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:07<00:37,  1.29it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:08<00:35,  1.31it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:09<00:36,  1.25it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:10<00:35,  1.28it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:10<00:33,  1.33it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:11<00:33,  1.28it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:12<00:34,  1.23it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:13<00:31,  1.29it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:13<00:31,  1.28it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:14<00:29,  1.30it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:15<00:28,  1.35it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:16<00:27,  1.36it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:16<00:26,  1.36it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:17<00:26,  1.32it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:18<00:24,  1.37it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:18<00:23,  1.41it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:19<00:22,  1.41it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:20<00:22,  1.37it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:21<00:21,  1.42it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:21<00:20,  1.43it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:22<00:20,  1.38it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:23<00:19,  1.40it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:23<00:18,  1.43it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:24<00:17,  1.39it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:25<00:17,  1.40it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:26<00:16,  1.42it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:26<00:15,  1.45it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:27<00:14,  1.49it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:27<00:13,  1.48it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:28<00:13,  1.45it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:29<00:13,  1.36it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:30<00:11,  1.42it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:30<00:10,  1.46it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:31<00:10,  1.38it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:32<00:09,  1.41it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:32<00:08,  1.46it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:33<00:08,  1.43it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:34<00:07,  1.42it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:35<00:07,  1.41it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:35<00:06,  1.45it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:36<00:05,  1.45it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:37<00:04,  1.43it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:37<00:04,  1.43it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:38<00:03,  1.46it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:39<00:02,  1.44it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:39<00:02,  1.43it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:40<00:01,  1.46it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:41<00:00,  1.50it/s][1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:57:50 model_runner.py:1535] Graph capturing finished in 102 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:42<00:00,  1.29it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:42<00:00,  1.28it/s]
INFO 04-07 09:57:50 model_runner.py:1535] Graph capturing finished in 102 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:57:50 model_runner.py:1535] Graph capturing finished in 102 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:57:50 model_runner.py:1535] Graph capturing finished in 103 secs, took 3.72 GiB
INFO 04-07 09:57:50 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 130.35 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:01, 419.50 examples/s]Generating train split: 500 examples [00:01, 418.38 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: substructure
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 09:58:49 scheduler.py:944] Input prompt (33677 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:49 scheduler.py:944] Input prompt (33200 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:38<5:18:17, 38.27s/it, est. speed input: 879.93 toks/s, output: 0.00 toks/s]WARNING 04-07 09:58:55 scheduler.py:944] Input prompt (33510 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:55 scheduler.py:944] Input prompt (33415 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:55 scheduler.py:944] Input prompt (33511 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:55 scheduler.py:944] Input prompt (34066 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:57 scheduler.py:944] Input prompt (33529 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [00:44<1:39:55, 12.06s/it, est. speed input: 2278.76 toks/s, output: 0.00 toks/s]WARNING 04-07 09:58:59 scheduler.py:944] Input prompt (33238 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:58:59 scheduler.py:944] Input prompt (33371 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|▏         | 7/500 [00:46<34:46,  4.23s/it, est. speed input: 5086.49 toks/s, output: 0.00 toks/s]  Processed prompts:   2%|▏         | 8/500 [00:47<30:21,  3.70s/it, est. speed input: 5621.92 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:05 scheduler.py:944] Input prompt (33239 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:08 scheduler.py:944] Input prompt (33412 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:08 scheduler.py:944] Input prompt (33671 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 10/500 [00:54<28:50,  3.53s/it, est. speed input: 6181.99 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:09 scheduler.py:944] Input prompt (33631 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:09 scheduler.py:944] Input prompt (33746 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:09 scheduler.py:944] Input prompt (33321 tokens) is too long and exceeds limit of 32768
Processed prompts:   2%|▏         | 11/500 [00:56<26:12,  3.21s/it, est. speed input: 6559.70 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 13/500 [00:58<19:58,  2.46s/it, est. speed input: 7448.76 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33748 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33204 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33426 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33296 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33769 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33598 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33461 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33818 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33554 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33409 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33581 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:15 scheduler.py:944] Input prompt (33345 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:17 scheduler.py:944] Input prompt (33550 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:17 scheduler.py:944] Input prompt (34240 tokens) is too long and exceeds limit of 32768
Processed prompts:   3%|▎         | 16/500 [01:04<17:48,  2.21s/it, est. speed input: 8363.96 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33245 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33293 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33226 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33740 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (34104 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33657 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33699 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33200 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33631 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33617 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33560 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33270 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33299 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33413 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33569 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33677 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33449 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33232 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33570 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (34401 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33433 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33385 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33302 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33684 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33693 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33364 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33542 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33682 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33831 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33623 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33541 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33377 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33424 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33269 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33597 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33704 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33531 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33470 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:19 scheduler.py:944] Input prompt (33480 tokens) is too long and exceeds limit of 32768
Processed prompts:   6%|▌         | 28/500 [01:06<05:53,  1.33it/s, est. speed input: 14182.41 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33360 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33197 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33577 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33411 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33218 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33393 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33846 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33204 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33739 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33935 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33403 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33209 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33278 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33209 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33395 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33284 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33663 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33726 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33524 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33312 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33588 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33951 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33843 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33201 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33325 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33959 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33280 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33363 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33379 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33887 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33467 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33622 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33596 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33262 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (34016 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33902 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33986 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33541 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33491 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33404 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:21 scheduler.py:944] Input prompt (33194 tokens) is too long and exceeds limit of 32768
Processed prompts:   6%|▌         | 30/500 [01:08<06:25,  1.22it/s, est. speed input: 14653.06 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33675 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33438 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33207 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33447 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33090 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33217 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33402 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33783 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33523 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33517 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (34258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33553 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33387 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33806 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33623 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33789 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33415 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33504 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33321 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33305 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33617 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:23 scheduler.py:944] Input prompt (33204 tokens) is too long and exceeds limit of 32768
Processed prompts:  14%|█▍        | 72/500 [01:09<01:15,  5.70it/s, est. speed input: 34580.74 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:25 scheduler.py:944] Input prompt (33850 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:25 scheduler.py:944] Input prompt (33191 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:25 scheduler.py:944] Input prompt (33233 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:25 scheduler.py:944] Input prompt (33660 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:25 scheduler.py:944] Input prompt (33356 tokens) is too long and exceeds limit of 32768
Processed prompts:  23%|██▎       | 116/500 [01:12<00:41,  9.22it/s, est. speed input: 53887.87 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33548 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (34117 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33760 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (34512 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (34118 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33750 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33322 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33519 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33325 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33174 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33314 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33526 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33173 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33784 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33448 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33563 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33742 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:27 scheduler.py:944] Input prompt (33277 tokens) is too long and exceeds limit of 32768
Processed prompts:  28%|██▊       | 139/500 [01:14<00:36,  9.77it/s, est. speed input: 62815.29 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33433 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (34426 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33681 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33562 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33373 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33378 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33310 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33834 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (32849 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33464 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33411 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33227 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33534 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33404 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33439 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33024 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33912 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33957 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33485 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33844 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33598 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33318 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33362 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33393 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33768 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33307 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33702 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33559 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:29 scheduler.py:944] Input prompt (33211 tokens) is too long and exceeds limit of 32768
Processed prompts:  29%|██▉       | 144/500 [01:15<00:41,  8.58it/s, est. speed input: 63889.92 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33225 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33480 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33198 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (34023 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33427 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33183 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33341 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33625 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33546 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:30 scheduler.py:944] Input prompt (33205 tokens) is too long and exceeds limit of 32768
Processed prompts:  32%|███▏      | 162/500 [01:17<00:37,  9.00it/s, est. speed input: 70250.73 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (34019 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33410 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33867 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33371 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33425 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33300 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (34015 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33236 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33211 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33175 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33386 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33817 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33463 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33375 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:32 scheduler.py:944] Input prompt (33158 tokens) is too long and exceeds limit of 32768
Processed prompts:  39%|███▉      | 195/500 [01:19<00:27, 10.91it/s, est. speed input: 82195.95 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33742 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33715 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33181 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33393 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33265 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33546 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33582 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33876 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33784 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33661 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33460 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33672 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33304 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33804 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33371 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33311 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33215 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33435 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33176 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33496 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33321 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33384 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33472 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33574 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33370 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33354 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:34 scheduler.py:944] Input prompt (33509 tokens) is too long and exceeds limit of 32768
Processed prompts:  41%|████      | 206/500 [01:21<00:32,  9.14it/s, est. speed input: 84553.27 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33449 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33815 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33815 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33552 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33839 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33349 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33587 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33364 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (34459 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33479 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33865 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33468 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33528 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33345 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33299 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33529 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33429 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:36 scheduler.py:944] Input prompt (33335 tokens) is too long and exceeds limit of 32768
Processed prompts:  44%|████▍     | 222/500 [01:23<00:32,  8.65it/s, est. speed input: 88799.98 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33343 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33813 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33721 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33258 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33199 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33351 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33242 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33184 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33442 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33311 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33607 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33498 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33521 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33536 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33496 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33324 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33256 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33441 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33320 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33446 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33559 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:39 scheduler.py:944] Input prompt (33202 tokens) is too long and exceeds limit of 32768
Processed prompts:  50%|█████     | 251/500 [01:25<00:22, 11.04it/s, est. speed input: 98543.09 toks/s, output: 0.00 toks/s]Processed prompts:  54%|█████▍    | 270/500 [01:27<00:20, 11.11it/s, est. speed input: 103965.24 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33718 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33530 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33448 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33489 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33698 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33246 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (34332 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33193 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33929 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33528 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:42 scheduler.py:944] Input prompt (33405 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:44 scheduler.py:944] Input prompt (33206 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:44 scheduler.py:944] Input prompt (33483 tokens) is too long and exceeds limit of 32768
Processed prompts:  59%|█████▊    | 293/500 [01:30<00:21,  9.60it/s, est. speed input: 108944.61 toks/s, output: 0.00 toks/s]WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33269 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33157 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33187 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33153 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33510 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33210 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33430 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33494 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33437 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33670 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33271 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33618 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33209 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33434 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33603 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33352 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33436 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33537 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (34004 tokens) is too long and exceeds limit of 32768
WARNING 04-07 09:59:45 scheduler.py:944] Input prompt (33936 tokens) is too long and exceeds limit of 32768
Processed prompts:  61%|██████    | 304/500 [01:32<00:22,  8.55it/s, est. speed input: 110673.97 toks/s, output: 0.00 toks/s]Processed prompts:  61%|██████    | 306/500 [01:32<00:22,  8.75it/s, est. speed input: 111261.40 toks/s, output: 0.00 toks/s]Processed prompts:  66%|██████▌   | 329/500 [01:32<00:12, 14.13it/s, est. speed input: 118997.09 toks/s, output: 0.02 toks/s]Processed prompts: 100%|██████████| 500/500 [01:32<00:00,  5.41it/s, est. speed input: 133734.58 toks/s, output: 3.72 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 09:59:47 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2630594)[0;0m INFO 04-07 09:59:47 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2630595)[0;0m INFO 04-07 09:59:47 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2630596)[0;0m INFO 04-07 09:59:47 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 10:00:07.897289751 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 10:00:26 config.py:510] This model supports multiple tasks: {'reward', 'classify', 'score', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 04-07 10:00:26 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 10:00:26 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 10:00:26 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 10:00:26 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 10:00:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:28 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:28 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 10:00:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:29 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:29 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 10:00:29 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:29 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:29 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:29 pynccl.py:69] vLLM is using nccl==2.21.5
WARNING 04-07 10:00:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2633104)[0;0m WARNING 04-07 10:00:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2633102)[0;0m WARNING 04-07 10:00:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2633103)[0;0m WARNING 04-07 10:00:29 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 10:00:29 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5a0c8394'), local_subscribe_port=43513, remote_subscribe_port=None)
INFO 04-07 10:00:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:29 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.62it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.74it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.56it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.64it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.64it/s]

INFO 04-07 10:00:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:31 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:36 worker.py:241] Memory profiling takes 4.12 seconds
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:36 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:36 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:36 worker.py:241] Memory profiling takes 4.15 seconds
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:36 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:36 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:36 worker.py:241] Memory profiling takes 4.16 seconds
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:36 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:36 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
INFO 04-07 10:00:36 worker.py:241] Memory profiling takes 4.25 seconds
INFO 04-07 10:00:36 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 10:00:36 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 10:00:36 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 10:00:36 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:00:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 10:00:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:00:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:00:59 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:20,  1.62it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:46,  1.21it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:43,  1.23it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:03<01:43,  1.23it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:40,  1.25it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:39,  1.25it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:36,  1.29it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:06<01:34,  1.31it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:07<01:35,  1.27it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:34,  1.28it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:08<01:35,  1.25it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:09<01:34,  1.26it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:10<01:32,  1.27it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:11<01:32,  1.27it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:11<01:30,  1.28it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:12<01:27,  1.31it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:13<01:30,  1.26it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:14<01:30,  1.25it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:15<01:30,  1.24it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:15<01:28,  1.26it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:16<01:28,  1.24it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:17<01:26,  1.25it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:18<01:28,  1.22it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:19<01:25,  1.25it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:19<01:24,  1.26it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:20<01:23,  1.25it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:21<01:24,  1.23it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:22<01:23,  1.24it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:23<01:21,  1.25it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:23<01:22,  1.23it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:24<01:19,  1.26it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:25<01:17,  1.28it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:26<01:16,  1.27it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:26<01:16,  1.26it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:27<01:14,  1.29it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:28<01:13,  1.29it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:29<01:12,  1.30it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:29<01:10,  1.33it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:30<01:10,  1.31it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:31<01:08,  1.33it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:32<01:08,  1.31it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:33<01:07,  1.32it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:33<01:06,  1.33it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:34<01:06,  1.31it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:35<01:03,  1.35it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:35<01:03,  1.35it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:36<01:02,  1.34it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:37<01:03,  1.30it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:38<01:01,  1.34it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:38<01:00,  1.34it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:39<01:00,  1.33it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:40<00:58,  1.35it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:41<00:56,  1.38it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:41<00:57,  1.33it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:42<00:57,  1.33it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:43<00:57,  1.31it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:44<00:56,  1.32it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:45<00:54,  1.33it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:45<00:52,  1.36it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:46<00:51,  1.37it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:47<00:52,  1.34it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:47<00:51,  1.34it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:48<00:49,  1.38it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:49<00:48,  1.39it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:50<00:47,  1.39it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:50<00:47,  1.38it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:51<00:45,  1.41it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:52<00:44,  1.43it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:52<00:43,  1.42it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:53<00:44,  1.39it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:54<00:44,  1.35it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:55<00:44,  1.34it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:55<00:43,  1.34it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:56<00:41,  1.38it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:57<00:39,  1.41it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:57<00:39,  1.40it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:58<00:38,  1.41it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:59<00:39,  1.36it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [01:00<00:38,  1.36it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [01:00<00:37,  1.37it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [01:01<00:36,  1.36it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [01:02<00:36,  1.33it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [01:03<00:34,  1.41it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [01:03<00:33,  1.40it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [01:04<00:32,  1.40it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [01:05<00:31,  1.44it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [01:05<00:30,  1.44it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [01:06<00:30,  1.39it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [01:07<00:30,  1.36it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [01:08<00:29,  1.39it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [01:08<00:27,  1.45it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:09<00:28,  1.39it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:10<00:27,  1.37it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:10<00:25,  1.43it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:11<00:25,  1.42it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:12<00:24,  1.42it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:13<00:24,  1.40it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:13<00:23,  1.43it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:14<00:22,  1.42it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:15<00:22,  1.40it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:15<00:21,  1.39it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:16<00:20,  1.40it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:17<00:20,  1.38it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:18<00:19,  1.38it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:18<00:18,  1.43it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:19<00:17,  1.44it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:20<00:16,  1.44it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:20<00:15,  1.47it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:21<00:15,  1.44it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:22<00:14,  1.45it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:22<00:13,  1.47it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:23<00:13,  1.44it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:24<00:12,  1.44it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:24<00:11,  1.45it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:25<00:10,  1.47it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:26<00:09,  1.51it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:26<00:09,  1.48it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:27<00:08,  1.46it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:28<00:08,  1.44it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:29<00:07,  1.44it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:29<00:06,  1.43it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:30<00:06,  1.44it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:31<00:05,  1.47it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:31<00:04,  1.45it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:32<00:04,  1.44it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:33<00:03,  1.48it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:33<00:02,  1.49it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:34<00:02,  1.49it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:35<00:01,  1.50it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:35<00:00,  1.52it/s][1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:02:36 model_runner.py:1535] Graph capturing finished in 97 secs, took 3.72 GiB
Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:36<00:00,  1.34it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:36<00:00,  1.36it/s]
INFO 04-07 10:02:36 model_runner.py:1535] Graph capturing finished in 97 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:02:36 model_runner.py:1535] Graph capturing finished in 97 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:02:36 model_runner.py:1535] Graph capturing finished in 97 secs, took 3.72 GiB
INFO 04-07 10:02:36 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 124.55 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:01, 347.41 examples/s]Generating train split: 500 examples [00:01, 346.23 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: topology
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:41 scheduler.py:944] Input prompt (34077 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:41 scheduler.py:944] Input prompt (33142 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [00:35<4:57:07, 35.73s/it, est. speed input: 953.83 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:44 scheduler.py:944] Input prompt (33426 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:44 scheduler.py:944] Input prompt (33312 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:44 scheduler.py:944] Input prompt (34022 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [00:39<1:27:42, 10.59s/it, est. speed input: 2560.34 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33809 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33595 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33962 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33363 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33700 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (34747 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (34689 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33265 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33474 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33432 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33380 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33340 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33630 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (34463 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33296 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (34690 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33149 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33455 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:47 scheduler.py:944] Input prompt (33572 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34929 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33586 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34835 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34687 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33547 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33144 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34465 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34755 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33559 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33411 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34169 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33457 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33514 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33331 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33448 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33154 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33208 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33315 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33871 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33892 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33978 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34221 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33547 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33634 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33390 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34159 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33418 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34308 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34626 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34180 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34516 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34450 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34611 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33700 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33505 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34754 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34041 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33167 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33940 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33136 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33566 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34496 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33414 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33454 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34711 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33157 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33292 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34219 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34546 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33389 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33149 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34084 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33436 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34565 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33201 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33983 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (34616 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33692 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33740 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33674 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:50 scheduler.py:944] Input prompt (33389 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 6/500 [00:43<41:25,  5.03s/it, est. speed input: 4597.08 toks/s, output: 0.00 toks/s]  WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34751 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33446 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33545 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33390 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34725 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33145 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33444 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33153 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33155 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34180 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33686 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33715 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33153 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33640 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34130 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33375 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33392 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33699 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33303 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33153 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33172 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34487 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34024 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33539 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34382 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33866 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33437 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33977 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33214 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34139 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33145 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34655 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33401 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33148 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33625 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33280 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34330 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33216 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33148 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (35150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33600 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34365 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34711 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33670 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34522 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33537 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33154 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33160 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34880 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33429 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33142 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34253 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34673 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33402 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33704 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33661 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33130 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33793 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34206 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34827 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33640 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33133 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33785 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34735 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33523 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33538 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33287 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33300 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34774 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34102 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34658 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33593 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33512 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33333 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33601 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34382 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34743 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34114 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33704 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33322 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34761 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33227 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33604 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34237 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34505 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33394 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33311 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33125 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33327 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33410 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34441 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33512 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33576 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33277 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33157 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34422 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34790 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33365 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34196 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33356 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34063 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34309 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33183 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34071 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33348 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33605 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33370 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33281 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33289 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33290 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34590 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33943 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33201 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33358 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33218 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34122 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34257 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33242 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34380 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34616 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33291 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33306 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33401 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33976 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33855 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33487 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33527 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33151 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33978 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (34767 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33549 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:52 scheduler.py:944] Input prompt (33605 tokens) is too long and exceeds limit of 32768
Processed prompts:   6%|▌         | 28/500 [00:45<05:55,  1.33it/s, est. speed input: 20605.03 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33435 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33611 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (34367 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33412 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33333 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (34478 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33325 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33429 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33318 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:54 scheduler.py:944] Input prompt (33376 tokens) is too long and exceeds limit of 32768
Processed prompts:  19%|█▉        | 95/500 [00:47<01:12,  5.59it/s, est. speed input: 67421.96 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33291 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33372 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33339 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33152 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33414 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33385 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33340 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33976 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33293 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33297 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33344 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33310 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34649 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33143 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33702 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33579 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33824 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34582 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33646 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33712 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34649 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34771 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34716 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33792 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33296 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34616 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34214 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33360 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34449 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33421 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (33283 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34045 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:56 scheduler.py:944] Input prompt (34148 tokens) is too long and exceeds limit of 32768
Processed prompts:  49%|████▉     | 245/500 [00:49<00:15, 16.27it/s, est. speed input: 165857.16 toks/s, output: 0.00 toks/s]WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34271 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34255 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33622 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33355 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33675 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33146 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33391 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34953 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33570 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33879 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33192 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33691 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34653 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33387 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33388 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33335 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34513 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33707 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34544 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33811 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34421 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33388 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33407 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33272 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33384 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34335 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33476 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34466 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33488 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33321 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33920 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33207 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34705 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (34595 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33293 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33544 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:03:58 scheduler.py:944] Input prompt (33322 tokens) is too long and exceeds limit of 32768
Processed prompts:  51%|█████     | 255/500 [00:52<00:17, 13.73it/s, est. speed input: 164684.95 toks/s, output: 0.00 toks/s]WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (33711 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (34618 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (34008 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (34464 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (33862 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (33389 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (33451 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (34655 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:00 scheduler.py:944] Input prompt (33628 tokens) is too long and exceeds limit of 32768
Processed prompts:  58%|█████▊    | 288/500 [00:54<00:14, 14.30it/s, est. speed input: 179205.93 toks/s, output: 0.00 toks/s]WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33433 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33380 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34206 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33837 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33398 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33574 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33300 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34121 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34584 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33131 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33739 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33568 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33381 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33446 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34179 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33227 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33638 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33828 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33776 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33578 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34454 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33458 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34373 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34779 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33938 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33301 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34685 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33415 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33419 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34538 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34420 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33314 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33694 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33526 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33820 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33638 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33349 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33368 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33561 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33355 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33350 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34146 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33625 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34317 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34733 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33557 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33354 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33993 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33150 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34005 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33186 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (35539 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (34262 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:02 scheduler.py:944] Input prompt (33808 tokens) is too long and exceeds limit of 32768
Processed prompts:  65%|██████▌   | 327/500 [00:56<00:11, 14.83it/s, est. speed input: 194946.36 toks/s, output: 0.00 toks/s]WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33260 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33491 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (35006 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33322 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33723 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33316 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (33148 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (34131 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:05 scheduler.py:944] Input prompt (34398 tokens) is too long and exceeds limit of 32768
Processed prompts:  67%|██████▋   | 336/500 [00:58<00:13, 12.57it/s, est. speed input: 193861.04 toks/s, output: 0.00 toks/s]WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (34773 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33328 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33521 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33912 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (34067 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33209 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33288 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (32966 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33596 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33896 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33417 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33513 tokens) is too long and exceeds limit of 32768
WARNING 04-07 10:04:07 scheduler.py:944] Input prompt (33825 tokens) is too long and exceeds limit of 32768
Processed prompts:  78%|███████▊  | 390/500 [00:59<00:06, 17.75it/s, est. speed input: 220095.29 toks/s, output: 0.00 toks/s]Processed prompts:  82%|████████▏ | 412/500 [01:00<00:04, 21.01it/s, est. speed input: 231136.82 toks/s, output: 0.03 toks/s]Processed prompts: 100%|██████████| 500/500 [01:00<00:00, 42.77it/s, est. speed input: 244812.58 toks/s, output: 3.04 toks/s]Processed prompts: 100%|██████████| 500/500 [01:00<00:00,  8.30it/s, est. speed input: 244812.58 toks/s, output: 3.04 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 10:04:08 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2633104)[0;0m INFO 04-07 10:04:08 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2633103)[0;0m INFO 04-07 10:04:08 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2633102)[0;0m INFO 04-07 10:04:08 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 10:04:29.836420674 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
INFO 04-07 10:04:48 config.py:510] This model supports multiple tasks: {'reward', 'score', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 04-07 10:04:48 config.py:1310] Defaulting to use mp for distributed inference
INFO 04-07 10:04:48 llm_engine.py:234] Initializing an LLM engine (v0.6.6) with config: model='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', speculative_config=None, tokenizer='/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[1024,1016,1008,1000,992,984,976,968,960,952,944,936,928,920,912,904,896,888,880,872,864,856,848,840,832,824,816,808,800,792,784,776,768,760,752,744,736,728,720,712,704,696,688,680,672,664,656,648,640,632,624,616,608,600,592,584,576,568,560,552,544,536,528,520,512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":1024}, use_cached_outputs=False, 
WARNING 04-07 10:04:49 multiproc_worker_utils.py:312] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 04-07 10:04:49 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 04-07 10:04:50 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:50 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:50 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:50 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:50 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:50 selector.py:120] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:50 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
INFO 04-07 10:04:51 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:51 utils.py:918] Found nccl from library libnccl.so.2
INFO 04-07 10:04:51 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:51 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:51 utils.py:918] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:51 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:51 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:51 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2644956)[0;0m WARNING 04-07 10:04:51 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2644955)[0;0m WARNING 04-07 10:04:51 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=2644954)[0;0m WARNING 04-07 10:04:51 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 04-07 10:04:51 custom_all_reduce.py:134] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 04-07 10:04:51 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_e2eed72a'), local_subscribe_port=59551, remote_subscribe_port=None)
INFO 04-07 10:04:51 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:51 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:51 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:51 model_runner.py:1094] Starting to load model /home/zch/Code/model/Qwen2.5-7B/Qwen/Qwen2___5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.49it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.61it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.38it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.43it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.44it/s]

INFO 04-07 10:04:53 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:53 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:53 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:53 model_runner.py:1099] Loading model weights took 3.5546 GB
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:57 worker.py:241] Memory profiling takes 4.06 seconds
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:57 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:04:57 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:57 worker.py:241] Memory profiling takes 4.07 seconds
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:57 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:04:57 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.64GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.86GiB.
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:58 worker.py:241] Memory profiling takes 4.13 seconds
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:58 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:04:58 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.57GiB; PyTorch activation peak memory takes 1.97GiB; the rest of the memory reserved for KV Cache is 31.94GiB.
INFO 04-07 10:04:58 worker.py:241] Memory profiling takes 4.19 seconds
INFO 04-07 10:04:58 worker.py:241] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.80) = 38.03GiB
INFO 04-07 10:04:58 worker.py:241] model weights take 3.55GiB; non_torch_memory takes 0.68GiB; PyTorch activation peak memory takes 5.74GiB; the rest of the memory reserved for KV Cache is 28.05GiB.
INFO 04-07 10:04:58 distributed_gpu_executor.py:57] # GPU blocks: 131317, # CPU blocks: 74898
INFO 04-07 10:04:58 distributed_gpu_executor.py:61] Maximum concurrency for 32768 tokens per request: 64.12x
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:05:21 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-07 10:05:21 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:05:21 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/131 [00:00<?, ?it/s][1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:05:21 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   1%|          | 1/131 [00:00<01:16,  1.71it/s]Capturing CUDA graph shapes:   2%|▏         | 2/131 [00:01<01:22,  1.56it/s]Capturing CUDA graph shapes:   2%|▏         | 3/131 [00:02<01:30,  1.42it/s]Capturing CUDA graph shapes:   3%|▎         | 4/131 [00:02<01:32,  1.37it/s]Capturing CUDA graph shapes:   4%|▍         | 5/131 [00:03<01:31,  1.38it/s]Capturing CUDA graph shapes:   5%|▍         | 6/131 [00:04<01:30,  1.38it/s]Capturing CUDA graph shapes:   5%|▌         | 7/131 [00:05<01:31,  1.36it/s]Capturing CUDA graph shapes:   6%|▌         | 8/131 [00:05<01:28,  1.38it/s]Capturing CUDA graph shapes:   7%|▋         | 9/131 [00:06<01:25,  1.43it/s]Capturing CUDA graph shapes:   8%|▊         | 10/131 [00:07<01:24,  1.44it/s]Capturing CUDA graph shapes:   8%|▊         | 11/131 [00:07<01:25,  1.41it/s]Capturing CUDA graph shapes:   9%|▉         | 12/131 [00:08<01:26,  1.38it/s]Capturing CUDA graph shapes:  10%|▉         | 13/131 [00:09<01:22,  1.42it/s]Capturing CUDA graph shapes:  11%|█         | 14/131 [00:09<01:22,  1.43it/s]Capturing CUDA graph shapes:  11%|█▏        | 15/131 [00:10<01:21,  1.42it/s]Capturing CUDA graph shapes:  12%|█▏        | 16/131 [00:11<01:21,  1.42it/s]Capturing CUDA graph shapes:  13%|█▎        | 17/131 [00:11<01:18,  1.45it/s]Capturing CUDA graph shapes:  14%|█▎        | 18/131 [00:12<01:18,  1.43it/s]Capturing CUDA graph shapes:  15%|█▍        | 19/131 [00:13<01:21,  1.38it/s]Capturing CUDA graph shapes:  15%|█▌        | 20/131 [00:14<01:18,  1.42it/s]Capturing CUDA graph shapes:  16%|█▌        | 21/131 [00:14<01:17,  1.42it/s]Capturing CUDA graph shapes:  17%|█▋        | 22/131 [00:15<01:18,  1.39it/s]Capturing CUDA graph shapes:  18%|█▊        | 23/131 [00:16<01:17,  1.39it/s]Capturing CUDA graph shapes:  18%|█▊        | 24/131 [00:16<01:14,  1.43it/s]Capturing CUDA graph shapes:  19%|█▉        | 25/131 [00:17<01:13,  1.45it/s]Capturing CUDA graph shapes:  20%|█▉        | 26/131 [00:18<01:12,  1.45it/s]Capturing CUDA graph shapes:  21%|██        | 27/131 [00:19<01:12,  1.43it/s]Capturing CUDA graph shapes:  21%|██▏       | 28/131 [00:19<01:10,  1.45it/s]Capturing CUDA graph shapes:  22%|██▏       | 29/131 [00:20<01:09,  1.47it/s]Capturing CUDA graph shapes:  23%|██▎       | 30/131 [00:21<01:09,  1.45it/s]Capturing CUDA graph shapes:  24%|██▎       | 31/131 [00:21<01:10,  1.42it/s]Capturing CUDA graph shapes:  24%|██▍       | 32/131 [00:22<01:09,  1.43it/s]Capturing CUDA graph shapes:  25%|██▌       | 33/131 [00:23<01:06,  1.47it/s]Capturing CUDA graph shapes:  26%|██▌       | 34/131 [00:23<01:05,  1.47it/s]Capturing CUDA graph shapes:  27%|██▋       | 35/131 [00:24<01:06,  1.45it/s]Capturing CUDA graph shapes:  27%|██▋       | 36/131 [00:25<01:03,  1.50it/s]Capturing CUDA graph shapes:  28%|██▊       | 37/131 [00:25<01:01,  1.52it/s]Capturing CUDA graph shapes:  29%|██▉       | 38/131 [00:26<01:01,  1.52it/s]Capturing CUDA graph shapes:  30%|██▉       | 39/131 [00:27<01:01,  1.50it/s]Capturing CUDA graph shapes:  31%|███       | 40/131 [00:27<00:59,  1.52it/s]Capturing CUDA graph shapes:  31%|███▏      | 41/131 [00:28<00:58,  1.54it/s]Capturing CUDA graph shapes:  32%|███▏      | 42/131 [00:29<00:58,  1.53it/s]Capturing CUDA graph shapes:  33%|███▎      | 43/131 [00:29<00:57,  1.54it/s]Capturing CUDA graph shapes:  34%|███▎      | 44/131 [00:30<00:56,  1.53it/s]Capturing CUDA graph shapes:  34%|███▍      | 45/131 [00:31<00:56,  1.53it/s]Capturing CUDA graph shapes:  35%|███▌      | 46/131 [00:31<00:54,  1.57it/s]Capturing CUDA graph shapes:  36%|███▌      | 47/131 [00:32<00:55,  1.52it/s]Capturing CUDA graph shapes:  37%|███▋      | 48/131 [00:32<00:55,  1.51it/s]Capturing CUDA graph shapes:  37%|███▋      | 49/131 [00:33<00:53,  1.55it/s]Capturing CUDA graph shapes:  38%|███▊      | 50/131 [00:34<00:51,  1.57it/s]Capturing CUDA graph shapes:  39%|███▉      | 51/131 [00:34<00:50,  1.58it/s]Capturing CUDA graph shapes:  40%|███▉      | 52/131 [00:35<00:51,  1.55it/s]Capturing CUDA graph shapes:  40%|████      | 53/131 [00:36<00:50,  1.55it/s]Capturing CUDA graph shapes:  41%|████      | 54/131 [00:36<00:48,  1.58it/s]Capturing CUDA graph shapes:  42%|████▏     | 55/131 [00:37<00:48,  1.57it/s]Capturing CUDA graph shapes:  43%|████▎     | 56/131 [00:38<00:48,  1.55it/s]Capturing CUDA graph shapes:  44%|████▎     | 57/131 [00:38<00:48,  1.53it/s]Capturing CUDA graph shapes:  44%|████▍     | 58/131 [00:39<00:46,  1.58it/s]Capturing CUDA graph shapes:  45%|████▌     | 59/131 [00:39<00:45,  1.58it/s]Capturing CUDA graph shapes:  46%|████▌     | 60/131 [00:40<00:45,  1.56it/s]Capturing CUDA graph shapes:  47%|████▋     | 61/131 [00:41<00:45,  1.55it/s]Capturing CUDA graph shapes:  47%|████▋     | 62/131 [00:41<00:44,  1.55it/s]Capturing CUDA graph shapes:  48%|████▊     | 63/131 [00:42<00:43,  1.58it/s]Capturing CUDA graph shapes:  49%|████▉     | 64/131 [00:43<00:43,  1.56it/s]Capturing CUDA graph shapes:  50%|████▉     | 65/131 [00:43<00:42,  1.54it/s]Capturing CUDA graph shapes:  50%|█████     | 66/131 [00:44<00:42,  1.55it/s]Capturing CUDA graph shapes:  51%|█████     | 67/131 [00:45<00:40,  1.58it/s]Capturing CUDA graph shapes:  52%|█████▏    | 68/131 [00:45<00:39,  1.59it/s]Capturing CUDA graph shapes:  53%|█████▎    | 69/131 [00:46<00:39,  1.57it/s]Capturing CUDA graph shapes:  53%|█████▎    | 70/131 [00:47<00:39,  1.55it/s]Capturing CUDA graph shapes:  54%|█████▍    | 71/131 [00:47<00:37,  1.59it/s]Capturing CUDA graph shapes:  55%|█████▍    | 72/131 [00:48<00:36,  1.62it/s]Capturing CUDA graph shapes:  56%|█████▌    | 73/131 [00:48<00:36,  1.59it/s]Capturing CUDA graph shapes:  56%|█████▋    | 74/131 [00:49<00:36,  1.57it/s]Capturing CUDA graph shapes:  57%|█████▋    | 75/131 [00:50<00:35,  1.57it/s]Capturing CUDA graph shapes:  58%|█████▊    | 76/131 [00:50<00:34,  1.60it/s]Capturing CUDA graph shapes:  59%|█████▉    | 77/131 [00:51<00:34,  1.58it/s]Capturing CUDA graph shapes:  60%|█████▉    | 78/131 [00:52<00:33,  1.56it/s]Capturing CUDA graph shapes:  60%|██████    | 79/131 [00:52<00:32,  1.60it/s]Capturing CUDA graph shapes:  61%|██████    | 80/131 [00:53<00:30,  1.65it/s]Capturing CUDA graph shapes:  62%|██████▏   | 81/131 [00:53<00:30,  1.65it/s]Capturing CUDA graph shapes:  63%|██████▎   | 82/131 [00:54<00:30,  1.61it/s]Capturing CUDA graph shapes:  63%|██████▎   | 83/131 [00:55<00:30,  1.58it/s]Capturing CUDA graph shapes:  64%|██████▍   | 84/131 [00:55<00:28,  1.62it/s]Capturing CUDA graph shapes:  65%|██████▍   | 85/131 [00:56<00:27,  1.65it/s]Capturing CUDA graph shapes:  66%|██████▌   | 86/131 [00:56<00:27,  1.63it/s]Capturing CUDA graph shapes:  66%|██████▋   | 87/131 [00:57<00:27,  1.63it/s]Capturing CUDA graph shapes:  67%|██████▋   | 88/131 [00:58<00:26,  1.64it/s]Capturing CUDA graph shapes:  68%|██████▊   | 89/131 [00:58<00:25,  1.67it/s]Capturing CUDA graph shapes:  69%|██████▊   | 90/131 [00:59<00:24,  1.67it/s]Capturing CUDA graph shapes:  69%|██████▉   | 91/131 [00:59<00:24,  1.66it/s]Capturing CUDA graph shapes:  70%|███████   | 92/131 [01:00<00:24,  1.62it/s]Capturing CUDA graph shapes:  71%|███████   | 93/131 [01:01<00:23,  1.65it/s]Capturing CUDA graph shapes:  72%|███████▏  | 94/131 [01:01<00:22,  1.65it/s]Capturing CUDA graph shapes:  73%|███████▎  | 95/131 [01:02<00:21,  1.64it/s]Capturing CUDA graph shapes:  73%|███████▎  | 96/131 [01:03<00:21,  1.63it/s]Capturing CUDA graph shapes:  74%|███████▍  | 97/131 [01:03<00:21,  1.62it/s]Capturing CUDA graph shapes:  75%|███████▍  | 98/131 [01:04<00:19,  1.67it/s]Capturing CUDA graph shapes:  76%|███████▌  | 99/131 [01:04<00:18,  1.69it/s]Capturing CUDA graph shapes:  76%|███████▋  | 100/131 [01:05<00:18,  1.67it/s]Capturing CUDA graph shapes:  77%|███████▋  | 101/131 [01:05<00:18,  1.65it/s]Capturing CUDA graph shapes:  78%|███████▊  | 102/131 [01:06<00:17,  1.62it/s]Capturing CUDA graph shapes:  79%|███████▊  | 103/131 [01:07<00:16,  1.65it/s]Capturing CUDA graph shapes:  79%|███████▉  | 104/131 [01:07<00:16,  1.67it/s]Capturing CUDA graph shapes:  80%|████████  | 105/131 [01:08<00:15,  1.65it/s]Capturing CUDA graph shapes:  81%|████████  | 106/131 [01:09<00:15,  1.65it/s]Capturing CUDA graph shapes:  82%|████████▏ | 107/131 [01:09<00:14,  1.69it/s]Capturing CUDA graph shapes:  82%|████████▏ | 108/131 [01:10<00:13,  1.72it/s]Capturing CUDA graph shapes:  83%|████████▎ | 109/131 [01:10<00:12,  1.72it/s]Capturing CUDA graph shapes:  84%|████████▍ | 110/131 [01:11<00:12,  1.71it/s]Capturing CUDA graph shapes:  85%|████████▍ | 111/131 [01:11<00:11,  1.69it/s]Capturing CUDA graph shapes:  85%|████████▌ | 112/131 [01:12<00:11,  1.71it/s]Capturing CUDA graph shapes:  86%|████████▋ | 113/131 [01:13<00:10,  1.72it/s]Capturing CUDA graph shapes:  87%|████████▋ | 114/131 [01:13<00:09,  1.71it/s]Capturing CUDA graph shapes:  88%|████████▊ | 115/131 [01:14<00:09,  1.71it/s]Capturing CUDA graph shapes:  89%|████████▊ | 116/131 [01:14<00:08,  1.68it/s]Capturing CUDA graph shapes:  89%|████████▉ | 117/131 [01:15<00:08,  1.74it/s]Capturing CUDA graph shapes:  90%|█████████ | 118/131 [01:15<00:07,  1.76it/s]Capturing CUDA graph shapes:  91%|█████████ | 119/131 [01:16<00:07,  1.71it/s]Capturing CUDA graph shapes:  92%|█████████▏| 120/131 [01:17<00:06,  1.70it/s]Capturing CUDA graph shapes:  92%|█████████▏| 121/131 [01:17<00:05,  1.69it/s]Capturing CUDA graph shapes:  93%|█████████▎| 122/131 [01:18<00:05,  1.64it/s]Capturing CUDA graph shapes:  94%|█████████▍| 123/131 [01:18<00:04,  1.67it/s]Capturing CUDA graph shapes:  95%|█████████▍| 124/131 [01:19<00:04,  1.62it/s]Capturing CUDA graph shapes:  95%|█████████▌| 125/131 [01:20<00:03,  1.59it/s]Capturing CUDA graph shapes:  96%|█████████▌| 126/131 [01:20<00:03,  1.61it/s]Capturing CUDA graph shapes:  97%|█████████▋| 127/131 [01:21<00:02,  1.59it/s]Capturing CUDA graph shapes:  98%|█████████▊| 128/131 [01:22<00:01,  1.60it/s]Capturing CUDA graph shapes:  98%|█████████▊| 129/131 [01:22<00:01,  1.56it/s]Capturing CUDA graph shapes:  99%|█████████▉| 130/131 [01:23<00:00,  1.58it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:24<00:00,  1.40it/s]Capturing CUDA graph shapes: 100%|██████████| 131/131 [01:24<00:00,  1.55it/s]
INFO 04-07 10:06:45 model_runner.py:1535] Graph capturing finished in 84 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:06:45 model_runner.py:1535] Graph capturing finished in 84 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:06:45 model_runner.py:1535] Graph capturing finished in 84 secs, took 3.72 GiB
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:06:45 model_runner.py:1535] Graph capturing finished in 85 secs, took 3.72 GiB
INFO 04-07 10:06:45 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 112.11 seconds
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 500 examples [00:00, 3316.61 examples/s]Generating train split: 500 examples [00:00, 3311.05 examples/s]
/home/zch/Code/GraphICL/evaluation/code_GraphInstruct/qwen-32B/IclAbilityTestResults.py:128: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.
  main()
Evaluating task: triangle
Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]WARNING 04-07 10:07:51 scheduler.py:944] Input prompt (33279 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 1/500 [01:00<8:19:17, 60.04s/it, est. speed input: 554.32 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:04 scheduler.py:944] Input prompt (33277 tokens) is too long and exceeds limit of 32768
Processed prompts:   0%|          | 2/500 [01:13<4:31:42, 32.74s/it, est. speed input: 903.53 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:08 scheduler.py:944] Input prompt (33523 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 3/500 [01:17<2:41:41, 19.52s/it, est. speed input: 1292.06 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:29 scheduler.py:944] Input prompt (33274 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 4/500 [01:38<2:44:52, 19.94s/it, est. speed input: 1360.05 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:39 scheduler.py:944] Input prompt (33273 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 5/500 [01:47<2:14:09, 16.26s/it, est. speed input: 1545.97 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:42 scheduler.py:944] Input prompt (33192 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|          | 6/500 [01:51<1:39:31, 12.09s/it, est. speed input: 1787.82 toks/s, output: 0.00 toks/s]WARNING 04-07 10:08:48 scheduler.py:944] Input prompt (33278 tokens) is too long and exceeds limit of 32768
Processed prompts:   1%|▏         | 7/500 [01:57<1:21:51,  9.96s/it, est. speed input: 1986.23 toks/s, output: 0.00 toks/s]Processed prompts:   2%|▏         | 8/500 [02:14<1:40:45, 12.29s/it, est. speed input: 1749.67 toks/s, output: 0.01 toks/s]WARNING 04-07 10:09:17 scheduler.py:944] Input prompt (33261 tokens) is too long and exceeds limit of 32768
Processed prompts:  90%|████████▉ | 448/500 [02:26<00:04, 11.37it/s, est. speed input: 16474.81 toks/s, output: 6.01 toks/s]Processed prompts:  90%|█████████ | 452/500 [02:27<00:04, 11.15it/s, est. speed input: 16513.65 toks/s, output: 6.03 toks/s]Processed prompts: 100%|██████████| 500/500 [02:27<00:00,  3.39it/s, est. speed input: 17770.84 toks/s, output: 6.68 toks/s]
Accuracy data has been saved to 'task_accuracies.txt'.
INFO 04-07 10:09:22 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2644954)[0;0m INFO 04-07 10:09:22 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2644955)[0;0m INFO 04-07 10:09:22 multiproc_worker_utils.py:247] Worker exiting
[1;36m(VllmWorkerProcess pid=2644956)[0;0m INFO 04-07 10:09:22 multiproc_worker_utils.py:247] Worker exiting
[rank0]:[W407 10:09:43.916425318 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/zch/anaconda3/envs/GraphICL/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
